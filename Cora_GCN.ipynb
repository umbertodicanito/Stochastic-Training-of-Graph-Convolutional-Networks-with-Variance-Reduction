{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Cora_GCN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umbertodicanito/Stochastic-Training-of-Graph-Convolutional-Networks-with-Variance-Reduction/blob/master/Cora_GCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inaEyeyeN3mP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4C3py11yrk_",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh4yOJOUN5kV",
        "colab_type": "code",
        "outputId": "44929f9a-4934-44a5-9588-8febde084c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install dgl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/ba/d15ce7fb56958f21d4e9815f96344d92c4982f3fb933a0e987e78cb787e5/dgl-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.3.2)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.4)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.17.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl) (4.4.1)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVHZxjokN3mX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dgl\n",
        "import dgl.function as fn\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from dgl import DGLGraph\n",
        "from google.colab import files\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gcn_msg = fn.copy_src(src='h', out='m')\n",
        "gcn_reduce = fn.sum(msg='m', out='h')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_H7tdbpN3mV",
        "colab_type": "text"
      },
      "source": [
        "**Original GCN was created by:** `Qi Huang <https://github.com/HQ01>`_, `Minjie Wang  <https://jermainewang.github.io/>`_,\n",
        "Yu Gai, Quan Gan, Zheng Zhang\n",
        "\n",
        "The actual GCN is been modified but it is based on these authors work.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbLw1KjvIXxt",
        "colab_type": "text"
      },
      "source": [
        "#Building matrices for algorithm 1 execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us006QFON3ml",
        "colab_type": "code",
        "outputId": "c4cab8e8-c1d4-4aca-f54f-42e616fa623b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from dgl.data import citation_graph as citegrh\n",
        "import networkx as nx\n",
        "def load_cora_data():\n",
        "    data = citegrh.load_cora()\n",
        "    features = th.FloatTensor(data.features)\n",
        "    labels = th.LongTensor(data.labels)\n",
        "    mask = th.ByteTensor(data.train_mask)\n",
        "    g = data.graph\n",
        "    print(g)\n",
        "    # add self loop\n",
        "    g.remove_edges_from(nx.selfloop_edges(g))\n",
        "    g = DGLGraph(g)\n",
        "    g.add_edges(g.nodes(), g.nodes())\n",
        "    return g, features, labels, mask\n",
        "    \n",
        "#get data\n",
        "g, features, labels, mask = load_cora_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.dgl/cora.zip from https://s3.us-east-2.amazonaws.com/dgl.ai/dataset/cora_raw.zip...\n",
            "Extracting file to /root/.dgl/cora\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXSXEsLe4LRU",
        "colab_type": "code",
        "outputId": "28931db5-d2b4-4c16-adf1-b405d6917156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "plain_deg_matrix = th.tensor(np.zeros((2708,2708)))\n",
        "for i in range(2708):\n",
        "  d = len(g.adjacency_matrix()[i]._indices()[0])\n",
        "  plain_deg_matrix[i][i] = d"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
            "  warnings.warn(msg, warn_type)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooyB0ahY4_4h",
        "colab_type": "code",
        "outputId": "639532f9-dcda-44ae-9093-f999f2d47251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "plain_deg_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 2., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 5.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 5., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 5., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 4.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6-kv5AzIcsG",
        "colab_type": "code",
        "outputId": "094423a0-5ccd-4883-cdbd-3115f07fba37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import math\n",
        "deg_matrix = th.tensor(np.zeros((2708,2708)))\n",
        "for i in range(2708):\n",
        "  d = len(g.adjacency_matrix()[i]._indices()[0])\n",
        "  deg_matrix[i][i] = math.pow(d,-0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
            "  warnings.warn(msg, warn_type)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv2IXZxXbUuy",
        "colab_type": "text"
      },
      "source": [
        "This is the diagonal degree matrix.\n",
        "This means that the degree of a node `'v'` with value `'d'`, is stored at `D[u][u]=d`, whereas all the other values of the matrix (except the diagonal) are equal to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoKiD3PhU3qr",
        "colab_type": "code",
        "outputId": "8f7af858-5a00-448b-c3b5-fc0dd20a658b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "deg_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4082, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.7071, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.4472,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.4472, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4472, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.5000]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saOTwTNqeGUY",
        "colab_type": "code",
        "outputId": "b7d352fa-f2b0-4770-e9e3-0747e39766e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "g.adjacency_matrix().to_dense()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
            "  warnings.warn(msg, warn_type)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THUMmsrHbPnT",
        "colab_type": "text"
      },
      "source": [
        "This is the propagation matrix P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RJv6E9_az-g",
        "colab_type": "code",
        "outputId": "b1ac4040-811a-4a68-90a6-c35b9439627d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "P = th.mm(th.mm(deg_matrix.float(),g.adjacency_matrix().to_dense().float()),deg_matrix.float())\n",
        "print(P.shape)\n",
        "print(P)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
            "  warnings.warn(msg, warn_type)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2708, 2708])\n",
            "tensor([[0.1667, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.2000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.2000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2500]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wjPK7kubzpg",
        "colab_type": "text"
      },
      "source": [
        "The object `g` allows us to get more easily the neighboors nodes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ-KmVf99CMB",
        "colab_type": "code",
        "outputId": "1e03cf02-2921-482d-b475-c96d36ea6a66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "r = random.randint(0,2707)\n",
        "print(\"Node \" + str(r))\n",
        "g.adjacency_matrix()[r]._indices()[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Node 626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([261, 687, 626])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8fm-73C-T-D",
        "colab_type": "code",
        "outputId": "0acdf5ae-1433-4959-9c7e-e8046dc0dfaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "a = list(g.adjacency_matrix()[r]._indices()[0].numpy())\n",
        "a.remove(r)\n",
        "print(type(a))\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "[261, 687]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNOMUjH6b_Px",
        "colab_type": "text"
      },
      "source": [
        "This is a simple method used to transforma a list into a torch.Tensor object corresponding to a mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TETrYuIvCrij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createMask(array):\n",
        "  a = []\n",
        "  for i in range(2708):\n",
        "    if i in array:\n",
        "      a.append(1)\n",
        "    else:\n",
        "      a.append(0)\n",
        "  m = th.ByteTensor(a)\n",
        "  return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nJTtgo-w2MU",
        "colab_type": "text"
      },
      "source": [
        "#Implementing algorithm 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taLcl787s7zF",
        "colab_type": "text"
      },
      "source": [
        "The following algorithm is used in order to retrive the receptive fields of each layer and the propagation matrices for each layer, just for the selected minibath of nodes.\n",
        "\n",
        "The algorithm is used in algorithm for training with CV approach.\n",
        "\n",
        "Pseudo-code:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "r_L = V_B\n",
        "for layer l = L - 1 to 0 do\n",
        "  r_l = 0\n",
        "  P'_l = 0\n",
        "  for each node u in r_l+1 do\n",
        "    r_l = r_l + {u}\n",
        "    P'_uu^l = P'_uu^l + P_uu*n(u)/D_l\n",
        "    for D_l - 1 random neighbors v in n(u) do\n",
        "      r_l = r_l + {v}\n",
        "      P'_uv^l = P'_uv^l + P_uv*n(u)/D_l\n",
        "    end for\n",
        "  end for\n",
        "end for\n",
        "```\n",
        "where\n",
        "\n",
        "\n",
        "*   r_L: the receptive field of layer L\n",
        "*   V_B: the minibatch set (a subset of nodes)\n",
        "*   P'_l: propagation matrix of the layer l\n",
        "*   P'_uv^l = P_uv^l * n(u)/D_l, if v is in n'(u)_l, otherwise 0\n",
        "*   n(u): neighbors of u\n",
        "*   n'(u): random subset of n(u)\n",
        "*   D_l: neighbors for each node at layer l\n",
        "\n",
        "Notice that, since we do not use MINIbatches, n(u)/D_l is always equal to 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "30EzN1TiVV-A",
        "colab": {}
      },
      "source": [
        "import time\n",
        "#implementation of the above algorithm#\n",
        "\n",
        "#minibatch = th.ByteTensor(...) of 0,1 boolean (it is a mask)\n",
        "\n",
        "#returning: the receptive fields and the propagation matrices\n",
        "def algOne(minibatch):\n",
        "  t0 = time.time()\n",
        "  rL = minibatch\n",
        "  l = 2\n",
        "  n = 2\n",
        "\n",
        "  receptiveField = dict()\n",
        "  propagationMatrix = dict()\n",
        "\n",
        "  receptiveField[l] = rL\n",
        "\n",
        "  #first for-loop\n",
        "  while l > 0:\n",
        "    #init\n",
        "    field = []\n",
        "    matrixP = np.zeros((2708,2708))\n",
        "    #second for-loop\n",
        "    k = 0\n",
        "    passedMask = False\n",
        "    for nodeValue in receptiveField[l]:\n",
        "      if nodeValue == 1:\n",
        "        node = k\n",
        "\n",
        "        if node not in field:\n",
        "          field.append(node)\n",
        "\n",
        "        matrixP[node][node] = matrixP[node][node] + P[node][node] * plain_deg_matrix[node][node] / n\n",
        "\n",
        "        #collecting n random neighbor\n",
        "        subset = []\n",
        "        a = list(g.adjacency_matrix()[node]._indices()[0].numpy())\n",
        "        a.remove(node)\n",
        "        if len(a) <= n:\n",
        "          subset = a\n",
        "        else:\n",
        "          subset = random.sample(a, k=n)\n",
        "\n",
        "        #last for-loop\n",
        "        for neighbor in subset:\n",
        "          if neighbor not in field:\n",
        "            field.append(neighbor)\n",
        "          matrixP[node][neighbor] = matrixP[node][neighbor] + P[node][neighbor] * plain_deg_matrix[node][node] / n\n",
        "\n",
        "      k = k + 1\n",
        "      \n",
        "    #updating level\n",
        "    l = l - 1\n",
        "\n",
        "    #convert field (array of nodes) to a mask\n",
        "    receptiveField[l] = createMask(field).detach()\n",
        "    propagationMatrix[l] = th.FloatTensor(matrixP).detach()\n",
        "  \n",
        "  #print(time.time() - t0)\n",
        "  return [receptiveField, propagationMatrix]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1GVRCyIN3mW",
        "colab_type": "text"
      },
      "source": [
        "#Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrKmDjqXcIuC",
        "colab_type": "text"
      },
      "source": [
        "Some commond parameters used to train the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45EUaxAcD04F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_of_training_cycles = 15\n",
        "n_of_epochs = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45QJRof3cNIN",
        "colab_type": "text"
      },
      "source": [
        "This methods creates some random masks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVcFLcl8V8vY",
        "colab_type": "code",
        "outputId": "52692ba5-0957-40ba-a9c0-a057e641dcbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#random mask\n",
        "masks = []\n",
        "n_masks = 10\n",
        "size_masks = 100\n",
        "a = range(2708)\n",
        "for i in range(n_masks):\n",
        "  mask = np.zeros(2708)\n",
        "  sub = random.sample(a,k=size_masks)\n",
        "  for s in sub:\n",
        "    mask[s] = 1\n",
        "  m = th.ByteTensor(mask)\n",
        "  masks.append(m)\n",
        "\n",
        "print(\"Generated \" + str(n_masks) + \" random masks with size \" + str(size_masks))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated 10 random masks with size 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgeKlv_CN3ma",
        "colab_type": "text"
      },
      "source": [
        "We then define the node UDF for ``apply_nodes``, which is a fully-connected layer:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcTM-w1gN3mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NodeApplyModule(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, activation):\n",
        "        super(NodeApplyModule, self).__init__()\n",
        "        self.linear = nn.Linear(in_feats, out_feats)\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, node):\n",
        "        z = self.linear(node.data['h'])\n",
        "        h = self.activation(z)\n",
        "        return {'h' : h}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD1DNkN8N3md",
        "colab_type": "text"
      },
      "source": [
        "We then proceed to define the GCN module. A GCN layer essentially performs\n",
        "message passing on all the nodes then applies the `NodeApplyModule`. Note\n",
        "that we omitted the dropout in the paper for simplicity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQy_eUuWN3me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, activation):\n",
        "        super(GCN, self).__init__()\n",
        "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
        "\n",
        "    def forward(self, g, feature):\n",
        "        g.ndata['h'] = feature\n",
        "        g.update_all(gcn_msg, gcn_reduce)\n",
        "        g.apply_nodes(func=self.apply_mod)\n",
        "        return g.ndata.pop('h')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEMMI4CXN3mh",
        "colab_type": "text"
      },
      "source": [
        "The forward function is essentially the same as any other commonly seen NNs\n",
        "model in PyTorch.  We can initialize GCN like any ``nn.Module``. For example,\n",
        "let's define a simple neural network consisting of two GCN layers. Suppose we\n",
        "are training the classifier for the cora dataset (the input feature size is\n",
        "1433 and the number of classes is 7).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVVOgunmN3mh",
        "colab_type": "code",
        "outputId": "2b9f4b9d-edf9-4185-a6d2-318deb16ab67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.gcn1 = GCN(1433, 16, F.relu)\n",
        "        self.gcn2 = GCN(16, 7, F.relu)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.gcn1(g, features)\n",
        "        x = self.gcn2(g, x)\n",
        "        return x\n",
        "        \n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (gcn1): GCN(\n",
            "    (apply_mod): NodeApplyModule(\n",
            "      (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (gcn2): GCN(\n",
            "    (apply_mod): NodeApplyModule(\n",
            "      (linear): Linear(in_features=16, out_features=7, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V5DJfryN3mk",
        "colab_type": "text"
      },
      "source": [
        "We load the cora dataset using DGL's built-in data module.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFzGHVDwN3mn",
        "colab_type": "text"
      },
      "source": [
        "We then train the network as follows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9z-t8-jmRLM",
        "colab_type": "text"
      },
      "source": [
        "This is the implementation of a standard GCN with 2 layers (+ 1 input layer). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3SQOrzeN3mo",
        "colab_type": "code",
        "outputId": "3ea3234a-9604-46b9-c5bf-db4c41c5028c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "import collections\n",
        "import numpy as np\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#init counters\n",
        "averageAccCora = []\n",
        "averageLossCora = []\n",
        "\n",
        "for t in range(n_of_training_cycles):\n",
        "  print(\"Starting new training\")\n",
        "  #get data from DGL\n",
        "  net = Net()\n",
        "  g, features, labels, mask = load_cora_data()\n",
        "  print(g)\n",
        "\n",
        "  #point to show on graph\n",
        "  pointsCora=dict()\n",
        "  pointsLossCora=dict()\n",
        "\n",
        "  #the number of masks to get when training per epoch\n",
        "  n_masks_to_try = 4\n",
        "  #initializing the optimizer (optimizer takes care of optimize the learining rate during training)\n",
        "  optimizer = th.optim.Adam(net.parameters(), lr=2e-2)\n",
        "  optimizer.state = collections.defaultdict(dict)\n",
        "\n",
        "  #dur is just an array to store the duration in order to show them later\n",
        "  dur = []\n",
        "\n",
        "  #this 'for' cycles on 200 epochs\n",
        "  for epoch in range(n_of_epochs):\n",
        "      t0 = time.time()\n",
        "\n",
        "      #getting only some masks (4)\n",
        "      masksToTry = random.sample(masks,n_masks_to_try)\n",
        "\n",
        "      for m in masksToTry:\n",
        "          #calling 'net(...)' it asks to the GCN to compute the forward    \n",
        "\n",
        "          logits = net(g, features)\n",
        "          logp = F.log_softmax(logits, 1)\n",
        "\n",
        "          #compute loss like the negative log likelihood loss\n",
        "          loss = F.nll_loss(logp[m], labels[m])\n",
        "          \n",
        "          #Since the backward() function accumulates gradients, and you \n",
        "          #don’t want to mix up gradients between minibatch, you have \n",
        "          #to zero them out at the start of a new minibatch. This is \n",
        "          #exactly like how a general (additive) accumulator variable is \n",
        "          #initialized to 0 in code.\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          #update network weights by loss\n",
        "          loss.backward()\n",
        "\n",
        "          #update optimizer's values after backward\n",
        "          optimizer.step()\n",
        "\n",
        "          #computing accuracy\n",
        "          i = 0\n",
        "          matched = 0\n",
        "          while i < 2708:\n",
        "            if m[i] == 0:\n",
        "              #getting index of the maximum\n",
        "              j = 0\n",
        "              max = None\n",
        "              jMax = 0\n",
        "              for a in logp[i]:\n",
        "                if max==None:\n",
        "                  max = a.item()\n",
        "                  jMax = j\n",
        "                elif max < a.item():\n",
        "                  max = a.item()\n",
        "                  jMax = j\n",
        "                j = j + 1\n",
        "              if jMax == labels[i]:\n",
        "                matched = matched + 1\n",
        "            i = i + 1\n",
        "          acc = matched/(2708-size_masks)*100\n",
        "\n",
        "          if epoch not in pointsCora:\n",
        "            pointsCora[epoch] = 0\n",
        "            pointsLossCora[epoch] = 0\n",
        "          pointsCora[epoch] = pointsCora[epoch] + acc\n",
        "          pointsLossCora[epoch] = pointsLossCora[epoch] + loss.item()\n",
        "          \n",
        "      dur.append(time.time() - t0)\n",
        "      \n",
        "      #computing the average of the accuracy and the loss\n",
        "      pointsCora[epoch] = pointsCora[epoch]/n_masks_to_try\n",
        "      pointsLossCora[epoch] = pointsLossCora[epoch]/n_masks_to_try\n",
        "\n",
        "      print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f} | Accuracy: {:.6f} %\".format(\n",
        "              epoch, loss.item(), np.mean(dur), pointsCora[epoch]))\n",
        "  #storing results    \n",
        "  averageAccCora.append(pointsCora)\n",
        "  averageLossCora.append(pointsLossCora)\n",
        "  print(\"Results stored.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.6824 | Time(s) 1.2594 | Accuracy: 26.457055 %\n",
            "Epoch 00001 | Loss 1.2791 | Time(s) 1.2878 | Accuracy: 45.437117 %\n",
            "Epoch 00002 | Loss 1.3135 | Time(s) 1.2610 | Accuracy: 56.786810 %\n",
            "Epoch 00003 | Loss 1.2255 | Time(s) 1.2668 | Accuracy: 58.502684 %\n",
            "Epoch 00004 | Loss 1.0052 | Time(s) 1.2681 | Accuracy: 59.998083 %\n",
            "Epoch 00005 | Loss 0.9653 | Time(s) 1.2599 | Accuracy: 61.685199 %\n",
            "Epoch 00006 | Loss 0.9593 | Time(s) 1.2544 | Accuracy: 61.953604 %\n",
            "Epoch 00007 | Loss 0.7863 | Time(s) 1.2503 | Accuracy: 66.027607 %\n",
            "Epoch 00008 | Loss 0.8931 | Time(s) 1.2529 | Accuracy: 68.366564 %\n",
            "Epoch 00009 | Loss 0.8896 | Time(s) 1.2494 | Accuracy: 68.510353 %\n",
            "Epoch 00010 | Loss 0.8433 | Time(s) 1.2497 | Accuracy: 67.494248 %\n",
            "Epoch 00011 | Loss 0.7004 | Time(s) 1.2448 | Accuracy: 68.481595 %\n",
            "Epoch 00012 | Loss 0.8238 | Time(s) 1.2435 | Accuracy: 69.852377 %\n",
            "Epoch 00013 | Loss 0.8298 | Time(s) 1.2430 | Accuracy: 70.293328 %\n",
            "Epoch 00014 | Loss 0.5870 | Time(s) 1.2434 | Accuracy: 69.104678 %\n",
            "Epoch 00015 | Loss 0.7993 | Time(s) 1.2420 | Accuracy: 69.612730 %\n",
            "Epoch 00016 | Loss 0.9664 | Time(s) 1.2419 | Accuracy: 70.791794 %\n",
            "Epoch 00017 | Loss 0.4383 | Time(s) 1.2401 | Accuracy: 70.763037 %\n",
            "Epoch 00018 | Loss 0.7947 | Time(s) 1.2387 | Accuracy: 70.945169 %\n",
            "Epoch 00019 | Loss 0.6257 | Time(s) 1.2381 | Accuracy: 70.370015 %\n",
            "Epoch 00020 | Loss 0.5522 | Time(s) 1.2393 | Accuracy: 69.699003 %\n",
            "Epoch 00021 | Loss 0.7686 | Time(s) 1.2396 | Accuracy: 70.830138 %\n",
            "Epoch 00022 | Loss 0.6919 | Time(s) 1.2429 | Accuracy: 71.194402 %\n",
            "Epoch 00023 | Loss 0.6600 | Time(s) 1.2437 | Accuracy: 70.561733 %\n",
            "Epoch 00024 | Loss 0.6593 | Time(s) 1.2449 | Accuracy: 71.299847 %\n",
            "Epoch 00025 | Loss 0.5246 | Time(s) 1.2473 | Accuracy: 71.376534 %\n",
            "Epoch 00026 | Loss 0.6278 | Time(s) 1.2478 | Accuracy: 71.069785 %\n",
            "Epoch 00027 | Loss 0.6150 | Time(s) 1.2491 | Accuracy: 71.338190 %\n",
            "Epoch 00028 | Loss 0.5489 | Time(s) 1.2522 | Accuracy: 71.750383 %\n",
            "Epoch 00029 | Loss 0.5847 | Time(s) 1.2529 | Accuracy: 71.932515 %\n",
            "Epoch 00030 | Loss 0.5807 | Time(s) 1.2515 | Accuracy: 72.162577 %\n",
            "Epoch 00031 | Loss 0.6959 | Time(s) 1.2514 | Accuracy: 71.855828 %\n",
            "Epoch 00032 | Loss 0.8320 | Time(s) 1.2514 | Accuracy: 71.750383 %\n",
            "Epoch 00033 | Loss 0.5014 | Time(s) 1.2511 | Accuracy: 71.587423 %\n",
            "Epoch 00034 | Loss 0.6246 | Time(s) 1.2508 | Accuracy: 71.366948 %\n",
            "Epoch 00035 | Loss 0.6035 | Time(s) 1.2503 | Accuracy: 71.290261 %\n",
            "Epoch 00036 | Loss 0.5343 | Time(s) 1.2492 | Accuracy: 71.347776 %\n",
            "Epoch 00037 | Loss 0.6045 | Time(s) 1.2492 | Accuracy: 71.510736 %\n",
            "Epoch 00038 | Loss 0.5970 | Time(s) 1.2497 | Accuracy: 71.951687 %\n",
            "Epoch 00039 | Loss 0.7905 | Time(s) 1.2501 | Accuracy: 71.990031 %\n",
            "Epoch 00040 | Loss 0.3851 | Time(s) 1.2498 | Accuracy: 71.587423 %\n",
            "Epoch 00041 | Loss 0.5113 | Time(s) 1.2502 | Accuracy: 70.925997 %\n",
            "Epoch 00042 | Loss 0.6504 | Time(s) 1.2500 | Accuracy: 71.606595 %\n",
            "Epoch 00043 | Loss 0.7536 | Time(s) 1.2502 | Accuracy: 71.903758 %\n",
            "Epoch 00044 | Loss 0.5037 | Time(s) 1.2507 | Accuracy: 72.363880 %\n",
            "Epoch 00045 | Loss 0.6075 | Time(s) 1.2517 | Accuracy: 72.143405 %\n",
            "Epoch 00046 | Loss 0.5006 | Time(s) 1.2515 | Accuracy: 72.095475 %\n",
            "Epoch 00047 | Loss 0.5528 | Time(s) 1.2515 | Accuracy: 71.577837 %\n",
            "Epoch 00048 | Loss 0.6146 | Time(s) 1.2516 | Accuracy: 71.721626 %\n",
            "Epoch 00049 | Loss 0.5091 | Time(s) 1.2541 | Accuracy: 71.798313 %\n",
            "Epoch 00050 | Loss 0.4945 | Time(s) 1.2539 | Accuracy: 72.085890 %\n",
            "Epoch 00051 | Loss 0.6115 | Time(s) 1.2538 | Accuracy: 71.424463 %\n",
            "Epoch 00052 | Loss 0.5865 | Time(s) 1.2533 | Accuracy: 72.239264 %\n",
            "Epoch 00053 | Loss 0.7265 | Time(s) 1.2528 | Accuracy: 71.990031 %\n",
            "Epoch 00054 | Loss 0.5621 | Time(s) 1.2527 | Accuracy: 71.999617 %\n",
            "Epoch 00055 | Loss 0.5003 | Time(s) 1.2520 | Accuracy: 71.692868 %\n",
            "Epoch 00056 | Loss 0.3653 | Time(s) 1.2528 | Accuracy: 71.875000 %\n",
            "Epoch 00057 | Loss 0.5835 | Time(s) 1.2532 | Accuracy: 71.922929 %\n",
            "Epoch 00058 | Loss 0.5069 | Time(s) 1.2527 | Accuracy: 71.875000 %\n",
            "Epoch 00059 | Loss 0.5467 | Time(s) 1.2528 | Accuracy: 71.999617 %\n",
            "Epoch 00060 | Loss 0.5724 | Time(s) 1.2523 | Accuracy: 72.220092 %\n",
            "Epoch 00061 | Loss 0.5919 | Time(s) 1.2518 | Accuracy: 72.143405 %\n",
            "Epoch 00062 | Loss 0.5423 | Time(s) 1.2522 | Accuracy: 72.057132 %\n",
            "Epoch 00063 | Loss 0.5418 | Time(s) 1.2521 | Accuracy: 72.028374 %\n",
            "Epoch 00064 | Loss 0.5680 | Time(s) 1.2520 | Accuracy: 71.999617 %\n",
            "Epoch 00065 | Loss 0.6363 | Time(s) 1.2526 | Accuracy: 71.750383 %\n",
            "Epoch 00066 | Loss 0.5373 | Time(s) 1.2520 | Accuracy: 71.779141 %\n",
            "Epoch 00067 | Loss 0.5371 | Time(s) 1.2528 | Accuracy: 71.884586 %\n",
            "Epoch 00068 | Loss 0.5516 | Time(s) 1.2522 | Accuracy: 71.846242 %\n",
            "Epoch 00069 | Loss 0.6476 | Time(s) 1.2520 | Accuracy: 71.990031 %\n",
            "Epoch 00070 | Loss 0.4966 | Time(s) 1.2517 | Accuracy: 71.970859 %\n",
            "Epoch 00071 | Loss 0.5973 | Time(s) 1.2512 | Accuracy: 71.903758 %\n",
            "Epoch 00072 | Loss 0.5368 | Time(s) 1.2511 | Accuracy: 72.037960 %\n",
            "Epoch 00073 | Loss 0.7875 | Time(s) 1.2513 | Accuracy: 72.268021 %\n",
            "Epoch 00074 | Loss 0.4905 | Time(s) 1.2507 | Accuracy: 72.152991 %\n",
            "Epoch 00075 | Loss 0.5894 | Time(s) 1.2508 | Accuracy: 72.066718 %\n",
            "Epoch 00076 | Loss 0.8146 | Time(s) 1.2510 | Accuracy: 72.057132 %\n",
            "Epoch 00077 | Loss 0.3597 | Time(s) 1.2506 | Accuracy: 72.172163 %\n",
            "Epoch 00078 | Loss 0.6453 | Time(s) 1.2504 | Accuracy: 72.315951 %\n",
            "Epoch 00079 | Loss 0.3544 | Time(s) 1.2494 | Accuracy: 72.028374 %\n",
            "Epoch 00080 | Loss 0.5891 | Time(s) 1.2489 | Accuracy: 72.009202 %\n",
            "Epoch 00081 | Loss 0.4900 | Time(s) 1.2482 | Accuracy: 72.076304 %\n",
            "Epoch 00082 | Loss 0.6357 | Time(s) 1.2481 | Accuracy: 72.430982 %\n",
            "Epoch 00083 | Loss 0.4927 | Time(s) 1.2479 | Accuracy: 72.335123 %\n",
            "Epoch 00084 | Loss 0.4916 | Time(s) 1.2474 | Accuracy: 72.210506 %\n",
            "Epoch 00085 | Loss 0.4960 | Time(s) 1.2471 | Accuracy: 71.807899 %\n",
            "Epoch 00086 | Loss 0.4905 | Time(s) 1.2481 | Accuracy: 71.769555 %\n",
            "Epoch 00087 | Loss 0.4890 | Time(s) 1.2473 | Accuracy: 71.529908 %\n",
            "Epoch 00088 | Loss 0.5301 | Time(s) 1.2470 | Accuracy: 72.018788 %\n",
            "Epoch 00089 | Loss 0.6450 | Time(s) 1.2466 | Accuracy: 71.999617 %\n",
            "Epoch 00090 | Loss 0.3526 | Time(s) 1.2460 | Accuracy: 72.133819 %\n",
            "Epoch 00091 | Loss 0.5301 | Time(s) 1.2459 | Accuracy: 72.076304 %\n",
            "Epoch 00092 | Loss 0.3536 | Time(s) 1.2453 | Accuracy: 72.152991 %\n",
            "Epoch 00093 | Loss 0.5308 | Time(s) 1.2448 | Accuracy: 72.076304 %\n",
            "Epoch 00094 | Loss 0.5792 | Time(s) 1.2443 | Accuracy: 71.501150 %\n",
            "Epoch 00095 | Loss 0.5010 | Time(s) 1.2444 | Accuracy: 71.999617 %\n",
            "Epoch 00096 | Loss 0.4898 | Time(s) 1.2442 | Accuracy: 71.558666 %\n",
            "Epoch 00097 | Loss 0.3530 | Time(s) 1.2444 | Accuracy: 71.731212 %\n",
            "Epoch 00098 | Loss 0.5747 | Time(s) 1.2455 | Accuracy: 71.817485 %\n",
            "Epoch 00099 | Loss 0.3534 | Time(s) 1.2453 | Accuracy: 71.990031 %\n",
            "Epoch 00100 | Loss 0.5317 | Time(s) 1.2453 | Accuracy: 72.411810 %\n",
            "Epoch 00101 | Loss 0.4886 | Time(s) 1.2452 | Accuracy: 72.440567 %\n",
            "Epoch 00102 | Loss 0.4885 | Time(s) 1.2449 | Accuracy: 72.172163 %\n",
            "Epoch 00103 | Loss 0.4970 | Time(s) 1.2449 | Accuracy: 71.846242 %\n",
            "Epoch 00104 | Loss 0.5290 | Time(s) 1.2448 | Accuracy: 72.268021 %\n",
            "Epoch 00105 | Loss 0.7156 | Time(s) 1.2449 | Accuracy: 72.172163 %\n",
            "Epoch 00106 | Loss 0.5735 | Time(s) 1.2449 | Accuracy: 71.961273 %\n",
            "Epoch 00107 | Loss 0.7048 | Time(s) 1.2447 | Accuracy: 71.990031 %\n",
            "Epoch 00108 | Loss 0.4888 | Time(s) 1.2442 | Accuracy: 72.114647 %\n",
            "Epoch 00109 | Loss 0.4885 | Time(s) 1.2441 | Accuracy: 72.229678 %\n",
            "Epoch 00110 | Loss 0.4882 | Time(s) 1.2442 | Accuracy: 72.105061 %\n",
            "Epoch 00111 | Loss 0.5286 | Time(s) 1.2440 | Accuracy: 72.018788 %\n",
            "Epoch 00112 | Loss 0.4879 | Time(s) 1.2438 | Accuracy: 71.980445 %\n",
            "Epoch 00113 | Loss 0.7567 | Time(s) 1.2435 | Accuracy: 71.932515 %\n",
            "Epoch 00114 | Loss 0.5702 | Time(s) 1.2434 | Accuracy: 72.076304 %\n",
            "Epoch 00115 | Loss 0.5723 | Time(s) 1.2430 | Accuracy: 71.769555 %\n",
            "Epoch 00116 | Loss 0.5687 | Time(s) 1.2428 | Accuracy: 71.913344 %\n",
            "Epoch 00117 | Loss 0.4897 | Time(s) 1.2426 | Accuracy: 72.124233 %\n",
            "Epoch 00118 | Loss 0.4924 | Time(s) 1.2422 | Accuracy: 72.287193 %\n",
            "Epoch 00119 | Loss 0.5697 | Time(s) 1.2421 | Accuracy: 72.459739 %\n",
            "Epoch 00120 | Loss 0.5728 | Time(s) 1.2419 | Accuracy: 72.363880 %\n",
            "Epoch 00121 | Loss 0.4963 | Time(s) 1.2421 | Accuracy: 72.229678 %\n",
            "Epoch 00122 | Loss 0.6329 | Time(s) 1.2419 | Accuracy: 71.990031 %\n",
            "Epoch 00123 | Loss 0.5742 | Time(s) 1.2417 | Accuracy: 72.018788 %\n",
            "Epoch 00124 | Loss 0.4900 | Time(s) 1.2419 | Accuracy: 72.028374 %\n",
            "Epoch 00125 | Loss 0.5271 | Time(s) 1.2424 | Accuracy: 71.932515 %\n",
            "Epoch 00126 | Loss 0.5270 | Time(s) 1.2421 | Accuracy: 71.922929 %\n",
            "Epoch 00127 | Loss 0.5563 | Time(s) 1.2417 | Accuracy: 72.095475 %\n",
            "Epoch 00128 | Loss 0.4876 | Time(s) 1.2415 | Accuracy: 72.258436 %\n",
            "Epoch 00129 | Loss 0.5272 | Time(s) 1.2415 | Accuracy: 72.047546 %\n",
            "Epoch 00130 | Loss 0.7016 | Time(s) 1.2411 | Accuracy: 72.114647 %\n",
            "Epoch 00131 | Loss 0.5270 | Time(s) 1.2406 | Accuracy: 71.788727 %\n",
            "Epoch 00132 | Loss 0.5856 | Time(s) 1.2406 | Accuracy: 71.731212 %\n",
            "Epoch 00133 | Loss 0.6784 | Time(s) 1.2402 | Accuracy: 71.961273 %\n",
            "Epoch 00134 | Loss 0.5706 | Time(s) 1.2403 | Accuracy: 71.884586 %\n",
            "Epoch 00135 | Loss 0.5701 | Time(s) 1.2402 | Accuracy: 71.673696 %\n",
            "Epoch 00136 | Loss 0.5283 | Time(s) 1.2399 | Accuracy: 71.807899 %\n",
            "Epoch 00137 | Loss 0.6893 | Time(s) 1.2394 | Accuracy: 71.980445 %\n",
            "Epoch 00138 | Loss 0.5275 | Time(s) 1.2392 | Accuracy: 72.047546 %\n",
            "Epoch 00139 | Loss 0.3526 | Time(s) 1.2392 | Accuracy: 71.702454 %\n",
            "Epoch 00140 | Loss 0.7022 | Time(s) 1.2387 | Accuracy: 71.865414 %\n",
            "Epoch 00141 | Loss 0.5480 | Time(s) 1.2383 | Accuracy: 71.932515 %\n",
            "Epoch 00142 | Loss 0.6673 | Time(s) 1.2378 | Accuracy: 71.855828 %\n",
            "Epoch 00143 | Loss 0.6266 | Time(s) 1.2375 | Accuracy: 71.961273 %\n",
            "Epoch 00144 | Loss 0.3511 | Time(s) 1.2373 | Accuracy: 71.721626 %\n",
            "Epoch 00145 | Loss 0.4934 | Time(s) 1.2371 | Accuracy: 71.788727 %\n",
            "Epoch 00146 | Loss 0.3510 | Time(s) 1.2373 | Accuracy: 72.085890 %\n",
            "Epoch 00147 | Loss 0.7194 | Time(s) 1.2377 | Accuracy: 72.124233 %\n",
            "Epoch 00148 | Loss 0.4876 | Time(s) 1.2376 | Accuracy: 71.865414 %\n",
            "Epoch 00149 | Loss 0.4899 | Time(s) 1.2377 | Accuracy: 71.779141 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.8177 | Time(s) 1.2187 | Accuracy: 22.661043 %\n",
            "Epoch 00001 | Loss 1.6197 | Time(s) 1.2039 | Accuracy: 33.358896 %\n",
            "Epoch 00002 | Loss 1.2583 | Time(s) 1.2036 | Accuracy: 43.318635 %\n",
            "Epoch 00003 | Loss 1.1070 | Time(s) 1.1978 | Accuracy: 52.492331 %\n",
            "Epoch 00004 | Loss 1.2849 | Time(s) 1.1967 | Accuracy: 55.396856 %\n",
            "Epoch 00005 | Loss 1.1689 | Time(s) 1.1958 | Accuracy: 57.774156 %\n",
            "Epoch 00006 | Loss 0.9974 | Time(s) 1.1958 | Accuracy: 58.771089 %\n",
            "Epoch 00007 | Loss 1.1565 | Time(s) 1.1957 | Accuracy: 58.981979 %\n",
            "Epoch 00008 | Loss 0.9270 | Time(s) 1.2001 | Accuracy: 58.378067 %\n",
            "Epoch 00009 | Loss 0.8323 | Time(s) 1.1982 | Accuracy: 57.937117 %\n",
            "Epoch 00010 | Loss 0.8505 | Time(s) 1.1994 | Accuracy: 58.866948 %\n",
            "Epoch 00011 | Loss 1.0945 | Time(s) 1.2003 | Accuracy: 59.662577 %\n",
            "Epoch 00012 | Loss 0.8254 | Time(s) 1.1997 | Accuracy: 59.585890 %\n",
            "Epoch 00013 | Loss 1.0190 | Time(s) 1.2032 | Accuracy: 59.672163 %\n",
            "Epoch 00014 | Loss 1.0139 | Time(s) 1.2013 | Accuracy: 59.116181 %\n",
            "Epoch 00015 | Loss 0.9758 | Time(s) 1.2008 | Accuracy: 59.605061 %\n",
            "Epoch 00016 | Loss 0.7841 | Time(s) 1.2041 | Accuracy: 59.892638 %\n",
            "Epoch 00017 | Loss 0.7863 | Time(s) 1.2077 | Accuracy: 60.170629 %\n",
            "Epoch 00018 | Loss 0.7973 | Time(s) 1.2082 | Accuracy: 59.978911 %\n",
            "Epoch 00019 | Loss 0.6665 | Time(s) 1.2119 | Accuracy: 59.633819 %\n",
            "Epoch 00020 | Loss 1.0248 | Time(s) 1.2111 | Accuracy: 59.796779 %\n",
            "Epoch 00021 | Loss 0.8670 | Time(s) 1.2131 | Accuracy: 59.940567 %\n",
            "Epoch 00022 | Loss 0.8415 | Time(s) 1.2106 | Accuracy: 59.873466 %\n",
            "Epoch 00023 | Loss 0.8361 | Time(s) 1.2107 | Accuracy: 59.902224 %\n",
            "Epoch 00024 | Loss 0.6631 | Time(s) 1.2087 | Accuracy: 60.026840 %\n",
            "Epoch 00025 | Loss 0.9771 | Time(s) 1.2101 | Accuracy: 60.065184 %\n",
            "Epoch 00026 | Loss 0.7559 | Time(s) 1.2104 | Accuracy: 60.228144 %\n",
            "Epoch 00027 | Loss 0.9611 | Time(s) 1.2079 | Accuracy: 60.103528 %\n",
            "Epoch 00028 | Loss 0.8657 | Time(s) 1.2065 | Accuracy: 59.796779 %\n",
            "Epoch 00029 | Loss 0.9603 | Time(s) 1.2056 | Accuracy: 60.688267 %\n",
            "Epoch 00030 | Loss 0.7335 | Time(s) 1.2062 | Accuracy: 60.429448 %\n",
            "Epoch 00031 | Loss 0.8443 | Time(s) 1.2049 | Accuracy: 60.026840 %\n",
            "Epoch 00032 | Loss 0.8540 | Time(s) 1.2037 | Accuracy: 59.978911 %\n",
            "Epoch 00033 | Loss 0.9116 | Time(s) 1.2028 | Accuracy: 59.902224 %\n",
            "Epoch 00034 | Loss 0.9696 | Time(s) 1.2014 | Accuracy: 60.036426 %\n",
            "Epoch 00035 | Loss 0.9384 | Time(s) 1.2004 | Accuracy: 60.180215 %\n",
            "Epoch 00036 | Loss 0.6252 | Time(s) 1.2000 | Accuracy: 60.218558 %\n",
            "Epoch 00037 | Loss 0.6127 | Time(s) 1.1986 | Accuracy: 60.439034 %\n",
            "Epoch 00038 | Loss 0.7551 | Time(s) 1.1991 | Accuracy: 60.266488 %\n",
            "Epoch 00039 | Loss 0.6700 | Time(s) 1.2008 | Accuracy: 60.285660 %\n",
            "Epoch 00040 | Loss 0.8676 | Time(s) 1.2003 | Accuracy: 60.525307 %\n",
            "Epoch 00041 | Loss 0.8411 | Time(s) 1.2003 | Accuracy: 59.883052 %\n",
            "Epoch 00042 | Loss 0.9325 | Time(s) 1.2014 | Accuracy: 59.681748 %\n",
            "Epoch 00043 | Loss 0.8273 | Time(s) 1.2028 | Accuracy: 59.940567 %\n",
            "Epoch 00044 | Loss 0.6215 | Time(s) 1.2033 | Accuracy: 60.295245 %\n",
            "Epoch 00045 | Loss 0.9158 | Time(s) 1.2044 | Accuracy: 59.978911 %\n",
            "Epoch 00046 | Loss 0.9345 | Time(s) 1.2039 | Accuracy: 60.851227 %\n",
            "Epoch 00047 | Loss 0.8490 | Time(s) 1.2044 | Accuracy: 60.899156 %\n",
            "Epoch 00048 | Loss 0.7520 | Time(s) 1.2033 | Accuracy: 60.630752 %\n",
            "Epoch 00049 | Loss 0.9320 | Time(s) 1.2035 | Accuracy: 60.180215 %\n",
            "Epoch 00050 | Loss 0.6606 | Time(s) 1.2037 | Accuracy: 60.103528 %\n",
            "Epoch 00051 | Loss 0.9042 | Time(s) 1.2034 | Accuracy: 59.547546 %\n",
            "Epoch 00052 | Loss 0.9639 | Time(s) 1.2033 | Accuracy: 59.787193 %\n",
            "Epoch 00053 | Loss 0.7536 | Time(s) 1.2039 | Accuracy: 59.729678 %\n",
            "Epoch 00054 | Loss 0.9298 | Time(s) 1.2046 | Accuracy: 60.554064 %\n",
            "Epoch 00055 | Loss 0.8223 | Time(s) 1.2049 | Accuracy: 59.835123 %\n",
            "Epoch 00056 | Loss 0.9093 | Time(s) 1.2043 | Accuracy: 59.605061 %\n",
            "Epoch 00057 | Loss 0.9439 | Time(s) 1.2038 | Accuracy: 59.336656 %\n",
            "Epoch 00058 | Loss 0.7599 | Time(s) 1.2033 | Accuracy: 59.221626 %\n",
            "Epoch 00059 | Loss 0.9567 | Time(s) 1.2030 | Accuracy: 59.863880 %\n",
            "Epoch 00060 | Loss 0.9743 | Time(s) 1.2030 | Accuracy: 60.017255 %\n",
            "Epoch 00061 | Loss 0.8287 | Time(s) 1.2027 | Accuracy: 59.135353 %\n",
            "Epoch 00062 | Loss 0.9019 | Time(s) 1.2025 | Accuracy: 59.240798 %\n",
            "Epoch 00063 | Loss 0.8288 | Time(s) 1.2032 | Accuracy: 59.154525 %\n",
            "Epoch 00064 | Loss 0.6782 | Time(s) 1.2029 | Accuracy: 59.509202 %\n",
            "Epoch 00065 | Loss 0.9430 | Time(s) 1.2029 | Accuracy: 60.266488 %\n",
            "Epoch 00066 | Loss 0.8304 | Time(s) 1.2023 | Accuracy: 60.247316 %\n",
            "Epoch 00067 | Loss 0.9996 | Time(s) 1.2038 | Accuracy: 59.883052 %\n",
            "Epoch 00068 | Loss 0.7263 | Time(s) 1.2039 | Accuracy: 60.410276 %\n",
            "Epoch 00069 | Loss 0.9240 | Time(s) 1.2047 | Accuracy: 59.729678 %\n",
            "Epoch 00070 | Loss 0.9635 | Time(s) 1.2048 | Accuracy: 59.672163 %\n",
            "Epoch 00071 | Loss 0.7527 | Time(s) 1.2048 | Accuracy: 60.314417 %\n",
            "Epoch 00072 | Loss 0.9288 | Time(s) 1.2044 | Accuracy: 59.825537 %\n",
            "Epoch 00073 | Loss 0.8232 | Time(s) 1.2039 | Accuracy: 59.835123 %\n",
            "Epoch 00074 | Loss 0.8206 | Time(s) 1.2040 | Accuracy: 60.074770 %\n",
            "Epoch 00075 | Loss 0.9807 | Time(s) 1.2039 | Accuracy: 60.055598 %\n",
            "Epoch 00076 | Loss 0.7347 | Time(s) 1.2046 | Accuracy: 59.844709 %\n",
            "Epoch 00077 | Loss 0.6343 | Time(s) 1.2042 | Accuracy: 59.777607 %\n",
            "Epoch 00078 | Loss 0.9100 | Time(s) 1.2036 | Accuracy: 60.074770 %\n",
            "Epoch 00079 | Loss 0.9256 | Time(s) 1.2032 | Accuracy: 60.199387 %\n",
            "Epoch 00080 | Loss 0.7459 | Time(s) 1.2029 | Accuracy: 60.352761 %\n",
            "Epoch 00081 | Loss 0.8831 | Time(s) 1.2024 | Accuracy: 60.151457 %\n",
            "Epoch 00082 | Loss 1.0438 | Time(s) 1.2019 | Accuracy: 60.333589 %\n",
            "Epoch 00083 | Loss 0.8794 | Time(s) 1.2014 | Accuracy: 60.333589 %\n",
            "Epoch 00084 | Loss 0.9014 | Time(s) 1.2010 | Accuracy: 60.496549 %\n",
            "Epoch 00085 | Loss 0.6369 | Time(s) 1.2011 | Accuracy: 60.343175 %\n",
            "Epoch 00086 | Loss 0.9059 | Time(s) 1.2011 | Accuracy: 60.295245 %\n",
            "Epoch 00087 | Loss 0.8198 | Time(s) 1.2006 | Accuracy: 60.247316 %\n",
            "Epoch 00088 | Loss 0.7443 | Time(s) 1.2008 | Accuracy: 60.180215 %\n",
            "Epoch 00089 | Loss 0.7433 | Time(s) 1.2006 | Accuracy: 60.256902 %\n",
            "Epoch 00090 | Loss 0.6847 | Time(s) 1.2004 | Accuracy: 60.343175 %\n",
            "Epoch 00091 | Loss 0.9048 | Time(s) 1.2003 | Accuracy: 60.314417 %\n",
            "Epoch 00092 | Loss 0.9390 | Time(s) 1.2003 | Accuracy: 60.467791 %\n",
            "Epoch 00093 | Loss 0.7440 | Time(s) 1.2008 | Accuracy: 60.419862 %\n",
            "Epoch 00094 | Loss 0.9359 | Time(s) 1.2004 | Accuracy: 60.419862 %\n",
            "Epoch 00095 | Loss 0.8853 | Time(s) 1.2000 | Accuracy: 60.410276 %\n",
            "Epoch 00096 | Loss 0.7250 | Time(s) 1.1994 | Accuracy: 60.295245 %\n",
            "Epoch 00097 | Loss 0.8192 | Time(s) 1.1986 | Accuracy: 60.419862 %\n",
            "Epoch 00098 | Loss 0.8191 | Time(s) 1.1981 | Accuracy: 60.554064 %\n",
            "Epoch 00099 | Loss 0.9227 | Time(s) 1.1979 | Accuracy: 60.419862 %\n",
            "Epoch 00100 | Loss 0.9190 | Time(s) 1.1981 | Accuracy: 60.324003 %\n",
            "Epoch 00101 | Loss 0.8799 | Time(s) 1.1980 | Accuracy: 60.237730 %\n",
            "Epoch 00102 | Loss 0.6237 | Time(s) 1.1982 | Accuracy: 60.410276 %\n",
            "Epoch 00103 | Loss 0.7220 | Time(s) 1.1979 | Accuracy: 60.256902 %\n",
            "Epoch 00104 | Loss 0.8775 | Time(s) 1.1979 | Accuracy: 60.343175 %\n",
            "Epoch 00105 | Loss 0.9202 | Time(s) 1.1979 | Accuracy: 60.439034 %\n",
            "Epoch 00106 | Loss 0.9184 | Time(s) 1.1984 | Accuracy: 60.534893 %\n",
            "Epoch 00107 | Loss 0.9280 | Time(s) 1.1985 | Accuracy: 60.477377 %\n",
            "Epoch 00108 | Loss 0.8185 | Time(s) 1.1989 | Accuracy: 60.419862 %\n",
            "Epoch 00109 | Loss 0.7412 | Time(s) 1.1990 | Accuracy: 60.295245 %\n",
            "Epoch 00110 | Loss 0.9616 | Time(s) 1.1996 | Accuracy: 60.266488 %\n",
            "Epoch 00111 | Loss 0.7410 | Time(s) 1.2002 | Accuracy: 60.448620 %\n",
            "Epoch 00112 | Loss 0.9123 | Time(s) 1.2008 | Accuracy: 60.180215 %\n",
            "Epoch 00113 | Loss 0.6838 | Time(s) 1.2009 | Accuracy: 60.170629 %\n",
            "Epoch 00114 | Loss 0.9198 | Time(s) 1.2013 | Accuracy: 60.467791 %\n",
            "Epoch 00115 | Loss 0.7218 | Time(s) 1.2013 | Accuracy: 60.601994 %\n",
            "Epoch 00116 | Loss 0.8184 | Time(s) 1.2017 | Accuracy: 60.324003 %\n",
            "Epoch 00117 | Loss 0.9019 | Time(s) 1.2026 | Accuracy: 60.295245 %\n",
            "Epoch 00118 | Loss 0.7413 | Time(s) 1.2030 | Accuracy: 60.649923 %\n",
            "Epoch 00119 | Loss 0.9205 | Time(s) 1.2042 | Accuracy: 60.467791 %\n",
            "Epoch 00120 | Loss 0.9367 | Time(s) 1.2046 | Accuracy: 60.477377 %\n",
            "Epoch 00121 | Loss 0.9855 | Time(s) 1.2051 | Accuracy: 60.439034 %\n",
            "Epoch 00122 | Loss 0.7223 | Time(s) 1.2052 | Accuracy: 60.429448 %\n",
            "Epoch 00123 | Loss 0.6837 | Time(s) 1.2051 | Accuracy: 60.381518 %\n",
            "Epoch 00124 | Loss 0.8808 | Time(s) 1.2053 | Accuracy: 60.343175 %\n",
            "Epoch 00125 | Loss 0.8223 | Time(s) 1.2055 | Accuracy: 60.419862 %\n",
            "Epoch 00126 | Loss 0.6234 | Time(s) 1.2054 | Accuracy: 60.324003 %\n",
            "Epoch 00127 | Loss 0.7210 | Time(s) 1.2054 | Accuracy: 60.563650 %\n",
            "Epoch 00128 | Loss 0.8181 | Time(s) 1.2053 | Accuracy: 60.237730 %\n",
            "Epoch 00129 | Loss 0.8209 | Time(s) 1.2055 | Accuracy: 60.419862 %\n",
            "Epoch 00130 | Loss 0.9297 | Time(s) 1.2060 | Accuracy: 60.381518 %\n",
            "Epoch 00131 | Loss 0.7408 | Time(s) 1.2059 | Accuracy: 60.276074 %\n",
            "Epoch 00132 | Loss 0.9229 | Time(s) 1.2062 | Accuracy: 60.467791 %\n",
            "Epoch 00133 | Loss 0.9341 | Time(s) 1.2064 | Accuracy: 60.295245 %\n",
            "Epoch 00134 | Loss 0.7407 | Time(s) 1.2063 | Accuracy: 60.055598 %\n",
            "Epoch 00135 | Loss 0.8320 | Time(s) 1.2069 | Accuracy: 60.199387 %\n",
            "Epoch 00136 | Loss 0.6236 | Time(s) 1.2072 | Accuracy: 60.122699 %\n",
            "Epoch 00137 | Loss 0.8995 | Time(s) 1.2075 | Accuracy: 60.247316 %\n",
            "Epoch 00138 | Loss 0.9359 | Time(s) 1.2073 | Accuracy: 60.419862 %\n",
            "Epoch 00139 | Loss 0.7210 | Time(s) 1.2072 | Accuracy: 60.496549 %\n",
            "Epoch 00140 | Loss 0.9222 | Time(s) 1.2072 | Accuracy: 60.343175 %\n",
            "Epoch 00141 | Loss 0.7211 | Time(s) 1.2080 | Accuracy: 60.467791 %\n",
            "Epoch 00142 | Loss 0.7487 | Time(s) 1.2086 | Accuracy: 60.362347 %\n",
            "Epoch 00143 | Loss 0.7408 | Time(s) 1.2093 | Accuracy: 60.247316 %\n",
            "Epoch 00144 | Loss 0.9192 | Time(s) 1.2095 | Accuracy: 60.314417 %\n",
            "Epoch 00145 | Loss 0.7209 | Time(s) 1.2095 | Accuracy: 60.400690 %\n",
            "Epoch 00146 | Loss 0.6232 | Time(s) 1.2095 | Accuracy: 60.141871 %\n",
            "Epoch 00147 | Loss 0.6232 | Time(s) 1.2095 | Accuracy: 60.295245 %\n",
            "Epoch 00148 | Loss 0.7211 | Time(s) 1.2097 | Accuracy: 60.333589 %\n",
            "Epoch 00149 | Loss 0.9368 | Time(s) 1.2098 | Accuracy: 60.295245 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7621 | Time(s) 1.3142 | Accuracy: 31.096626 %\n",
            "Epoch 00001 | Loss 1.4408 | Time(s) 1.2869 | Accuracy: 51.006518 %\n",
            "Epoch 00002 | Loss 1.2668 | Time(s) 1.2617 | Accuracy: 56.144555 %\n",
            "Epoch 00003 | Loss 1.1489 | Time(s) 1.2458 | Accuracy: 58.790261 %\n",
            "Epoch 00004 | Loss 1.2368 | Time(s) 1.2331 | Accuracy: 60.439034 %\n",
            "Epoch 00005 | Loss 1.0114 | Time(s) 1.2283 | Accuracy: 65.203221 %\n",
            "Epoch 00006 | Loss 1.0358 | Time(s) 1.2349 | Accuracy: 65.960506 %\n",
            "Epoch 00007 | Loss 0.9921 | Time(s) 1.2361 | Accuracy: 64.580138 %\n",
            "Epoch 00008 | Loss 0.9926 | Time(s) 1.2315 | Accuracy: 63.784509 %\n",
            "Epoch 00009 | Loss 0.9230 | Time(s) 1.2292 | Accuracy: 65.625000 %\n",
            "Epoch 00010 | Loss 0.6868 | Time(s) 1.2267 | Accuracy: 66.631518 %\n",
            "Epoch 00011 | Loss 1.1080 | Time(s) 1.2267 | Accuracy: 66.727377 %\n",
            "Epoch 00012 | Loss 0.5326 | Time(s) 1.2319 | Accuracy: 67.168328 %\n",
            "Epoch 00013 | Loss 0.9378 | Time(s) 1.2320 | Accuracy: 67.177914 %\n",
            "Epoch 00014 | Loss 0.8882 | Time(s) 1.2359 | Accuracy: 66.890337 %\n",
            "Epoch 00015 | Loss 0.5078 | Time(s) 1.2393 | Accuracy: 66.736963 %\n",
            "Epoch 00016 | Loss 0.7032 | Time(s) 1.2410 | Accuracy: 66.267255 %\n",
            "Epoch 00017 | Loss 1.0990 | Time(s) 1.2407 | Accuracy: 66.804064 %\n",
            "Epoch 00018 | Loss 0.4775 | Time(s) 1.2410 | Accuracy: 66.919095 %\n",
            "Epoch 00019 | Loss 0.4594 | Time(s) 1.2430 | Accuracy: 67.053298 %\n",
            "Epoch 00020 | Loss 0.4488 | Time(s) 1.2423 | Accuracy: 67.187500 %\n",
            "Epoch 00021 | Loss 0.7406 | Time(s) 1.2398 | Accuracy: 67.321702 %\n",
            "Epoch 00022 | Loss 0.7984 | Time(s) 1.2379 | Accuracy: 67.292945 %\n",
            "Epoch 00023 | Loss 0.4102 | Time(s) 1.2389 | Accuracy: 67.379218 %\n",
            "Epoch 00024 | Loss 0.4137 | Time(s) 1.2375 | Accuracy: 67.273773 %\n",
            "Epoch 00025 | Loss 0.5901 | Time(s) 1.2387 | Accuracy: 67.858512 %\n",
            "Epoch 00026 | Loss 0.7805 | Time(s) 1.2384 | Accuracy: 68.117331 %\n",
            "Epoch 00027 | Loss 0.8388 | Time(s) 1.2379 | Accuracy: 67.877684 %\n",
            "Epoch 00028 | Loss 0.7505 | Time(s) 1.2369 | Accuracy: 67.935199 %\n",
            "Epoch 00029 | Loss 0.3968 | Time(s) 1.2347 | Accuracy: 67.887270 %\n",
            "Epoch 00030 | Loss 0.8065 | Time(s) 1.2337 | Accuracy: 67.935199 %\n",
            "Epoch 00031 | Loss 0.8291 | Time(s) 1.2340 | Accuracy: 67.992715 %\n",
            "Epoch 00032 | Loss 0.6194 | Time(s) 1.2337 | Accuracy: 67.618865 %\n",
            "Epoch 00033 | Loss 0.3962 | Time(s) 1.2337 | Accuracy: 67.120399 %\n",
            "Epoch 00034 | Loss 0.6639 | Time(s) 1.2316 | Accuracy: 66.679448 %\n",
            "Epoch 00035 | Loss 0.6679 | Time(s) 1.2314 | Accuracy: 67.542178 %\n",
            "Epoch 00036 | Loss 0.3971 | Time(s) 1.2330 | Accuracy: 67.417561 %\n",
            "Epoch 00037 | Loss 0.7607 | Time(s) 1.2338 | Accuracy: 67.992715 %\n",
            "Epoch 00038 | Loss 0.7608 | Time(s) 1.2345 | Accuracy: 67.963957 %\n",
            "Epoch 00039 | Loss 0.6366 | Time(s) 1.2340 | Accuracy: 68.155675 %\n",
            "Epoch 00040 | Loss 0.6747 | Time(s) 1.2343 | Accuracy: 68.165261 %\n",
            "Epoch 00041 | Loss 0.7749 | Time(s) 1.2340 | Accuracy: 68.184433 %\n",
            "Epoch 00042 | Loss 0.7025 | Time(s) 1.2338 | Accuracy: 68.069402 %\n",
            "Epoch 00043 | Loss 0.6319 | Time(s) 1.2346 | Accuracy: 68.184433 %\n",
            "Epoch 00044 | Loss 0.8050 | Time(s) 1.2351 | Accuracy: 68.289877 %\n",
            "Epoch 00045 | Loss 0.7167 | Time(s) 1.2346 | Accuracy: 68.472009 %\n",
            "Epoch 00046 | Loss 0.5812 | Time(s) 1.2337 | Accuracy: 68.213190 %\n",
            "Epoch 00047 | Loss 0.6612 | Time(s) 1.2336 | Accuracy: 68.165261 %\n",
            "Epoch 00048 | Loss 0.7218 | Time(s) 1.2333 | Accuracy: 68.021472 %\n",
            "Epoch 00049 | Loss 0.7647 | Time(s) 1.2333 | Accuracy: 68.203604 %\n",
            "Epoch 00050 | Loss 0.7108 | Time(s) 1.2330 | Accuracy: 68.078988 %\n",
            "Epoch 00051 | Loss 0.3807 | Time(s) 1.2340 | Accuracy: 67.973543 %\n",
            "Epoch 00052 | Loss 0.7692 | Time(s) 1.2338 | Accuracy: 68.519939 %\n",
            "Epoch 00053 | Loss 0.7155 | Time(s) 1.2339 | Accuracy: 68.261120 %\n",
            "Epoch 00054 | Loss 0.7792 | Time(s) 1.2342 | Accuracy: 68.126917 %\n",
            "Epoch 00055 | Loss 0.3766 | Time(s) 1.2349 | Accuracy: 68.165261 %\n",
            "Epoch 00056 | Loss 0.5765 | Time(s) 1.2358 | Accuracy: 68.261120 %\n",
            "Epoch 00057 | Loss 0.5728 | Time(s) 1.2352 | Accuracy: 68.194018 %\n",
            "Epoch 00058 | Loss 0.7199 | Time(s) 1.2353 | Accuracy: 68.270706 %\n",
            "Epoch 00059 | Loss 0.3776 | Time(s) 1.2345 | Accuracy: 68.146089 %\n",
            "Epoch 00060 | Loss 0.7272 | Time(s) 1.2345 | Accuracy: 68.136503 %\n",
            "Epoch 00061 | Loss 0.7266 | Time(s) 1.2353 | Accuracy: 68.184433 %\n",
            "Epoch 00062 | Loss 0.6291 | Time(s) 1.2360 | Accuracy: 68.270706 %\n",
            "Epoch 00063 | Loss 0.7583 | Time(s) 1.2357 | Accuracy: 67.820169 %\n",
            "Epoch 00064 | Loss 0.7045 | Time(s) 1.2361 | Accuracy: 68.376150 %\n",
            "Epoch 00065 | Loss 0.6729 | Time(s) 1.2355 | Accuracy: 68.280291 %\n",
            "Epoch 00066 | Loss 0.7046 | Time(s) 1.2362 | Accuracy: 68.414494 %\n",
            "Epoch 00067 | Loss 0.7596 | Time(s) 1.2357 | Accuracy: 68.337807 %\n",
            "Epoch 00068 | Loss 0.3765 | Time(s) 1.2359 | Accuracy: 68.146089 %\n",
            "Epoch 00069 | Loss 0.7302 | Time(s) 1.2355 | Accuracy: 68.203604 %\n",
            "Epoch 00070 | Loss 0.3745 | Time(s) 1.2351 | Accuracy: 68.241948 %\n",
            "Epoch 00071 | Loss 0.5690 | Time(s) 1.2350 | Accuracy: 68.280291 %\n",
            "Epoch 00072 | Loss 0.7512 | Time(s) 1.2347 | Accuracy: 68.491181 %\n",
            "Epoch 00073 | Loss 0.7060 | Time(s) 1.2346 | Accuracy: 68.424080 %\n",
            "Epoch 00074 | Loss 0.7047 | Time(s) 1.2344 | Accuracy: 68.510353 %\n",
            "Epoch 00075 | Loss 0.6455 | Time(s) 1.2342 | Accuracy: 68.510353 %\n",
            "Epoch 00076 | Loss 0.6867 | Time(s) 1.2344 | Accuracy: 67.963957 %\n",
            "Epoch 00077 | Loss 0.7320 | Time(s) 1.2340 | Accuracy: 68.376150 %\n",
            "Epoch 00078 | Loss 0.3741 | Time(s) 1.2342 | Accuracy: 68.443252 %\n",
            "Epoch 00079 | Loss 0.5688 | Time(s) 1.2341 | Accuracy: 68.443252 %\n",
            "Epoch 00080 | Loss 0.7557 | Time(s) 1.2344 | Accuracy: 68.222776 %\n",
            "Epoch 00081 | Loss 0.7526 | Time(s) 1.2344 | Accuracy: 68.376150 %\n",
            "Epoch 00082 | Loss 0.6439 | Time(s) 1.2344 | Accuracy: 68.510353 %\n",
            "Epoch 00083 | Loss 0.6254 | Time(s) 1.2342 | Accuracy: 68.634969 %\n",
            "Epoch 00084 | Loss 0.5701 | Time(s) 1.2344 | Accuracy: 68.443252 %\n",
            "Epoch 00085 | Loss 0.6455 | Time(s) 1.2355 | Accuracy: 68.385736 %\n",
            "Epoch 00086 | Loss 0.7578 | Time(s) 1.2351 | Accuracy: 68.328221 %\n",
            "Epoch 00087 | Loss 0.5542 | Time(s) 1.2351 | Accuracy: 68.356979 %\n",
            "Epoch 00088 | Loss 0.6270 | Time(s) 1.2350 | Accuracy: 68.452837 %\n",
            "Epoch 00089 | Loss 0.5668 | Time(s) 1.2347 | Accuracy: 68.491181 %\n",
            "Epoch 00090 | Loss 0.7564 | Time(s) 1.2350 | Accuracy: 68.539110 %\n",
            "Epoch 00091 | Loss 0.7477 | Time(s) 1.2348 | Accuracy: 68.452837 %\n",
            "Epoch 00092 | Loss 0.6441 | Time(s) 1.2351 | Accuracy: 68.309049 %\n",
            "Epoch 00093 | Loss 0.7230 | Time(s) 1.2347 | Accuracy: 68.069402 %\n",
            "Epoch 00094 | Loss 0.7032 | Time(s) 1.2341 | Accuracy: 68.232362 %\n",
            "Epoch 00095 | Loss 0.7024 | Time(s) 1.2339 | Accuracy: 68.165261 %\n",
            "Epoch 00096 | Loss 0.6441 | Time(s) 1.2340 | Accuracy: 68.222776 %\n",
            "Epoch 00097 | Loss 0.5660 | Time(s) 1.2337 | Accuracy: 68.443252 %\n",
            "Epoch 00098 | Loss 0.6437 | Time(s) 1.2338 | Accuracy: 68.385736 %\n",
            "Epoch 00099 | Loss 0.6248 | Time(s) 1.2333 | Accuracy: 68.251534 %\n",
            "Epoch 00100 | Loss 0.5520 | Time(s) 1.2332 | Accuracy: 68.519939 %\n",
            "Epoch 00101 | Loss 0.3713 | Time(s) 1.2327 | Accuracy: 68.366564 %\n",
            "Epoch 00102 | Loss 0.7449 | Time(s) 1.2322 | Accuracy: 68.587040 %\n",
            "Epoch 00103 | Loss 0.7449 | Time(s) 1.2325 | Accuracy: 68.587040 %\n",
            "Epoch 00104 | Loss 0.7497 | Time(s) 1.2321 | Accuracy: 68.596626 %\n",
            "Epoch 00105 | Loss 0.3720 | Time(s) 1.2324 | Accuracy: 68.462423 %\n",
            "Epoch 00106 | Loss 0.6239 | Time(s) 1.2323 | Accuracy: 68.385736 %\n",
            "Epoch 00107 | Loss 0.5655 | Time(s) 1.2321 | Accuracy: 68.539110 %\n",
            "Epoch 00108 | Loss 0.5524 | Time(s) 1.2318 | Accuracy: 68.404908 %\n",
            "Epoch 00109 | Loss 0.5773 | Time(s) 1.2325 | Accuracy: 68.472009 %\n",
            "Epoch 00110 | Loss 0.5488 | Time(s) 1.2321 | Accuracy: 68.117331 %\n",
            "Epoch 00111 | Loss 0.5353 | Time(s) 1.2329 | Accuracy: 68.443252 %\n",
            "Epoch 00112 | Loss 0.5332 | Time(s) 1.2330 | Accuracy: 68.126917 %\n",
            "Epoch 00113 | Loss 0.7334 | Time(s) 1.2332 | Accuracy: 68.328221 %\n",
            "Epoch 00114 | Loss 0.3718 | Time(s) 1.2331 | Accuracy: 68.385736 %\n",
            "Epoch 00115 | Loss 0.6436 | Time(s) 1.2331 | Accuracy: 68.500767 %\n",
            "Epoch 00116 | Loss 0.7055 | Time(s) 1.2329 | Accuracy: 68.615798 %\n",
            "Epoch 00117 | Loss 0.7745 | Time(s) 1.2328 | Accuracy: 68.491181 %\n",
            "Epoch 00118 | Loss 0.6585 | Time(s) 1.2325 | Accuracy: 68.050230 %\n",
            "Epoch 00119 | Loss 0.6293 | Time(s) 1.2322 | Accuracy: 68.098160 %\n",
            "Epoch 00120 | Loss 0.4198 | Time(s) 1.2322 | Accuracy: 67.494248 %\n",
            "Epoch 00121 | Loss 0.6700 | Time(s) 1.2320 | Accuracy: 67.446319 %\n",
            "Epoch 00122 | Loss 0.7725 | Time(s) 1.2321 | Accuracy: 68.011887 %\n",
            "Epoch 00123 | Loss 0.7851 | Time(s) 1.2322 | Accuracy: 67.388804 %\n",
            "Epoch 00124 | Loss 0.3728 | Time(s) 1.2320 | Accuracy: 67.254601 %\n",
            "Epoch 00125 | Loss 0.8288 | Time(s) 1.2320 | Accuracy: 67.340874 %\n",
            "Epoch 00126 | Loss 0.7850 | Time(s) 1.2316 | Accuracy: 67.532592 %\n",
            "Epoch 00127 | Loss 0.6274 | Time(s) 1.2316 | Accuracy: 67.800997 %\n",
            "Epoch 00128 | Loss 0.7872 | Time(s) 1.2314 | Accuracy: 65.835890 %\n",
            "Epoch 00129 | Loss 0.7367 | Time(s) 1.2317 | Accuracy: 67.197086 %\n",
            "Epoch 00130 | Loss 0.3786 | Time(s) 1.2314 | Accuracy: 67.868098 %\n",
            "Epoch 00131 | Loss 0.5825 | Time(s) 1.2313 | Accuracy: 68.136503 %\n",
            "Epoch 00132 | Loss 0.6364 | Time(s) 1.2314 | Accuracy: 68.807515 %\n",
            "Epoch 00133 | Loss 0.6352 | Time(s) 1.2318 | Accuracy: 68.721242 %\n",
            "Epoch 00134 | Loss 0.7080 | Time(s) 1.2321 | Accuracy: 68.893788 %\n",
            "Epoch 00135 | Loss 0.6328 | Time(s) 1.2321 | Accuracy: 69.056748 %\n",
            "Epoch 00136 | Loss 0.5730 | Time(s) 1.2329 | Accuracy: 69.104678 %\n",
            "Epoch 00137 | Loss 0.3721 | Time(s) 1.2327 | Accuracy: 69.027991 %\n",
            "Epoch 00138 | Loss 0.7349 | Time(s) 1.2327 | Accuracy: 69.085506 %\n",
            "Epoch 00139 | Loss 0.3728 | Time(s) 1.2325 | Accuracy: 69.027991 %\n",
            "Epoch 00140 | Loss 0.3726 | Time(s) 1.2326 | Accuracy: 69.095092 %\n",
            "Epoch 00141 | Loss 0.7019 | Time(s) 1.2327 | Accuracy: 69.075920 %\n",
            "Epoch 00142 | Loss 0.6452 | Time(s) 1.2323 | Accuracy: 69.085506 %\n",
            "Epoch 00143 | Loss 0.6449 | Time(s) 1.2321 | Accuracy: 69.334739 %\n",
            "Epoch 00144 | Loss 0.7030 | Time(s) 1.2318 | Accuracy: 69.219709 %\n",
            "Epoch 00145 | Loss 0.6247 | Time(s) 1.2322 | Accuracy: 69.334739 %\n",
            "Epoch 00146 | Loss 0.5657 | Time(s) 1.2326 | Accuracy: 69.344325 %\n",
            "Epoch 00147 | Loss 0.7442 | Time(s) 1.2325 | Accuracy: 69.325153 %\n",
            "Epoch 00148 | Loss 0.6244 | Time(s) 1.2326 | Accuracy: 69.171779 %\n",
            "Epoch 00149 | Loss 0.7017 | Time(s) 1.2326 | Accuracy: 69.123850 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.8342 | Time(s) 1.2265 | Accuracy: 15.778374 %\n",
            "Epoch 00001 | Loss 1.7408 | Time(s) 1.2109 | Accuracy: 29.658742 %\n",
            "Epoch 00002 | Loss 1.7472 | Time(s) 1.2036 | Accuracy: 26.504985 %\n",
            "Epoch 00003 | Loss 1.6426 | Time(s) 1.2113 | Accuracy: 30.205138 %\n",
            "Epoch 00004 | Loss 1.5927 | Time(s) 1.2297 | Accuracy: 31.058282 %\n",
            "Epoch 00005 | Loss 1.6102 | Time(s) 1.2288 | Accuracy: 30.348926 %\n",
            "Epoch 00006 | Loss 1.5741 | Time(s) 1.2289 | Accuracy: 30.914494 %\n",
            "Epoch 00007 | Loss 1.5139 | Time(s) 1.2281 | Accuracy: 31.077454 %\n",
            "Epoch 00008 | Loss 1.6978 | Time(s) 1.2273 | Accuracy: 31.374617 %\n",
            "Epoch 00009 | Loss 1.5605 | Time(s) 1.2244 | Accuracy: 31.067868 %\n",
            "Epoch 00010 | Loss 1.5523 | Time(s) 1.2180 | Accuracy: 31.805982 %\n",
            "Epoch 00011 | Loss 1.5570 | Time(s) 1.2153 | Accuracy: 31.767638 %\n",
            "Epoch 00012 | Loss 1.5918 | Time(s) 1.2146 | Accuracy: 31.892255 %\n",
            "Epoch 00013 | Loss 1.7168 | Time(s) 1.2100 | Accuracy: 31.786810 %\n",
            "Epoch 00014 | Loss 1.5285 | Time(s) 1.2062 | Accuracy: 31.633436 %\n",
            "Epoch 00015 | Loss 1.5497 | Time(s) 1.2047 | Accuracy: 31.758052 %\n",
            "Epoch 00016 | Loss 1.5520 | Time(s) 1.2018 | Accuracy: 31.738880 %\n",
            "Epoch 00017 | Loss 1.6835 | Time(s) 1.2027 | Accuracy: 31.537577 %\n",
            "Epoch 00018 | Loss 1.5482 | Time(s) 1.1995 | Accuracy: 31.508819 %\n",
            "Epoch 00019 | Loss 1.4356 | Time(s) 1.1981 | Accuracy: 31.307515 %\n",
            "Epoch 00020 | Loss 1.4283 | Time(s) 1.1964 | Accuracy: 31.288344 %\n",
            "Epoch 00021 | Loss 1.4159 | Time(s) 1.1954 | Accuracy: 31.403374 %\n",
            "Epoch 00022 | Loss 1.5056 | Time(s) 1.1950 | Accuracy: 31.566334 %\n",
            "Epoch 00023 | Loss 1.6529 | Time(s) 1.1938 | Accuracy: 31.566334 %\n",
            "Epoch 00024 | Loss 1.5137 | Time(s) 1.1927 | Accuracy: 31.480061 %\n",
            "Epoch 00025 | Loss 1.4164 | Time(s) 1.1923 | Accuracy: 31.422546 %\n",
            "Epoch 00026 | Loss 1.4152 | Time(s) 1.1916 | Accuracy: 31.508819 %\n",
            "Epoch 00027 | Loss 1.6619 | Time(s) 1.1922 | Accuracy: 31.480061 %\n",
            "Epoch 00028 | Loss 1.4861 | Time(s) 1.1905 | Accuracy: 31.250000 %\n",
            "Epoch 00029 | Loss 1.5605 | Time(s) 1.1951 | Accuracy: 31.230828 %\n",
            "Epoch 00030 | Loss 1.5108 | Time(s) 1.1947 | Accuracy: 31.010353 %\n",
            "Epoch 00031 | Loss 1.5618 | Time(s) 1.1955 | Accuracy: 31.134969 %\n",
            "Epoch 00032 | Loss 1.5004 | Time(s) 1.1943 | Accuracy: 31.307515 %\n",
            "Epoch 00033 | Loss 1.4139 | Time(s) 1.1942 | Accuracy: 30.924080 %\n",
            "Epoch 00034 | Loss 1.5584 | Time(s) 1.1936 | Accuracy: 30.943252 %\n",
            "Epoch 00035 | Loss 1.5004 | Time(s) 1.1937 | Accuracy: 31.211656 %\n",
            "Epoch 00036 | Loss 1.5037 | Time(s) 1.1927 | Accuracy: 31.192485 %\n",
            "Epoch 00037 | Loss 1.4044 | Time(s) 1.1932 | Accuracy: 30.818635 %\n",
            "Epoch 00038 | Loss 1.4043 | Time(s) 1.1932 | Accuracy: 31.106212 %\n",
            "Epoch 00039 | Loss 1.4882 | Time(s) 1.1932 | Accuracy: 31.614264 %\n",
            "Epoch 00040 | Loss 1.6410 | Time(s) 1.1931 | Accuracy: 31.575920 %\n",
            "Epoch 00041 | Loss 1.6435 | Time(s) 1.1935 | Accuracy: 31.154141 %\n",
            "Epoch 00042 | Loss 1.5029 | Time(s) 1.1932 | Accuracy: 31.134969 %\n",
            "Epoch 00043 | Loss 1.5385 | Time(s) 1.1928 | Accuracy: 31.278758 %\n",
            "Epoch 00044 | Loss 1.5380 | Time(s) 1.1918 | Accuracy: 31.384202 %\n",
            "Epoch 00045 | Loss 1.5712 | Time(s) 1.1911 | Accuracy: 31.652607 %\n",
            "Epoch 00046 | Loss 1.6384 | Time(s) 1.1909 | Accuracy: 31.566334 %\n",
            "Epoch 00047 | Loss 1.4887 | Time(s) 1.1906 | Accuracy: 31.460890 %\n",
            "Epoch 00048 | Loss 1.4023 | Time(s) 1.1907 | Accuracy: 31.489647 %\n",
            "Epoch 00049 | Loss 1.4034 | Time(s) 1.1893 | Accuracy: 31.748466 %\n",
            "Epoch 00050 | Loss 1.5401 | Time(s) 1.1896 | Accuracy: 31.643021 %\n",
            "Epoch 00051 | Loss 1.4028 | Time(s) 1.1900 | Accuracy: 31.470475 %\n",
            "Epoch 00052 | Loss 1.6371 | Time(s) 1.1897 | Accuracy: 31.412960 %\n",
            "Epoch 00053 | Loss 1.4811 | Time(s) 1.1888 | Accuracy: 31.221242 %\n",
            "Epoch 00054 | Loss 1.4991 | Time(s) 1.1889 | Accuracy: 31.566334 %\n",
            "Epoch 00055 | Loss 1.4034 | Time(s) 1.1891 | Accuracy: 31.259586 %\n",
            "Epoch 00056 | Loss 1.4990 | Time(s) 1.1885 | Accuracy: 31.345859 %\n",
            "Epoch 00057 | Loss 1.4024 | Time(s) 1.1882 | Accuracy: 31.441718 %\n",
            "Epoch 00058 | Loss 1.4989 | Time(s) 1.1875 | Accuracy: 31.336273 %\n",
            "Epoch 00059 | Loss 1.5019 | Time(s) 1.1878 | Accuracy: 31.777224 %\n",
            "Epoch 00060 | Loss 1.4987 | Time(s) 1.1871 | Accuracy: 31.758052 %\n",
            "Epoch 00061 | Loss 1.4021 | Time(s) 1.1863 | Accuracy: 31.901840 %\n",
            "Epoch 00062 | Loss 1.4794 | Time(s) 1.1856 | Accuracy: 31.700537 %\n",
            "Epoch 00063 | Loss 1.4793 | Time(s) 1.1847 | Accuracy: 31.825153 %\n",
            "Epoch 00064 | Loss 1.4793 | Time(s) 1.1848 | Accuracy: 31.690951 %\n",
            "Epoch 00065 | Loss 1.4015 | Time(s) 1.1842 | Accuracy: 31.527991 %\n",
            "Epoch 00066 | Loss 1.5376 | Time(s) 1.1837 | Accuracy: 31.451304 %\n",
            "Epoch 00067 | Loss 1.4019 | Time(s) 1.1835 | Accuracy: 31.336273 %\n",
            "Epoch 00068 | Loss 1.6361 | Time(s) 1.1832 | Accuracy: 31.374617 %\n",
            "Epoch 00069 | Loss 1.6570 | Time(s) 1.1824 | Accuracy: 31.173313 %\n",
            "Epoch 00070 | Loss 1.5456 | Time(s) 1.1835 | Accuracy: 31.432132 %\n",
            "Epoch 00071 | Loss 1.5378 | Time(s) 1.1827 | Accuracy: 31.710123 %\n",
            "Epoch 00072 | Loss 1.4986 | Time(s) 1.1820 | Accuracy: 31.767638 %\n",
            "Epoch 00073 | Loss 1.4985 | Time(s) 1.1816 | Accuracy: 31.748466 %\n",
            "Epoch 00074 | Loss 1.4015 | Time(s) 1.1809 | Accuracy: 31.575920 %\n",
            "Epoch 00075 | Loss 1.4986 | Time(s) 1.1802 | Accuracy: 31.585506 %\n",
            "Epoch 00076 | Loss 1.6639 | Time(s) 1.1797 | Accuracy: 31.614264 %\n",
            "Epoch 00077 | Loss 1.4017 | Time(s) 1.1797 | Accuracy: 31.326687 %\n",
            "Epoch 00078 | Loss 1.5378 | Time(s) 1.1793 | Accuracy: 30.818635 %\n",
            "Epoch 00079 | Loss 1.4986 | Time(s) 1.1788 | Accuracy: 31.432132 %\n",
            "Epoch 00080 | Loss 1.5038 | Time(s) 1.1783 | Accuracy: 31.460890 %\n",
            "Epoch 00081 | Loss 1.5006 | Time(s) 1.1784 | Accuracy: 31.029525 %\n",
            "Epoch 00082 | Loss 1.4988 | Time(s) 1.1790 | Accuracy: 30.636503 %\n",
            "Epoch 00083 | Loss 1.5573 | Time(s) 1.1788 | Accuracy: 31.326687 %\n",
            "Epoch 00084 | Loss 1.4030 | Time(s) 1.1784 | Accuracy: 31.345859 %\n",
            "Epoch 00085 | Loss 1.4997 | Time(s) 1.1777 | Accuracy: 31.441718 %\n",
            "Epoch 00086 | Loss 1.6551 | Time(s) 1.1777 | Accuracy: 31.365031 %\n",
            "Epoch 00087 | Loss 1.6578 | Time(s) 1.1770 | Accuracy: 31.048696 %\n",
            "Epoch 00088 | Loss 1.4018 | Time(s) 1.1768 | Accuracy: 31.173313 %\n",
            "Epoch 00089 | Loss 1.4018 | Time(s) 1.1763 | Accuracy: 31.077454 %\n",
            "Epoch 00090 | Loss 1.4986 | Time(s) 1.1756 | Accuracy: 31.269172 %\n",
            "Epoch 00091 | Loss 1.5246 | Time(s) 1.1758 | Accuracy: 31.163727 %\n",
            "Epoch 00092 | Loss 1.6357 | Time(s) 1.1753 | Accuracy: 31.393788 %\n",
            "Epoch 00093 | Loss 1.4988 | Time(s) 1.1752 | Accuracy: 31.374617 %\n",
            "Epoch 00094 | Loss 1.4015 | Time(s) 1.1753 | Accuracy: 31.432132 %\n",
            "Epoch 00095 | Loss 1.4016 | Time(s) 1.1751 | Accuracy: 31.527991 %\n",
            "Epoch 00096 | Loss 1.4013 | Time(s) 1.1752 | Accuracy: 31.518405 %\n",
            "Epoch 00097 | Loss 1.6548 | Time(s) 1.1746 | Accuracy: 31.489647 %\n",
            "Epoch 00098 | Loss 1.6546 | Time(s) 1.1743 | Accuracy: 31.518405 %\n",
            "Epoch 00099 | Loss 1.5005 | Time(s) 1.1738 | Accuracy: 31.403374 %\n",
            "Epoch 00100 | Loss 1.4792 | Time(s) 1.1740 | Accuracy: 31.566334 %\n",
            "Epoch 00101 | Loss 1.4985 | Time(s) 1.1740 | Accuracy: 31.480061 %\n",
            "Epoch 00102 | Loss 1.6353 | Time(s) 1.1746 | Accuracy: 31.719709 %\n",
            "Epoch 00103 | Loss 1.5417 | Time(s) 1.1743 | Accuracy: 31.719709 %\n",
            "Epoch 00104 | Loss 1.5374 | Time(s) 1.1739 | Accuracy: 31.738880 %\n",
            "Epoch 00105 | Loss 1.5374 | Time(s) 1.1736 | Accuracy: 31.652607 %\n",
            "Epoch 00106 | Loss 1.6932 | Time(s) 1.1740 | Accuracy: 31.825153 %\n",
            "Epoch 00107 | Loss 1.5374 | Time(s) 1.1740 | Accuracy: 31.240414 %\n",
            "Epoch 00108 | Loss 1.5374 | Time(s) 1.1748 | Accuracy: 30.463957 %\n",
            "Epoch 00109 | Loss 1.4014 | Time(s) 1.1751 | Accuracy: 31.259586 %\n",
            "Epoch 00110 | Loss 1.6705 | Time(s) 1.1755 | Accuracy: 31.758052 %\n",
            "Epoch 00111 | Loss 1.6355 | Time(s) 1.1753 | Accuracy: 31.825153 %\n",
            "Epoch 00112 | Loss 1.5500 | Time(s) 1.1753 | Accuracy: 31.297929 %\n",
            "Epoch 00113 | Loss 1.4844 | Time(s) 1.1754 | Accuracy: 30.962423 %\n",
            "Epoch 00114 | Loss 1.4027 | Time(s) 1.1750 | Accuracy: 30.952837 %\n",
            "Epoch 00115 | Loss 1.4987 | Time(s) 1.1754 | Accuracy: 31.039110 %\n",
            "Epoch 00116 | Loss 1.4047 | Time(s) 1.1750 | Accuracy: 30.789877 %\n",
            "Epoch 00117 | Loss 1.4792 | Time(s) 1.1747 | Accuracy: 30.895322 %\n",
            "Epoch 00118 | Loss 1.4915 | Time(s) 1.1744 | Accuracy: 31.096626 %\n",
            "Epoch 00119 | Loss 1.4820 | Time(s) 1.1744 | Accuracy: 31.039110 %\n",
            "Epoch 00120 | Loss 1.6353 | Time(s) 1.1748 | Accuracy: 31.250000 %\n",
            "Epoch 00121 | Loss 1.4995 | Time(s) 1.1743 | Accuracy: 31.154141 %\n",
            "Epoch 00122 | Loss 1.5414 | Time(s) 1.1739 | Accuracy: 30.943252 %\n",
            "Epoch 00123 | Loss 1.4831 | Time(s) 1.1738 | Accuracy: 31.039110 %\n",
            "Epoch 00124 | Loss 1.6550 | Time(s) 1.1734 | Accuracy: 31.077454 %\n",
            "Epoch 00125 | Loss 1.4863 | Time(s) 1.1732 | Accuracy: 31.259586 %\n",
            "Epoch 00126 | Loss 1.6351 | Time(s) 1.1729 | Accuracy: 31.154141 %\n",
            "Epoch 00127 | Loss 1.5004 | Time(s) 1.1728 | Accuracy: 31.134969 %\n",
            "Epoch 00128 | Loss 1.5546 | Time(s) 1.1726 | Accuracy: 31.144555 %\n",
            "Epoch 00129 | Loss 1.6352 | Time(s) 1.1726 | Accuracy: 31.182899 %\n",
            "Epoch 00130 | Loss 1.6352 | Time(s) 1.1726 | Accuracy: 31.000767 %\n",
            "Epoch 00131 | Loss 1.5377 | Time(s) 1.1727 | Accuracy: 30.933666 %\n",
            "Epoch 00132 | Loss 1.4012 | Time(s) 1.1732 | Accuracy: 31.250000 %\n",
            "Epoch 00133 | Loss 1.4790 | Time(s) 1.1735 | Accuracy: 31.077454 %\n",
            "Epoch 00134 | Loss 1.5374 | Time(s) 1.1736 | Accuracy: 31.211656 %\n",
            "Epoch 00135 | Loss 1.6543 | Time(s) 1.1740 | Accuracy: 31.154141 %\n",
            "Epoch 00136 | Loss 1.5380 | Time(s) 1.1741 | Accuracy: 30.991181 %\n",
            "Epoch 00137 | Loss 1.5001 | Time(s) 1.1742 | Accuracy: 31.115798 %\n",
            "Epoch 00138 | Loss 1.4018 | Time(s) 1.1743 | Accuracy: 30.914494 %\n",
            "Epoch 00139 | Loss 1.4956 | Time(s) 1.1745 | Accuracy: 31.010353 %\n",
            "Epoch 00140 | Loss 1.4013 | Time(s) 1.1748 | Accuracy: 31.269172 %\n",
            "Epoch 00141 | Loss 1.4012 | Time(s) 1.1745 | Accuracy: 31.019939 %\n",
            "Epoch 00142 | Loss 1.5451 | Time(s) 1.1746 | Accuracy: 30.866564 %\n",
            "Epoch 00143 | Loss 1.4984 | Time(s) 1.1745 | Accuracy: 31.019939 %\n",
            "Epoch 00144 | Loss 1.5427 | Time(s) 1.1747 | Accuracy: 30.991181 %\n",
            "Epoch 00145 | Loss 1.4211 | Time(s) 1.1747 | Accuracy: 30.972009 %\n",
            "Epoch 00146 | Loss 1.4986 | Time(s) 1.1744 | Accuracy: 30.981595 %\n",
            "Epoch 00147 | Loss 1.4893 | Time(s) 1.1742 | Accuracy: 31.048696 %\n",
            "Epoch 00148 | Loss 1.6351 | Time(s) 1.1738 | Accuracy: 31.182899 %\n",
            "Epoch 00149 | Loss 1.4013 | Time(s) 1.1735 | Accuracy: 30.943252 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7833 | Time(s) 1.1434 | Accuracy: 26.322853 %\n",
            "Epoch 00001 | Loss 1.5326 | Time(s) 1.1752 | Accuracy: 52.616948 %\n",
            "Epoch 00002 | Loss 1.1810 | Time(s) 1.1780 | Accuracy: 66.018021 %\n",
            "Epoch 00003 | Loss 1.0488 | Time(s) 1.1685 | Accuracy: 69.526457 %\n",
            "Epoch 00004 | Loss 0.7500 | Time(s) 1.1843 | Accuracy: 72.306365 %\n",
            "Epoch 00005 | Loss 0.8178 | Time(s) 1.1857 | Accuracy: 74.750767 %\n",
            "Epoch 00006 | Loss 0.6757 | Time(s) 1.1897 | Accuracy: 77.645706 %\n",
            "Epoch 00007 | Loss 0.6473 | Time(s) 1.2015 | Accuracy: 79.016488 %\n",
            "Epoch 00008 | Loss 0.4366 | Time(s) 1.2001 | Accuracy: 78.958972 %\n",
            "Epoch 00009 | Loss 0.5283 | Time(s) 1.1970 | Accuracy: 80.674847 %\n",
            "Epoch 00010 | Loss 0.4054 | Time(s) 1.1950 | Accuracy: 80.828221 %\n",
            "Epoch 00011 | Loss 0.5368 | Time(s) 1.1913 | Accuracy: 80.694018 %\n",
            "Epoch 00012 | Loss 0.4295 | Time(s) 1.1892 | Accuracy: 80.904908 %\n",
            "Epoch 00013 | Loss 0.3442 | Time(s) 1.1862 | Accuracy: 80.425613 %\n",
            "Epoch 00014 | Loss 0.2747 | Time(s) 1.1827 | Accuracy: 80.761120 %\n",
            "Epoch 00015 | Loss 0.3973 | Time(s) 1.1836 | Accuracy: 80.741948 %\n",
            "Epoch 00016 | Loss 0.2801 | Time(s) 1.1825 | Accuracy: 81.518405 %\n",
            "Epoch 00017 | Loss 0.2238 | Time(s) 1.1841 | Accuracy: 81.614264 %\n",
            "Epoch 00018 | Loss 0.2077 | Time(s) 1.1826 | Accuracy: 81.652607 %\n",
            "Epoch 00019 | Loss 0.2062 | Time(s) 1.1825 | Accuracy: 82.151074 %\n",
            "Epoch 00020 | Loss 0.2746 | Time(s) 1.1821 | Accuracy: 81.796396 %\n",
            "Epoch 00021 | Loss 0.3916 | Time(s) 1.1829 | Accuracy: 82.352377 %\n",
            "Epoch 00022 | Loss 0.1827 | Time(s) 1.1820 | Accuracy: 82.016871 %\n",
            "Epoch 00023 | Loss 0.2409 | Time(s) 1.1811 | Accuracy: 81.892255 %\n",
            "Epoch 00024 | Loss 0.2323 | Time(s) 1.1809 | Accuracy: 82.189417 %\n",
            "Epoch 00025 | Loss 0.2146 | Time(s) 1.1797 | Accuracy: 82.649540 %\n",
            "Epoch 00026 | Loss 0.5515 | Time(s) 1.1787 | Accuracy: 82.965874 %\n",
            "Epoch 00027 | Loss 0.1999 | Time(s) 1.1811 | Accuracy: 82.965874 %\n",
            "Epoch 00028 | Loss 0.4730 | Time(s) 1.1816 | Accuracy: 82.687883 %\n",
            "Epoch 00029 | Loss 0.2445 | Time(s) 1.1819 | Accuracy: 82.553681 %\n",
            "Epoch 00030 | Loss 0.2731 | Time(s) 1.1823 | Accuracy: 82.946702 %\n",
            "Epoch 00031 | Loss 0.1358 | Time(s) 1.1818 | Accuracy: 83.109663 %\n",
            "Epoch 00032 | Loss 0.1862 | Time(s) 1.1819 | Accuracy: 82.994632 %\n",
            "Epoch 00033 | Loss 0.1107 | Time(s) 1.1829 | Accuracy: 82.218175 %\n",
            "Epoch 00034 | Loss 0.2537 | Time(s) 1.1818 | Accuracy: 82.400307 %\n",
            "Epoch 00035 | Loss 0.1634 | Time(s) 1.1810 | Accuracy: 83.224693 %\n",
            "Epoch 00036 | Loss 0.1630 | Time(s) 1.1823 | Accuracy: 82.726227 %\n",
            "Epoch 00037 | Loss 0.1113 | Time(s) 1.1816 | Accuracy: 82.592025 %\n",
            "Epoch 00038 | Loss 0.2531 | Time(s) 1.1819 | Accuracy: 82.534509 %\n",
            "Epoch 00039 | Loss 0.2389 | Time(s) 1.1812 | Accuracy: 82.524923 %\n",
            "Epoch 00040 | Loss 0.1071 | Time(s) 1.1818 | Accuracy: 82.831672 %\n",
            "Epoch 00041 | Loss 0.1388 | Time(s) 1.1818 | Accuracy: 82.774156 %\n",
            "Epoch 00042 | Loss 0.1878 | Time(s) 1.1835 | Accuracy: 82.898773 %\n",
            "Epoch 00043 | Loss 0.1155 | Time(s) 1.1832 | Accuracy: 82.965874 %\n",
            "Epoch 00044 | Loss 0.1566 | Time(s) 1.1824 | Accuracy: 82.946702 %\n",
            "Epoch 00045 | Loss 0.1539 | Time(s) 1.1818 | Accuracy: 82.620782 %\n",
            "Epoch 00046 | Loss 0.1232 | Time(s) 1.1807 | Accuracy: 82.831672 %\n",
            "Epoch 00047 | Loss 0.3573 | Time(s) 1.1815 | Accuracy: 83.195936 %\n",
            "Epoch 00048 | Loss 0.1195 | Time(s) 1.1819 | Accuracy: 82.496166 %\n",
            "Epoch 00049 | Loss 0.1496 | Time(s) 1.1814 | Accuracy: 82.774156 %\n",
            "Epoch 00050 | Loss 0.2636 | Time(s) 1.1809 | Accuracy: 83.109663 %\n",
            "Epoch 00051 | Loss 0.1145 | Time(s) 1.1809 | Accuracy: 83.090491 %\n",
            "Epoch 00052 | Loss 0.1102 | Time(s) 1.1813 | Accuracy: 82.707055 %\n",
            "Epoch 00053 | Loss 0.1405 | Time(s) 1.1819 | Accuracy: 83.042561 %\n",
            "Epoch 00054 | Loss 0.1589 | Time(s) 1.1834 | Accuracy: 83.109663 %\n",
            "Epoch 00055 | Loss 0.0781 | Time(s) 1.1828 | Accuracy: 83.234279 %\n",
            "Epoch 00056 | Loss 0.1713 | Time(s) 1.1833 | Accuracy: 83.224693 %\n",
            "Epoch 00057 | Loss 0.1312 | Time(s) 1.1826 | Accuracy: 83.148006 %\n",
            "Epoch 00058 | Loss 0.2673 | Time(s) 1.1837 | Accuracy: 83.263037 %\n",
            "Epoch 00059 | Loss 0.1287 | Time(s) 1.1829 | Accuracy: 83.243865 %\n",
            "Epoch 00060 | Loss 0.2542 | Time(s) 1.1829 | Accuracy: 83.042561 %\n",
            "Epoch 00061 | Loss 0.0910 | Time(s) 1.1823 | Accuracy: 82.927531 %\n",
            "Epoch 00062 | Loss 0.1305 | Time(s) 1.1820 | Accuracy: 83.080905 %\n",
            "Epoch 00063 | Loss 0.0762 | Time(s) 1.1821 | Accuracy: 83.195936 %\n",
            "Epoch 00064 | Loss 0.1081 | Time(s) 1.1817 | Accuracy: 83.195936 %\n",
            "Epoch 00065 | Loss 0.1070 | Time(s) 1.1816 | Accuracy: 83.138420 %\n",
            "Epoch 00066 | Loss 0.1050 | Time(s) 1.1810 | Accuracy: 83.148006 %\n",
            "Epoch 00067 | Loss 0.1033 | Time(s) 1.1805 | Accuracy: 83.291794 %\n",
            "Epoch 00068 | Loss 0.1279 | Time(s) 1.1806 | Accuracy: 82.956288 %\n",
            "Epoch 00069 | Loss 0.1332 | Time(s) 1.1803 | Accuracy: 82.908359 %\n",
            "Epoch 00070 | Loss 0.1288 | Time(s) 1.1803 | Accuracy: 83.157592 %\n",
            "Epoch 00071 | Loss 0.1045 | Time(s) 1.1794 | Accuracy: 82.965874 %\n",
            "Epoch 00072 | Loss 0.0690 | Time(s) 1.1788 | Accuracy: 82.716641 %\n",
            "Epoch 00073 | Loss 0.0887 | Time(s) 1.1788 | Accuracy: 83.339724 %\n",
            "Epoch 00074 | Loss 0.0677 | Time(s) 1.1784 | Accuracy: 83.263037 %\n",
            "Epoch 00075 | Loss 0.0933 | Time(s) 1.1782 | Accuracy: 83.493098 %\n",
            "Epoch 00076 | Loss 0.1044 | Time(s) 1.1781 | Accuracy: 83.349310 %\n",
            "Epoch 00077 | Loss 0.0725 | Time(s) 1.1785 | Accuracy: 82.678298 %\n",
            "Epoch 00078 | Loss 0.1017 | Time(s) 1.1783 | Accuracy: 82.476994 %\n",
            "Epoch 00079 | Loss 0.0979 | Time(s) 1.1788 | Accuracy: 82.639954 %\n",
            "Epoch 00080 | Loss 0.1631 | Time(s) 1.1787 | Accuracy: 83.167178 %\n",
            "Epoch 00081 | Loss 0.1019 | Time(s) 1.1787 | Accuracy: 83.454755 %\n",
            "Epoch 00082 | Loss 0.1269 | Time(s) 1.1791 | Accuracy: 83.397239 %\n",
            "Epoch 00083 | Loss 0.1465 | Time(s) 1.1786 | Accuracy: 83.406825 %\n",
            "Epoch 00084 | Loss 0.1453 | Time(s) 1.1785 | Accuracy: 83.627301 %\n",
            "Epoch 00085 | Loss 0.1470 | Time(s) 1.1791 | Accuracy: 83.636887 %\n",
            "Epoch 00086 | Loss 0.1026 | Time(s) 1.1796 | Accuracy: 83.167178 %\n",
            "Epoch 00087 | Loss 0.1440 | Time(s) 1.1797 | Accuracy: 83.004218 %\n",
            "Epoch 00088 | Loss 0.0878 | Time(s) 1.1796 | Accuracy: 83.358896 %\n",
            "Epoch 00089 | Loss 0.2294 | Time(s) 1.1810 | Accuracy: 83.569785 %\n",
            "Epoch 00090 | Loss 0.1007 | Time(s) 1.1812 | Accuracy: 83.617715 %\n",
            "Epoch 00091 | Loss 0.1213 | Time(s) 1.1808 | Accuracy: 83.349310 %\n",
            "Epoch 00092 | Loss 0.1445 | Time(s) 1.1804 | Accuracy: 83.703988 %\n",
            "Epoch 00093 | Loss 0.1238 | Time(s) 1.1803 | Accuracy: 83.502684 %\n",
            "Epoch 00094 | Loss 0.1861 | Time(s) 1.1802 | Accuracy: 83.224693 %\n",
            "Epoch 00095 | Loss 0.1275 | Time(s) 1.1804 | Accuracy: 83.368482 %\n",
            "Epoch 00096 | Loss 0.1220 | Time(s) 1.1804 | Accuracy: 83.128834 %\n",
            "Epoch 00097 | Loss 0.0913 | Time(s) 1.1801 | Accuracy: 82.994632 %\n",
            "Epoch 00098 | Loss 0.1000 | Time(s) 1.1801 | Accuracy: 83.358896 %\n",
            "Epoch 00099 | Loss 0.0964 | Time(s) 1.1802 | Accuracy: 83.358896 %\n",
            "Epoch 00100 | Loss 0.1410 | Time(s) 1.1806 | Accuracy: 82.965874 %\n",
            "Epoch 00101 | Loss 0.1019 | Time(s) 1.1808 | Accuracy: 83.023390 %\n",
            "Epoch 00102 | Loss 0.1241 | Time(s) 1.1809 | Accuracy: 83.521856 %\n",
            "Epoch 00103 | Loss 0.0685 | Time(s) 1.1812 | Accuracy: 83.445169 %\n",
            "Epoch 00104 | Loss 0.1003 | Time(s) 1.1816 | Accuracy: 83.397239 %\n",
            "Epoch 00105 | Loss 0.1340 | Time(s) 1.1824 | Accuracy: 83.148006 %\n",
            "Epoch 00106 | Loss 0.1218 | Time(s) 1.1822 | Accuracy: 82.697469 %\n",
            "Epoch 00107 | Loss 0.0826 | Time(s) 1.1831 | Accuracy: 82.572853 %\n",
            "Epoch 00108 | Loss 0.2315 | Time(s) 1.1828 | Accuracy: 82.917945 %\n",
            "Epoch 00109 | Loss 0.1557 | Time(s) 1.1834 | Accuracy: 83.550613 %\n",
            "Epoch 00110 | Loss 0.1294 | Time(s) 1.1830 | Accuracy: 83.617715 %\n",
            "Epoch 00111 | Loss 0.0856 | Time(s) 1.1829 | Accuracy: 83.435583 %\n",
            "Epoch 00112 | Loss 0.1399 | Time(s) 1.1832 | Accuracy: 83.330138 %\n",
            "Epoch 00113 | Loss 0.1203 | Time(s) 1.1832 | Accuracy: 83.483512 %\n",
            "Epoch 00114 | Loss 0.0926 | Time(s) 1.1828 | Accuracy: 83.636887 %\n",
            "Epoch 00115 | Loss 0.1530 | Time(s) 1.1825 | Accuracy: 83.330138 %\n",
            "Epoch 00116 | Loss 0.1401 | Time(s) 1.1820 | Accuracy: 82.965874 %\n",
            "Epoch 00117 | Loss 0.0616 | Time(s) 1.1820 | Accuracy: 82.946702 %\n",
            "Epoch 00118 | Loss 0.1394 | Time(s) 1.1822 | Accuracy: 83.473926 %\n",
            "Epoch 00119 | Loss 0.0616 | Time(s) 1.1828 | Accuracy: 83.464340 %\n",
            "Epoch 00120 | Loss 0.0993 | Time(s) 1.1828 | Accuracy: 83.224693 %\n",
            "Epoch 00121 | Loss 0.1209 | Time(s) 1.1827 | Accuracy: 83.263037 %\n",
            "Epoch 00122 | Loss 0.2342 | Time(s) 1.1823 | Accuracy: 83.167178 %\n",
            "Epoch 00123 | Loss 0.0989 | Time(s) 1.1822 | Accuracy: 82.898773 %\n",
            "Epoch 00124 | Loss 0.0994 | Time(s) 1.1823 | Accuracy: 83.186350 %\n",
            "Epoch 00125 | Loss 0.1194 | Time(s) 1.1819 | Accuracy: 83.349310 %\n",
            "Epoch 00126 | Loss 0.1391 | Time(s) 1.1818 | Accuracy: 83.119248 %\n",
            "Epoch 00127 | Loss 0.1192 | Time(s) 1.1817 | Accuracy: 83.205521 %\n",
            "Epoch 00128 | Loss 0.1435 | Time(s) 1.1815 | Accuracy: 83.234279 %\n",
            "Epoch 00129 | Loss 0.1000 | Time(s) 1.1813 | Accuracy: 83.052147 %\n",
            "Epoch 00130 | Loss 0.2287 | Time(s) 1.1824 | Accuracy: 82.716641 %\n",
            "Epoch 00131 | Loss 0.0803 | Time(s) 1.1824 | Accuracy: 82.870015 %\n",
            "Epoch 00132 | Loss 0.1399 | Time(s) 1.1828 | Accuracy: 83.310966 %\n",
            "Epoch 00133 | Loss 0.0988 | Time(s) 1.1826 | Accuracy: 83.282209 %\n",
            "Epoch 00134 | Loss 0.1024 | Time(s) 1.1824 | Accuracy: 83.272623 %\n",
            "Epoch 00135 | Loss 0.0803 | Time(s) 1.1822 | Accuracy: 82.985046 %\n",
            "Epoch 00136 | Loss 0.1206 | Time(s) 1.1822 | Accuracy: 83.195936 %\n",
            "Epoch 00137 | Loss 0.0807 | Time(s) 1.1820 | Accuracy: 83.253451 %\n",
            "Epoch 00138 | Loss 0.1286 | Time(s) 1.1821 | Accuracy: 83.310966 %\n",
            "Epoch 00139 | Loss 0.0604 | Time(s) 1.1820 | Accuracy: 83.378067 %\n",
            "Epoch 00140 | Loss 0.1439 | Time(s) 1.1818 | Accuracy: 82.937117 %\n",
            "Epoch 00141 | Loss 0.0797 | Time(s) 1.1816 | Accuracy: 82.889187 %\n",
            "Epoch 00142 | Loss 0.1236 | Time(s) 1.1815 | Accuracy: 82.793328 %\n",
            "Epoch 00143 | Loss 0.0983 | Time(s) 1.1816 | Accuracy: 82.659126 %\n",
            "Epoch 00144 | Loss 0.1185 | Time(s) 1.1821 | Accuracy: 82.735813 %\n",
            "Epoch 00145 | Loss 0.1200 | Time(s) 1.1819 | Accuracy: 83.119248 %\n",
            "Epoch 00146 | Loss 0.1377 | Time(s) 1.1820 | Accuracy: 83.167178 %\n",
            "Epoch 00147 | Loss 0.0797 | Time(s) 1.1817 | Accuracy: 83.243865 %\n",
            "Epoch 00148 | Loss 0.0848 | Time(s) 1.1813 | Accuracy: 83.100077 %\n",
            "Epoch 00149 | Loss 0.1621 | Time(s) 1.1812 | Accuracy: 82.908359 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.4710 | Time(s) 1.1576 | Accuracy: 34.135353 %\n",
            "Epoch 00001 | Loss 1.2962 | Time(s) 1.1985 | Accuracy: 59.269555 %\n",
            "Epoch 00002 | Loss 1.1029 | Time(s) 1.2183 | Accuracy: 65.960506 %\n",
            "Epoch 00003 | Loss 1.0875 | Time(s) 1.2112 | Accuracy: 65.557899 %\n",
            "Epoch 00004 | Loss 0.7279 | Time(s) 1.2196 | Accuracy: 71.529908 %\n",
            "Epoch 00005 | Loss 0.7777 | Time(s) 1.2133 | Accuracy: 73.868865 %\n",
            "Epoch 00006 | Loss 0.6172 | Time(s) 1.2142 | Accuracy: 75.546396 %\n",
            "Epoch 00007 | Loss 0.5463 | Time(s) 1.2123 | Accuracy: 76.725460 %\n",
            "Epoch 00008 | Loss 0.8882 | Time(s) 1.2047 | Accuracy: 77.319785 %\n",
            "Epoch 00009 | Loss 0.6352 | Time(s) 1.2003 | Accuracy: 76.773390 %\n",
            "Epoch 00010 | Loss 0.5503 | Time(s) 1.1980 | Accuracy: 76.620015 %\n",
            "Epoch 00011 | Loss 0.7418 | Time(s) 1.1965 | Accuracy: 78.661810 %\n",
            "Epoch 00012 | Loss 0.5365 | Time(s) 1.1938 | Accuracy: 79.179448 %\n",
            "Epoch 00013 | Loss 0.4111 | Time(s) 1.1912 | Accuracy: 79.371166 %\n",
            "Epoch 00014 | Loss 0.4313 | Time(s) 1.1889 | Accuracy: 78.796012 %\n",
            "Epoch 00015 | Loss 0.5650 | Time(s) 1.1883 | Accuracy: 79.457439 %\n",
            "Epoch 00016 | Loss 0.5754 | Time(s) 1.1855 | Accuracy: 80.272239 %\n",
            "Epoch 00017 | Loss 0.5110 | Time(s) 1.1904 | Accuracy: 80.943252 %\n",
            "Epoch 00018 | Loss 0.3490 | Time(s) 1.1905 | Accuracy: 80.991181 %\n",
            "Epoch 00019 | Loss 0.3621 | Time(s) 1.1889 | Accuracy: 80.531058 %\n",
            "Epoch 00020 | Loss 0.3314 | Time(s) 1.1859 | Accuracy: 80.454371 %\n",
            "Epoch 00021 | Loss 0.2979 | Time(s) 1.1870 | Accuracy: 81.336273 %\n",
            "Epoch 00022 | Loss 0.3595 | Time(s) 1.1871 | Accuracy: 80.799463 %\n",
            "Epoch 00023 | Loss 0.4313 | Time(s) 1.1852 | Accuracy: 80.109279 %\n",
            "Epoch 00024 | Loss 0.5177 | Time(s) 1.1839 | Accuracy: 79.879218 %\n",
            "Epoch 00025 | Loss 0.3307 | Time(s) 1.1833 | Accuracy: 79.419095 %\n",
            "Epoch 00026 | Loss 0.5438 | Time(s) 1.1822 | Accuracy: 80.531058 %\n",
            "Epoch 00027 | Loss 0.2828 | Time(s) 1.1867 | Accuracy: 81.250000 %\n",
            "Epoch 00028 | Loss 0.3079 | Time(s) 1.1857 | Accuracy: 81.470475 %\n",
            "Epoch 00029 | Loss 0.4338 | Time(s) 1.1873 | Accuracy: 81.719709 %\n",
            "Epoch 00030 | Loss 0.2623 | Time(s) 1.1867 | Accuracy: 81.250000 %\n",
            "Epoch 00031 | Loss 0.2702 | Time(s) 1.1864 | Accuracy: 81.470475 %\n",
            "Epoch 00032 | Loss 0.2582 | Time(s) 1.1853 | Accuracy: 81.029525 %\n",
            "Epoch 00033 | Loss 0.6137 | Time(s) 1.1844 | Accuracy: 81.269172 %\n",
            "Epoch 00034 | Loss 0.4775 | Time(s) 1.1837 | Accuracy: 81.595092 %\n",
            "Epoch 00035 | Loss 0.2727 | Time(s) 1.1842 | Accuracy: 81.144555 %\n",
            "Epoch 00036 | Loss 0.2507 | Time(s) 1.1844 | Accuracy: 81.202071 %\n",
            "Epoch 00037 | Loss 0.5717 | Time(s) 1.1850 | Accuracy: 80.770706 %\n",
            "Epoch 00038 | Loss 0.2458 | Time(s) 1.1850 | Accuracy: 80.569402 %\n",
            "Epoch 00039 | Loss 0.3867 | Time(s) 1.1850 | Accuracy: 81.805982 %\n",
            "Epoch 00040 | Loss 0.2562 | Time(s) 1.1848 | Accuracy: 81.997699 %\n",
            "Epoch 00041 | Loss 0.4347 | Time(s) 1.1873 | Accuracy: 82.409893 %\n",
            "Epoch 00042 | Loss 0.3041 | Time(s) 1.1866 | Accuracy: 82.285276 %\n",
            "Epoch 00043 | Loss 0.4867 | Time(s) 1.1878 | Accuracy: 82.055215 %\n",
            "Epoch 00044 | Loss 0.4169 | Time(s) 1.1873 | Accuracy: 81.297929 %\n",
            "Epoch 00045 | Loss 0.4306 | Time(s) 1.1872 | Accuracy: 81.480061 %\n",
            "Epoch 00046 | Loss 0.3079 | Time(s) 1.1867 | Accuracy: 80.262653 %\n",
            "Epoch 00047 | Loss 0.2663 | Time(s) 1.1875 | Accuracy: 81.202071 %\n",
            "Epoch 00048 | Loss 0.2323 | Time(s) 1.1866 | Accuracy: 81.940184 %\n",
            "Epoch 00049 | Loss 0.3843 | Time(s) 1.1862 | Accuracy: 80.761120 %\n",
            "Epoch 00050 | Loss 0.4681 | Time(s) 1.1856 | Accuracy: 81.988113 %\n",
            "Epoch 00051 | Loss 0.2801 | Time(s) 1.1845 | Accuracy: 81.585506 %\n",
            "Epoch 00052 | Loss 0.4383 | Time(s) 1.1849 | Accuracy: 81.729294 %\n",
            "Epoch 00053 | Loss 0.3449 | Time(s) 1.1859 | Accuracy: 82.160660 %\n",
            "Epoch 00054 | Loss 0.5477 | Time(s) 1.1862 | Accuracy: 81.901840 %\n",
            "Epoch 00055 | Loss 0.2288 | Time(s) 1.1870 | Accuracy: 81.988113 %\n",
            "Epoch 00056 | Loss 0.3492 | Time(s) 1.1871 | Accuracy: 81.671779 %\n",
            "Epoch 00057 | Loss 0.3360 | Time(s) 1.1882 | Accuracy: 81.470475 %\n",
            "Epoch 00058 | Loss 0.2269 | Time(s) 1.1892 | Accuracy: 81.250000 %\n",
            "Epoch 00059 | Loss 0.2337 | Time(s) 1.1897 | Accuracy: 81.460890 %\n",
            "Epoch 00060 | Loss 0.3386 | Time(s) 1.1906 | Accuracy: 81.623850 %\n",
            "Epoch 00061 | Loss 0.3219 | Time(s) 1.1918 | Accuracy: 81.345859 %\n",
            "Epoch 00062 | Loss 0.2260 | Time(s) 1.1917 | Accuracy: 81.039110 %\n",
            "Epoch 00063 | Loss 0.4399 | Time(s) 1.1911 | Accuracy: 80.780291 %\n",
            "Epoch 00064 | Loss 0.3798 | Time(s) 1.1907 | Accuracy: 80.866564 %\n",
            "Epoch 00065 | Loss 0.2729 | Time(s) 1.1905 | Accuracy: 81.067868 %\n",
            "Epoch 00066 | Loss 0.2320 | Time(s) 1.1903 | Accuracy: 81.882669 %\n",
            "Epoch 00067 | Loss 0.2241 | Time(s) 1.1899 | Accuracy: 81.873083 %\n",
            "Epoch 00068 | Loss 0.3707 | Time(s) 1.1895 | Accuracy: 81.949770 %\n",
            "Epoch 00069 | Loss 0.4613 | Time(s) 1.1887 | Accuracy: 81.575920 %\n",
            "Epoch 00070 | Loss 0.2232 | Time(s) 1.1882 | Accuracy: 81.403374 %\n",
            "Epoch 00071 | Loss 0.3648 | Time(s) 1.1884 | Accuracy: 81.432132 %\n",
            "Epoch 00072 | Loss 0.2212 | Time(s) 1.1876 | Accuracy: 82.016871 %\n",
            "Epoch 00073 | Loss 0.4876 | Time(s) 1.1873 | Accuracy: 81.911426 %\n",
            "Epoch 00074 | Loss 0.2183 | Time(s) 1.1868 | Accuracy: 81.949770 %\n",
            "Epoch 00075 | Loss 0.2188 | Time(s) 1.1868 | Accuracy: 81.460890 %\n",
            "Epoch 00076 | Loss 0.4252 | Time(s) 1.1863 | Accuracy: 81.403374 %\n",
            "Epoch 00077 | Loss 0.2256 | Time(s) 1.1862 | Accuracy: 81.595092 %\n",
            "Epoch 00078 | Loss 0.3829 | Time(s) 1.1871 | Accuracy: 81.508819 %\n",
            "Epoch 00079 | Loss 0.4055 | Time(s) 1.1879 | Accuracy: 81.805982 %\n",
            "Epoch 00080 | Loss 0.3979 | Time(s) 1.1889 | Accuracy: 82.045629 %\n",
            "Epoch 00081 | Loss 0.2180 | Time(s) 1.1891 | Accuracy: 81.796396 %\n",
            "Epoch 00082 | Loss 0.2657 | Time(s) 1.1896 | Accuracy: 81.614264 %\n",
            "Epoch 00083 | Loss 0.3967 | Time(s) 1.1897 | Accuracy: 81.853911 %\n",
            "Epoch 00084 | Loss 0.4099 | Time(s) 1.1898 | Accuracy: 81.921012 %\n",
            "Epoch 00085 | Loss 0.4091 | Time(s) 1.1901 | Accuracy: 81.968942 %\n",
            "Epoch 00086 | Loss 0.2201 | Time(s) 1.1902 | Accuracy: 81.700537 %\n",
            "Epoch 00087 | Loss 0.3592 | Time(s) 1.1900 | Accuracy: 81.499233 %\n",
            "Epoch 00088 | Loss 0.3652 | Time(s) 1.1898 | Accuracy: 81.623850 %\n",
            "Epoch 00089 | Loss 0.2193 | Time(s) 1.1902 | Accuracy: 81.738880 %\n",
            "Epoch 00090 | Loss 0.4122 | Time(s) 1.1902 | Accuracy: 81.719709 %\n",
            "Epoch 00091 | Loss 0.4326 | Time(s) 1.1904 | Accuracy: 81.221242 %\n",
            "Epoch 00092 | Loss 0.2217 | Time(s) 1.1901 | Accuracy: 81.345859 %\n",
            "Epoch 00093 | Loss 0.5127 | Time(s) 1.1902 | Accuracy: 81.767638 %\n",
            "Epoch 00094 | Loss 0.3561 | Time(s) 1.1905 | Accuracy: 82.208589 %\n",
            "Epoch 00095 | Loss 0.3598 | Time(s) 1.1907 | Accuracy: 82.074387 %\n",
            "Epoch 00096 | Loss 0.3298 | Time(s) 1.1908 | Accuracy: 81.997699 %\n",
            "Epoch 00097 | Loss 0.3470 | Time(s) 1.1908 | Accuracy: 81.892255 %\n",
            "Epoch 00098 | Loss 0.4247 | Time(s) 1.1909 | Accuracy: 81.719709 %\n",
            "Epoch 00099 | Loss 0.2564 | Time(s) 1.1905 | Accuracy: 81.355445 %\n",
            "Epoch 00100 | Loss 0.3557 | Time(s) 1.1903 | Accuracy: 81.556748 %\n",
            "Epoch 00101 | Loss 0.3559 | Time(s) 1.1898 | Accuracy: 81.537577 %\n",
            "Epoch 00102 | Loss 0.4106 | Time(s) 1.1899 | Accuracy: 81.796396 %\n",
            "Epoch 00103 | Loss 0.2206 | Time(s) 1.1903 | Accuracy: 81.748466 %\n",
            "Epoch 00104 | Loss 0.3435 | Time(s) 1.1909 | Accuracy: 81.844325 %\n",
            "Epoch 00105 | Loss 0.3935 | Time(s) 1.1918 | Accuracy: 81.758052 %\n",
            "Epoch 00106 | Loss 0.3938 | Time(s) 1.1921 | Accuracy: 81.623850 %\n",
            "Epoch 00107 | Loss 0.4418 | Time(s) 1.1921 | Accuracy: 81.221242 %\n",
            "Epoch 00108 | Loss 0.5147 | Time(s) 1.1923 | Accuracy: 81.825153 %\n",
            "Epoch 00109 | Loss 0.2698 | Time(s) 1.1921 | Accuracy: 81.154141 %\n",
            "Epoch 00110 | Loss 0.2770 | Time(s) 1.1921 | Accuracy: 81.115798 %\n",
            "Epoch 00111 | Loss 0.5077 | Time(s) 1.1920 | Accuracy: 81.614264 %\n",
            "Epoch 00112 | Loss 0.2580 | Time(s) 1.1923 | Accuracy: 82.036043 %\n",
            "Epoch 00113 | Loss 0.2168 | Time(s) 1.1924 | Accuracy: 82.103144 %\n",
            "Epoch 00114 | Loss 0.4054 | Time(s) 1.1920 | Accuracy: 82.400307 %\n",
            "Epoch 00115 | Loss 0.2168 | Time(s) 1.1918 | Accuracy: 81.882669 %\n",
            "Epoch 00116 | Loss 0.4573 | Time(s) 1.1920 | Accuracy: 81.585506 %\n",
            "Epoch 00117 | Loss 0.2206 | Time(s) 1.1918 | Accuracy: 81.336273 %\n",
            "Epoch 00118 | Loss 0.3566 | Time(s) 1.1919 | Accuracy: 81.796396 %\n",
            "Epoch 00119 | Loss 0.3206 | Time(s) 1.1915 | Accuracy: 81.959356 %\n",
            "Epoch 00120 | Loss 0.3135 | Time(s) 1.1914 | Accuracy: 82.026457 %\n",
            "Epoch 00121 | Loss 0.4190 | Time(s) 1.1914 | Accuracy: 81.968942 %\n",
            "Epoch 00122 | Loss 0.3541 | Time(s) 1.1913 | Accuracy: 81.882669 %\n",
            "Epoch 00123 | Loss 0.2180 | Time(s) 1.1914 | Accuracy: 81.652607 %\n",
            "Epoch 00124 | Loss 0.2154 | Time(s) 1.1914 | Accuracy: 81.738880 %\n",
            "Epoch 00125 | Loss 0.2606 | Time(s) 1.1914 | Accuracy: 81.623850 %\n",
            "Epoch 00126 | Loss 0.2174 | Time(s) 1.1915 | Accuracy: 81.748466 %\n",
            "Epoch 00127 | Loss 0.2178 | Time(s) 1.1917 | Accuracy: 82.141488 %\n",
            "Epoch 00128 | Loss 0.4025 | Time(s) 1.1925 | Accuracy: 82.189417 %\n",
            "Epoch 00129 | Loss 0.2167 | Time(s) 1.1930 | Accuracy: 82.160660 %\n",
            "Epoch 00130 | Loss 0.3923 | Time(s) 1.1934 | Accuracy: 81.997699 %\n",
            "Epoch 00131 | Loss 0.2167 | Time(s) 1.1932 | Accuracy: 81.988113 %\n",
            "Epoch 00132 | Loss 0.3924 | Time(s) 1.1931 | Accuracy: 81.758052 %\n",
            "Epoch 00133 | Loss 0.3533 | Time(s) 1.1929 | Accuracy: 81.940184 %\n",
            "Epoch 00134 | Loss 0.2176 | Time(s) 1.1930 | Accuracy: 82.131902 %\n",
            "Epoch 00135 | Loss 0.3308 | Time(s) 1.1932 | Accuracy: 82.141488 %\n",
            "Epoch 00136 | Loss 0.4551 | Time(s) 1.1931 | Accuracy: 81.930598 %\n",
            "Epoch 00137 | Loss 0.3925 | Time(s) 1.1932 | Accuracy: 81.585506 %\n",
            "Epoch 00138 | Loss 0.4525 | Time(s) 1.1932 | Accuracy: 81.489647 %\n",
            "Epoch 00139 | Loss 0.3945 | Time(s) 1.1931 | Accuracy: 81.355445 %\n",
            "Epoch 00140 | Loss 0.3939 | Time(s) 1.1931 | Accuracy: 81.652607 %\n",
            "Epoch 00141 | Loss 0.2171 | Time(s) 1.1931 | Accuracy: 81.959356 %\n",
            "Epoch 00142 | Loss 0.4186 | Time(s) 1.1929 | Accuracy: 81.978528 %\n",
            "Epoch 00143 | Loss 0.2164 | Time(s) 1.1929 | Accuracy: 81.796396 %\n",
            "Epoch 00144 | Loss 0.4766 | Time(s) 1.1930 | Accuracy: 81.834739 %\n",
            "Epoch 00145 | Loss 0.4577 | Time(s) 1.1929 | Accuracy: 81.882669 %\n",
            "Epoch 00146 | Loss 0.3525 | Time(s) 1.1930 | Accuracy: 82.007285 %\n",
            "Epoch 00147 | Loss 0.3008 | Time(s) 1.1931 | Accuracy: 81.719709 %\n",
            "Epoch 00148 | Loss 0.3614 | Time(s) 1.1934 | Accuracy: 81.480061 %\n",
            "Epoch 00149 | Loss 0.3524 | Time(s) 1.1931 | Accuracy: 81.441718 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.5888 | Time(s) 1.2205 | Accuracy: 29.649156 %\n",
            "Epoch 00001 | Loss 1.4491 | Time(s) 1.2486 | Accuracy: 53.460506 %\n",
            "Epoch 00002 | Loss 1.1262 | Time(s) 1.2482 | Accuracy: 56.940184 %\n",
            "Epoch 00003 | Loss 1.1011 | Time(s) 1.2431 | Accuracy: 61.857745 %\n",
            "Epoch 00004 | Loss 1.1973 | Time(s) 1.2270 | Accuracy: 63.218942 %\n",
            "Epoch 00005 | Loss 0.9921 | Time(s) 1.2143 | Accuracy: 66.104294 %\n",
            "Epoch 00006 | Loss 0.9717 | Time(s) 1.2099 | Accuracy: 65.347009 %\n",
            "Epoch 00007 | Loss 0.8680 | Time(s) 1.2060 | Accuracy: 67.216258 %\n",
            "Epoch 00008 | Loss 1.0607 | Time(s) 1.2024 | Accuracy: 70.015337 %\n",
            "Epoch 00009 | Loss 0.9725 | Time(s) 1.1971 | Accuracy: 69.497699 %\n",
            "Epoch 00010 | Loss 0.8900 | Time(s) 1.1925 | Accuracy: 70.743865 %\n",
            "Epoch 00011 | Loss 0.8693 | Time(s) 1.1937 | Accuracy: 70.600077 %\n",
            "Epoch 00012 | Loss 0.9613 | Time(s) 1.1935 | Accuracy: 70.667178 %\n",
            "Epoch 00013 | Loss 0.9026 | Time(s) 1.1879 | Accuracy: 71.079371 %\n",
            "Epoch 00014 | Loss 0.5413 | Time(s) 1.1856 | Accuracy: 71.654525 %\n",
            "Epoch 00015 | Loss 0.7773 | Time(s) 1.1827 | Accuracy: 72.421396 %\n",
            "Epoch 00016 | Loss 0.7246 | Time(s) 1.1856 | Accuracy: 72.986963 %\n",
            "Epoch 00017 | Loss 0.4796 | Time(s) 1.1821 | Accuracy: 73.130752 %\n",
            "Epoch 00018 | Loss 0.6172 | Time(s) 1.1794 | Accuracy: 73.466258 %\n",
            "Epoch 00019 | Loss 0.4730 | Time(s) 1.1764 | Accuracy: 72.622699 %\n",
            "Epoch 00020 | Loss 0.6778 | Time(s) 1.1784 | Accuracy: 72.315951 %\n",
            "Epoch 00021 | Loss 0.5382 | Time(s) 1.1773 | Accuracy: 72.363880 %\n",
            "Epoch 00022 | Loss 0.5224 | Time(s) 1.1769 | Accuracy: 72.469325 %\n",
            "Epoch 00023 | Loss 0.6111 | Time(s) 1.1748 | Accuracy: 72.210506 %\n",
            "Epoch 00024 | Loss 0.6559 | Time(s) 1.1798 | Accuracy: 72.133819 %\n",
            "Epoch 00025 | Loss 0.5937 | Time(s) 1.1781 | Accuracy: 72.881518 %\n",
            "Epoch 00026 | Loss 0.3578 | Time(s) 1.1777 | Accuracy: 72.756902 %\n",
            "Epoch 00027 | Loss 0.5973 | Time(s) 1.1774 | Accuracy: 72.268021 %\n",
            "Epoch 00028 | Loss 0.5866 | Time(s) 1.1765 | Accuracy: 72.708972 %\n",
            "Epoch 00029 | Loss 0.6683 | Time(s) 1.1772 | Accuracy: 72.891104 %\n",
            "Epoch 00030 | Loss 0.5675 | Time(s) 1.1753 | Accuracy: 72.996549 %\n",
            "Epoch 00031 | Loss 0.6594 | Time(s) 1.1751 | Accuracy: 73.293712 %\n",
            "Epoch 00032 | Loss 0.4547 | Time(s) 1.1743 | Accuracy: 72.574770 %\n",
            "Epoch 00033 | Loss 0.6935 | Time(s) 1.1732 | Accuracy: 73.044479 %\n",
            "Epoch 00034 | Loss 0.6521 | Time(s) 1.1742 | Accuracy: 73.734663 %\n",
            "Epoch 00035 | Loss 0.3251 | Time(s) 1.1746 | Accuracy: 73.447086 %\n",
            "Epoch 00036 | Loss 0.7017 | Time(s) 1.1747 | Accuracy: 73.006135 %\n",
            "Epoch 00037 | Loss 0.7141 | Time(s) 1.1753 | Accuracy: 73.590874 %\n",
            "Epoch 00038 | Loss 0.6435 | Time(s) 1.1765 | Accuracy: 73.964724 %\n",
            "Epoch 00039 | Loss 0.5032 | Time(s) 1.1760 | Accuracy: 73.600460 %\n",
            "Epoch 00040 | Loss 0.4882 | Time(s) 1.1773 | Accuracy: 72.344709 %\n",
            "Epoch 00041 | Loss 0.6527 | Time(s) 1.1767 | Accuracy: 72.565184 %\n",
            "Epoch 00042 | Loss 0.4798 | Time(s) 1.1771 | Accuracy: 73.552531 %\n",
            "Epoch 00043 | Loss 0.6295 | Time(s) 1.1778 | Accuracy: 73.379985 %\n",
            "Epoch 00044 | Loss 0.5529 | Time(s) 1.1775 | Accuracy: 73.792178 %\n",
            "Epoch 00045 | Loss 0.5954 | Time(s) 1.1775 | Accuracy: 73.657975 %\n",
            "Epoch 00046 | Loss 0.5965 | Time(s) 1.1767 | Accuracy: 73.006135 %\n",
            "Epoch 00047 | Loss 0.6567 | Time(s) 1.1765 | Accuracy: 73.121166 %\n",
            "Epoch 00048 | Loss 0.5882 | Time(s) 1.1761 | Accuracy: 73.006135 %\n",
            "Epoch 00049 | Loss 0.5654 | Time(s) 1.1770 | Accuracy: 72.852761 %\n",
            "Epoch 00050 | Loss 0.5819 | Time(s) 1.1773 | Accuracy: 73.255368 %\n",
            "Epoch 00051 | Loss 0.5333 | Time(s) 1.1775 | Accuracy: 72.661043 %\n",
            "Epoch 00052 | Loss 0.5553 | Time(s) 1.1786 | Accuracy: 73.562117 %\n",
            "Epoch 00053 | Loss 0.6636 | Time(s) 1.1795 | Accuracy: 73.514187 %\n",
            "Epoch 00054 | Loss 0.6622 | Time(s) 1.1806 | Accuracy: 73.782592 %\n",
            "Epoch 00055 | Loss 0.5969 | Time(s) 1.1807 | Accuracy: 73.581288 %\n",
            "Epoch 00056 | Loss 0.5992 | Time(s) 1.1802 | Accuracy: 73.485429 %\n",
            "Epoch 00057 | Loss 0.5794 | Time(s) 1.1799 | Accuracy: 73.734663 %\n",
            "Epoch 00058 | Loss 0.6260 | Time(s) 1.1800 | Accuracy: 73.629218 %\n",
            "Epoch 00059 | Loss 0.4825 | Time(s) 1.1803 | Accuracy: 73.475844 %\n",
            "Epoch 00060 | Loss 0.6183 | Time(s) 1.1807 | Accuracy: 72.986963 %\n",
            "Epoch 00061 | Loss 0.6180 | Time(s) 1.1805 | Accuracy: 73.341641 %\n",
            "Epoch 00062 | Loss 0.5731 | Time(s) 1.1805 | Accuracy: 73.456672 %\n",
            "Epoch 00063 | Loss 0.6509 | Time(s) 1.1804 | Accuracy: 73.303298 %\n",
            "Epoch 00064 | Loss 0.5312 | Time(s) 1.1795 | Accuracy: 73.197853 %\n",
            "Epoch 00065 | Loss 0.4975 | Time(s) 1.1790 | Accuracy: 73.101994 %\n",
            "Epoch 00066 | Loss 0.5548 | Time(s) 1.1781 | Accuracy: 73.427914 %\n",
            "Epoch 00067 | Loss 0.5469 | Time(s) 1.1777 | Accuracy: 73.590874 %\n",
            "Epoch 00068 | Loss 0.3882 | Time(s) 1.1772 | Accuracy: 73.667561 %\n",
            "Epoch 00069 | Loss 0.5514 | Time(s) 1.1770 | Accuracy: 73.801764 %\n",
            "Epoch 00070 | Loss 0.3059 | Time(s) 1.1767 | Accuracy: 73.705905 %\n",
            "Epoch 00071 | Loss 0.3742 | Time(s) 1.1762 | Accuracy: 73.600460 %\n",
            "Epoch 00072 | Loss 0.5451 | Time(s) 1.1761 | Accuracy: 73.533359 %\n",
            "Epoch 00073 | Loss 0.3720 | Time(s) 1.1760 | Accuracy: 73.667561 %\n",
            "Epoch 00074 | Loss 0.5422 | Time(s) 1.1756 | Accuracy: 73.744248 %\n",
            "Epoch 00075 | Loss 0.4718 | Time(s) 1.1771 | Accuracy: 73.840107 %\n",
            "Epoch 00076 | Loss 0.5713 | Time(s) 1.1771 | Accuracy: 73.552531 %\n",
            "Epoch 00077 | Loss 0.6086 | Time(s) 1.1771 | Accuracy: 73.600460 %\n",
            "Epoch 00078 | Loss 0.6492 | Time(s) 1.1771 | Accuracy: 73.437500 %\n",
            "Epoch 00079 | Loss 0.5486 | Time(s) 1.1768 | Accuracy: 73.629218 %\n",
            "Epoch 00080 | Loss 0.6078 | Time(s) 1.1767 | Accuracy: 73.705905 %\n",
            "Epoch 00081 | Loss 0.6075 | Time(s) 1.1768 | Accuracy: 73.677147 %\n",
            "Epoch 00082 | Loss 0.6682 | Time(s) 1.1768 | Accuracy: 73.562117 %\n",
            "Epoch 00083 | Loss 0.5716 | Time(s) 1.1767 | Accuracy: 73.562117 %\n",
            "Epoch 00084 | Loss 0.3687 | Time(s) 1.1764 | Accuracy: 73.466258 %\n",
            "Epoch 00085 | Loss 0.5485 | Time(s) 1.1762 | Accuracy: 73.552531 %\n",
            "Epoch 00086 | Loss 0.6080 | Time(s) 1.1761 | Accuracy: 73.657975 %\n",
            "Epoch 00087 | Loss 0.3001 | Time(s) 1.1755 | Accuracy: 73.360813 %\n",
            "Epoch 00088 | Loss 0.4706 | Time(s) 1.1753 | Accuracy: 73.523773 %\n",
            "Epoch 00089 | Loss 0.5526 | Time(s) 1.1755 | Accuracy: 73.217025 %\n",
            "Epoch 00090 | Loss 0.6516 | Time(s) 1.1755 | Accuracy: 73.619632 %\n",
            "Epoch 00091 | Loss 0.2984 | Time(s) 1.1753 | Accuracy: 73.801764 %\n",
            "Epoch 00092 | Loss 0.4711 | Time(s) 1.1748 | Accuracy: 73.725077 %\n",
            "Epoch 00093 | Loss 0.6350 | Time(s) 1.1746 | Accuracy: 73.907209 %\n",
            "Epoch 00094 | Loss 0.2959 | Time(s) 1.1744 | Accuracy: 73.763420 %\n",
            "Epoch 00095 | Loss 0.5278 | Time(s) 1.1743 | Accuracy: 73.686733 %\n",
            "Epoch 00096 | Loss 0.5277 | Time(s) 1.1740 | Accuracy: 73.523773 %\n",
            "Epoch 00097 | Loss 0.6307 | Time(s) 1.1737 | Accuracy: 73.523773 %\n",
            "Epoch 00098 | Loss 0.2962 | Time(s) 1.1734 | Accuracy: 73.408742 %\n",
            "Epoch 00099 | Loss 0.6486 | Time(s) 1.1731 | Accuracy: 73.466258 %\n",
            "Epoch 00100 | Loss 0.6509 | Time(s) 1.1732 | Accuracy: 73.619632 %\n",
            "Epoch 00101 | Loss 0.6299 | Time(s) 1.1731 | Accuracy: 73.648390 %\n",
            "Epoch 00102 | Loss 0.6081 | Time(s) 1.1730 | Accuracy: 73.629218 %\n",
            "Epoch 00103 | Loss 0.5272 | Time(s) 1.1735 | Accuracy: 73.590874 %\n",
            "Epoch 00104 | Loss 0.6061 | Time(s) 1.1738 | Accuracy: 73.466258 %\n",
            "Epoch 00105 | Loss 0.6462 | Time(s) 1.1741 | Accuracy: 73.533359 %\n",
            "Epoch 00106 | Loss 0.5664 | Time(s) 1.1736 | Accuracy: 73.638804 %\n",
            "Epoch 00107 | Loss 0.6649 | Time(s) 1.1734 | Accuracy: 73.495015 %\n",
            "Epoch 00108 | Loss 0.5468 | Time(s) 1.1730 | Accuracy: 73.389571 %\n",
            "Epoch 00109 | Loss 0.5664 | Time(s) 1.1728 | Accuracy: 73.418328 %\n",
            "Epoch 00110 | Loss 0.6073 | Time(s) 1.1724 | Accuracy: 73.360813 %\n",
            "Epoch 00111 | Loss 0.3662 | Time(s) 1.1721 | Accuracy: 73.332055 %\n",
            "Epoch 00112 | Loss 0.5460 | Time(s) 1.1718 | Accuracy: 73.466258 %\n",
            "Epoch 00113 | Loss 0.6320 | Time(s) 1.1717 | Accuracy: 73.447086 %\n",
            "Epoch 00114 | Loss 0.6453 | Time(s) 1.1717 | Accuracy: 73.197853 %\n",
            "Epoch 00115 | Loss 0.5270 | Time(s) 1.1720 | Accuracy: 73.322469 %\n",
            "Epoch 00116 | Loss 0.6333 | Time(s) 1.1722 | Accuracy: 73.475844 %\n",
            "Epoch 00117 | Loss 0.5675 | Time(s) 1.1725 | Accuracy: 73.332055 %\n",
            "Epoch 00118 | Loss 0.5341 | Time(s) 1.1725 | Accuracy: 73.514187 %\n",
            "Epoch 00119 | Loss 0.3644 | Time(s) 1.1720 | Accuracy: 73.418328 %\n",
            "Epoch 00120 | Loss 0.2943 | Time(s) 1.1722 | Accuracy: 73.437500 %\n",
            "Epoch 00121 | Loss 0.3602 | Time(s) 1.1721 | Accuracy: 73.322469 %\n",
            "Epoch 00122 | Loss 0.6055 | Time(s) 1.1720 | Accuracy: 73.514187 %\n",
            "Epoch 00123 | Loss 0.6362 | Time(s) 1.1718 | Accuracy: 73.523773 %\n",
            "Epoch 00124 | Loss 0.6056 | Time(s) 1.1718 | Accuracy: 73.657975 %\n",
            "Epoch 00125 | Loss 0.5460 | Time(s) 1.1726 | Accuracy: 73.667561 %\n",
            "Epoch 00126 | Loss 0.2937 | Time(s) 1.1723 | Accuracy: 73.514187 %\n",
            "Epoch 00127 | Loss 0.4754 | Time(s) 1.1723 | Accuracy: 73.523773 %\n",
            "Epoch 00128 | Loss 0.3602 | Time(s) 1.1722 | Accuracy: 73.379985 %\n",
            "Epoch 00129 | Loss 0.2958 | Time(s) 1.1724 | Accuracy: 73.408742 %\n",
            "Epoch 00130 | Loss 0.2950 | Time(s) 1.1726 | Accuracy: 73.217025 %\n",
            "Epoch 00131 | Loss 0.3601 | Time(s) 1.1726 | Accuracy: 73.207439 %\n",
            "Epoch 00132 | Loss 0.5264 | Time(s) 1.1724 | Accuracy: 73.495015 %\n",
            "Epoch 00133 | Loss 0.6352 | Time(s) 1.1720 | Accuracy: 73.523773 %\n",
            "Epoch 00134 | Loss 0.5418 | Time(s) 1.1719 | Accuracy: 73.418328 %\n",
            "Epoch 00135 | Loss 0.5324 | Time(s) 1.1718 | Accuracy: 73.437500 %\n",
            "Epoch 00136 | Loss 0.2935 | Time(s) 1.1720 | Accuracy: 73.408742 %\n",
            "Epoch 00137 | Loss 0.2936 | Time(s) 1.1719 | Accuracy: 73.542945 %\n",
            "Epoch 00138 | Loss 0.6477 | Time(s) 1.1718 | Accuracy: 73.466258 %\n",
            "Epoch 00139 | Loss 0.5659 | Time(s) 1.1718 | Accuracy: 73.552531 %\n",
            "Epoch 00140 | Loss 0.6294 | Time(s) 1.1716 | Accuracy: 73.715491 %\n",
            "Epoch 00141 | Loss 0.5304 | Time(s) 1.1714 | Accuracy: 73.677147 %\n",
            "Epoch 00142 | Loss 0.5457 | Time(s) 1.1713 | Accuracy: 73.495015 %\n",
            "Epoch 00143 | Loss 0.6269 | Time(s) 1.1712 | Accuracy: 73.159509 %\n",
            "Epoch 00144 | Loss 0.5687 | Time(s) 1.1710 | Accuracy: 73.121166 %\n",
            "Epoch 00145 | Loss 0.4681 | Time(s) 1.1707 | Accuracy: 73.284126 %\n",
            "Epoch 00146 | Loss 0.6305 | Time(s) 1.1709 | Accuracy: 73.504601 %\n",
            "Epoch 00147 | Loss 0.4682 | Time(s) 1.1708 | Accuracy: 73.447086 %\n",
            "Epoch 00148 | Loss 0.5265 | Time(s) 1.1706 | Accuracy: 73.495015 %\n",
            "Epoch 00149 | Loss 0.5297 | Time(s) 1.1704 | Accuracy: 73.514187 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.4736 | Time(s) 1.1777 | Accuracy: 35.371933 %\n",
            "Epoch 00001 | Loss 1.1902 | Time(s) 1.2033 | Accuracy: 69.104678 %\n",
            "Epoch 00002 | Loss 0.9787 | Time(s) 1.2030 | Accuracy: 71.069785 %\n",
            "Epoch 00003 | Loss 0.8224 | Time(s) 1.2051 | Accuracy: 74.731595 %\n",
            "Epoch 00004 | Loss 0.6276 | Time(s) 1.1948 | Accuracy: 77.712807 %\n",
            "Epoch 00005 | Loss 0.6445 | Time(s) 1.1857 | Accuracy: 77.070552 %\n",
            "Epoch 00006 | Loss 0.6081 | Time(s) 1.1871 | Accuracy: 78.498850 %\n",
            "Epoch 00007 | Loss 0.5991 | Time(s) 1.1809 | Accuracy: 79.006902 %\n",
            "Epoch 00008 | Loss 0.5758 | Time(s) 1.1828 | Accuracy: 79.572469 %\n",
            "Epoch 00009 | Loss 0.6999 | Time(s) 1.1764 | Accuracy: 79.179448 %\n",
            "Epoch 00010 | Loss 0.3779 | Time(s) 1.1733 | Accuracy: 78.815184 %\n",
            "Epoch 00011 | Loss 0.4048 | Time(s) 1.1775 | Accuracy: 79.399923 %\n",
            "Epoch 00012 | Loss 0.3960 | Time(s) 1.1767 | Accuracy: 80.924080 %\n",
            "Epoch 00013 | Loss 0.4695 | Time(s) 1.1774 | Accuracy: 80.722776 %\n",
            "Epoch 00014 | Loss 0.4994 | Time(s) 1.1748 | Accuracy: 81.192485 %\n",
            "Epoch 00015 | Loss 0.4651 | Time(s) 1.1746 | Accuracy: 81.547163 %\n",
            "Epoch 00016 | Loss 0.3231 | Time(s) 1.1722 | Accuracy: 81.221242 %\n",
            "Epoch 00017 | Loss 0.5365 | Time(s) 1.1710 | Accuracy: 80.713190 %\n",
            "Epoch 00018 | Loss 0.3190 | Time(s) 1.1706 | Accuracy: 81.374617 %\n",
            "Epoch 00019 | Loss 0.2811 | Time(s) 1.1688 | Accuracy: 80.885736 %\n",
            "Epoch 00020 | Loss 0.2196 | Time(s) 1.1691 | Accuracy: 81.019939 %\n",
            "Epoch 00021 | Loss 0.2141 | Time(s) 1.1672 | Accuracy: 80.013420 %\n",
            "Epoch 00022 | Loss 0.2267 | Time(s) 1.1685 | Accuracy: 80.694018 %\n",
            "Epoch 00023 | Loss 0.2682 | Time(s) 1.1671 | Accuracy: 80.243482 %\n",
            "Epoch 00024 | Loss 0.2958 | Time(s) 1.1710 | Accuracy: 81.192485 %\n",
            "Epoch 00025 | Loss 0.3848 | Time(s) 1.1724 | Accuracy: 80.751534 %\n",
            "Epoch 00026 | Loss 0.3095 | Time(s) 1.1749 | Accuracy: 81.518405 %\n",
            "Epoch 00027 | Loss 0.3052 | Time(s) 1.1744 | Accuracy: 81.412960 %\n",
            "Epoch 00028 | Loss 0.2143 | Time(s) 1.1762 | Accuracy: 81.393788 %\n",
            "Epoch 00029 | Loss 0.2410 | Time(s) 1.1770 | Accuracy: 81.163727 %\n",
            "Epoch 00030 | Loss 0.1722 | Time(s) 1.1781 | Accuracy: 81.134969 %\n",
            "Epoch 00031 | Loss 0.2340 | Time(s) 1.1789 | Accuracy: 81.250000 %\n",
            "Epoch 00032 | Loss 0.1629 | Time(s) 1.1804 | Accuracy: 81.480061 %\n",
            "Epoch 00033 | Loss 0.1850 | Time(s) 1.1791 | Accuracy: 81.460890 %\n",
            "Epoch 00034 | Loss 0.2660 | Time(s) 1.1783 | Accuracy: 81.777224 %\n",
            "Epoch 00035 | Loss 0.1821 | Time(s) 1.1784 | Accuracy: 81.700537 %\n",
            "Epoch 00036 | Loss 0.2732 | Time(s) 1.1786 | Accuracy: 81.767638 %\n",
            "Epoch 00037 | Loss 0.2389 | Time(s) 1.1779 | Accuracy: 81.719709 %\n",
            "Epoch 00038 | Loss 0.3369 | Time(s) 1.1780 | Accuracy: 81.614264 %\n",
            "Epoch 00039 | Loss 0.2579 | Time(s) 1.1764 | Accuracy: 81.259586 %\n",
            "Epoch 00040 | Loss 0.0775 | Time(s) 1.1756 | Accuracy: 83.838190 %\n",
            "Epoch 00041 | Loss 0.2020 | Time(s) 1.1756 | Accuracy: 87.356212 %\n",
            "Epoch 00042 | Loss 0.2094 | Time(s) 1.1746 | Accuracy: 87.337040 %\n",
            "Epoch 00043 | Loss 0.1603 | Time(s) 1.1738 | Accuracy: 86.934433 %\n",
            "Epoch 00044 | Loss 0.2291 | Time(s) 1.1737 | Accuracy: 87.710890 %\n",
            "Epoch 00045 | Loss 0.1228 | Time(s) 1.1731 | Accuracy: 87.605445 %\n",
            "Epoch 00046 | Loss 0.1107 | Time(s) 1.1718 | Accuracy: 87.749233 %\n",
            "Epoch 00047 | Loss 0.2051 | Time(s) 1.1720 | Accuracy: 87.912193 %\n",
            "Epoch 00048 | Loss 0.0761 | Time(s) 1.1719 | Accuracy: 88.324387 %\n",
            "Epoch 00049 | Loss 0.0316 | Time(s) 1.1722 | Accuracy: 88.343558 %\n",
            "Epoch 00050 | Loss 0.0227 | Time(s) 1.1728 | Accuracy: 88.286043 %\n",
            "Epoch 00051 | Loss 0.0753 | Time(s) 1.1728 | Accuracy: 88.171012 %\n",
            "Epoch 00052 | Loss 0.0671 | Time(s) 1.1736 | Accuracy: 88.094325 %\n",
            "Epoch 00053 | Loss 0.0623 | Time(s) 1.1737 | Accuracy: 88.103911 %\n",
            "Epoch 00054 | Loss 0.1049 | Time(s) 1.1740 | Accuracy: 87.979294 %\n",
            "Epoch 00055 | Loss 0.1542 | Time(s) 1.1734 | Accuracy: 88.094325 %\n",
            "Epoch 00056 | Loss 0.0425 | Time(s) 1.1734 | Accuracy: 87.864264 %\n",
            "Epoch 00057 | Loss 0.0158 | Time(s) 1.1733 | Accuracy: 88.238113 %\n",
            "Epoch 00058 | Loss 0.1282 | Time(s) 1.1725 | Accuracy: 88.247699 %\n",
            "Epoch 00059 | Loss 0.1405 | Time(s) 1.1736 | Accuracy: 88.238113 %\n",
            "Epoch 00060 | Loss 0.0438 | Time(s) 1.1741 | Accuracy: 87.835506 %\n",
            "Epoch 00061 | Loss 0.0610 | Time(s) 1.1735 | Accuracy: 87.461656 %\n",
            "Epoch 00062 | Loss 0.2325 | Time(s) 1.1733 | Accuracy: 87.845092 %\n",
            "Epoch 00063 | Loss 0.0325 | Time(s) 1.1732 | Accuracy: 87.902607 %\n",
            "Epoch 00064 | Loss 0.0886 | Time(s) 1.1728 | Accuracy: 87.730061 %\n",
            "Epoch 00065 | Loss 0.0301 | Time(s) 1.1722 | Accuracy: 87.931365 %\n",
            "Epoch 00066 | Loss 0.1133 | Time(s) 1.1723 | Accuracy: 88.161426 %\n",
            "Epoch 00067 | Loss 0.0730 | Time(s) 1.1723 | Accuracy: 87.988880 %\n",
            "Epoch 00068 | Loss 0.0309 | Time(s) 1.1721 | Accuracy: 87.864264 %\n",
            "Epoch 00069 | Loss 0.0537 | Time(s) 1.1712 | Accuracy: 87.701304 %\n",
            "Epoch 00070 | Loss 0.0468 | Time(s) 1.1709 | Accuracy: 87.710890 %\n",
            "Epoch 00071 | Loss 0.0428 | Time(s) 1.1702 | Accuracy: 87.739647 %\n",
            "Epoch 00072 | Loss 0.0501 | Time(s) 1.1698 | Accuracy: 87.662960 %\n",
            "Epoch 00073 | Loss 0.0525 | Time(s) 1.1696 | Accuracy: 87.154908 %\n",
            "Epoch 00074 | Loss 0.0415 | Time(s) 1.1693 | Accuracy: 86.991948 %\n",
            "Epoch 00075 | Loss 0.0386 | Time(s) 1.1697 | Accuracy: 87.365798 %\n",
            "Epoch 00076 | Loss 0.0897 | Time(s) 1.1699 | Accuracy: 87.758819 %\n",
            "Epoch 00077 | Loss 0.0079 | Time(s) 1.1692 | Accuracy: 88.036810 %\n",
            "Epoch 00078 | Loss 0.0177 | Time(s) 1.1696 | Accuracy: 87.730061 %\n",
            "Epoch 00079 | Loss 0.0470 | Time(s) 1.1695 | Accuracy: 88.008052 %\n",
            "Epoch 00080 | Loss 0.0195 | Time(s) 1.1699 | Accuracy: 87.864264 %\n",
            "Epoch 00081 | Loss 0.0339 | Time(s) 1.1700 | Accuracy: 87.950537 %\n",
            "Epoch 00082 | Loss 0.0200 | Time(s) 1.1700 | Accuracy: 87.710890 %\n",
            "Epoch 00083 | Loss 0.0555 | Time(s) 1.1697 | Accuracy: 87.576687 %\n",
            "Epoch 00084 | Loss 0.0197 | Time(s) 1.1695 | Accuracy: 87.653374 %\n",
            "Epoch 00085 | Loss 0.0477 | Time(s) 1.1700 | Accuracy: 87.730061 %\n",
            "Epoch 00086 | Loss 0.0539 | Time(s) 1.1703 | Accuracy: 87.691718 %\n",
            "Epoch 00087 | Loss 0.0446 | Time(s) 1.1698 | Accuracy: 87.662960 %\n",
            "Epoch 00088 | Loss 0.0771 | Time(s) 1.1696 | Accuracy: 87.701304 %\n",
            "Epoch 00089 | Loss 0.0158 | Time(s) 1.1704 | Accuracy: 87.749233 %\n",
            "Epoch 00090 | Loss 0.0468 | Time(s) 1.1701 | Accuracy: 87.500000 %\n",
            "Epoch 00091 | Loss 0.0496 | Time(s) 1.1700 | Accuracy: 87.605445 %\n",
            "Epoch 00092 | Loss 0.0058 | Time(s) 1.1699 | Accuracy: 87.605445 %\n",
            "Epoch 00093 | Loss 0.0126 | Time(s) 1.1697 | Accuracy: 87.931365 %\n",
            "Epoch 00094 | Loss 0.0465 | Time(s) 1.1694 | Accuracy: 87.864264 %\n",
            "Epoch 00095 | Loss 0.0219 | Time(s) 1.1698 | Accuracy: 87.960123 %\n",
            "Epoch 00096 | Loss 0.0256 | Time(s) 1.1699 | Accuracy: 87.845092 %\n",
            "Epoch 00097 | Loss 0.0160 | Time(s) 1.1695 | Accuracy: 87.845092 %\n",
            "Epoch 00098 | Loss 0.0430 | Time(s) 1.1692 | Accuracy: 87.940951 %\n",
            "Epoch 00099 | Loss 0.0434 | Time(s) 1.1693 | Accuracy: 87.662960 %\n",
            "Epoch 00100 | Loss 0.0436 | Time(s) 1.1693 | Accuracy: 87.567101 %\n",
            "Epoch 00101 | Loss 0.0584 | Time(s) 1.1694 | Accuracy: 87.691718 %\n",
            "Epoch 00102 | Loss 0.0290 | Time(s) 1.1689 | Accuracy: 87.873850 %\n",
            "Epoch 00103 | Loss 0.0379 | Time(s) 1.1693 | Accuracy: 87.691718 %\n",
            "Epoch 00104 | Loss 0.0045 | Time(s) 1.1695 | Accuracy: 87.615031 %\n",
            "Epoch 00105 | Loss 0.0208 | Time(s) 1.1706 | Accuracy: 87.787577 %\n",
            "Epoch 00106 | Loss 0.0424 | Time(s) 1.1706 | Accuracy: 87.902607 %\n",
            "Epoch 00107 | Loss 0.0123 | Time(s) 1.1706 | Accuracy: 87.902607 %\n",
            "Epoch 00108 | Loss 0.0229 | Time(s) 1.1707 | Accuracy: 87.902607 %\n",
            "Epoch 00109 | Loss 0.0428 | Time(s) 1.1707 | Accuracy: 87.825920 %\n",
            "Epoch 00110 | Loss 0.0425 | Time(s) 1.1702 | Accuracy: 87.720475 %\n",
            "Epoch 00111 | Loss 0.0460 | Time(s) 1.1698 | Accuracy: 87.557515 %\n",
            "Epoch 00112 | Loss 0.0058 | Time(s) 1.1695 | Accuracy: 87.461656 %\n",
            "Epoch 00113 | Loss 0.0044 | Time(s) 1.1692 | Accuracy: 87.576687 %\n",
            "Epoch 00114 | Loss 0.0274 | Time(s) 1.1690 | Accuracy: 87.605445 %\n",
            "Epoch 00115 | Loss 0.0264 | Time(s) 1.1688 | Accuracy: 87.500000 %\n",
            "Epoch 00116 | Loss 0.0488 | Time(s) 1.1684 | Accuracy: 87.442485 %\n",
            "Epoch 00117 | Loss 0.0120 | Time(s) 1.1684 | Accuracy: 87.404141 %\n",
            "Epoch 00118 | Loss 0.0046 | Time(s) 1.1680 | Accuracy: 87.624617 %\n",
            "Epoch 00119 | Loss 0.0043 | Time(s) 1.1675 | Accuracy: 87.595859 %\n",
            "Epoch 00120 | Loss 0.0268 | Time(s) 1.1671 | Accuracy: 87.528758 %\n",
            "Epoch 00121 | Loss 0.0038 | Time(s) 1.1668 | Accuracy: 87.528758 %\n",
            "Epoch 00122 | Loss 0.0431 | Time(s) 1.1667 | Accuracy: 87.653374 %\n",
            "Epoch 00123 | Loss 0.0429 | Time(s) 1.1665 | Accuracy: 87.624617 %\n",
            "Epoch 00124 | Loss 0.0042 | Time(s) 1.1663 | Accuracy: 87.356212 %\n",
            "Epoch 00125 | Loss 0.0121 | Time(s) 1.1662 | Accuracy: 87.452071 %\n",
            "Epoch 00126 | Loss 0.0674 | Time(s) 1.1658 | Accuracy: 87.154908 %\n",
            "Epoch 00127 | Loss 0.0099 | Time(s) 1.1665 | Accuracy: 87.500000 %\n",
            "Epoch 00128 | Loss 0.0848 | Time(s) 1.1663 | Accuracy: 87.384969 %\n",
            "Epoch 00129 | Loss 0.1512 | Time(s) 1.1668 | Accuracy: 87.720475 %\n",
            "Epoch 00130 | Loss 0.0022 | Time(s) 1.1665 | Accuracy: 87.777991 %\n",
            "Epoch 00131 | Loss 0.0030 | Time(s) 1.1666 | Accuracy: 87.413727 %\n",
            "Epoch 00132 | Loss 0.0043 | Time(s) 1.1668 | Accuracy: 87.682132 %\n",
            "Epoch 00133 | Loss 0.0409 | Time(s) 1.1668 | Accuracy: 87.864264 %\n",
            "Epoch 00134 | Loss 0.0243 | Time(s) 1.1668 | Accuracy: 87.739647 %\n",
            "Epoch 00135 | Loss 0.0214 | Time(s) 1.1667 | Accuracy: 87.960123 %\n",
            "Epoch 00136 | Loss 0.0070 | Time(s) 1.1666 | Accuracy: 87.931365 %\n",
            "Epoch 00137 | Loss 0.0025 | Time(s) 1.1669 | Accuracy: 87.758819 %\n",
            "Epoch 00138 | Loss 0.0023 | Time(s) 1.1671 | Accuracy: 87.595859 %\n",
            "Epoch 00139 | Loss 0.0369 | Time(s) 1.1670 | Accuracy: 87.768405 %\n",
            "Epoch 00140 | Loss 0.0514 | Time(s) 1.1675 | Accuracy: 87.576687 %\n",
            "Epoch 00141 | Loss 0.0028 | Time(s) 1.1678 | Accuracy: 87.643788 %\n",
            "Epoch 00142 | Loss 0.0024 | Time(s) 1.1676 | Accuracy: 87.883436 %\n",
            "Epoch 00143 | Loss 0.0497 | Time(s) 1.1676 | Accuracy: 87.864264 %\n",
            "Epoch 00144 | Loss 0.0232 | Time(s) 1.1675 | Accuracy: 87.864264 %\n",
            "Epoch 00145 | Loss 0.0229 | Time(s) 1.1674 | Accuracy: 87.758819 %\n",
            "Epoch 00146 | Loss 0.0411 | Time(s) 1.1675 | Accuracy: 87.758819 %\n",
            "Epoch 00147 | Loss 0.0026 | Time(s) 1.1675 | Accuracy: 87.643788 %\n",
            "Epoch 00148 | Loss 0.0244 | Time(s) 1.1672 | Accuracy: 87.538344 %\n",
            "Epoch 00149 | Loss 0.0225 | Time(s) 1.1671 | Accuracy: 87.710890 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.8384 | Time(s) 1.1404 | Accuracy: 24.108512 %\n",
            "Epoch 00001 | Loss 1.6336 | Time(s) 1.2106 | Accuracy: 32.965874 %\n",
            "Epoch 00002 | Loss 1.4898 | Time(s) 1.2037 | Accuracy: 40.855061 %\n",
            "Epoch 00003 | Loss 1.1557 | Time(s) 1.2059 | Accuracy: 54.792945 %\n",
            "Epoch 00004 | Loss 1.0018 | Time(s) 1.2064 | Accuracy: 54.946319 %\n",
            "Epoch 00005 | Loss 1.0262 | Time(s) 1.2046 | Accuracy: 58.962807 %\n",
            "Epoch 00006 | Loss 1.1790 | Time(s) 1.2050 | Accuracy: 62.039877 %\n",
            "Epoch 00007 | Loss 0.7428 | Time(s) 1.2091 | Accuracy: 67.877684 %\n",
            "Epoch 00008 | Loss 0.6783 | Time(s) 1.2094 | Accuracy: 66.976610 %\n",
            "Epoch 00009 | Loss 0.7385 | Time(s) 1.2018 | Accuracy: 67.628451 %\n",
            "Epoch 00010 | Loss 0.6260 | Time(s) 1.2005 | Accuracy: 68.213190 %\n",
            "Epoch 00011 | Loss 0.9549 | Time(s) 1.1974 | Accuracy: 68.855445 %\n",
            "Epoch 00012 | Loss 0.7202 | Time(s) 1.2011 | Accuracy: 69.507285 %\n",
            "Epoch 00013 | Loss 0.7196 | Time(s) 1.2004 | Accuracy: 69.574387 %\n",
            "Epoch 00014 | Loss 0.7201 | Time(s) 1.2005 | Accuracy: 68.817101 %\n",
            "Epoch 00015 | Loss 0.8421 | Time(s) 1.1979 | Accuracy: 68.481595 %\n",
            "Epoch 00016 | Loss 0.4530 | Time(s) 1.1952 | Accuracy: 69.507285 %\n",
            "Epoch 00017 | Loss 0.4203 | Time(s) 1.1979 | Accuracy: 68.941718 %\n",
            "Epoch 00018 | Loss 0.6158 | Time(s) 1.1961 | Accuracy: 68.874617 %\n",
            "Epoch 00019 | Loss 0.6332 | Time(s) 1.1952 | Accuracy: 69.190951 %\n",
            "Epoch 00020 | Loss 0.7645 | Time(s) 1.1950 | Accuracy: 69.315567 %\n",
            "Epoch 00021 | Loss 0.7876 | Time(s) 1.1932 | Accuracy: 71.462807 %\n",
            "Epoch 00022 | Loss 0.5419 | Time(s) 1.1906 | Accuracy: 72.009202 %\n",
            "Epoch 00023 | Loss 0.6559 | Time(s) 1.1882 | Accuracy: 71.088957 %\n",
            "Epoch 00024 | Loss 0.8660 | Time(s) 1.1905 | Accuracy: 71.146472 %\n",
            "Epoch 00025 | Loss 0.6865 | Time(s) 1.1898 | Accuracy: 71.606595 %\n",
            "Epoch 00026 | Loss 0.6631 | Time(s) 1.1902 | Accuracy: 70.935583 %\n",
            "Epoch 00027 | Loss 0.5514 | Time(s) 1.1887 | Accuracy: 71.750383 %\n",
            "Epoch 00028 | Loss 0.6447 | Time(s) 1.1867 | Accuracy: 72.268021 %\n",
            "Epoch 00029 | Loss 0.5668 | Time(s) 1.1855 | Accuracy: 71.597009 %\n",
            "Epoch 00030 | Loss 0.6913 | Time(s) 1.1856 | Accuracy: 72.085890 %\n",
            "Epoch 00031 | Loss 0.5234 | Time(s) 1.1846 | Accuracy: 71.309433 %\n",
            "Epoch 00032 | Loss 0.6790 | Time(s) 1.1836 | Accuracy: 71.625767 %\n",
            "Epoch 00033 | Loss 0.6420 | Time(s) 1.1828 | Accuracy: 72.210506 %\n",
            "Epoch 00034 | Loss 0.6207 | Time(s) 1.1834 | Accuracy: 72.191334 %\n",
            "Epoch 00035 | Loss 0.6407 | Time(s) 1.1814 | Accuracy: 71.740798 %\n",
            "Epoch 00036 | Loss 0.5567 | Time(s) 1.1800 | Accuracy: 71.616181 %\n",
            "Epoch 00037 | Loss 0.5470 | Time(s) 1.1788 | Accuracy: 71.625767 %\n",
            "Epoch 00038 | Loss 0.3687 | Time(s) 1.1789 | Accuracy: 71.740798 %\n",
            "Epoch 00039 | Loss 0.3627 | Time(s) 1.1781 | Accuracy: 71.951687 %\n",
            "Epoch 00040 | Loss 0.6153 | Time(s) 1.1790 | Accuracy: 72.076304 %\n",
            "Epoch 00041 | Loss 0.6122 | Time(s) 1.1779 | Accuracy: 72.613113 %\n",
            "Epoch 00042 | Loss 0.6778 | Time(s) 1.1767 | Accuracy: 73.101994 %\n",
            "Epoch 00043 | Loss 0.5542 | Time(s) 1.1756 | Accuracy: 73.130752 %\n",
            "Epoch 00044 | Loss 0.5937 | Time(s) 1.1754 | Accuracy: 73.217025 %\n",
            "Epoch 00045 | Loss 0.7298 | Time(s) 1.1745 | Accuracy: 73.054064 %\n",
            "Epoch 00046 | Loss 0.6599 | Time(s) 1.1735 | Accuracy: 72.910276 %\n",
            "Epoch 00047 | Loss 0.4976 | Time(s) 1.1721 | Accuracy: 72.152991 %\n",
            "Epoch 00048 | Loss 0.4937 | Time(s) 1.1727 | Accuracy: 71.462807 %\n",
            "Epoch 00049 | Loss 0.5848 | Time(s) 1.1735 | Accuracy: 71.635353 %\n",
            "Epoch 00050 | Loss 0.5031 | Time(s) 1.1737 | Accuracy: 71.990031 %\n",
            "Epoch 00051 | Loss 0.7837 | Time(s) 1.1726 | Accuracy: 71.299847 %\n",
            "Epoch 00052 | Loss 0.4946 | Time(s) 1.1734 | Accuracy: 71.865414 %\n",
            "Epoch 00053 | Loss 0.5416 | Time(s) 1.1732 | Accuracy: 71.529908 %\n",
            "Epoch 00054 | Loss 0.6663 | Time(s) 1.1740 | Accuracy: 71.539494 %\n",
            "Epoch 00055 | Loss 0.5266 | Time(s) 1.1735 | Accuracy: 72.076304 %\n",
            "Epoch 00056 | Loss 0.5768 | Time(s) 1.1749 | Accuracy: 71.558666 %\n",
            "Epoch 00057 | Loss 0.4996 | Time(s) 1.1740 | Accuracy: 71.213574 %\n",
            "Epoch 00058 | Loss 0.4946 | Time(s) 1.1743 | Accuracy: 72.124233 %\n",
            "Epoch 00059 | Loss 0.4929 | Time(s) 1.1731 | Accuracy: 72.507669 %\n",
            "Epoch 00060 | Loss 0.4911 | Time(s) 1.1726 | Accuracy: 72.450153 %\n",
            "Epoch 00061 | Loss 0.6410 | Time(s) 1.1716 | Accuracy: 71.999617 %\n",
            "Epoch 00062 | Loss 0.5081 | Time(s) 1.1710 | Accuracy: 72.018788 %\n",
            "Epoch 00063 | Loss 0.5185 | Time(s) 1.1705 | Accuracy: 72.152991 %\n",
            "Epoch 00064 | Loss 0.4910 | Time(s) 1.1708 | Accuracy: 72.325537 %\n",
            "Epoch 00065 | Loss 0.5879 | Time(s) 1.1709 | Accuracy: 72.277607 %\n",
            "Epoch 00066 | Loss 0.5806 | Time(s) 1.1716 | Accuracy: 72.469325 %\n",
            "Epoch 00067 | Loss 0.5749 | Time(s) 1.1709 | Accuracy: 72.517255 %\n",
            "Epoch 00068 | Loss 0.6095 | Time(s) 1.1708 | Accuracy: 72.277607 %\n",
            "Epoch 00069 | Loss 0.5722 | Time(s) 1.1706 | Accuracy: 72.028374 %\n",
            "Epoch 00070 | Loss 0.5494 | Time(s) 1.1700 | Accuracy: 72.268021 %\n",
            "Epoch 00071 | Loss 0.4931 | Time(s) 1.1700 | Accuracy: 72.277607 %\n",
            "Epoch 00072 | Loss 0.5294 | Time(s) 1.1694 | Accuracy: 72.335123 %\n",
            "Epoch 00073 | Loss 0.5772 | Time(s) 1.1687 | Accuracy: 72.335123 %\n",
            "Epoch 00074 | Loss 0.5780 | Time(s) 1.1688 | Accuracy: 72.392638 %\n",
            "Epoch 00075 | Loss 0.4890 | Time(s) 1.1688 | Accuracy: 72.248850 %\n",
            "Epoch 00076 | Loss 0.3526 | Time(s) 1.1693 | Accuracy: 72.191334 %\n",
            "Epoch 00077 | Loss 0.6060 | Time(s) 1.1696 | Accuracy: 72.373466 %\n",
            "Epoch 00078 | Loss 0.4904 | Time(s) 1.1699 | Accuracy: 72.469325 %\n",
            "Epoch 00079 | Loss 0.6058 | Time(s) 1.1693 | Accuracy: 72.392638 %\n",
            "Epoch 00080 | Loss 0.3576 | Time(s) 1.1690 | Accuracy: 72.392638 %\n",
            "Epoch 00081 | Loss 0.5810 | Time(s) 1.1682 | Accuracy: 72.383052 %\n",
            "Epoch 00082 | Loss 0.6054 | Time(s) 1.1679 | Accuracy: 72.335123 %\n",
            "Epoch 00083 | Loss 0.5275 | Time(s) 1.1679 | Accuracy: 72.248850 %\n",
            "Epoch 00084 | Loss 0.5275 | Time(s) 1.1677 | Accuracy: 72.152991 %\n",
            "Epoch 00085 | Loss 0.4884 | Time(s) 1.1677 | Accuracy: 71.942101 %\n",
            "Epoch 00086 | Loss 0.5490 | Time(s) 1.1678 | Accuracy: 71.913344 %\n",
            "Epoch 00087 | Loss 0.5473 | Time(s) 1.1678 | Accuracy: 72.239264 %\n",
            "Epoch 00088 | Loss 0.6051 | Time(s) 1.1679 | Accuracy: 72.325537 %\n",
            "Epoch 00089 | Loss 0.5468 | Time(s) 1.1674 | Accuracy: 72.268021 %\n",
            "Epoch 00090 | Loss 0.3537 | Time(s) 1.1672 | Accuracy: 72.335123 %\n",
            "Epoch 00091 | Loss 0.4889 | Time(s) 1.1667 | Accuracy: 72.498083 %\n",
            "Epoch 00092 | Loss 0.5492 | Time(s) 1.1678 | Accuracy: 72.469325 %\n",
            "Epoch 00093 | Loss 0.4888 | Time(s) 1.1687 | Accuracy: 72.344709 %\n",
            "Epoch 00094 | Loss 0.5135 | Time(s) 1.1710 | Accuracy: 72.373466 %\n",
            "Epoch 00095 | Loss 0.5471 | Time(s) 1.1734 | Accuracy: 72.373466 %\n",
            "Epoch 00096 | Loss 0.5270 | Time(s) 1.1757 | Accuracy: 72.239264 %\n",
            "Epoch 00097 | Loss 0.7027 | Time(s) 1.1778 | Accuracy: 72.162577 %\n",
            "Epoch 00098 | Loss 0.4883 | Time(s) 1.1795 | Accuracy: 72.105061 %\n",
            "Epoch 00099 | Loss 0.5769 | Time(s) 1.1795 | Accuracy: 72.047546 %\n",
            "Epoch 00100 | Loss 0.7023 | Time(s) 1.1800 | Accuracy: 72.268021 %\n",
            "Epoch 00101 | Loss 0.4883 | Time(s) 1.1802 | Accuracy: 72.287193 %\n",
            "Epoch 00102 | Loss 0.4885 | Time(s) 1.1806 | Accuracy: 72.076304 %\n",
            "Epoch 00103 | Loss 0.5270 | Time(s) 1.1812 | Accuracy: 72.268021 %\n",
            "Epoch 00104 | Loss 0.4877 | Time(s) 1.1818 | Accuracy: 72.229678 %\n",
            "Epoch 00105 | Loss 0.6048 | Time(s) 1.1823 | Accuracy: 72.344709 %\n",
            "Epoch 00106 | Loss 0.6054 | Time(s) 1.1831 | Accuracy: 71.894172 %\n",
            "Epoch 00107 | Loss 0.6047 | Time(s) 1.1836 | Accuracy: 71.970859 %\n",
            "Epoch 00108 | Loss 0.5466 | Time(s) 1.1842 | Accuracy: 72.440567 %\n",
            "Epoch 00109 | Loss 0.4879 | Time(s) 1.1845 | Accuracy: 72.354294 %\n",
            "Epoch 00110 | Loss 0.6045 | Time(s) 1.1846 | Accuracy: 72.383052 %\n",
            "Epoch 00111 | Loss 0.4881 | Time(s) 1.1848 | Accuracy: 72.383052 %\n",
            "Epoch 00112 | Loss 0.6827 | Time(s) 1.1844 | Accuracy: 72.315951 %\n",
            "Epoch 00113 | Loss 0.5467 | Time(s) 1.1841 | Accuracy: 72.229678 %\n",
            "Epoch 00114 | Loss 0.5466 | Time(s) 1.1840 | Accuracy: 72.210506 %\n",
            "Epoch 00115 | Loss 0.3517 | Time(s) 1.1836 | Accuracy: 72.076304 %\n",
            "Epoch 00116 | Loss 0.5470 | Time(s) 1.1835 | Accuracy: 72.143405 %\n",
            "Epoch 00117 | Loss 0.6477 | Time(s) 1.1833 | Accuracy: 72.133819 %\n",
            "Epoch 00118 | Loss 0.3521 | Time(s) 1.1839 | Accuracy: 72.181748 %\n",
            "Epoch 00119 | Loss 0.5135 | Time(s) 1.1846 | Accuracy: 72.248850 %\n",
            "Epoch 00120 | Loss 0.5267 | Time(s) 1.1844 | Accuracy: 72.114647 %\n",
            "Epoch 00121 | Loss 0.5203 | Time(s) 1.1841 | Accuracy: 72.114647 %\n",
            "Epoch 00122 | Loss 0.6483 | Time(s) 1.1844 | Accuracy: 72.124233 %\n",
            "Epoch 00123 | Loss 0.6464 | Time(s) 1.1854 | Accuracy: 72.172163 %\n",
            "Epoch 00124 | Loss 0.6457 | Time(s) 1.1868 | Accuracy: 72.191334 %\n",
            "Epoch 00125 | Loss 0.5266 | Time(s) 1.1904 | Accuracy: 72.268021 %\n",
            "Epoch 00126 | Loss 0.5460 | Time(s) 1.1927 | Accuracy: 72.018788 %\n",
            "Epoch 00127 | Loss 0.4877 | Time(s) 1.1945 | Accuracy: 71.865414 %\n",
            "Epoch 00128 | Loss 0.4877 | Time(s) 1.1968 | Accuracy: 71.855828 %\n",
            "Epoch 00129 | Loss 0.6834 | Time(s) 1.1987 | Accuracy: 71.990031 %\n",
            "Epoch 00130 | Loss 0.4875 | Time(s) 1.2004 | Accuracy: 72.076304 %\n",
            "Epoch 00131 | Loss 0.6041 | Time(s) 1.2019 | Accuracy: 72.152991 %\n",
            "Epoch 00132 | Loss 0.6820 | Time(s) 1.2033 | Accuracy: 72.009202 %\n",
            "Epoch 00133 | Loss 0.5703 | Time(s) 1.2043 | Accuracy: 72.114647 %\n",
            "Epoch 00134 | Loss 0.6830 | Time(s) 1.2051 | Accuracy: 72.124233 %\n",
            "Epoch 00135 | Loss 0.5463 | Time(s) 1.2058 | Accuracy: 72.181748 %\n",
            "Epoch 00136 | Loss 0.6451 | Time(s) 1.2067 | Accuracy: 72.143405 %\n",
            "Epoch 00137 | Loss 0.5261 | Time(s) 1.2075 | Accuracy: 71.951687 %\n",
            "Epoch 00138 | Loss 0.5261 | Time(s) 1.2086 | Accuracy: 71.961273 %\n",
            "Epoch 00139 | Loss 0.6041 | Time(s) 1.2093 | Accuracy: 71.961273 %\n",
            "Epoch 00140 | Loss 0.5794 | Time(s) 1.2099 | Accuracy: 71.875000 %\n",
            "Epoch 00141 | Loss 0.5260 | Time(s) 1.2107 | Accuracy: 71.903758 %\n",
            "Epoch 00142 | Loss 0.5484 | Time(s) 1.2114 | Accuracy: 72.028374 %\n",
            "Epoch 00143 | Loss 0.5261 | Time(s) 1.2125 | Accuracy: 72.152991 %\n",
            "Epoch 00144 | Loss 0.6040 | Time(s) 1.2134 | Accuracy: 72.239264 %\n",
            "Epoch 00145 | Loss 0.5190 | Time(s) 1.2143 | Accuracy: 72.191334 %\n",
            "Epoch 00146 | Loss 0.5714 | Time(s) 1.2155 | Accuracy: 72.143405 %\n",
            "Epoch 00147 | Loss 0.5717 | Time(s) 1.2168 | Accuracy: 71.990031 %\n",
            "Epoch 00148 | Loss 0.3511 | Time(s) 1.2182 | Accuracy: 71.970859 %\n",
            "Epoch 00149 | Loss 0.3513 | Time(s) 1.2195 | Accuracy: 72.076304 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.4617 | Time(s) 1.4534 | Accuracy: 31.269172 %\n",
            "Epoch 00001 | Loss 1.5398 | Time(s) 1.4310 | Accuracy: 49.482362 %\n",
            "Epoch 00002 | Loss 1.4272 | Time(s) 1.4199 | Accuracy: 57.323620 %\n",
            "Epoch 00003 | Loss 1.2717 | Time(s) 1.4108 | Accuracy: 59.902224 %\n",
            "Epoch 00004 | Loss 1.0453 | Time(s) 1.4057 | Accuracy: 66.439801 %\n",
            "Epoch 00005 | Loss 1.1538 | Time(s) 1.4143 | Accuracy: 66.612347 %\n",
            "Epoch 00006 | Loss 1.0867 | Time(s) 1.4054 | Accuracy: 68.433666 %\n",
            "Epoch 00007 | Loss 0.9901 | Time(s) 1.4022 | Accuracy: 68.817101 %\n",
            "Epoch 00008 | Loss 0.8386 | Time(s) 1.4007 | Accuracy: 69.823620 %\n",
            "Epoch 00009 | Loss 0.9305 | Time(s) 1.3980 | Accuracy: 70.523390 %\n",
            "Epoch 00010 | Loss 0.6327 | Time(s) 1.3934 | Accuracy: 69.794862 %\n",
            "Epoch 00011 | Loss 0.6157 | Time(s) 1.3930 | Accuracy: 70.053681 %\n",
            "Epoch 00012 | Loss 0.7675 | Time(s) 1.3914 | Accuracy: 70.398773 %\n",
            "Epoch 00013 | Loss 0.8123 | Time(s) 1.3890 | Accuracy: 70.801380 %\n",
            "Epoch 00014 | Loss 0.7997 | Time(s) 1.3861 | Accuracy: 70.887653 %\n",
            "Epoch 00015 | Loss 0.5736 | Time(s) 1.3862 | Accuracy: 69.804448 %\n",
            "Epoch 00016 | Loss 0.5347 | Time(s) 1.3803 | Accuracy: 69.315567 %\n",
            "Epoch 00017 | Loss 0.8530 | Time(s) 1.3768 | Accuracy: 70.465874 %\n",
            "Epoch 00018 | Loss 0.8551 | Time(s) 1.3724 | Accuracy: 70.417945 %\n",
            "Epoch 00019 | Loss 0.8107 | Time(s) 1.3669 | Accuracy: 71.184816 %\n",
            "Epoch 00020 | Loss 0.5315 | Time(s) 1.3633 | Accuracy: 70.485046 %\n",
            "Epoch 00021 | Loss 0.7583 | Time(s) 1.3622 | Accuracy: 70.628834 %\n",
            "Epoch 00022 | Loss 0.6248 | Time(s) 1.3624 | Accuracy: 71.050613 %\n",
            "Epoch 00023 | Loss 0.5767 | Time(s) 1.3611 | Accuracy: 71.184816 %\n",
            "Epoch 00024 | Loss 0.6838 | Time(s) 1.3609 | Accuracy: 71.453221 %\n",
            "Epoch 00025 | Loss 0.5792 | Time(s) 1.3601 | Accuracy: 71.261503 %\n",
            "Epoch 00026 | Loss 0.6649 | Time(s) 1.3589 | Accuracy: 71.913344 %\n",
            "Epoch 00027 | Loss 0.6077 | Time(s) 1.3566 | Accuracy: 71.817485 %\n",
            "Epoch 00028 | Loss 0.4815 | Time(s) 1.3532 | Accuracy: 71.328604 %\n",
            "Epoch 00029 | Loss 0.4781 | Time(s) 1.3519 | Accuracy: 71.261503 %\n",
            "Epoch 00030 | Loss 0.4878 | Time(s) 1.3489 | Accuracy: 71.625767 %\n",
            "Epoch 00031 | Loss 0.6588 | Time(s) 1.3475 | Accuracy: 71.712040 %\n",
            "Epoch 00032 | Loss 0.7212 | Time(s) 1.3478 | Accuracy: 71.855828 %\n",
            "Epoch 00033 | Loss 0.6687 | Time(s) 1.3473 | Accuracy: 71.798313 %\n",
            "Epoch 00034 | Loss 0.6152 | Time(s) 1.3467 | Accuracy: 71.855828 %\n",
            "Epoch 00035 | Loss 0.9445 | Time(s) 1.3477 | Accuracy: 72.258436 %\n",
            "Epoch 00036 | Loss 0.6063 | Time(s) 1.3469 | Accuracy: 70.820552 %\n",
            "Epoch 00037 | Loss 0.6599 | Time(s) 1.3487 | Accuracy: 71.041028 %\n",
            "Epoch 00038 | Loss 0.5804 | Time(s) 1.3554 | Accuracy: 70.724693 %\n",
            "Epoch 00039 | Loss 0.5278 | Time(s) 1.3582 | Accuracy: 70.964340 %\n",
            "Epoch 00040 | Loss 0.7370 | Time(s) 1.3578 | Accuracy: 71.913344 %\n",
            "Epoch 00041 | Loss 0.5008 | Time(s) 1.3571 | Accuracy: 71.712040 %\n",
            "Epoch 00042 | Loss 0.4653 | Time(s) 1.3558 | Accuracy: 71.913344 %\n",
            "Epoch 00043 | Loss 0.6516 | Time(s) 1.3543 | Accuracy: 71.606595 %\n",
            "Epoch 00044 | Loss 0.6783 | Time(s) 1.3538 | Accuracy: 70.916411 %\n",
            "Epoch 00045 | Loss 0.6425 | Time(s) 1.3538 | Accuracy: 71.558666 %\n",
            "Epoch 00046 | Loss 0.7005 | Time(s) 1.3566 | Accuracy: 71.510736 %\n",
            "Epoch 00047 | Loss 0.7028 | Time(s) 1.3583 | Accuracy: 71.673696 %\n",
            "Epoch 00048 | Loss 0.4463 | Time(s) 1.3592 | Accuracy: 71.539494 %\n",
            "Epoch 00049 | Loss 0.6535 | Time(s) 1.3623 | Accuracy: 71.568252 %\n",
            "Epoch 00050 | Loss 0.7517 | Time(s) 1.3624 | Accuracy: 71.309433 %\n",
            "Epoch 00051 | Loss 0.7312 | Time(s) 1.3636 | Accuracy: 71.299847 %\n",
            "Epoch 00052 | Loss 0.4656 | Time(s) 1.3640 | Accuracy: 71.664110 %\n",
            "Epoch 00053 | Loss 0.6336 | Time(s) 1.3681 | Accuracy: 72.200920 %\n",
            "Epoch 00054 | Loss 0.6821 | Time(s) 1.3703 | Accuracy: 71.942101 %\n",
            "Epoch 00055 | Loss 0.6502 | Time(s) 1.3706 | Accuracy: 72.210506 %\n",
            "Epoch 00056 | Loss 0.4596 | Time(s) 1.3693 | Accuracy: 71.961273 %\n",
            "Epoch 00057 | Loss 0.5564 | Time(s) 1.3695 | Accuracy: 72.047546 %\n",
            "Epoch 00058 | Loss 0.5104 | Time(s) 1.3708 | Accuracy: 71.759969 %\n",
            "Epoch 00059 | Loss 0.7194 | Time(s) 1.3738 | Accuracy: 71.549080 %\n",
            "Epoch 00060 | Loss 0.4187 | Time(s) 1.3751 | Accuracy: 71.405291 %\n",
            "Epoch 00061 | Loss 0.4764 | Time(s) 1.3761 | Accuracy: 71.683282 %\n",
            "Epoch 00062 | Loss 0.6889 | Time(s) 1.3757 | Accuracy: 71.616181 %\n",
            "Epoch 00063 | Loss 0.7152 | Time(s) 1.3757 | Accuracy: 71.673696 %\n",
            "Epoch 00064 | Loss 0.4593 | Time(s) 1.3751 | Accuracy: 71.922929 %\n",
            "Epoch 00065 | Loss 0.6304 | Time(s) 1.3761 | Accuracy: 72.085890 %\n",
            "Epoch 00066 | Loss 0.4154 | Time(s) 1.3755 | Accuracy: 71.951687 %\n",
            "Epoch 00067 | Loss 0.4570 | Time(s) 1.3756 | Accuracy: 72.162577 %\n",
            "Epoch 00068 | Loss 0.5309 | Time(s) 1.3760 | Accuracy: 72.152991 %\n",
            "Epoch 00069 | Loss 0.5306 | Time(s) 1.3764 | Accuracy: 72.124233 %\n",
            "Epoch 00070 | Loss 0.6494 | Time(s) 1.3766 | Accuracy: 71.807899 %\n",
            "Epoch 00071 | Loss 0.7105 | Time(s) 1.3769 | Accuracy: 71.951687 %\n",
            "Epoch 00072 | Loss 0.6875 | Time(s) 1.3772 | Accuracy: 71.759969 %\n",
            "Epoch 00073 | Loss 0.4206 | Time(s) 1.3787 | Accuracy: 71.817485 %\n",
            "Epoch 00074 | Loss 0.4594 | Time(s) 1.3783 | Accuracy: 71.903758 %\n",
            "Epoch 00075 | Loss 0.4754 | Time(s) 1.3792 | Accuracy: 71.251917 %\n",
            "Epoch 00076 | Loss 0.4132 | Time(s) 1.3793 | Accuracy: 72.210506 %\n",
            "Epoch 00077 | Loss 0.4121 | Time(s) 1.3796 | Accuracy: 72.028374 %\n",
            "Epoch 00078 | Loss 0.5496 | Time(s) 1.3798 | Accuracy: 71.836656 %\n",
            "Epoch 00079 | Loss 0.4138 | Time(s) 1.3799 | Accuracy: 71.817485 %\n",
            "Epoch 00080 | Loss 0.5539 | Time(s) 1.3802 | Accuracy: 71.827071 %\n",
            "Epoch 00081 | Loss 0.4654 | Time(s) 1.3790 | Accuracy: 72.009202 %\n",
            "Epoch 00082 | Loss 0.6870 | Time(s) 1.3786 | Accuracy: 72.028374 %\n",
            "Epoch 00083 | Loss 0.6164 | Time(s) 1.3775 | Accuracy: 72.143405 %\n",
            "Epoch 00084 | Loss 0.6749 | Time(s) 1.3775 | Accuracy: 71.903758 %\n",
            "Epoch 00085 | Loss 0.6443 | Time(s) 1.3766 | Accuracy: 71.692868 %\n",
            "Epoch 00086 | Loss 0.4185 | Time(s) 1.3759 | Accuracy: 71.146472 %\n",
            "Epoch 00087 | Loss 0.5520 | Time(s) 1.3750 | Accuracy: 71.549080 %\n",
            "Epoch 00088 | Loss 0.6489 | Time(s) 1.3739 | Accuracy: 71.769555 %\n",
            "Epoch 00089 | Loss 0.6291 | Time(s) 1.3738 | Accuracy: 71.654525 %\n",
            "Epoch 00090 | Loss 0.6766 | Time(s) 1.3734 | Accuracy: 71.481979 %\n",
            "Epoch 00091 | Loss 0.4545 | Time(s) 1.3730 | Accuracy: 71.366948 %\n",
            "Epoch 00092 | Loss 0.5437 | Time(s) 1.3726 | Accuracy: 71.357362 %\n",
            "Epoch 00093 | Loss 0.4114 | Time(s) 1.3718 | Accuracy: 71.539494 %\n",
            "Epoch 00094 | Loss 0.4775 | Time(s) 1.3714 | Accuracy: 71.558666 %\n",
            "Epoch 00095 | Loss 0.6132 | Time(s) 1.3709 | Accuracy: 71.855828 %\n",
            "Epoch 00096 | Loss 0.6451 | Time(s) 1.3695 | Accuracy: 71.079371 %\n",
            "Epoch 00097 | Loss 0.5332 | Time(s) 1.3694 | Accuracy: 71.414877 %\n",
            "Epoch 00098 | Loss 0.7203 | Time(s) 1.3682 | Accuracy: 71.625767 %\n",
            "Epoch 00099 | Loss 0.6823 | Time(s) 1.3675 | Accuracy: 72.181748 %\n",
            "Epoch 00100 | Loss 0.5049 | Time(s) 1.3666 | Accuracy: 72.287193 %\n",
            "Epoch 00101 | Loss 0.6118 | Time(s) 1.3656 | Accuracy: 71.424463 %\n",
            "Epoch 00102 | Loss 0.7031 | Time(s) 1.3652 | Accuracy: 71.002684 %\n",
            "Epoch 00103 | Loss 0.5303 | Time(s) 1.3655 | Accuracy: 71.865414 %\n",
            "Epoch 00104 | Loss 0.7006 | Time(s) 1.3649 | Accuracy: 71.702454 %\n",
            "Epoch 00105 | Loss 0.6738 | Time(s) 1.3644 | Accuracy: 71.635353 %\n",
            "Epoch 00106 | Loss 0.6387 | Time(s) 1.3636 | Accuracy: 71.673696 %\n",
            "Epoch 00107 | Loss 0.5948 | Time(s) 1.3635 | Accuracy: 71.740798 %\n",
            "Epoch 00108 | Loss 0.4527 | Time(s) 1.3625 | Accuracy: 71.654525 %\n",
            "Epoch 00109 | Loss 0.4141 | Time(s) 1.3621 | Accuracy: 71.702454 %\n",
            "Epoch 00110 | Loss 0.6660 | Time(s) 1.3616 | Accuracy: 71.990031 %\n",
            "Epoch 00111 | Loss 0.4957 | Time(s) 1.3606 | Accuracy: 72.124233 %\n",
            "Epoch 00112 | Loss 0.5290 | Time(s) 1.3604 | Accuracy: 71.970859 %\n",
            "Epoch 00113 | Loss 0.4718 | Time(s) 1.3597 | Accuracy: 71.568252 %\n",
            "Epoch 00114 | Loss 0.7132 | Time(s) 1.3594 | Accuracy: 71.721626 %\n",
            "Epoch 00115 | Loss 0.4570 | Time(s) 1.3590 | Accuracy: 71.779141 %\n",
            "Epoch 00116 | Loss 0.4529 | Time(s) 1.3585 | Accuracy: 71.616181 %\n",
            "Epoch 00117 | Loss 0.4689 | Time(s) 1.3584 | Accuracy: 70.763037 %\n",
            "Epoch 00118 | Loss 0.6964 | Time(s) 1.3581 | Accuracy: 71.664110 %\n",
            "Epoch 00119 | Loss 0.5657 | Time(s) 1.3577 | Accuracy: 70.552147 %\n",
            "Epoch 00120 | Loss 0.6346 | Time(s) 1.3578 | Accuracy: 71.683282 %\n",
            "Epoch 00121 | Loss 0.7152 | Time(s) 1.3593 | Accuracy: 71.750383 %\n",
            "Epoch 00122 | Loss 0.5375 | Time(s) 1.3591 | Accuracy: 71.290261 %\n",
            "Epoch 00123 | Loss 0.6582 | Time(s) 1.3598 | Accuracy: 71.759969 %\n",
            "Epoch 00124 | Loss 0.7038 | Time(s) 1.3612 | Accuracy: 71.903758 %\n",
            "Epoch 00125 | Loss 0.6027 | Time(s) 1.3616 | Accuracy: 71.990031 %\n",
            "Epoch 00126 | Loss 0.4592 | Time(s) 1.3618 | Accuracy: 71.453221 %\n",
            "Epoch 00127 | Loss 0.5312 | Time(s) 1.3626 | Accuracy: 71.510736 %\n",
            "Epoch 00128 | Loss 0.6341 | Time(s) 1.3624 | Accuracy: 71.875000 %\n",
            "Epoch 00129 | Loss 0.4797 | Time(s) 1.3625 | Accuracy: 71.999617 %\n",
            "Epoch 00130 | Loss 0.5811 | Time(s) 1.3628 | Accuracy: 71.884586 %\n",
            "Epoch 00131 | Loss 0.5306 | Time(s) 1.3629 | Accuracy: 72.018788 %\n",
            "Epoch 00132 | Loss 0.4714 | Time(s) 1.3632 | Accuracy: 72.325537 %\n",
            "Epoch 00133 | Loss 0.4689 | Time(s) 1.3633 | Accuracy: 72.009202 %\n",
            "Epoch 00134 | Loss 0.4583 | Time(s) 1.3634 | Accuracy: 72.095475 %\n",
            "Epoch 00135 | Loss 0.6362 | Time(s) 1.3637 | Accuracy: 71.942101 %\n",
            "Epoch 00136 | Loss 0.4598 | Time(s) 1.3644 | Accuracy: 71.951687 %\n",
            "Epoch 00137 | Loss 0.4686 | Time(s) 1.3650 | Accuracy: 72.143405 %\n",
            "Epoch 00138 | Loss 0.6663 | Time(s) 1.3656 | Accuracy: 72.028374 %\n",
            "Epoch 00139 | Loss 0.5279 | Time(s) 1.3662 | Accuracy: 72.268021 %\n",
            "Epoch 00140 | Loss 0.4679 | Time(s) 1.3658 | Accuracy: 72.268021 %\n",
            "Epoch 00141 | Loss 0.6649 | Time(s) 1.3653 | Accuracy: 72.152991 %\n",
            "Epoch 00142 | Loss 0.5739 | Time(s) 1.3650 | Accuracy: 72.335123 %\n",
            "Epoch 00143 | Loss 0.6645 | Time(s) 1.3653 | Accuracy: 72.210506 %\n",
            "Epoch 00144 | Loss 0.4102 | Time(s) 1.3648 | Accuracy: 72.239264 %\n",
            "Epoch 00145 | Loss 0.6317 | Time(s) 1.3645 | Accuracy: 72.143405 %\n",
            "Epoch 00146 | Loss 0.5265 | Time(s) 1.3645 | Accuracy: 72.047546 %\n",
            "Epoch 00147 | Loss 0.6712 | Time(s) 1.3646 | Accuracy: 72.325537 %\n",
            "Epoch 00148 | Loss 0.6240 | Time(s) 1.3644 | Accuracy: 72.143405 %\n",
            "Epoch 00149 | Loss 0.4101 | Time(s) 1.3641 | Accuracy: 72.229678 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.4473 | Time(s) 1.3403 | Accuracy: 34.748850 %\n",
            "Epoch 00001 | Loss 1.1080 | Time(s) 1.3269 | Accuracy: 59.940567 %\n",
            "Epoch 00002 | Loss 1.0530 | Time(s) 1.3187 | Accuracy: 62.059049 %\n",
            "Epoch 00003 | Loss 1.0793 | Time(s) 1.3142 | Accuracy: 68.711656 %\n",
            "Epoch 00004 | Loss 1.0717 | Time(s) 1.3323 | Accuracy: 71.577837 %\n",
            "Epoch 00005 | Loss 0.8709 | Time(s) 1.3267 | Accuracy: 70.139954 %\n",
            "Epoch 00006 | Loss 0.7046 | Time(s) 1.3220 | Accuracy: 71.184816 %\n",
            "Epoch 00007 | Loss 0.7717 | Time(s) 1.3189 | Accuracy: 74.491948 %\n",
            "Epoch 00008 | Loss 0.8635 | Time(s) 1.3183 | Accuracy: 75.364264 %\n",
            "Epoch 00009 | Loss 0.4955 | Time(s) 1.3134 | Accuracy: 74.511120 %\n",
            "Epoch 00010 | Loss 0.5557 | Time(s) 1.3110 | Accuracy: 76.140721 %\n",
            "Epoch 00011 | Loss 0.4163 | Time(s) 1.3112 | Accuracy: 76.504985 %\n",
            "Epoch 00012 | Loss 0.5415 | Time(s) 1.3117 | Accuracy: 76.907592 %\n",
            "Epoch 00013 | Loss 0.4897 | Time(s) 1.3110 | Accuracy: 77.712807 %\n",
            "Epoch 00014 | Loss 0.4743 | Time(s) 1.3115 | Accuracy: 77.722393 %\n",
            "Epoch 00015 | Loss 0.3486 | Time(s) 1.3109 | Accuracy: 78.105828 %\n",
            "Epoch 00016 | Loss 0.3425 | Time(s) 1.3142 | Accuracy: 77.875767 %\n",
            "Epoch 00017 | Loss 0.3389 | Time(s) 1.3137 | Accuracy: 78.700153 %\n",
            "Epoch 00018 | Loss 0.6986 | Time(s) 1.3159 | Accuracy: 79.160276 %\n",
            "Epoch 00019 | Loss 0.4831 | Time(s) 1.3153 | Accuracy: 78.939801 %\n",
            "Epoch 00020 | Loss 0.4365 | Time(s) 1.3154 | Accuracy: 78.776840 %\n",
            "Epoch 00021 | Loss 0.5961 | Time(s) 1.3160 | Accuracy: 78.824770 %\n",
            "Epoch 00022 | Loss 0.6831 | Time(s) 1.3173 | Accuracy: 79.591641 %\n",
            "Epoch 00023 | Loss 0.5912 | Time(s) 1.3162 | Accuracy: 79.562883 %\n",
            "Epoch 00024 | Loss 0.5663 | Time(s) 1.3153 | Accuracy: 78.815184 %\n",
            "Epoch 00025 | Loss 0.4367 | Time(s) 1.3175 | Accuracy: 79.802531 %\n",
            "Epoch 00026 | Loss 0.3855 | Time(s) 1.3168 | Accuracy: 79.716258 %\n",
            "Epoch 00027 | Loss 0.3104 | Time(s) 1.3165 | Accuracy: 79.275307 %\n",
            "Epoch 00028 | Loss 0.4941 | Time(s) 1.3175 | Accuracy: 79.246549 %\n",
            "Epoch 00029 | Loss 0.3173 | Time(s) 1.3169 | Accuracy: 79.668328 %\n",
            "Epoch 00030 | Loss 0.4582 | Time(s) 1.3171 | Accuracy: 79.879218 %\n",
            "Epoch 00031 | Loss 0.3782 | Time(s) 1.3164 | Accuracy: 79.725844 %\n",
            "Epoch 00032 | Loss 0.3876 | Time(s) 1.3160 | Accuracy: 79.361580 %\n",
            "Epoch 00033 | Loss 0.4121 | Time(s) 1.3154 | Accuracy: 79.486196 %\n",
            "Epoch 00034 | Loss 0.3935 | Time(s) 1.3150 | Accuracy: 79.629985 %\n",
            "Epoch 00035 | Loss 0.3341 | Time(s) 1.3156 | Accuracy: 79.735429 %\n",
            "Epoch 00036 | Loss 0.4080 | Time(s) 1.3154 | Accuracy: 80.444785 %\n",
            "Epoch 00037 | Loss 0.3495 | Time(s) 1.3153 | Accuracy: 80.090107 %\n",
            "Epoch 00038 | Loss 0.3907 | Time(s) 1.3163 | Accuracy: 80.070936 %\n",
            "Epoch 00039 | Loss 0.3661 | Time(s) 1.3174 | Accuracy: 79.869632 %\n",
            "Epoch 00040 | Loss 0.4595 | Time(s) 1.3183 | Accuracy: 79.677914 %\n",
            "Epoch 00041 | Loss 0.4619 | Time(s) 1.3184 | Accuracy: 78.997316 %\n",
            "Epoch 00042 | Loss 0.3630 | Time(s) 1.3179 | Accuracy: 79.428681 %\n",
            "Epoch 00043 | Loss 0.3169 | Time(s) 1.3174 | Accuracy: 80.061350 %\n",
            "Epoch 00044 | Loss 0.5759 | Time(s) 1.3174 | Accuracy: 79.725844 %\n",
            "Epoch 00045 | Loss 0.4081 | Time(s) 1.3179 | Accuracy: 79.754601 %\n",
            "Epoch 00046 | Loss 0.4540 | Time(s) 1.3183 | Accuracy: 78.316718 %\n",
            "Epoch 00047 | Loss 0.3241 | Time(s) 1.3184 | Accuracy: 79.169862 %\n",
            "Epoch 00048 | Loss 0.3957 | Time(s) 1.3184 | Accuracy: 76.773390 %\n",
            "Epoch 00049 | Loss 0.3950 | Time(s) 1.3182 | Accuracy: 79.246549 %\n",
            "Epoch 00050 | Loss 0.3808 | Time(s) 1.3183 | Accuracy: 79.284893 %\n",
            "Epoch 00051 | Loss 0.5153 | Time(s) 1.3184 | Accuracy: 78.863113 %\n",
            "Epoch 00052 | Loss 0.4337 | Time(s) 1.3179 | Accuracy: 80.003834 %\n",
            "Epoch 00053 | Loss 0.3921 | Time(s) 1.3180 | Accuracy: 79.907975 %\n",
            "Epoch 00054 | Loss 0.4184 | Time(s) 1.3179 | Accuracy: 79.917561 %\n",
            "Epoch 00055 | Loss 0.3855 | Time(s) 1.3184 | Accuracy: 79.792945 %\n",
            "Epoch 00056 | Loss 0.3154 | Time(s) 1.3182 | Accuracy: 79.735429 %\n",
            "Epoch 00057 | Loss 0.5580 | Time(s) 1.3177 | Accuracy: 79.984663 %\n",
            "Epoch 00058 | Loss 0.3778 | Time(s) 1.3173 | Accuracy: 79.907975 %\n",
            "Epoch 00059 | Loss 0.5131 | Time(s) 1.3170 | Accuracy: 79.256135 %\n",
            "Epoch 00060 | Loss 0.4250 | Time(s) 1.3169 | Accuracy: 80.099693 %\n",
            "Epoch 00061 | Loss 0.3628 | Time(s) 1.3185 | Accuracy: 80.109279 %\n",
            "Epoch 00062 | Loss 0.4694 | Time(s) 1.3183 | Accuracy: 78.901457 %\n",
            "Epoch 00063 | Loss 0.3771 | Time(s) 1.3193 | Accuracy: 79.524540 %\n",
            "Epoch 00064 | Loss 0.4519 | Time(s) 1.3198 | Accuracy: 79.610813 %\n",
            "Epoch 00065 | Loss 0.3776 | Time(s) 1.3199 | Accuracy: 79.994248 %\n",
            "Epoch 00066 | Loss 0.5386 | Time(s) 1.3194 | Accuracy: 80.109279 %\n",
            "Epoch 00067 | Loss 0.4508 | Time(s) 1.3193 | Accuracy: 79.898390 %\n",
            "Epoch 00068 | Loss 0.3141 | Time(s) 1.3189 | Accuracy: 80.051764 %\n",
            "Epoch 00069 | Loss 0.3157 | Time(s) 1.3189 | Accuracy: 80.377684 %\n",
            "Epoch 00070 | Loss 0.3386 | Time(s) 1.3186 | Accuracy: 80.147623 %\n",
            "Epoch 00071 | Loss 0.5430 | Time(s) 1.3194 | Accuracy: 80.138037 %\n",
            "Epoch 00072 | Loss 0.3732 | Time(s) 1.3194 | Accuracy: 80.090107 %\n",
            "Epoch 00073 | Loss 0.3441 | Time(s) 1.3191 | Accuracy: 79.677914 %\n",
            "Epoch 00074 | Loss 0.3340 | Time(s) 1.3191 | Accuracy: 79.668328 %\n",
            "Epoch 00075 | Loss 0.3812 | Time(s) 1.3190 | Accuracy: 79.783359 %\n",
            "Epoch 00076 | Loss 0.5379 | Time(s) 1.3189 | Accuracy: 79.888804 %\n",
            "Epoch 00077 | Loss 0.4001 | Time(s) 1.3192 | Accuracy: 80.205138 %\n",
            "Epoch 00078 | Loss 0.3728 | Time(s) 1.3192 | Accuracy: 80.032592 %\n",
            "Epoch 00079 | Loss 0.3889 | Time(s) 1.3190 | Accuracy: 79.840874 %\n",
            "Epoch 00080 | Loss 0.3128 | Time(s) 1.3191 | Accuracy: 79.840874 %\n",
            "Epoch 00081 | Loss 0.3129 | Time(s) 1.3190 | Accuracy: 79.965491 %\n",
            "Epoch 00082 | Loss 0.3351 | Time(s) 1.3190 | Accuracy: 79.907975 %\n",
            "Epoch 00083 | Loss 0.4804 | Time(s) 1.3192 | Accuracy: 79.840874 %\n",
            "Epoch 00084 | Loss 0.4437 | Time(s) 1.3204 | Accuracy: 79.994248 %\n",
            "Epoch 00085 | Loss 0.3753 | Time(s) 1.3201 | Accuracy: 80.099693 %\n",
            "Epoch 00086 | Loss 0.3707 | Time(s) 1.3202 | Accuracy: 79.735429 %\n",
            "Epoch 00087 | Loss 0.3342 | Time(s) 1.3201 | Accuracy: 79.572469 %\n",
            "Epoch 00088 | Loss 0.5407 | Time(s) 1.3201 | Accuracy: 79.610813 %\n",
            "Epoch 00089 | Loss 0.5587 | Time(s) 1.3198 | Accuracy: 79.907975 %\n",
            "Epoch 00090 | Loss 0.3347 | Time(s) 1.3200 | Accuracy: 79.706672 %\n",
            "Epoch 00091 | Loss 0.3729 | Time(s) 1.3205 | Accuracy: 79.524540 %\n",
            "Epoch 00092 | Loss 0.3725 | Time(s) 1.3208 | Accuracy: 79.313650 %\n",
            "Epoch 00093 | Loss 0.3539 | Time(s) 1.3209 | Accuracy: 79.332822 %\n",
            "Epoch 00094 | Loss 0.4899 | Time(s) 1.3214 | Accuracy: 79.888804 %\n",
            "Epoch 00095 | Loss 0.5314 | Time(s) 1.3211 | Accuracy: 79.860046 %\n",
            "Epoch 00096 | Loss 0.4341 | Time(s) 1.3213 | Accuracy: 79.706672 %\n",
            "Epoch 00097 | Loss 0.3341 | Time(s) 1.3211 | Accuracy: 79.888804 %\n",
            "Epoch 00098 | Loss 0.5310 | Time(s) 1.3213 | Accuracy: 80.138037 %\n",
            "Epoch 00099 | Loss 0.3122 | Time(s) 1.3211 | Accuracy: 80.013420 %\n",
            "Epoch 00100 | Loss 0.4890 | Time(s) 1.3215 | Accuracy: 79.984663 %\n",
            "Epoch 00101 | Loss 0.2935 | Time(s) 1.3219 | Accuracy: 79.869632 %\n",
            "Epoch 00102 | Loss 0.4327 | Time(s) 1.3219 | Accuracy: 80.013420 %\n",
            "Epoch 00103 | Loss 0.4359 | Time(s) 1.3220 | Accuracy: 79.888804 %\n",
            "Epoch 00104 | Loss 0.2932 | Time(s) 1.3222 | Accuracy: 79.745015 %\n",
            "Epoch 00105 | Loss 0.4889 | Time(s) 1.3220 | Accuracy: 79.802531 %\n",
            "Epoch 00106 | Loss 0.3758 | Time(s) 1.3223 | Accuracy: 79.773773 %\n",
            "Epoch 00107 | Loss 0.3680 | Time(s) 1.3228 | Accuracy: 79.754601 %\n",
            "Epoch 00108 | Loss 0.3321 | Time(s) 1.3231 | Accuracy: 79.850460 %\n",
            "Epoch 00109 | Loss 0.3320 | Time(s) 1.3233 | Accuracy: 79.697086 %\n",
            "Epoch 00110 | Loss 0.3319 | Time(s) 1.3235 | Accuracy: 79.428681 %\n",
            "Epoch 00111 | Loss 0.2932 | Time(s) 1.3237 | Accuracy: 79.284893 %\n",
            "Epoch 00112 | Loss 0.5288 | Time(s) 1.3237 | Accuracy: 79.687500 %\n",
            "Epoch 00113 | Loss 0.3572 | Time(s) 1.3238 | Accuracy: 79.591641 %\n",
            "Epoch 00114 | Loss 0.3368 | Time(s) 1.3238 | Accuracy: 79.677914 %\n",
            "Epoch 00115 | Loss 0.3866 | Time(s) 1.3242 | Accuracy: 79.754601 %\n",
            "Epoch 00116 | Loss 0.3336 | Time(s) 1.3242 | Accuracy: 79.601227 %\n",
            "Epoch 00117 | Loss 0.4331 | Time(s) 1.3242 | Accuracy: 79.534126 %\n",
            "Epoch 00118 | Loss 0.3807 | Time(s) 1.3246 | Accuracy: 79.697086 %\n",
            "Epoch 00119 | Loss 0.4901 | Time(s) 1.3246 | Accuracy: 79.562883 %\n",
            "Epoch 00120 | Loss 0.3598 | Time(s) 1.3245 | Accuracy: 79.524540 %\n",
            "Epoch 00121 | Loss 0.4878 | Time(s) 1.3246 | Accuracy: 79.735429 %\n",
            "Epoch 00122 | Loss 0.4339 | Time(s) 1.3245 | Accuracy: 79.649156 %\n",
            "Epoch 00123 | Loss 0.5335 | Time(s) 1.3249 | Accuracy: 79.514954 %\n",
            "Epoch 00124 | Loss 0.2933 | Time(s) 1.3248 | Accuracy: 79.495782 %\n",
            "Epoch 00125 | Loss 0.3751 | Time(s) 1.3249 | Accuracy: 79.256135 %\n",
            "Epoch 00126 | Loss 0.3710 | Time(s) 1.3250 | Accuracy: 79.246549 %\n",
            "Epoch 00127 | Loss 0.3735 | Time(s) 1.3251 | Accuracy: 79.524540 %\n",
            "Epoch 00128 | Loss 0.5302 | Time(s) 1.3253 | Accuracy: 79.438267 %\n",
            "Epoch 00129 | Loss 0.5289 | Time(s) 1.3255 | Accuracy: 79.332822 %\n",
            "Epoch 00130 | Loss 0.3117 | Time(s) 1.3260 | Accuracy: 79.045245 %\n",
            "Epoch 00131 | Loss 0.4890 | Time(s) 1.3262 | Accuracy: 79.246549 %\n",
            "Epoch 00132 | Loss 0.3334 | Time(s) 1.3261 | Accuracy: 79.409509 %\n",
            "Epoch 00133 | Loss 0.4745 | Time(s) 1.3260 | Accuracy: 79.409509 %\n",
            "Epoch 00134 | Loss 0.3327 | Time(s) 1.3261 | Accuracy: 79.514954 %\n",
            "Epoch 00135 | Loss 0.3559 | Time(s) 1.3261 | Accuracy: 79.495782 %\n",
            "Epoch 00136 | Loss 0.3320 | Time(s) 1.3261 | Accuracy: 79.505368 %\n",
            "Epoch 00137 | Loss 0.5279 | Time(s) 1.3261 | Accuracy: 79.399923 %\n",
            "Epoch 00138 | Loss 0.4307 | Time(s) 1.3263 | Accuracy: 79.514954 %\n",
            "Epoch 00139 | Loss 0.2927 | Time(s) 1.3265 | Accuracy: 79.610813 %\n",
            "Epoch 00140 | Loss 0.4875 | Time(s) 1.3266 | Accuracy: 79.658742 %\n",
            "Epoch 00141 | Loss 0.5359 | Time(s) 1.3265 | Accuracy: 79.716258 %\n",
            "Epoch 00142 | Loss 0.3706 | Time(s) 1.3263 | Accuracy: 79.812117 %\n",
            "Epoch 00143 | Loss 0.4507 | Time(s) 1.3263 | Accuracy: 79.649156 %\n",
            "Epoch 00144 | Loss 0.3326 | Time(s) 1.3261 | Accuracy: 79.677914 %\n",
            "Epoch 00145 | Loss 0.2927 | Time(s) 1.3260 | Accuracy: 79.745015 %\n",
            "Epoch 00146 | Loss 0.3631 | Time(s) 1.3261 | Accuracy: 79.697086 %\n",
            "Epoch 00147 | Loss 0.3116 | Time(s) 1.3263 | Accuracy: 79.745015 %\n",
            "Epoch 00148 | Loss 0.3315 | Time(s) 1.3261 | Accuracy: 79.697086 %\n",
            "Epoch 00149 | Loss 0.3315 | Time(s) 1.3264 | Accuracy: 79.543712 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.6702 | Time(s) 1.3815 | Accuracy: 35.266488 %\n",
            "Epoch 00001 | Loss 1.5988 | Time(s) 1.3815 | Accuracy: 41.113880 %\n",
            "Epoch 00002 | Loss 1.4999 | Time(s) 1.3758 | Accuracy: 42.983129 %\n",
            "Epoch 00003 | Loss 1.4304 | Time(s) 1.3654 | Accuracy: 46.702454 %\n",
            "Epoch 00004 | Loss 1.2830 | Time(s) 1.3575 | Accuracy: 53.719325 %\n",
            "Epoch 00005 | Loss 1.0562 | Time(s) 1.3569 | Accuracy: 61.560583 %\n",
            "Epoch 00006 | Loss 0.9604 | Time(s) 1.3555 | Accuracy: 61.819402 %\n",
            "Epoch 00007 | Loss 0.7910 | Time(s) 1.3543 | Accuracy: 62.739647 %\n",
            "Epoch 00008 | Loss 1.0428 | Time(s) 1.3596 | Accuracy: 66.439801 %\n",
            "Epoch 00009 | Loss 0.6333 | Time(s) 1.3607 | Accuracy: 69.200537 %\n",
            "Epoch 00010 | Loss 0.8850 | Time(s) 1.3560 | Accuracy: 69.296396 %\n",
            "Epoch 00011 | Loss 0.5722 | Time(s) 1.3547 | Accuracy: 70.197469 %\n",
            "Epoch 00012 | Loss 0.8201 | Time(s) 1.3521 | Accuracy: 71.510736 %\n",
            "Epoch 00013 | Loss 0.7296 | Time(s) 1.3522 | Accuracy: 71.223160 %\n",
            "Epoch 00014 | Loss 0.7194 | Time(s) 1.3527 | Accuracy: 71.616181 %\n",
            "Epoch 00015 | Loss 0.4670 | Time(s) 1.3532 | Accuracy: 72.028374 %\n",
            "Epoch 00016 | Loss 0.5437 | Time(s) 1.3519 | Accuracy: 72.287193 %\n",
            "Epoch 00017 | Loss 0.4969 | Time(s) 1.3500 | Accuracy: 72.277607 %\n",
            "Epoch 00018 | Loss 0.7035 | Time(s) 1.3499 | Accuracy: 72.152991 %\n",
            "Epoch 00019 | Loss 0.3947 | Time(s) 1.3495 | Accuracy: 72.239264 %\n",
            "Epoch 00020 | Loss 0.5787 | Time(s) 1.3515 | Accuracy: 72.526840 %\n",
            "Epoch 00021 | Loss 0.4911 | Time(s) 1.3518 | Accuracy: 73.245782 %\n",
            "Epoch 00022 | Loss 0.4193 | Time(s) 1.3512 | Accuracy: 72.824003 %\n",
            "Epoch 00023 | Loss 0.3440 | Time(s) 1.3503 | Accuracy: 73.763420 %\n",
            "Epoch 00024 | Loss 0.3870 | Time(s) 1.3498 | Accuracy: 73.571702 %\n",
            "Epoch 00025 | Loss 0.4411 | Time(s) 1.3489 | Accuracy: 73.495015 %\n",
            "Epoch 00026 | Loss 0.6462 | Time(s) 1.3487 | Accuracy: 73.705905 %\n",
            "Epoch 00027 | Loss 0.6439 | Time(s) 1.3488 | Accuracy: 75.287577 %\n",
            "Epoch 00028 | Loss 0.4084 | Time(s) 1.3489 | Accuracy: 77.645706 %\n",
            "Epoch 00029 | Loss 0.4587 | Time(s) 1.3502 | Accuracy: 77.837423 %\n",
            "Epoch 00030 | Loss 0.5661 | Time(s) 1.3517 | Accuracy: 77.540261 %\n",
            "Epoch 00031 | Loss 0.3422 | Time(s) 1.3530 | Accuracy: 77.501917 %\n",
            "Epoch 00032 | Loss 0.2899 | Time(s) 1.3521 | Accuracy: 78.240031 %\n",
            "Epoch 00033 | Loss 0.4371 | Time(s) 1.3512 | Accuracy: 78.565951 %\n",
            "Epoch 00034 | Loss 0.3836 | Time(s) 1.3500 | Accuracy: 79.102761 %\n",
            "Epoch 00035 | Loss 0.3161 | Time(s) 1.3489 | Accuracy: 79.601227 %\n",
            "Epoch 00036 | Loss 0.3626 | Time(s) 1.3508 | Accuracy: 79.467025 %\n",
            "Epoch 00037 | Loss 0.4725 | Time(s) 1.3498 | Accuracy: 79.457439 %\n",
            "Epoch 00038 | Loss 0.3116 | Time(s) 1.3498 | Accuracy: 79.131518 %\n",
            "Epoch 00039 | Loss 0.4104 | Time(s) 1.3493 | Accuracy: 79.572469 %\n",
            "Epoch 00040 | Loss 0.4821 | Time(s) 1.3484 | Accuracy: 79.409509 %\n",
            "Epoch 00041 | Loss 0.3502 | Time(s) 1.3483 | Accuracy: 79.093175 %\n",
            "Epoch 00042 | Loss 0.3668 | Time(s) 1.3504 | Accuracy: 78.930215 %\n",
            "Epoch 00043 | Loss 0.3056 | Time(s) 1.3503 | Accuracy: 78.891871 %\n",
            "Epoch 00044 | Loss 0.4048 | Time(s) 1.3506 | Accuracy: 80.224310 %\n",
            "Epoch 00045 | Loss 0.4030 | Time(s) 1.3511 | Accuracy: 80.655675 %\n",
            "Epoch 00046 | Loss 0.4017 | Time(s) 1.3515 | Accuracy: 80.329755 %\n",
            "Epoch 00047 | Loss 0.4004 | Time(s) 1.3506 | Accuracy: 80.023006 %\n",
            "Epoch 00048 | Loss 0.4014 | Time(s) 1.3503 | Accuracy: 80.080521 %\n",
            "Epoch 00049 | Loss 0.4067 | Time(s) 1.3500 | Accuracy: 79.486196 %\n",
            "Epoch 00050 | Loss 0.2593 | Time(s) 1.3497 | Accuracy: 79.658742 %\n",
            "Epoch 00051 | Loss 0.5559 | Time(s) 1.3494 | Accuracy: 78.997316 %\n",
            "Epoch 00052 | Loss 0.4988 | Time(s) 1.3497 | Accuracy: 79.888804 %\n",
            "Epoch 00053 | Loss 0.4240 | Time(s) 1.3503 | Accuracy: 79.812117 %\n",
            "Epoch 00054 | Loss 0.4993 | Time(s) 1.3498 | Accuracy: 80.300997 %\n",
            "Epoch 00055 | Loss 0.3996 | Time(s) 1.3504 | Accuracy: 79.160276 %\n",
            "Epoch 00056 | Loss 0.2623 | Time(s) 1.3505 | Accuracy: 78.508436 %\n",
            "Epoch 00057 | Loss 0.3558 | Time(s) 1.3503 | Accuracy: 79.831288 %\n",
            "Epoch 00058 | Loss 0.3552 | Time(s) 1.3500 | Accuracy: 80.291411 %\n",
            "Epoch 00059 | Loss 0.3977 | Time(s) 1.3496 | Accuracy: 80.703604 %\n",
            "Epoch 00060 | Loss 0.4364 | Time(s) 1.3496 | Accuracy: 80.665261 %\n",
            "Epoch 00061 | Loss 0.4446 | Time(s) 1.3505 | Accuracy: 80.090107 %\n",
            "Epoch 00062 | Loss 0.5005 | Time(s) 1.3506 | Accuracy: 80.023006 %\n",
            "Epoch 00063 | Loss 0.2952 | Time(s) 1.3505 | Accuracy: 80.185966 %\n",
            "Epoch 00064 | Loss 0.3501 | Time(s) 1.3508 | Accuracy: 80.262653 %\n",
            "Epoch 00065 | Loss 0.4029 | Time(s) 1.3506 | Accuracy: 80.243482 %\n",
            "Epoch 00066 | Loss 0.3924 | Time(s) 1.3508 | Accuracy: 80.463957 %\n",
            "Epoch 00067 | Loss 0.4396 | Time(s) 1.3509 | Accuracy: 80.157209 %\n",
            "Epoch 00068 | Loss 0.3645 | Time(s) 1.3506 | Accuracy: 79.802531 %\n",
            "Epoch 00069 | Loss 0.4812 | Time(s) 1.3504 | Accuracy: 80.099693 %\n",
            "Epoch 00070 | Loss 0.3421 | Time(s) 1.3502 | Accuracy: 80.502301 %\n",
            "Epoch 00071 | Loss 0.4376 | Time(s) 1.3501 | Accuracy: 80.531058 %\n",
            "Epoch 00072 | Loss 0.3578 | Time(s) 1.3499 | Accuracy: 80.607745 %\n",
            "Epoch 00073 | Loss 0.2669 | Time(s) 1.3499 | Accuracy: 80.358512 %\n",
            "Epoch 00074 | Loss 0.3552 | Time(s) 1.3499 | Accuracy: 80.377684 %\n",
            "Epoch 00075 | Loss 0.3551 | Time(s) 1.3500 | Accuracy: 80.607745 %\n",
            "Epoch 00076 | Loss 0.5241 | Time(s) 1.3505 | Accuracy: 80.703604 %\n",
            "Epoch 00077 | Loss 0.3360 | Time(s) 1.3500 | Accuracy: 80.770706 %\n",
            "Epoch 00078 | Loss 0.3355 | Time(s) 1.3498 | Accuracy: 80.396856 %\n",
            "Epoch 00079 | Loss 0.3351 | Time(s) 1.3494 | Accuracy: 80.406442 %\n",
            "Epoch 00080 | Loss 0.4749 | Time(s) 1.3490 | Accuracy: 80.550230 %\n",
            "Epoch 00081 | Loss 0.3339 | Time(s) 1.3487 | Accuracy: 80.377684 %\n",
            "Epoch 00082 | Loss 0.2591 | Time(s) 1.3487 | Accuracy: 80.157209 %\n",
            "Epoch 00083 | Loss 0.4787 | Time(s) 1.3483 | Accuracy: 80.358512 %\n",
            "Epoch 00084 | Loss 0.3916 | Time(s) 1.3481 | Accuracy: 80.291411 %\n",
            "Epoch 00085 | Loss 0.3915 | Time(s) 1.3477 | Accuracy: 80.502301 %\n",
            "Epoch 00086 | Loss 0.4318 | Time(s) 1.3486 | Accuracy: 80.694018 %\n",
            "Epoch 00087 | Loss 0.3831 | Time(s) 1.3487 | Accuracy: 80.473543 %\n",
            "Epoch 00088 | Loss 0.3423 | Time(s) 1.3493 | Accuracy: 80.416028 %\n",
            "Epoch 00089 | Loss 0.3830 | Time(s) 1.3497 | Accuracy: 80.463957 %\n",
            "Epoch 00090 | Loss 0.3341 | Time(s) 1.3502 | Accuracy: 80.406442 %\n",
            "Epoch 00091 | Loss 0.4716 | Time(s) 1.3513 | Accuracy: 80.329755 %\n",
            "Epoch 00092 | Loss 0.4708 | Time(s) 1.3521 | Accuracy: 80.473543 %\n",
            "Epoch 00093 | Loss 0.2937 | Time(s) 1.3532 | Accuracy: 80.646089 %\n",
            "Epoch 00094 | Loss 0.4703 | Time(s) 1.3549 | Accuracy: 80.809049 %\n",
            "Epoch 00095 | Loss 0.4704 | Time(s) 1.3569 | Accuracy: 80.809049 %\n",
            "Epoch 00096 | Loss 0.3439 | Time(s) 1.3586 | Accuracy: 80.943252 %\n",
            "Epoch 00097 | Loss 0.4929 | Time(s) 1.3604 | Accuracy: 80.789877 %\n",
            "Epoch 00098 | Loss 0.3912 | Time(s) 1.3624 | Accuracy: 80.761120 %\n",
            "Epoch 00099 | Loss 0.4332 | Time(s) 1.3639 | Accuracy: 80.511887 %\n",
            "Epoch 00100 | Loss 0.2932 | Time(s) 1.3650 | Accuracy: 80.502301 %\n",
            "Epoch 00101 | Loss 0.4901 | Time(s) 1.3653 | Accuracy: 80.281825 %\n",
            "Epoch 00102 | Loss 0.2933 | Time(s) 1.3652 | Accuracy: 80.166794 %\n",
            "Epoch 00103 | Loss 0.4713 | Time(s) 1.3646 | Accuracy: 80.262653 %\n",
            "Epoch 00104 | Loss 0.3910 | Time(s) 1.3641 | Accuracy: 80.473543 %\n",
            "Epoch 00105 | Loss 0.3803 | Time(s) 1.3640 | Accuracy: 80.483129 %\n",
            "Epoch 00106 | Loss 0.3327 | Time(s) 1.3643 | Accuracy: 80.483129 %\n",
            "Epoch 00107 | Loss 0.3326 | Time(s) 1.3649 | Accuracy: 80.425613 %\n",
            "Epoch 00108 | Loss 0.3526 | Time(s) 1.3652 | Accuracy: 80.435199 %\n",
            "Epoch 00109 | Loss 0.4689 | Time(s) 1.3658 | Accuracy: 80.550230 %\n",
            "Epoch 00110 | Loss 0.3814 | Time(s) 1.3658 | Accuracy: 80.540644 %\n",
            "Epoch 00111 | Loss 0.3802 | Time(s) 1.3664 | Accuracy: 80.492715 %\n",
            "Epoch 00112 | Loss 0.3444 | Time(s) 1.3674 | Accuracy: 80.416028 %\n",
            "Epoch 00113 | Loss 0.3417 | Time(s) 1.3676 | Accuracy: 80.473543 %\n",
            "Epoch 00114 | Loss 0.3329 | Time(s) 1.3682 | Accuracy: 80.109279 %\n",
            "Epoch 00115 | Loss 0.3330 | Time(s) 1.3688 | Accuracy: 79.812117 %\n",
            "Epoch 00116 | Loss 0.3519 | Time(s) 1.3693 | Accuracy: 79.984663 %\n",
            "Epoch 00117 | Loss 0.4690 | Time(s) 1.3700 | Accuracy: 80.291411 %\n",
            "Epoch 00118 | Loss 0.4688 | Time(s) 1.3708 | Accuracy: 80.416028 %\n",
            "Epoch 00119 | Loss 0.3773 | Time(s) 1.3713 | Accuracy: 80.291411 %\n",
            "Epoch 00120 | Loss 0.3905 | Time(s) 1.3713 | Accuracy: 80.253067 %\n",
            "Epoch 00121 | Loss 0.3321 | Time(s) 1.3709 | Accuracy: 80.454371 %\n",
            "Epoch 00122 | Loss 0.4684 | Time(s) 1.3706 | Accuracy: 80.626917 %\n",
            "Epoch 00123 | Loss 0.4927 | Time(s) 1.3705 | Accuracy: 80.473543 %\n",
            "Epoch 00124 | Loss 0.2927 | Time(s) 1.3702 | Accuracy: 80.540644 %\n",
            "Epoch 00125 | Loss 0.3385 | Time(s) 1.3701 | Accuracy: 80.626917 %\n",
            "Epoch 00126 | Loss 0.3516 | Time(s) 1.3699 | Accuracy: 80.521472 %\n",
            "Epoch 00127 | Loss 0.2926 | Time(s) 1.3698 | Accuracy: 80.588574 %\n",
            "Epoch 00128 | Loss 0.2537 | Time(s) 1.3700 | Accuracy: 80.425613 %\n",
            "Epoch 00129 | Loss 0.3890 | Time(s) 1.3699 | Accuracy: 80.329755 %\n",
            "Epoch 00130 | Loss 0.2924 | Time(s) 1.3698 | Accuracy: 80.205138 %\n",
            "Epoch 00131 | Loss 0.3877 | Time(s) 1.3698 | Accuracy: 80.387270 %\n",
            "Epoch 00132 | Loss 0.2934 | Time(s) 1.3698 | Accuracy: 80.320169 %\n",
            "Epoch 00133 | Loss 0.3903 | Time(s) 1.3699 | Accuracy: 80.626917 %\n",
            "Epoch 00134 | Loss 0.3903 | Time(s) 1.3695 | Accuracy: 80.588574 %\n",
            "Epoch 00135 | Loss 0.2924 | Time(s) 1.3695 | Accuracy: 80.483129 %\n",
            "Epoch 00136 | Loss 0.3519 | Time(s) 1.3693 | Accuracy: 80.483129 %\n",
            "Epoch 00137 | Loss 0.3321 | Time(s) 1.3690 | Accuracy: 80.377684 %\n",
            "Epoch 00138 | Loss 0.3346 | Time(s) 1.3688 | Accuracy: 80.339340 %\n",
            "Epoch 00139 | Loss 0.4685 | Time(s) 1.3693 | Accuracy: 80.377684 %\n",
            "Epoch 00140 | Loss 0.3517 | Time(s) 1.3690 | Accuracy: 80.425613 %\n",
            "Epoch 00141 | Loss 0.4684 | Time(s) 1.3688 | Accuracy: 80.416028 %\n",
            "Epoch 00142 | Loss 0.2923 | Time(s) 1.3687 | Accuracy: 80.214724 %\n",
            "Epoch 00143 | Loss 0.4295 | Time(s) 1.3685 | Accuracy: 80.099693 %\n",
            "Epoch 00144 | Loss 0.3381 | Time(s) 1.3682 | Accuracy: 80.128451 %\n",
            "Epoch 00145 | Loss 0.3900 | Time(s) 1.3679 | Accuracy: 80.157209 %\n",
            "Epoch 00146 | Loss 0.4683 | Time(s) 1.3678 | Accuracy: 80.061350 %\n",
            "Epoch 00147 | Loss 0.2923 | Time(s) 1.3674 | Accuracy: 80.003834 %\n",
            "Epoch 00148 | Loss 0.4300 | Time(s) 1.3672 | Accuracy: 79.936733 %\n",
            "Epoch 00149 | Loss 0.3363 | Time(s) 1.3669 | Accuracy: 79.946319 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7777 | Time(s) 1.3660 | Accuracy: 26.236580 %\n",
            "Epoch 00001 | Loss 1.5656 | Time(s) 1.3411 | Accuracy: 35.764954 %\n",
            "Epoch 00002 | Loss 1.4089 | Time(s) 1.3377 | Accuracy: 46.041028 %\n",
            "Epoch 00003 | Loss 1.0820 | Time(s) 1.3381 | Accuracy: 57.026457 %\n",
            "Epoch 00004 | Loss 0.9976 | Time(s) 1.3437 | Accuracy: 59.470859 %\n",
            "Epoch 00005 | Loss 1.0756 | Time(s) 1.3487 | Accuracy: 59.480445 %\n",
            "Epoch 00006 | Loss 0.7781 | Time(s) 1.3489 | Accuracy: 62.078221 %\n",
            "Epoch 00007 | Loss 1.0216 | Time(s) 1.3464 | Accuracy: 64.666411 %\n",
            "Epoch 00008 | Loss 0.9062 | Time(s) 1.3493 | Accuracy: 66.506902 %\n",
            "Epoch 00009 | Loss 0.9340 | Time(s) 1.3488 | Accuracy: 67.753067 %\n",
            "Epoch 00010 | Loss 0.7603 | Time(s) 1.3492 | Accuracy: 68.960890 %\n",
            "Epoch 00011 | Loss 0.6164 | Time(s) 1.3502 | Accuracy: 69.545629 %\n",
            "Epoch 00012 | Loss 0.9034 | Time(s) 1.3474 | Accuracy: 69.564801 %\n",
            "Epoch 00013 | Loss 0.6587 | Time(s) 1.3457 | Accuracy: 69.488113 %\n",
            "Epoch 00014 | Loss 0.9031 | Time(s) 1.3477 | Accuracy: 68.481595 %\n",
            "Epoch 00015 | Loss 0.6929 | Time(s) 1.3481 | Accuracy: 68.845859 %\n",
            "Epoch 00016 | Loss 0.8387 | Time(s) 1.3483 | Accuracy: 69.075920 %\n",
            "Epoch 00017 | Loss 0.5457 | Time(s) 1.3488 | Accuracy: 69.957822 %\n",
            "Epoch 00018 | Loss 0.7615 | Time(s) 1.3475 | Accuracy: 70.638420 %\n",
            "Epoch 00019 | Loss 0.8657 | Time(s) 1.3511 | Accuracy: 70.695936 %\n",
            "Epoch 00020 | Loss 0.8474 | Time(s) 1.3504 | Accuracy: 70.734279 %\n",
            "Epoch 00021 | Loss 0.6059 | Time(s) 1.3526 | Accuracy: 70.600077 %\n",
            "Epoch 00022 | Loss 0.5078 | Time(s) 1.3534 | Accuracy: 70.858896 %\n",
            "Epoch 00023 | Loss 0.6694 | Time(s) 1.3535 | Accuracy: 70.935583 %\n",
            "Epoch 00024 | Loss 0.5093 | Time(s) 1.3525 | Accuracy: 71.127301 %\n",
            "Epoch 00025 | Loss 0.6931 | Time(s) 1.3525 | Accuracy: 71.472393 %\n",
            "Epoch 00026 | Loss 0.8057 | Time(s) 1.3521 | Accuracy: 70.839724 %\n",
            "Epoch 00027 | Loss 0.4845 | Time(s) 1.3532 | Accuracy: 70.657592 %\n",
            "Epoch 00028 | Loss 0.7376 | Time(s) 1.3535 | Accuracy: 71.328604 %\n",
            "Epoch 00029 | Loss 0.4910 | Time(s) 1.3533 | Accuracy: 71.558666 %\n",
            "Epoch 00030 | Loss 0.6882 | Time(s) 1.3530 | Accuracy: 71.434049 %\n",
            "Epoch 00031 | Loss 0.5622 | Time(s) 1.3530 | Accuracy: 71.779141 %\n",
            "Epoch 00032 | Loss 0.7866 | Time(s) 1.3529 | Accuracy: 70.945169 %\n",
            "Epoch 00033 | Loss 0.6679 | Time(s) 1.3526 | Accuracy: 70.600077 %\n",
            "Epoch 00034 | Loss 0.5311 | Time(s) 1.3530 | Accuracy: 71.549080 %\n",
            "Epoch 00035 | Loss 0.4555 | Time(s) 1.3527 | Accuracy: 71.347776 %\n",
            "Epoch 00036 | Loss 0.7612 | Time(s) 1.3527 | Accuracy: 71.175230 %\n",
            "Epoch 00037 | Loss 0.4385 | Time(s) 1.3531 | Accuracy: 71.606595 %\n",
            "Epoch 00038 | Loss 0.5996 | Time(s) 1.3524 | Accuracy: 71.788727 %\n",
            "Epoch 00039 | Loss 0.5832 | Time(s) 1.3516 | Accuracy: 71.759969 %\n",
            "Epoch 00040 | Loss 0.7232 | Time(s) 1.3517 | Accuracy: 71.731212 %\n",
            "Epoch 00041 | Loss 0.4240 | Time(s) 1.3519 | Accuracy: 71.577837 %\n",
            "Epoch 00042 | Loss 0.6448 | Time(s) 1.3551 | Accuracy: 71.635353 %\n",
            "Epoch 00043 | Loss 0.4654 | Time(s) 1.3553 | Accuracy: 71.692868 %\n",
            "Epoch 00044 | Loss 0.4706 | Time(s) 1.3552 | Accuracy: 71.779141 %\n",
            "Epoch 00045 | Loss 0.6681 | Time(s) 1.3545 | Accuracy: 71.779141 %\n",
            "Epoch 00046 | Loss 0.7445 | Time(s) 1.3541 | Accuracy: 71.664110 %\n",
            "Epoch 00047 | Loss 0.6135 | Time(s) 1.3544 | Accuracy: 71.098543 %\n",
            "Epoch 00048 | Loss 0.7561 | Time(s) 1.3542 | Accuracy: 71.597009 %\n",
            "Epoch 00049 | Loss 0.4747 | Time(s) 1.3540 | Accuracy: 70.791794 %\n",
            "Epoch 00050 | Loss 0.7243 | Time(s) 1.3538 | Accuracy: 71.481979 %\n",
            "Epoch 00051 | Loss 0.7187 | Time(s) 1.3539 | Accuracy: 71.290261 %\n",
            "Epoch 00052 | Loss 0.4236 | Time(s) 1.3534 | Accuracy: 71.558666 %\n",
            "Epoch 00053 | Loss 0.7121 | Time(s) 1.3535 | Accuracy: 71.827071 %\n",
            "Epoch 00054 | Loss 0.7981 | Time(s) 1.3540 | Accuracy: 72.009202 %\n",
            "Epoch 00055 | Loss 0.4236 | Time(s) 1.3541 | Accuracy: 71.587423 %\n",
            "Epoch 00056 | Loss 0.4605 | Time(s) 1.3540 | Accuracy: 71.616181 %\n",
            "Epoch 00057 | Loss 0.4258 | Time(s) 1.3542 | Accuracy: 71.549080 %\n",
            "Epoch 00058 | Loss 0.4213 | Time(s) 1.3542 | Accuracy: 71.520322 %\n",
            "Epoch 00059 | Loss 0.6835 | Time(s) 1.3538 | Accuracy: 71.951687 %\n",
            "Epoch 00060 | Loss 0.6469 | Time(s) 1.3544 | Accuracy: 71.692868 %\n",
            "Epoch 00061 | Loss 0.7377 | Time(s) 1.3548 | Accuracy: 71.529908 %\n",
            "Epoch 00062 | Loss 0.5758 | Time(s) 1.3542 | Accuracy: 71.156058 %\n",
            "Epoch 00063 | Loss 0.4139 | Time(s) 1.3538 | Accuracy: 71.319018 %\n",
            "Epoch 00064 | Loss 0.4581 | Time(s) 1.3541 | Accuracy: 71.558666 %\n",
            "Epoch 00065 | Loss 0.4187 | Time(s) 1.3550 | Accuracy: 71.338190 %\n",
            "Epoch 00066 | Loss 0.4574 | Time(s) 1.3552 | Accuracy: 71.271089 %\n",
            "Epoch 00067 | Loss 0.7072 | Time(s) 1.3558 | Accuracy: 71.405291 %\n",
            "Epoch 00068 | Loss 0.6482 | Time(s) 1.3561 | Accuracy: 71.529908 %\n",
            "Epoch 00069 | Loss 0.4565 | Time(s) 1.3562 | Accuracy: 71.481979 %\n",
            "Epoch 00070 | Loss 0.4546 | Time(s) 1.3563 | Accuracy: 71.769555 %\n",
            "Epoch 00071 | Loss 0.4532 | Time(s) 1.3564 | Accuracy: 71.759969 %\n",
            "Epoch 00072 | Loss 0.6498 | Time(s) 1.3565 | Accuracy: 71.644939 %\n",
            "Epoch 00073 | Loss 0.4544 | Time(s) 1.3562 | Accuracy: 71.712040 %\n",
            "Epoch 00074 | Loss 0.4156 | Time(s) 1.3564 | Accuracy: 71.434049 %\n",
            "Epoch 00075 | Loss 0.7040 | Time(s) 1.3568 | Accuracy: 71.779141 %\n",
            "Epoch 00076 | Loss 0.4131 | Time(s) 1.3565 | Accuracy: 71.424463 %\n",
            "Epoch 00077 | Loss 0.4124 | Time(s) 1.3566 | Accuracy: 71.625767 %\n",
            "Epoch 00078 | Loss 0.6402 | Time(s) 1.3565 | Accuracy: 71.750383 %\n",
            "Epoch 00079 | Loss 0.6340 | Time(s) 1.3563 | Accuracy: 71.807899 %\n",
            "Epoch 00080 | Loss 0.4126 | Time(s) 1.3562 | Accuracy: 71.683282 %\n",
            "Epoch 00081 | Loss 0.6358 | Time(s) 1.3561 | Accuracy: 72.028374 %\n",
            "Epoch 00082 | Loss 0.7038 | Time(s) 1.3557 | Accuracy: 71.913344 %\n",
            "Epoch 00083 | Loss 0.4115 | Time(s) 1.3557 | Accuracy: 71.635353 %\n",
            "Epoch 00084 | Loss 0.6511 | Time(s) 1.3556 | Accuracy: 71.568252 %\n",
            "Epoch 00085 | Loss 0.6362 | Time(s) 1.3556 | Accuracy: 71.846242 %\n",
            "Epoch 00086 | Loss 0.5475 | Time(s) 1.3558 | Accuracy: 71.759969 %\n",
            "Epoch 00087 | Loss 0.6313 | Time(s) 1.3559 | Accuracy: 71.702454 %\n",
            "Epoch 00088 | Loss 0.4518 | Time(s) 1.3556 | Accuracy: 71.395706 %\n",
            "Epoch 00089 | Loss 0.6338 | Time(s) 1.3556 | Accuracy: 71.184816 %\n",
            "Epoch 00090 | Loss 0.6357 | Time(s) 1.3555 | Accuracy: 71.386120 %\n",
            "Epoch 00091 | Loss 0.5539 | Time(s) 1.3553 | Accuracy: 70.504218 %\n",
            "Epoch 00092 | Loss 0.6836 | Time(s) 1.3550 | Accuracy: 70.293328 %\n",
            "Epoch 00093 | Loss 0.6228 | Time(s) 1.3552 | Accuracy: 71.319018 %\n",
            "Epoch 00094 | Loss 0.4118 | Time(s) 1.3550 | Accuracy: 71.855828 %\n",
            "Epoch 00095 | Loss 0.4118 | Time(s) 1.3558 | Accuracy: 71.606595 %\n",
            "Epoch 00096 | Loss 0.7058 | Time(s) 1.3562 | Accuracy: 70.858896 %\n",
            "Epoch 00097 | Loss 0.4957 | Time(s) 1.3560 | Accuracy: 70.868482 %\n",
            "Epoch 00098 | Loss 0.4152 | Time(s) 1.3560 | Accuracy: 71.654525 %\n",
            "Epoch 00099 | Loss 0.7405 | Time(s) 1.3561 | Accuracy: 71.549080 %\n",
            "Epoch 00100 | Loss 0.4124 | Time(s) 1.3560 | Accuracy: 71.597009 %\n",
            "Epoch 00101 | Loss 0.4510 | Time(s) 1.3561 | Accuracy: 72.028374 %\n",
            "Epoch 00102 | Loss 0.4133 | Time(s) 1.3562 | Accuracy: 71.664110 %\n",
            "Epoch 00103 | Loss 0.4135 | Time(s) 1.3562 | Accuracy: 71.319018 %\n",
            "Epoch 00104 | Loss 0.5186 | Time(s) 1.3565 | Accuracy: 71.481979 %\n",
            "Epoch 00105 | Loss 0.4503 | Time(s) 1.3564 | Accuracy: 71.894172 %\n",
            "Epoch 00106 | Loss 0.4492 | Time(s) 1.3562 | Accuracy: 71.673696 %\n",
            "Epoch 00107 | Loss 0.7084 | Time(s) 1.3565 | Accuracy: 71.759969 %\n",
            "Epoch 00108 | Loss 0.7053 | Time(s) 1.3566 | Accuracy: 71.932515 %\n",
            "Epoch 00109 | Loss 0.5493 | Time(s) 1.3570 | Accuracy: 71.865414 %\n",
            "Epoch 00110 | Loss 0.7490 | Time(s) 1.3576 | Accuracy: 71.156058 %\n",
            "Epoch 00111 | Loss 0.4508 | Time(s) 1.3575 | Accuracy: 71.692868 %\n",
            "Epoch 00112 | Loss 0.4537 | Time(s) 1.3575 | Accuracy: 71.913344 %\n",
            "Epoch 00113 | Loss 0.6578 | Time(s) 1.3573 | Accuracy: 71.980445 %\n",
            "Epoch 00114 | Loss 0.7015 | Time(s) 1.3572 | Accuracy: 71.846242 %\n",
            "Epoch 00115 | Loss 0.7019 | Time(s) 1.3571 | Accuracy: 71.213574 %\n",
            "Epoch 00116 | Loss 0.7152 | Time(s) 1.3569 | Accuracy: 70.868482 %\n",
            "Epoch 00117 | Loss 0.4928 | Time(s) 1.3573 | Accuracy: 71.223160 %\n",
            "Epoch 00118 | Loss 0.4123 | Time(s) 1.3570 | Accuracy: 71.069785 %\n",
            "Epoch 00119 | Loss 0.7485 | Time(s) 1.3573 | Accuracy: 70.906825 %\n",
            "Epoch 00120 | Loss 0.7029 | Time(s) 1.3575 | Accuracy: 71.146472 %\n",
            "Epoch 00121 | Loss 0.5490 | Time(s) 1.3579 | Accuracy: 71.261503 %\n",
            "Epoch 00122 | Loss 0.4112 | Time(s) 1.3581 | Accuracy: 71.357362 %\n",
            "Epoch 00123 | Loss 0.4508 | Time(s) 1.3579 | Accuracy: 71.481979 %\n",
            "Epoch 00124 | Loss 0.6266 | Time(s) 1.3578 | Accuracy: 71.539494 %\n",
            "Epoch 00125 | Loss 0.4111 | Time(s) 1.3582 | Accuracy: 71.319018 %\n",
            "Epoch 00126 | Loss 0.6396 | Time(s) 1.3581 | Accuracy: 71.424463 %\n",
            "Epoch 00127 | Loss 0.6860 | Time(s) 1.3583 | Accuracy: 71.510736 %\n",
            "Epoch 00128 | Loss 0.7021 | Time(s) 1.3583 | Accuracy: 71.319018 %\n",
            "Epoch 00129 | Loss 0.4127 | Time(s) 1.3584 | Accuracy: 71.290261 %\n",
            "Epoch 00130 | Loss 0.5196 | Time(s) 1.3587 | Accuracy: 71.136887 %\n",
            "Epoch 00131 | Loss 0.6908 | Time(s) 1.3589 | Accuracy: 71.338190 %\n",
            "Epoch 00132 | Loss 0.4112 | Time(s) 1.3592 | Accuracy: 71.472393 %\n",
            "Epoch 00133 | Loss 0.6262 | Time(s) 1.3591 | Accuracy: 71.673696 %\n",
            "Epoch 00134 | Loss 0.4103 | Time(s) 1.3589 | Accuracy: 71.405291 %\n",
            "Epoch 00135 | Loss 0.6147 | Time(s) 1.3588 | Accuracy: 71.644939 %\n",
            "Epoch 00136 | Loss 0.6406 | Time(s) 1.3590 | Accuracy: 72.009202 %\n",
            "Epoch 00137 | Loss 0.4575 | Time(s) 1.3589 | Accuracy: 71.913344 %\n",
            "Epoch 00138 | Loss 0.4493 | Time(s) 1.3588 | Accuracy: 71.750383 %\n",
            "Epoch 00139 | Loss 0.4629 | Time(s) 1.3591 | Accuracy: 71.568252 %\n",
            "Epoch 00140 | Loss 0.4495 | Time(s) 1.3591 | Accuracy: 71.635353 %\n",
            "Epoch 00141 | Loss 0.7042 | Time(s) 1.3593 | Accuracy: 71.597009 %\n",
            "Epoch 00142 | Loss 0.4489 | Time(s) 1.3591 | Accuracy: 71.616181 %\n",
            "Epoch 00143 | Loss 0.7033 | Time(s) 1.3591 | Accuracy: 71.644939 %\n",
            "Epoch 00144 | Loss 0.6412 | Time(s) 1.3591 | Accuracy: 71.913344 %\n",
            "Epoch 00145 | Loss 0.6116 | Time(s) 1.3590 | Accuracy: 71.903758 %\n",
            "Epoch 00146 | Loss 0.7011 | Time(s) 1.3590 | Accuracy: 71.884586 %\n",
            "Epoch 00147 | Loss 0.6905 | Time(s) 1.3591 | Accuracy: 71.759969 %\n",
            "Epoch 00148 | Loss 0.4097 | Time(s) 1.3590 | Accuracy: 71.913344 %\n",
            "Epoch 00149 | Loss 0.4097 | Time(s) 1.3590 | Accuracy: 71.855828 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.6393 | Time(s) 1.3729 | Accuracy: 29.045245 %\n",
            "Epoch 00001 | Loss 1.4554 | Time(s) 1.3769 | Accuracy: 50.076687 %\n",
            "Epoch 00002 | Loss 1.2831 | Time(s) 1.3681 | Accuracy: 61.273006 %\n",
            "Epoch 00003 | Loss 1.1906 | Time(s) 1.3663 | Accuracy: 69.861963 %\n",
            "Epoch 00004 | Loss 1.0361 | Time(s) 1.3657 | Accuracy: 72.593942 %\n",
            "Epoch 00005 | Loss 0.9807 | Time(s) 1.3611 | Accuracy: 72.814417 %\n",
            "Epoch 00006 | Loss 0.8388 | Time(s) 1.3579 | Accuracy: 74.856212 %\n",
            "Epoch 00007 | Loss 0.7700 | Time(s) 1.3585 | Accuracy: 75.153374 %\n",
            "Epoch 00008 | Loss 0.8963 | Time(s) 1.3598 | Accuracy: 75.479294 %\n",
            "Epoch 00009 | Loss 0.6615 | Time(s) 1.3622 | Accuracy: 75.977761 %\n",
            "Epoch 00010 | Loss 0.6889 | Time(s) 1.3611 | Accuracy: 75.728528 %\n",
            "Epoch 00011 | Loss 0.6155 | Time(s) 1.3611 | Accuracy: 76.131135 %\n",
            "Epoch 00012 | Loss 0.4420 | Time(s) 1.3611 | Accuracy: 76.543328 %\n",
            "Epoch 00013 | Loss 0.5147 | Time(s) 1.3595 | Accuracy: 76.773390 %\n",
            "Epoch 00014 | Loss 0.4214 | Time(s) 1.3593 | Accuracy: 77.444402 %\n",
            "Epoch 00015 | Loss 0.5541 | Time(s) 1.3586 | Accuracy: 77.501917 %\n",
            "Epoch 00016 | Loss 0.5973 | Time(s) 1.3591 | Accuracy: 77.818252 %\n",
            "Epoch 00017 | Loss 0.3638 | Time(s) 1.3593 | Accuracy: 78.240031 %\n",
            "Epoch 00018 | Loss 0.5174 | Time(s) 1.3582 | Accuracy: 78.019555 %\n",
            "Epoch 00019 | Loss 0.3615 | Time(s) 1.3583 | Accuracy: 78.287960 %\n",
            "Epoch 00020 | Loss 0.3351 | Time(s) 1.3592 | Accuracy: 78.287960 %\n",
            "Epoch 00021 | Loss 0.3297 | Time(s) 1.3591 | Accuracy: 78.470092 %\n",
            "Epoch 00022 | Loss 0.4243 | Time(s) 1.3615 | Accuracy: 78.086656 %\n",
            "Epoch 00023 | Loss 0.4052 | Time(s) 1.3620 | Accuracy: 78.153758 %\n",
            "Epoch 00024 | Loss 0.3689 | Time(s) 1.3640 | Accuracy: 78.326304 %\n",
            "Epoch 00025 | Loss 0.3209 | Time(s) 1.3648 | Accuracy: 78.498850 %\n",
            "Epoch 00026 | Loss 0.4793 | Time(s) 1.3655 | Accuracy: 78.623466 %\n",
            "Epoch 00027 | Loss 0.3014 | Time(s) 1.3670 | Accuracy: 78.383819 %\n",
            "Epoch 00028 | Loss 0.2691 | Time(s) 1.3680 | Accuracy: 78.144172 %\n",
            "Epoch 00029 | Loss 0.5052 | Time(s) 1.3680 | Accuracy: 78.230445 %\n",
            "Epoch 00030 | Loss 0.4095 | Time(s) 1.3680 | Accuracy: 78.067485 %\n",
            "Epoch 00031 | Loss 0.2459 | Time(s) 1.3683 | Accuracy: 78.383819 %\n",
            "Epoch 00032 | Loss 0.3597 | Time(s) 1.3678 | Accuracy: 78.633052 %\n",
            "Epoch 00033 | Loss 0.2914 | Time(s) 1.3671 | Accuracy: 78.364647 %\n",
            "Epoch 00034 | Loss 0.3012 | Time(s) 1.3674 | Accuracy: 78.565951 %\n",
            "Epoch 00035 | Loss 0.2867 | Time(s) 1.3676 | Accuracy: 78.604294 %\n",
            "Epoch 00036 | Loss 0.2778 | Time(s) 1.3666 | Accuracy: 78.920629 %\n",
            "Epoch 00037 | Loss 0.3422 | Time(s) 1.3672 | Accuracy: 78.786426 %\n",
            "Epoch 00038 | Loss 0.3550 | Time(s) 1.3667 | Accuracy: 78.815184 %\n",
            "Epoch 00039 | Loss 0.2293 | Time(s) 1.3670 | Accuracy: 78.680982 %\n",
            "Epoch 00040 | Loss 0.2808 | Time(s) 1.3672 | Accuracy: 78.565951 %\n",
            "Epoch 00041 | Loss 0.3192 | Time(s) 1.3680 | Accuracy: 78.623466 %\n",
            "Epoch 00042 | Loss 0.3492 | Time(s) 1.3682 | Accuracy: 78.422163 %\n",
            "Epoch 00043 | Loss 0.3729 | Time(s) 1.3693 | Accuracy: 78.211273 %\n",
            "Epoch 00044 | Loss 0.2909 | Time(s) 1.3691 | Accuracy: 78.211273 %\n",
            "Epoch 00045 | Loss 0.4280 | Time(s) 1.3692 | Accuracy: 78.700153 %\n",
            "Epoch 00046 | Loss 0.2920 | Time(s) 1.3705 | Accuracy: 78.805598 %\n",
            "Epoch 00047 | Loss 0.3029 | Time(s) 1.3703 | Accuracy: 78.537193 %\n",
            "Epoch 00048 | Loss 0.3997 | Time(s) 1.3703 | Accuracy: 78.671396 %\n",
            "Epoch 00049 | Loss 0.2109 | Time(s) 1.3700 | Accuracy: 78.575537 %\n",
            "Epoch 00050 | Loss 0.3332 | Time(s) 1.3704 | Accuracy: 78.441334 %\n",
            "Epoch 00051 | Loss 0.3250 | Time(s) 1.3708 | Accuracy: 78.853528 %\n",
            "Epoch 00052 | Loss 0.2068 | Time(s) 1.3711 | Accuracy: 78.709739 %\n",
            "Epoch 00053 | Loss 0.3426 | Time(s) 1.3709 | Accuracy: 78.546779 %\n",
            "Epoch 00054 | Loss 0.3185 | Time(s) 1.3711 | Accuracy: 78.201687 %\n",
            "Epoch 00055 | Loss 0.3650 | Time(s) 1.3712 | Accuracy: 78.431748 %\n",
            "Epoch 00056 | Loss 0.2101 | Time(s) 1.3720 | Accuracy: 77.981212 %\n",
            "Epoch 00057 | Loss 0.2883 | Time(s) 1.3724 | Accuracy: 78.470092 %\n",
            "Epoch 00058 | Loss 0.3118 | Time(s) 1.3721 | Accuracy: 78.172929 %\n",
            "Epoch 00059 | Loss 0.3146 | Time(s) 1.3723 | Accuracy: 78.201687 %\n",
            "Epoch 00060 | Loss 0.2646 | Time(s) 1.3721 | Accuracy: 78.575537 %\n",
            "Epoch 00061 | Loss 0.2663 | Time(s) 1.3723 | Accuracy: 78.211273 %\n",
            "Epoch 00062 | Loss 0.3526 | Time(s) 1.3726 | Accuracy: 77.856595 %\n",
            "Epoch 00063 | Loss 0.3114 | Time(s) 1.3730 | Accuracy: 77.914110 %\n",
            "Epoch 00064 | Loss 0.2759 | Time(s) 1.3735 | Accuracy: 77.377301 %\n",
            "Epoch 00065 | Loss 0.3238 | Time(s) 1.3740 | Accuracy: 77.923696 %\n",
            "Epoch 00066 | Loss 0.3345 | Time(s) 1.3748 | Accuracy: 77.770322 %\n",
            "Epoch 00067 | Loss 0.2747 | Time(s) 1.3750 | Accuracy: 78.153758 %\n",
            "Epoch 00068 | Loss 0.3064 | Time(s) 1.3751 | Accuracy: 78.115414 %\n",
            "Epoch 00069 | Loss 0.2060 | Time(s) 1.3751 | Accuracy: 78.125000 %\n",
            "Epoch 00070 | Loss 0.3022 | Time(s) 1.3747 | Accuracy: 78.163344 %\n",
            "Epoch 00071 | Loss 0.2655 | Time(s) 1.3747 | Accuracy: 78.115414 %\n",
            "Epoch 00072 | Loss 0.2517 | Time(s) 1.3749 | Accuracy: 78.249617 %\n",
            "Epoch 00073 | Loss 0.2513 | Time(s) 1.3747 | Accuracy: 77.760736 %\n",
            "Epoch 00074 | Loss 0.3200 | Time(s) 1.3744 | Accuracy: 77.684049 %\n",
            "Epoch 00075 | Loss 0.2829 | Time(s) 1.3743 | Accuracy: 77.942868 %\n",
            "Epoch 00076 | Loss 0.2469 | Time(s) 1.3750 | Accuracy: 78.057899 %\n",
            "Epoch 00077 | Loss 0.2441 | Time(s) 1.3749 | Accuracy: 78.192101 %\n",
            "Epoch 00078 | Loss 0.2015 | Time(s) 1.3750 | Accuracy: 78.364647 %\n",
            "Epoch 00079 | Loss 0.3010 | Time(s) 1.3756 | Accuracy: 78.431748 %\n",
            "Epoch 00080 | Loss 0.3286 | Time(s) 1.3754 | Accuracy: 77.914110 %\n",
            "Epoch 00081 | Loss 0.3331 | Time(s) 1.3750 | Accuracy: 77.664877 %\n",
            "Epoch 00082 | Loss 0.3621 | Time(s) 1.3748 | Accuracy: 78.345475 %\n",
            "Epoch 00083 | Loss 0.1583 | Time(s) 1.3745 | Accuracy: 78.565951 %\n",
            "Epoch 00084 | Loss 0.3477 | Time(s) 1.3744 | Accuracy: 78.431748 %\n",
            "Epoch 00085 | Loss 0.3449 | Time(s) 1.3746 | Accuracy: 78.268788 %\n",
            "Epoch 00086 | Loss 0.3557 | Time(s) 1.3746 | Accuracy: 77.914110 %\n",
            "Epoch 00087 | Loss 0.3520 | Time(s) 1.3751 | Accuracy: 77.616948 %\n",
            "Epoch 00088 | Loss 0.4349 | Time(s) 1.3754 | Accuracy: 76.859663 %\n",
            "Epoch 00089 | Loss 0.2916 | Time(s) 1.3753 | Accuracy: 76.677531 %\n",
            "Epoch 00090 | Loss 0.2349 | Time(s) 1.3754 | Accuracy: 76.907592 %\n",
            "Epoch 00091 | Loss 0.3007 | Time(s) 1.3755 | Accuracy: 77.271856 %\n",
            "Epoch 00092 | Loss 0.2279 | Time(s) 1.3752 | Accuracy: 77.425230 %\n",
            "Epoch 00093 | Loss 0.1574 | Time(s) 1.3750 | Accuracy: 77.310199 %\n",
            "Epoch 00094 | Loss 0.3351 | Time(s) 1.3750 | Accuracy: 77.875767 %\n",
            "Epoch 00095 | Loss 0.3081 | Time(s) 1.3755 | Accuracy: 78.297546 %\n",
            "Epoch 00096 | Loss 0.3429 | Time(s) 1.3757 | Accuracy: 78.364647 %\n",
            "Epoch 00097 | Loss 0.3311 | Time(s) 1.3757 | Accuracy: 78.326304 %\n",
            "Epoch 00098 | Loss 0.2983 | Time(s) 1.3761 | Accuracy: 78.182515 %\n",
            "Epoch 00099 | Loss 0.2984 | Time(s) 1.3763 | Accuracy: 77.760736 %\n",
            "Epoch 00100 | Loss 0.1995 | Time(s) 1.3765 | Accuracy: 77.942868 %\n",
            "Epoch 00101 | Loss 0.1967 | Time(s) 1.3763 | Accuracy: 77.933282 %\n",
            "Epoch 00102 | Loss 0.2624 | Time(s) 1.3763 | Accuracy: 77.894939 %\n",
            "Epoch 00103 | Loss 0.3146 | Time(s) 1.3761 | Accuracy: 77.607362 %\n",
            "Epoch 00104 | Loss 0.2563 | Time(s) 1.3761 | Accuracy: 77.693635 %\n",
            "Epoch 00105 | Loss 0.2478 | Time(s) 1.3760 | Accuracy: 77.406058 %\n",
            "Epoch 00106 | Loss 0.3161 | Time(s) 1.3765 | Accuracy: 77.645706 %\n",
            "Epoch 00107 | Loss 0.2602 | Time(s) 1.3767 | Accuracy: 77.684049 %\n",
            "Epoch 00108 | Loss 0.1992 | Time(s) 1.3769 | Accuracy: 77.808666 %\n",
            "Epoch 00109 | Loss 0.3014 | Time(s) 1.3769 | Accuracy: 77.952454 %\n",
            "Epoch 00110 | Loss 0.2408 | Time(s) 1.3769 | Accuracy: 77.962040 %\n",
            "Epoch 00111 | Loss 0.3108 | Time(s) 1.3768 | Accuracy: 77.923696 %\n",
            "Epoch 00112 | Loss 0.1631 | Time(s) 1.3767 | Accuracy: 78.067485 %\n",
            "Epoch 00113 | Loss 0.2600 | Time(s) 1.3771 | Accuracy: 78.029141 %\n",
            "Epoch 00114 | Loss 0.2172 | Time(s) 1.3771 | Accuracy: 77.693635 %\n",
            "Epoch 00115 | Loss 0.2977 | Time(s) 1.3771 | Accuracy: 78.067485 %\n",
            "Epoch 00116 | Loss 0.1797 | Time(s) 1.3775 | Accuracy: 77.808666 %\n",
            "Epoch 00117 | Loss 0.2550 | Time(s) 1.3776 | Accuracy: 77.703221 %\n",
            "Epoch 00118 | Loss 0.2972 | Time(s) 1.3780 | Accuracy: 77.703221 %\n",
            "Epoch 00119 | Loss 0.1798 | Time(s) 1.3779 | Accuracy: 77.751150 %\n",
            "Epoch 00120 | Loss 0.2544 | Time(s) 1.3777 | Accuracy: 77.837423 %\n",
            "Epoch 00121 | Loss 0.1887 | Time(s) 1.3781 | Accuracy: 77.875767 %\n",
            "Epoch 00122 | Loss 0.3097 | Time(s) 1.3781 | Accuracy: 78.000383 %\n",
            "Epoch 00123 | Loss 0.3029 | Time(s) 1.3784 | Accuracy: 77.827837 %\n",
            "Epoch 00124 | Loss 0.2554 | Time(s) 1.3786 | Accuracy: 77.693635 %\n",
            "Epoch 00125 | Loss 0.2002 | Time(s) 1.3786 | Accuracy: 77.693635 %\n",
            "Epoch 00126 | Loss 0.2580 | Time(s) 1.3791 | Accuracy: 78.125000 %\n",
            "Epoch 00127 | Loss 0.2960 | Time(s) 1.3794 | Accuracy: 78.172929 %\n",
            "Epoch 00128 | Loss 0.3591 | Time(s) 1.3802 | Accuracy: 78.153758 %\n",
            "Epoch 00129 | Loss 0.2452 | Time(s) 1.3804 | Accuracy: 78.211273 %\n",
            "Epoch 00130 | Loss 0.3483 | Time(s) 1.3807 | Accuracy: 78.268788 %\n",
            "Epoch 00131 | Loss 0.3426 | Time(s) 1.3815 | Accuracy: 78.268788 %\n",
            "Epoch 00132 | Loss 0.3391 | Time(s) 1.3823 | Accuracy: 78.278374 %\n",
            "Epoch 00133 | Loss 0.2960 | Time(s) 1.3828 | Accuracy: 78.153758 %\n",
            "Epoch 00134 | Loss 0.1987 | Time(s) 1.3835 | Accuracy: 78.096242 %\n",
            "Epoch 00135 | Loss 0.1575 | Time(s) 1.3844 | Accuracy: 78.086656 %\n",
            "Epoch 00136 | Loss 0.2555 | Time(s) 1.3852 | Accuracy: 78.067485 %\n",
            "Epoch 00137 | Loss 0.2942 | Time(s) 1.3861 | Accuracy: 78.201687 %\n",
            "Epoch 00138 | Loss 0.3072 | Time(s) 1.3871 | Accuracy: 78.086656 %\n",
            "Epoch 00139 | Loss 0.2947 | Time(s) 1.3877 | Accuracy: 78.172929 %\n",
            "Epoch 00140 | Loss 0.1967 | Time(s) 1.3884 | Accuracy: 78.019555 %\n",
            "Epoch 00141 | Loss 0.2543 | Time(s) 1.3892 | Accuracy: 77.990798 %\n",
            "Epoch 00142 | Loss 0.1964 | Time(s) 1.3901 | Accuracy: 78.163344 %\n",
            "Epoch 00143 | Loss 0.2936 | Time(s) 1.3906 | Accuracy: 78.355061 %\n",
            "Epoch 00144 | Loss 0.2936 | Time(s) 1.3914 | Accuracy: 78.259202 %\n",
            "Epoch 00145 | Loss 0.2544 | Time(s) 1.3924 | Accuracy: 78.163344 %\n",
            "Epoch 00146 | Loss 0.2937 | Time(s) 1.3930 | Accuracy: 78.144172 %\n",
            "Epoch 00147 | Loss 0.2551 | Time(s) 1.3937 | Accuracy: 78.249617 %\n",
            "Epoch 00148 | Loss 0.2935 | Time(s) 1.3947 | Accuracy: 78.422163 %\n",
            "Epoch 00149 | Loss 0.2538 | Time(s) 1.3953 | Accuracy: 78.374233 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7864 | Time(s) 1.4351 | Accuracy: 20.207055 %\n",
            "Epoch 00001 | Loss 1.5082 | Time(s) 1.4075 | Accuracy: 41.180982 %\n",
            "Epoch 00002 | Loss 1.3929 | Time(s) 1.4033 | Accuracy: 55.253067 %\n",
            "Epoch 00003 | Loss 1.0665 | Time(s) 1.4084 | Accuracy: 63.420245 %\n",
            "Epoch 00004 | Loss 1.0133 | Time(s) 1.4151 | Accuracy: 69.305982 %\n",
            "Epoch 00005 | Loss 1.0387 | Time(s) 1.4268 | Accuracy: 71.050613 %\n",
            "Epoch 00006 | Loss 1.0775 | Time(s) 1.4241 | Accuracy: 71.884586 %\n",
            "Epoch 00007 | Loss 0.9400 | Time(s) 1.4207 | Accuracy: 72.795245 %\n",
            "Epoch 00008 | Loss 0.6941 | Time(s) 1.4243 | Accuracy: 72.430982 %\n",
            "Epoch 00009 | Loss 0.8322 | Time(s) 1.4278 | Accuracy: 72.162577 %\n",
            "Epoch 00010 | Loss 0.5633 | Time(s) 1.4302 | Accuracy: 72.565184 %\n",
            "Epoch 00011 | Loss 0.5196 | Time(s) 1.4315 | Accuracy: 72.268021 %\n",
            "Epoch 00012 | Loss 0.7730 | Time(s) 1.4256 | Accuracy: 72.172163 %\n",
            "Epoch 00013 | Loss 0.4603 | Time(s) 1.4207 | Accuracy: 72.517255 %\n",
            "Epoch 00014 | Loss 0.7402 | Time(s) 1.4161 | Accuracy: 72.124233 %\n",
            "Epoch 00015 | Loss 0.5831 | Time(s) 1.4149 | Accuracy: 72.824003 %\n",
            "Epoch 00016 | Loss 0.5238 | Time(s) 1.4136 | Accuracy: 72.814417 %\n",
            "Epoch 00017 | Loss 0.6840 | Time(s) 1.4134 | Accuracy: 72.699387 %\n",
            "Epoch 00018 | Loss 0.6259 | Time(s) 1.4111 | Accuracy: 72.728144 %\n",
            "Epoch 00019 | Loss 0.6172 | Time(s) 1.4104 | Accuracy: 73.159509 %\n",
            "Epoch 00020 | Loss 0.4004 | Time(s) 1.4098 | Accuracy: 73.427914 %\n",
            "Epoch 00021 | Loss 0.3839 | Time(s) 1.4076 | Accuracy: 73.514187 %\n",
            "Epoch 00022 | Loss 0.4314 | Time(s) 1.4047 | Accuracy: 73.495015 %\n",
            "Epoch 00023 | Loss 0.4138 | Time(s) 1.4031 | Accuracy: 73.859279 %\n",
            "Epoch 00024 | Loss 0.3729 | Time(s) 1.4018 | Accuracy: 73.907209 %\n",
            "Epoch 00025 | Loss 0.3957 | Time(s) 1.4007 | Accuracy: 73.849693 %\n",
            "Epoch 00026 | Loss 0.5042 | Time(s) 1.3991 | Accuracy: 73.773006 %\n",
            "Epoch 00027 | Loss 0.3140 | Time(s) 1.3986 | Accuracy: 73.696319 %\n",
            "Epoch 00028 | Loss 0.5929 | Time(s) 1.3968 | Accuracy: 73.782592 %\n",
            "Epoch 00029 | Loss 0.3154 | Time(s) 1.3959 | Accuracy: 73.466258 %\n",
            "Epoch 00030 | Loss 0.4076 | Time(s) 1.3947 | Accuracy: 73.245782 %\n",
            "Epoch 00031 | Loss 0.3553 | Time(s) 1.3930 | Accuracy: 73.197853 %\n",
            "Epoch 00032 | Loss 0.3676 | Time(s) 1.3925 | Accuracy: 73.264954 %\n",
            "Epoch 00033 | Loss 0.3643 | Time(s) 1.3919 | Accuracy: 73.523773 %\n",
            "Epoch 00034 | Loss 0.3476 | Time(s) 1.3912 | Accuracy: 73.149923 %\n",
            "Epoch 00035 | Loss 0.4750 | Time(s) 1.3902 | Accuracy: 72.708972 %\n",
            "Epoch 00036 | Loss 0.3564 | Time(s) 1.3900 | Accuracy: 72.488497 %\n",
            "Epoch 00037 | Loss 0.5389 | Time(s) 1.3903 | Accuracy: 72.737730 %\n",
            "Epoch 00038 | Loss 0.3570 | Time(s) 1.3890 | Accuracy: 72.910276 %\n",
            "Epoch 00039 | Loss 0.3545 | Time(s) 1.3894 | Accuracy: 72.996549 %\n",
            "Epoch 00040 | Loss 0.4006 | Time(s) 1.3882 | Accuracy: 73.264954 %\n",
            "Epoch 00041 | Loss 0.3832 | Time(s) 1.3884 | Accuracy: 73.514187 %\n",
            "Epoch 00042 | Loss 0.2752 | Time(s) 1.3885 | Accuracy: 73.475844 %\n",
            "Epoch 00043 | Loss 0.4919 | Time(s) 1.3876 | Accuracy: 73.370399 %\n",
            "Epoch 00044 | Loss 0.3463 | Time(s) 1.3870 | Accuracy: 73.332055 %\n",
            "Epoch 00045 | Loss 0.4960 | Time(s) 1.3864 | Accuracy: 73.303298 %\n",
            "Epoch 00046 | Loss 0.4438 | Time(s) 1.3856 | Accuracy: 73.562117 %\n",
            "Epoch 00047 | Loss 0.4002 | Time(s) 1.3854 | Accuracy: 73.207439 %\n",
            "Epoch 00048 | Loss 0.3608 | Time(s) 1.3845 | Accuracy: 73.264954 %\n",
            "Epoch 00049 | Loss 0.2704 | Time(s) 1.3840 | Accuracy: 73.169095 %\n",
            "Epoch 00050 | Loss 0.2659 | Time(s) 1.3831 | Accuracy: 73.140337 %\n",
            "Epoch 00051 | Loss 0.3784 | Time(s) 1.3822 | Accuracy: 73.121166 %\n",
            "Epoch 00052 | Loss 0.4499 | Time(s) 1.3813 | Accuracy: 73.006135 %\n",
            "Epoch 00053 | Loss 0.5648 | Time(s) 1.3805 | Accuracy: 73.130752 %\n",
            "Epoch 00054 | Loss 0.3437 | Time(s) 1.3809 | Accuracy: 73.063650 %\n",
            "Epoch 00055 | Loss 0.4562 | Time(s) 1.3808 | Accuracy: 73.149923 %\n",
            "Epoch 00056 | Loss 0.5908 | Time(s) 1.3800 | Accuracy: 72.871933 %\n",
            "Epoch 00057 | Loss 0.3866 | Time(s) 1.3796 | Accuracy: 72.871933 %\n",
            "Epoch 00058 | Loss 0.4262 | Time(s) 1.3786 | Accuracy: 73.025307 %\n",
            "Epoch 00059 | Loss 0.3145 | Time(s) 1.3795 | Accuracy: 73.015721 %\n",
            "Epoch 00060 | Loss 0.3413 | Time(s) 1.3789 | Accuracy: 72.824003 %\n",
            "Epoch 00061 | Loss 0.5575 | Time(s) 1.3790 | Accuracy: 72.929448 %\n",
            "Epoch 00062 | Loss 0.4430 | Time(s) 1.3791 | Accuracy: 73.140337 %\n",
            "Epoch 00063 | Loss 0.4487 | Time(s) 1.3797 | Accuracy: 73.332055 %\n",
            "Epoch 00064 | Loss 0.4361 | Time(s) 1.3791 | Accuracy: 73.466258 %\n",
            "Epoch 00065 | Loss 0.4120 | Time(s) 1.3784 | Accuracy: 73.447086 %\n",
            "Epoch 00066 | Loss 0.2659 | Time(s) 1.3776 | Accuracy: 73.293712 %\n",
            "Epoch 00067 | Loss 0.4482 | Time(s) 1.3773 | Accuracy: 72.929448 %\n",
            "Epoch 00068 | Loss 0.4493 | Time(s) 1.3768 | Accuracy: 72.756902 %\n",
            "Epoch 00069 | Loss 0.3405 | Time(s) 1.3762 | Accuracy: 72.929448 %\n",
            "Epoch 00070 | Loss 0.4436 | Time(s) 1.3755 | Accuracy: 72.900690 %\n",
            "Epoch 00071 | Loss 0.3862 | Time(s) 1.3753 | Accuracy: 73.054064 %\n",
            "Epoch 00072 | Loss 0.3345 | Time(s) 1.3749 | Accuracy: 72.967791 %\n",
            "Epoch 00073 | Loss 0.4003 | Time(s) 1.3744 | Accuracy: 73.082822 %\n",
            "Epoch 00074 | Loss 0.3414 | Time(s) 1.3742 | Accuracy: 73.101994 %\n",
            "Epoch 00075 | Loss 0.3965 | Time(s) 1.3736 | Accuracy: 73.264954 %\n",
            "Epoch 00076 | Loss 0.3366 | Time(s) 1.3733 | Accuracy: 72.900690 %\n",
            "Epoch 00077 | Loss 0.3393 | Time(s) 1.3732 | Accuracy: 72.574770 %\n",
            "Epoch 00078 | Loss 0.3826 | Time(s) 1.3729 | Accuracy: 72.718558 %\n",
            "Epoch 00079 | Loss 0.4584 | Time(s) 1.3728 | Accuracy: 72.843175 %\n",
            "Epoch 00080 | Loss 0.3988 | Time(s) 1.3722 | Accuracy: 73.063650 %\n",
            "Epoch 00081 | Loss 0.3213 | Time(s) 1.3723 | Accuracy: 72.862347 %\n",
            "Epoch 00082 | Loss 0.3722 | Time(s) 1.3724 | Accuracy: 73.063650 %\n",
            "Epoch 00083 | Loss 0.4375 | Time(s) 1.3729 | Accuracy: 72.891104 %\n",
            "Epoch 00084 | Loss 0.3568 | Time(s) 1.3729 | Accuracy: 72.756902 %\n",
            "Epoch 00085 | Loss 0.2632 | Time(s) 1.3727 | Accuracy: 72.871933 %\n",
            "Epoch 00086 | Loss 0.3331 | Time(s) 1.3725 | Accuracy: 72.766488 %\n",
            "Epoch 00087 | Loss 0.2638 | Time(s) 1.3723 | Accuracy: 72.718558 %\n",
            "Epoch 00088 | Loss 0.3344 | Time(s) 1.3722 | Accuracy: 72.824003 %\n",
            "Epoch 00089 | Loss 0.4983 | Time(s) 1.3720 | Accuracy: 72.469325 %\n",
            "Epoch 00090 | Loss 0.3757 | Time(s) 1.3719 | Accuracy: 72.670629 %\n",
            "Epoch 00091 | Loss 0.2580 | Time(s) 1.3716 | Accuracy: 72.804831 %\n",
            "Epoch 00092 | Loss 0.3378 | Time(s) 1.3718 | Accuracy: 72.277607 %\n",
            "Epoch 00093 | Loss 0.3290 | Time(s) 1.3719 | Accuracy: 72.478911 %\n",
            "Epoch 00094 | Loss 0.2847 | Time(s) 1.3716 | Accuracy: 72.689801 %\n",
            "Epoch 00095 | Loss 0.4000 | Time(s) 1.3713 | Accuracy: 72.689801 %\n",
            "Epoch 00096 | Loss 0.3741 | Time(s) 1.3714 | Accuracy: 72.603528 %\n",
            "Epoch 00097 | Loss 0.4045 | Time(s) 1.3711 | Accuracy: 72.191334 %\n",
            "Epoch 00098 | Loss 0.3773 | Time(s) 1.3713 | Accuracy: 72.766488 %\n",
            "Epoch 00099 | Loss 0.3424 | Time(s) 1.3713 | Accuracy: 72.689801 %\n",
            "Epoch 00100 | Loss 0.5248 | Time(s) 1.3710 | Accuracy: 72.325537 %\n",
            "Epoch 00101 | Loss 0.3052 | Time(s) 1.3706 | Accuracy: 71.664110 %\n",
            "Epoch 00102 | Loss 0.2586 | Time(s) 1.3699 | Accuracy: 72.517255 %\n",
            "Epoch 00103 | Loss 0.4572 | Time(s) 1.3699 | Accuracy: 72.977377 %\n",
            "Epoch 00104 | Loss 0.2567 | Time(s) 1.3696 | Accuracy: 72.785660 %\n",
            "Epoch 00105 | Loss 0.2560 | Time(s) 1.3693 | Accuracy: 72.910276 %\n",
            "Epoch 00106 | Loss 0.2561 | Time(s) 1.3690 | Accuracy: 72.939034 %\n",
            "Epoch 00107 | Loss 0.3339 | Time(s) 1.3690 | Accuracy: 72.871933 %\n",
            "Epoch 00108 | Loss 0.4352 | Time(s) 1.3690 | Accuracy: 72.459739 %\n",
            "Epoch 00109 | Loss 0.3364 | Time(s) 1.3686 | Accuracy: 72.641871 %\n",
            "Epoch 00110 | Loss 0.3334 | Time(s) 1.3683 | Accuracy: 72.776074 %\n",
            "Epoch 00111 | Loss 0.3362 | Time(s) 1.3678 | Accuracy: 72.756902 %\n",
            "Epoch 00112 | Loss 0.3010 | Time(s) 1.3675 | Accuracy: 72.402224 %\n",
            "Epoch 00113 | Loss 0.4054 | Time(s) 1.3675 | Accuracy: 72.795245 %\n",
            "Epoch 00114 | Loss 0.3429 | Time(s) 1.3676 | Accuracy: 72.392638 %\n",
            "Epoch 00115 | Loss 0.4052 | Time(s) 1.3678 | Accuracy: 72.325537 %\n",
            "Epoch 00116 | Loss 0.2696 | Time(s) 1.3676 | Accuracy: 72.488497 %\n",
            "Epoch 00117 | Loss 0.4352 | Time(s) 1.3675 | Accuracy: 72.526840 %\n",
            "Epoch 00118 | Loss 0.2569 | Time(s) 1.3674 | Accuracy: 72.747316 %\n",
            "Epoch 00119 | Loss 0.3494 | Time(s) 1.3675 | Accuracy: 72.843175 %\n",
            "Epoch 00120 | Loss 0.2572 | Time(s) 1.3675 | Accuracy: 72.699387 %\n",
            "Epoch 00121 | Loss 0.2557 | Time(s) 1.3673 | Accuracy: 72.804831 %\n",
            "Epoch 00122 | Loss 0.3712 | Time(s) 1.3675 | Accuracy: 73.130752 %\n",
            "Epoch 00123 | Loss 0.3332 | Time(s) 1.3672 | Accuracy: 73.006135 %\n",
            "Epoch 00124 | Loss 0.3713 | Time(s) 1.3670 | Accuracy: 73.073236 %\n",
            "Epoch 00125 | Loss 0.3321 | Time(s) 1.3669 | Accuracy: 73.111580 %\n",
            "Epoch 00126 | Loss 0.3925 | Time(s) 1.3668 | Accuracy: 73.130752 %\n",
            "Epoch 00127 | Loss 0.5231 | Time(s) 1.3668 | Accuracy: 73.322469 %\n",
            "Epoch 00128 | Loss 0.2549 | Time(s) 1.3668 | Accuracy: 72.996549 %\n",
            "Epoch 00129 | Loss 0.4373 | Time(s) 1.3667 | Accuracy: 72.996549 %\n",
            "Epoch 00130 | Loss 0.3910 | Time(s) 1.3670 | Accuracy: 73.054064 %\n",
            "Epoch 00131 | Loss 0.3325 | Time(s) 1.3668 | Accuracy: 72.929448 %\n",
            "Epoch 00132 | Loss 0.3324 | Time(s) 1.3666 | Accuracy: 73.025307 %\n",
            "Epoch 00133 | Loss 0.4466 | Time(s) 1.3665 | Accuracy: 72.919862 %\n",
            "Epoch 00134 | Loss 0.4422 | Time(s) 1.3663 | Accuracy: 72.919862 %\n",
            "Epoch 00135 | Loss 0.4291 | Time(s) 1.3662 | Accuracy: 72.939034 %\n",
            "Epoch 00136 | Loss 0.3913 | Time(s) 1.3662 | Accuracy: 73.044479 %\n",
            "Epoch 00137 | Loss 0.3324 | Time(s) 1.3664 | Accuracy: 72.986963 %\n",
            "Epoch 00138 | Loss 0.2543 | Time(s) 1.3662 | Accuracy: 73.034893 %\n",
            "Epoch 00139 | Loss 0.3319 | Time(s) 1.3661 | Accuracy: 73.034893 %\n",
            "Epoch 00140 | Loss 0.2545 | Time(s) 1.3659 | Accuracy: 73.054064 %\n",
            "Epoch 00141 | Loss 0.3138 | Time(s) 1.3657 | Accuracy: 73.140337 %\n",
            "Epoch 00142 | Loss 0.4300 | Time(s) 1.3660 | Accuracy: 73.092408 %\n",
            "Epoch 00143 | Loss 0.4405 | Time(s) 1.3660 | Accuracy: 73.063650 %\n",
            "Epoch 00144 | Loss 0.2543 | Time(s) 1.3659 | Accuracy: 72.977377 %\n",
            "Epoch 00145 | Loss 0.2540 | Time(s) 1.3659 | Accuracy: 72.919862 %\n",
            "Epoch 00146 | Loss 0.4423 | Time(s) 1.3661 | Accuracy: 72.996549 %\n",
            "Epoch 00147 | Loss 0.3142 | Time(s) 1.3662 | Accuracy: 72.986963 %\n",
            "Epoch 00148 | Loss 0.3139 | Time(s) 1.3663 | Accuracy: 73.101994 %\n",
            "Epoch 00149 | Loss 0.3321 | Time(s) 1.3662 | Accuracy: 72.929448 %\n",
            "Results stored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-ipAEZcN5LT",
        "colab_type": "text"
      },
      "source": [
        "#On graphic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUjMKV_LXIu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accPointsCora = [0]*n_of_epochs\n",
        "lossPointsCora = [0]*n_of_epochs\n",
        "\n",
        "for d in range(n_of_training_cycles):\n",
        "  for i in range(n_of_epochs):\n",
        "    accPointsCora[i] = accPointsCora[i] + averageAccCora[d][i]\n",
        "    lossPointsCora[i] = lossPointsCora[i] + averageLossCora[d][i]\n",
        "\n",
        "for i in range(n_of_epochs):\n",
        "  accPointsCora[i] = accPointsCora[i]/n_of_training_cycles\n",
        "  lossPointsCora[i] = lossPointsCora[i]/n_of_training_cycles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Erkh6MqGjl",
        "colab_type": "code",
        "outputId": "1e546e9e-ac67-45aa-8b2a-7888dd695179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "maxAccCora = np.argmax(accPointsCora)\n",
        "maxAccCora"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1TBb1GlN7rC",
        "colab_type": "code",
        "outputId": "9085a796-1be4-4614-bb5c-f5fb1711fe88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "axisX = range(n_of_epochs)\n",
        "\n",
        "plt.plot(axisX, accPointsCora, color='orange', label='Cora')\n",
        "#plt.plot(axisX, pointsPubMed, color='blue', label='PubMed')\n",
        "plt.plot([maxAccCora], accPointsCora[maxAccCora], marker='o', color='red')\n",
        "#plt.plot([maxAccPubMed], pointsPubMed[maxAccPubMed], marker='o', color='blue')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSKQU4CIikfr/1a0DAJ60UZ0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5mBRqr82F5e",
        "colab_type": "code",
        "outputId": "4efc66f6-2c01-49fb-97dd-376bc159984c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Max accuracy Cora at {:03d} epochs with value {:05f}\"\n",
        "  .format(maxAccCora, pointsCora[maxAccCora]))\n",
        "#print(\"Max accuracy PubMed at {:03d} epochs with value {:05f}\"\n",
        "#  .format(maxAccPubMed, pointsPubMed[maxAccPubMed]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max accuracy Cora at 083 epochs with value 72.891104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdTRUep-4FFJ",
        "colab_type": "code",
        "outputId": "64b5123a-28db-4eb3-a372-d8bb4bc71d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(axisX, lossPointsCora, color='orange', label='Cora')\n",
        "#plt.plot(axisX, pointsLossPubMed, color='blue', label='PubMed')\n",
        "plt.plot([maxAccCora], lossPointsCora[maxAccCora], marker='o', color='red')\n",
        "#plt.plot([maxAccPubMed], pointsLossPubMed[maxAccPubMed].item(), marker='o',color='blue')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KUKoacJ2t6h",
        "colab_type": "code",
        "outputId": "3e65980c-5b18-4762-cdbb-47f5cf41fe0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"For Cora, at epoch {:03d}, loss was {:05f}\"\n",
        "  .format(maxAccCora, lossPointsCora[maxAccCora]))\n",
        "#print(\"For PubMed, at epoch {:03d}, loss was {:05f}\"\n",
        "#  .format(maxAccPubMed, pointsLossPubMed[maxAccPubMed]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Cora, at epoch 083, loss was 0.518383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5EwZ8SD9nSW",
        "colab_type": "text"
      },
      "source": [
        "#Our algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eizH41lSch10",
        "colab_type": "text"
      },
      "source": [
        "For our algorithm we need to store somewhere some information. In particular for each training cycle we will update the historical activation in order to bring an efficent approximation. Also, we need to store the last recent h_0 and h_1, for computational purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMnnSp8_LU8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HMatrices():\n",
        "  def __init__(self):\n",
        "    self.historical_activation_1 = th.Tensor(np.zeros((2708,1433)))\n",
        "    self.historical_activation_2 = th.Tensor(np.zeros((2708,16)))\n",
        "    self.h_0 = th.Tensor([])\n",
        "    self.h_1 = th.Tensor([])\n",
        "\n",
        "  def updateHMatrix(self,features,x):\n",
        "    self.h_0 = features\n",
        "    self.h_1 = x\n",
        "  \n",
        "  def updateActivation(self, row, level, a):\n",
        "    if level == 0:\n",
        "      self.historical_activation_1[row] = a\n",
        "    elif level == 1:\n",
        "      self.historical_activation_2[row] = a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0rSVV_I1S-03",
        "colab": {}
      },
      "source": [
        "class SimpleNodeApplyModule(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, activation):\n",
        "        super(SimpleNodeApplyModule, self).__init__()\n",
        "        self.linear = nn.Linear(in_feats, out_feats)\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, node):\n",
        "        #type of node: dgl.udf.NodeBatch\n",
        "        #type of node.data['h']: torch.Tensor\n",
        "        z = self.linear(node.data['h'])\n",
        "        h = self.activation(z)\n",
        "        return {'h' : h}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fXAYnjwgTCfR",
        "colab": {}
      },
      "source": [
        "class SimpleGCN(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, activation):\n",
        "        super(SimpleGCN, self).__init__()\n",
        "        self.apply_mod = SimpleNodeApplyModule(in_feats, out_feats, activation)\n",
        "\n",
        "    def forward(self, g, feature):\n",
        "        g.ndata['h'] = feature\n",
        "        g.update_all(gcn_msg, gcn_reduce)\n",
        "        g.apply_nodes(func=self.apply_mod)\n",
        "        return g.ndata.pop('h')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oBqQpHvLTHUD",
        "outputId": "353bb105-88b8-42c6-8114-9a8778fdb214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.gcn1 = SimpleGCN(1433, 16, F.relu)\n",
        "        self.gcn2 = SimpleGCN(16, 7, F.relu)\n",
        "\n",
        "    def forward(self, g, features, propMatrix, historicalActivation, hContainer):\n",
        "        #type of 'g': dgl.graph.DGLGraph\n",
        "        x = self.gcn1(g, features)\n",
        "        hContainer.updateHMatrix(features, x)\n",
        "        # CV = (P'_l*(H_l-H'_l)+P*H'_l)\n",
        "        x = th.mm(propMatrix,x.sub(historicalActivation)).add(th.mm(P,historicalActivation))\n",
        "        x = self.gcn2(g, x)\n",
        "        return x\n",
        "\n",
        "simpleNet = SimpleNet()\n",
        "print(simpleNet)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SimpleNet(\n",
            "  (gcn1): SimpleGCN(\n",
            "    (apply_mod): SimpleNodeApplyModule(\n",
            "      (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (gcn2): SimpleGCN(\n",
            "    (apply_mod): SimpleNodeApplyModule(\n",
            "      (linear): Linear(in_features=16, out_features=7, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "omo3JIZQT8Br",
        "outputId": "20cebb32-33c4-4e37-da42-5570b365382a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "import collections\n",
        "import numpy as np\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#init counters\n",
        "averageAccCora_our = []\n",
        "averageLossCora_our = []\n",
        "\n",
        "for t in range(n_of_training_cycles):\n",
        "  print(\"Starting new training cycle\")\n",
        "\n",
        "  simpleNet = SimpleNet()\n",
        "  #point to show on graph\n",
        "  pointsOurCora=dict()\n",
        "  pointsOurLossCora=dict()\n",
        "\n",
        "  with th.no_grad():\n",
        "    #get data\n",
        "    g, features, labels, mask = load_cora_data()\n",
        "\n",
        "    print(g)\n",
        "    n_masks_to_try = 4\n",
        "    ourOptimizer = th.optim.Adam(simpleNet.parameters(), lr=2e-2)\n",
        "    ourOptimizer.state = collections.defaultdict(dict)\n",
        "    dur = []\n",
        "\n",
        "    #running algOne for each mask\n",
        "    t0 = time.time()\n",
        "    print(\"Computing algorithm 1 for each mask...\")\n",
        "    resForMasks = dict()\n",
        "    for m in masks:\n",
        "      resForMasks[m] = algOne(m)\n",
        "    print(\"{:03f} seconds\".format(time.time()-t0))\n",
        "\n",
        "  #this is an object storing some constant data\n",
        "  hs = HMatrices()\n",
        "\n",
        "  for epoch in range(n_of_epochs):\n",
        "        \n",
        "      t0 = time.time()\n",
        "      #getting only some masks (4)\n",
        "      masksToTry = random.sample(masks,n_masks_to_try)\n",
        "      for m in masksToTry:\n",
        "          #calling 'net(...)' it asks to the GCN to compute the forward\n",
        "\n",
        "          #M=(P'_l*(H_l-H'_l)+P*H'_l)\n",
        "          #H_l = feature\n",
        "          #P': progationMatrix\n",
        "          #H': get from initialized matrix\n",
        "          #P: computed before\n",
        "          CV = th.mm(resForMasks[m][1][0],features.sub(hs.historical_activation_1.detach())).add(th.mm(P,hs.historical_activation_1.detach()))\n",
        "          logits = simpleNet(g, CV, resForMasks[m][1][1], hs.historical_activation_2.detach(), hs)\n",
        "          logp = F.log_softmax(logits, 1)\n",
        "\n",
        "          #compute loss like the negative log likelihood loss\n",
        "          ourLoss = F.nll_loss(logp[m], labels[m])\n",
        "\n",
        "          #Since the backward() function accumulates gradients, and you \n",
        "          #don’t want to mix up gradients between minibatch, you have \n",
        "          #to zero them out at the start of a new minibatch. This is \n",
        "          #exactly like how a general (additive) accumulator variable is \n",
        "          #initialized to 0 in code.\n",
        "          ourOptimizer.zero_grad()\n",
        "\n",
        "          #update network weights by loss\n",
        "          #ourLoss.backward(retain_graph=True)\n",
        "          ourLoss.backward()\n",
        "\n",
        "          #update optimizer's values after backward\n",
        "          ourOptimizer.step()\n",
        "\n",
        "          #computing accuracy\n",
        "          i = 0\n",
        "          matched = 0\n",
        "          while i < 2708:\n",
        "            if m[i] == 0:\n",
        "              #getting index of the maximum\n",
        "              j = 0\n",
        "              max = None\n",
        "              jMax = 0\n",
        "              for a in logp[i]:\n",
        "                if max==None:\n",
        "                  max = a.item()\n",
        "                  jMax = j\n",
        "                elif max < a.item():\n",
        "                  max = a.item()\n",
        "                  jMax = j\n",
        "                j = j + 1\n",
        "              if jMax == labels[i]:\n",
        "                matched = matched + 1\n",
        "            i = i + 1\n",
        "          acc = matched/(2708-size_masks)*100\n",
        "\n",
        "          if epoch not in pointsOurCora:\n",
        "            pointsOurCora[epoch] = 0\n",
        "            pointsOurLossCora[epoch] = 0\n",
        "          pointsOurCora[epoch] = pointsOurCora[epoch] + acc\n",
        "          pointsOurLossCora[epoch] = pointsOurLossCora[epoch] + ourLoss.item()\n",
        "          \n",
        "          #update historical activation\n",
        "          for i in range(2):\n",
        "            recField = resForMasks[m][0][i]\n",
        "            k = 0\n",
        "            if i == 0:\n",
        "              for n in recField:\n",
        "                if n == 1:\n",
        "                  hs.updateActivation(k,i,hs.h_0[k])\n",
        "                k = k + 1\n",
        "            elif i == 1:\n",
        "              for n in recField:\n",
        "                if n == 1:\n",
        "                  hs.updateActivation(k,i,hs.h_1[k])\n",
        "                k = k + 1\n",
        "\n",
        "      dur.append(time.time() - t0)\n",
        "      \n",
        "      pointsOurCora[epoch] = pointsOurCora[epoch]/n_masks_to_try\n",
        "      pointsOurLossCora[epoch] = pointsOurLossCora[epoch]/n_masks_to_try\n",
        "\n",
        "      print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f} | Accuracy: {:.6f}\".format(\n",
        "              epoch, ourLoss.item(), np.mean(dur), pointsOurCora[epoch]))\n",
        "  \n",
        "  averageAccCora_our.append(pointsOurCora)\n",
        "  averageLossCora_our.append(pointsOurLossCora)\n",
        "  print(\"Results stored\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.800358 seconds\n",
            "Epoch 00000 | Loss 1.7820 | Time(s) 4.0821 | Accuracy: 19.603144\n",
            "Epoch 00001 | Loss 1.6073 | Time(s) 4.1309 | Accuracy: 39.311733\n",
            "Epoch 00002 | Loss 1.4304 | Time(s) 4.1166 | Accuracy: 44.699003\n",
            "Epoch 00003 | Loss 1.4045 | Time(s) 4.1112 | Accuracy: 48.773006\n",
            "Epoch 00004 | Loss 1.3018 | Time(s) 4.1231 | Accuracy: 52.540261\n",
            "Epoch 00005 | Loss 1.0862 | Time(s) 4.1133 | Accuracy: 51.706288\n",
            "Epoch 00006 | Loss 1.0044 | Time(s) 4.1088 | Accuracy: 54.927147\n",
            "Epoch 00007 | Loss 1.0371 | Time(s) 4.1061 | Accuracy: 56.815567\n",
            "Epoch 00008 | Loss 1.1111 | Time(s) 4.1030 | Accuracy: 60.534893\n",
            "Epoch 00009 | Loss 1.1328 | Time(s) 4.0997 | Accuracy: 61.004601\n",
            "Epoch 00010 | Loss 1.0450 | Time(s) 4.0921 | Accuracy: 61.771472\n",
            "Epoch 00011 | Loss 0.9626 | Time(s) 4.0884 | Accuracy: 63.084739\n",
            "Epoch 00012 | Loss 0.8534 | Time(s) 4.0845 | Accuracy: 63.736580\n",
            "Epoch 00013 | Loss 1.0156 | Time(s) 4.0827 | Accuracy: 63.918712\n",
            "Epoch 00014 | Loss 0.8770 | Time(s) 4.0816 | Accuracy: 64.091258\n",
            "Epoch 00015 | Loss 0.7325 | Time(s) 4.0768 | Accuracy: 63.794095\n",
            "Epoch 00016 | Loss 0.6980 | Time(s) 4.0753 | Accuracy: 64.081672\n",
            "Epoch 00017 | Loss 0.6814 | Time(s) 4.0743 | Accuracy: 64.723926\n",
            "Epoch 00018 | Loss 0.8898 | Time(s) 4.0704 | Accuracy: 64.695169\n",
            "Epoch 00019 | Loss 0.7346 | Time(s) 4.0766 | Accuracy: 64.359663\n",
            "Epoch 00020 | Loss 0.5202 | Time(s) 4.0772 | Accuracy: 64.177531\n",
            "Epoch 00021 | Loss 0.6883 | Time(s) 4.0813 | Accuracy: 63.899540\n",
            "Epoch 00022 | Loss 0.7726 | Time(s) 4.0810 | Accuracy: 64.311733\n",
            "Epoch 00023 | Loss 0.6426 | Time(s) 4.0802 | Accuracy: 63.602377\n",
            "Epoch 00024 | Loss 0.6795 | Time(s) 4.0763 | Accuracy: 64.033742\n",
            "Epoch 00025 | Loss 0.7749 | Time(s) 4.0723 | Accuracy: 63.995399\n",
            "Epoch 00026 | Loss 0.7723 | Time(s) 4.0704 | Accuracy: 64.024156\n",
            "Epoch 00027 | Loss 0.6513 | Time(s) 4.0721 | Accuracy: 63.774923\n",
            "Epoch 00028 | Loss 0.7890 | Time(s) 4.0710 | Accuracy: 63.688650\n",
            "Epoch 00029 | Loss 0.6613 | Time(s) 4.0694 | Accuracy: 64.388420\n",
            "Epoch 00030 | Loss 0.8091 | Time(s) 4.0684 | Accuracy: 64.560966\n",
            "Epoch 00031 | Loss 0.7888 | Time(s) 4.0678 | Accuracy: 64.206288\n",
            "Epoch 00032 | Loss 0.5813 | Time(s) 4.0665 | Accuracy: 63.621549\n",
            "Epoch 00033 | Loss 0.7674 | Time(s) 4.0655 | Accuracy: 64.570552\n",
            "Epoch 00034 | Loss 0.5319 | Time(s) 4.0641 | Accuracy: 64.685583\n",
            "Epoch 00035 | Loss 0.6137 | Time(s) 4.0622 | Accuracy: 64.704755\n",
            "Epoch 00036 | Loss 0.4837 | Time(s) 4.0604 | Accuracy: 64.465107\n",
            "Epoch 00037 | Loss 0.7443 | Time(s) 4.0587 | Accuracy: 63.822853\n",
            "Epoch 00038 | Loss 0.6102 | Time(s) 4.0593 | Accuracy: 63.966641\n",
            "Epoch 00039 | Loss 0.6373 | Time(s) 4.0574 | Accuracy: 63.592791\n",
            "Epoch 00040 | Loss 0.7463 | Time(s) 4.0556 | Accuracy: 63.583206\n",
            "Epoch 00041 | Loss 0.4911 | Time(s) 4.0568 | Accuracy: 64.024156\n",
            "Epoch 00042 | Loss 0.8046 | Time(s) 4.0555 | Accuracy: 62.394555\n",
            "Epoch 00043 | Loss 0.7609 | Time(s) 4.0555 | Accuracy: 62.087807\n",
            "Epoch 00044 | Loss 0.6194 | Time(s) 4.0561 | Accuracy: 63.353144\n",
            "Epoch 00045 | Loss 0.7534 | Time(s) 4.0544 | Accuracy: 62.442485\n",
            "Epoch 00046 | Loss 0.7352 | Time(s) 4.0530 | Accuracy: 62.864264\n",
            "Epoch 00047 | Loss 0.5247 | Time(s) 4.0525 | Accuracy: 62.653374\n",
            "Epoch 00048 | Loss 0.7240 | Time(s) 4.0515 | Accuracy: 63.055982\n",
            "Epoch 00049 | Loss 0.6556 | Time(s) 4.0536 | Accuracy: 63.544862\n",
            "Epoch 00050 | Loss 0.8460 | Time(s) 4.0543 | Accuracy: 63.659893\n",
            "Epoch 00051 | Loss 0.7803 | Time(s) 4.0523 | Accuracy: 63.209356\n",
            "Epoch 00052 | Loss 0.6360 | Time(s) 4.0522 | Accuracy: 63.199770\n",
            "Epoch 00053 | Loss 0.4790 | Time(s) 4.0511 | Accuracy: 62.806748\n",
            "Epoch 00054 | Loss 0.6775 | Time(s) 4.0508 | Accuracy: 62.174080\n",
            "Epoch 00055 | Loss 0.7205 | Time(s) 4.0505 | Accuracy: 62.480828\n",
            "Epoch 00056 | Loss 0.5379 | Time(s) 4.0491 | Accuracy: 63.190184\n",
            "Epoch 00057 | Loss 0.5335 | Time(s) 4.0485 | Accuracy: 63.832439\n",
            "Epoch 00058 | Loss 0.6704 | Time(s) 4.0470 | Accuracy: 63.209356\n",
            "Epoch 00059 | Loss 0.6178 | Time(s) 4.0472 | Accuracy: 63.669479\n",
            "Epoch 00060 | Loss 0.6395 | Time(s) 4.0481 | Accuracy: 63.611963\n",
            "Epoch 00061 | Loss 0.8069 | Time(s) 4.0466 | Accuracy: 63.621549\n",
            "Epoch 00062 | Loss 0.6431 | Time(s) 4.0454 | Accuracy: 63.449003\n",
            "Epoch 00063 | Loss 0.6382 | Time(s) 4.0443 | Accuracy: 63.564034\n",
            "Epoch 00064 | Loss 0.6925 | Time(s) 4.0440 | Accuracy: 63.755752\n",
            "Epoch 00065 | Loss 0.4802 | Time(s) 4.0438 | Accuracy: 62.912193\n",
            "Epoch 00066 | Loss 0.4711 | Time(s) 4.0427 | Accuracy: 63.305215\n",
            "Epoch 00067 | Loss 0.5274 | Time(s) 4.0420 | Accuracy: 63.573620\n",
            "Epoch 00068 | Loss 0.8239 | Time(s) 4.0411 | Accuracy: 63.669479\n",
            "Epoch 00069 | Loss 0.6307 | Time(s) 4.0396 | Accuracy: 63.573620\n",
            "Epoch 00070 | Loss 0.6161 | Time(s) 4.0392 | Accuracy: 62.806748\n",
            "Epoch 00071 | Loss 0.4549 | Time(s) 4.0386 | Accuracy: 63.372316\n",
            "Epoch 00072 | Loss 0.8097 | Time(s) 4.0389 | Accuracy: 64.004985\n",
            "Epoch 00073 | Loss 0.6190 | Time(s) 4.0378 | Accuracy: 63.717408\n",
            "Epoch 00074 | Loss 0.5023 | Time(s) 4.0379 | Accuracy: 63.161426\n",
            "Epoch 00075 | Loss 0.4622 | Time(s) 4.0375 | Accuracy: 62.883436\n",
            "Epoch 00076 | Loss 0.6234 | Time(s) 4.0371 | Accuracy: 62.720475\n",
            "Epoch 00077 | Loss 0.6287 | Time(s) 4.0378 | Accuracy: 63.161426\n",
            "Epoch 00078 | Loss 0.6915 | Time(s) 4.0370 | Accuracy: 62.950537\n",
            "Epoch 00079 | Loss 0.5172 | Time(s) 4.0380 | Accuracy: 62.528758\n",
            "Epoch 00080 | Loss 0.7664 | Time(s) 4.0374 | Accuracy: 63.679064\n",
            "Epoch 00081 | Loss 0.7467 | Time(s) 4.0362 | Accuracy: 63.477761\n",
            "Epoch 00082 | Loss 0.7661 | Time(s) 4.0348 | Accuracy: 63.084739\n",
            "Epoch 00083 | Loss 0.5134 | Time(s) 4.0346 | Accuracy: 63.036810\n",
            "Epoch 00084 | Loss 0.6444 | Time(s) 4.0337 | Accuracy: 63.247699\n",
            "Epoch 00085 | Loss 0.5837 | Time(s) 4.0334 | Accuracy: 63.851610\n",
            "Epoch 00086 | Loss 0.4490 | Time(s) 4.0330 | Accuracy: 64.292561\n",
            "Epoch 00087 | Loss 0.7215 | Time(s) 4.0327 | Accuracy: 63.631135\n",
            "Epoch 00088 | Loss 0.7087 | Time(s) 4.0325 | Accuracy: 63.765337\n",
            "Epoch 00089 | Loss 0.5928 | Time(s) 4.0314 | Accuracy: 63.784509\n",
            "Epoch 00090 | Loss 0.5927 | Time(s) 4.0312 | Accuracy: 63.564034\n",
            "Epoch 00091 | Loss 0.7245 | Time(s) 4.0309 | Accuracy: 63.477761\n",
            "Epoch 00092 | Loss 0.6870 | Time(s) 4.0306 | Accuracy: 63.305215\n",
            "Epoch 00093 | Loss 0.6030 | Time(s) 4.0312 | Accuracy: 63.631135\n",
            "Epoch 00094 | Loss 0.6252 | Time(s) 4.0306 | Accuracy: 63.343558\n",
            "Epoch 00095 | Loss 0.6404 | Time(s) 4.0305 | Accuracy: 63.190184\n",
            "Epoch 00096 | Loss 0.6038 | Time(s) 4.0296 | Accuracy: 62.576687\n",
            "Epoch 00097 | Loss 0.6351 | Time(s) 4.0292 | Accuracy: 61.560583\n",
            "Epoch 00098 | Loss 0.6480 | Time(s) 4.0302 | Accuracy: 62.394555\n",
            "Epoch 00099 | Loss 0.5504 | Time(s) 4.0295 | Accuracy: 63.324387\n",
            "Epoch 00100 | Loss 0.4372 | Time(s) 4.0284 | Accuracy: 62.413727\n",
            "Epoch 00101 | Loss 0.6722 | Time(s) 4.0273 | Accuracy: 63.103911\n",
            "Epoch 00102 | Loss 0.6179 | Time(s) 4.0275 | Accuracy: 62.643788\n",
            "Epoch 00103 | Loss 0.7637 | Time(s) 4.0269 | Accuracy: 61.733129\n",
            "Epoch 00104 | Loss 0.6132 | Time(s) 4.0262 | Accuracy: 62.126150\n",
            "Epoch 00105 | Loss 0.5576 | Time(s) 4.0257 | Accuracy: 63.429831\n",
            "Epoch 00106 | Loss 0.6653 | Time(s) 4.0259 | Accuracy: 63.314801\n",
            "Epoch 00107 | Loss 0.6491 | Time(s) 4.0253 | Accuracy: 63.909126\n",
            "Epoch 00108 | Loss 0.6323 | Time(s) 4.0252 | Accuracy: 63.813267\n",
            "Epoch 00109 | Loss 0.8650 | Time(s) 4.0249 | Accuracy: 63.247699\n",
            "Epoch 00110 | Loss 0.4444 | Time(s) 4.0246 | Accuracy: 63.027224\n",
            "Epoch 00111 | Loss 0.7351 | Time(s) 4.0245 | Accuracy: 63.688650\n",
            "Epoch 00112 | Loss 0.4282 | Time(s) 4.0238 | Accuracy: 63.161426\n",
            "Epoch 00113 | Loss 0.6371 | Time(s) 4.0235 | Accuracy: 62.298696\n",
            "Epoch 00114 | Loss 0.7604 | Time(s) 4.0224 | Accuracy: 63.113497\n",
            "Epoch 00115 | Loss 0.5298 | Time(s) 4.0218 | Accuracy: 62.825920\n",
            "Epoch 00116 | Loss 0.6320 | Time(s) 4.0218 | Accuracy: 63.276457\n",
            "Epoch 00117 | Loss 0.5434 | Time(s) 4.0214 | Accuracy: 63.008052\n",
            "Epoch 00118 | Loss 0.5089 | Time(s) 4.0207 | Accuracy: 63.151840\n",
            "Epoch 00119 | Loss 0.6363 | Time(s) 4.0204 | Accuracy: 63.324387\n",
            "Epoch 00120 | Loss 0.6217 | Time(s) 4.0197 | Accuracy: 62.816334\n",
            "Epoch 00121 | Loss 0.7411 | Time(s) 4.0193 | Accuracy: 63.899540\n",
            "Epoch 00122 | Loss 0.5537 | Time(s) 4.0187 | Accuracy: 63.611963\n",
            "Epoch 00123 | Loss 0.6177 | Time(s) 4.0187 | Accuracy: 63.209356\n",
            "Epoch 00124 | Loss 0.5523 | Time(s) 4.0202 | Accuracy: 63.966641\n",
            "Epoch 00125 | Loss 0.5548 | Time(s) 4.0214 | Accuracy: 64.081672\n",
            "Epoch 00126 | Loss 0.6940 | Time(s) 4.0217 | Accuracy: 64.043328\n",
            "Epoch 00127 | Loss 0.5915 | Time(s) 4.0211 | Accuracy: 63.439417\n",
            "Epoch 00128 | Loss 0.7546 | Time(s) 4.0204 | Accuracy: 63.324387\n",
            "Epoch 00129 | Loss 0.5470 | Time(s) 4.0204 | Accuracy: 62.931365\n",
            "Epoch 00130 | Loss 0.6464 | Time(s) 4.0208 | Accuracy: 63.247699\n",
            "Epoch 00131 | Loss 0.6696 | Time(s) 4.0212 | Accuracy: 63.084739\n",
            "Epoch 00132 | Loss 0.5873 | Time(s) 4.0211 | Accuracy: 64.206288\n",
            "Epoch 00133 | Loss 0.6043 | Time(s) 4.0208 | Accuracy: 63.947469\n",
            "Epoch 00134 | Loss 0.6276 | Time(s) 4.0202 | Accuracy: 63.372316\n",
            "Epoch 00135 | Loss 0.7474 | Time(s) 4.0202 | Accuracy: 63.468175\n",
            "Epoch 00136 | Loss 0.7676 | Time(s) 4.0197 | Accuracy: 63.305215\n",
            "Epoch 00137 | Loss 0.5952 | Time(s) 4.0200 | Accuracy: 62.739647\n",
            "Epoch 00138 | Loss 0.5770 | Time(s) 4.0196 | Accuracy: 61.886503\n",
            "Epoch 00139 | Loss 0.5943 | Time(s) 4.0196 | Accuracy: 62.413727\n",
            "Epoch 00140 | Loss 0.6246 | Time(s) 4.0202 | Accuracy: 63.391488\n",
            "Epoch 00141 | Loss 0.6438 | Time(s) 4.0196 | Accuracy: 63.458589\n",
            "Epoch 00142 | Loss 0.6929 | Time(s) 4.0187 | Accuracy: 63.640721\n",
            "Epoch 00143 | Loss 0.5379 | Time(s) 4.0181 | Accuracy: 63.602377\n",
            "Epoch 00144 | Loss 0.6373 | Time(s) 4.0177 | Accuracy: 62.806748\n",
            "Epoch 00145 | Loss 0.5646 | Time(s) 4.0166 | Accuracy: 62.174080\n",
            "Epoch 00146 | Loss 0.5307 | Time(s) 4.0155 | Accuracy: 62.950537\n",
            "Epoch 00147 | Loss 0.6147 | Time(s) 4.0153 | Accuracy: 63.650307\n",
            "Epoch 00148 | Loss 0.8511 | Time(s) 4.0143 | Accuracy: 64.091258\n",
            "Epoch 00149 | Loss 0.7326 | Time(s) 4.0130 | Accuracy: 63.286043\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.499774 seconds\n",
            "Epoch 00000 | Loss 1.8616 | Time(s) 3.9030 | Accuracy: 18.050230\n",
            "Epoch 00001 | Loss 1.6843 | Time(s) 3.9518 | Accuracy: 34.422929\n",
            "Epoch 00002 | Loss 1.4102 | Time(s) 3.8930 | Accuracy: 41.286426\n",
            "Epoch 00003 | Loss 1.3180 | Time(s) 3.8748 | Accuracy: 52.837423\n",
            "Epoch 00004 | Loss 1.2016 | Time(s) 3.8665 | Accuracy: 58.109663\n",
            "Epoch 00005 | Loss 1.0652 | Time(s) 3.8573 | Accuracy: 59.643405\n",
            "Epoch 00006 | Loss 1.2780 | Time(s) 3.8450 | Accuracy: 59.902224\n",
            "Epoch 00007 | Loss 0.8947 | Time(s) 3.8228 | Accuracy: 60.515721\n",
            "Epoch 00008 | Loss 0.9004 | Time(s) 3.8149 | Accuracy: 61.301764\n",
            "Epoch 00009 | Loss 0.8843 | Time(s) 3.8103 | Accuracy: 62.011120\n",
            "Epoch 00010 | Loss 0.9488 | Time(s) 3.8066 | Accuracy: 63.247699\n",
            "Epoch 00011 | Loss 0.8091 | Time(s) 3.8069 | Accuracy: 63.564034\n",
            "Epoch 00012 | Loss 0.6066 | Time(s) 3.7994 | Accuracy: 64.330905\n",
            "Epoch 00013 | Loss 0.7343 | Time(s) 3.8037 | Accuracy: 64.120015\n",
            "Epoch 00014 | Loss 0.5812 | Time(s) 3.8062 | Accuracy: 64.196702\n",
            "Epoch 00015 | Loss 0.5847 | Time(s) 3.8094 | Accuracy: 64.541794\n",
            "Epoch 00016 | Loss 0.6423 | Time(s) 3.8163 | Accuracy: 64.263804\n",
            "Epoch 00017 | Loss 0.8489 | Time(s) 3.8217 | Accuracy: 64.819785\n",
            "Epoch 00018 | Loss 0.7901 | Time(s) 3.8258 | Accuracy: 65.299080\n",
            "Epoch 00019 | Loss 0.7636 | Time(s) 3.8312 | Accuracy: 65.634586\n",
            "Epoch 00020 | Loss 0.6332 | Time(s) 3.8317 | Accuracy: 65.730445\n",
            "Epoch 00021 | Loss 0.6997 | Time(s) 3.8314 | Accuracy: 66.660276\n",
            "Epoch 00022 | Loss 0.4933 | Time(s) 3.8294 | Accuracy: 66.104294\n",
            "Epoch 00023 | Loss 0.6414 | Time(s) 3.8316 | Accuracy: 65.902991\n",
            "Epoch 00024 | Loss 0.6222 | Time(s) 3.8339 | Accuracy: 66.296012\n",
            "Epoch 00025 | Loss 0.6153 | Time(s) 3.8405 | Accuracy: 66.267255\n",
            "Epoch 00026 | Loss 0.4434 | Time(s) 3.8402 | Accuracy: 66.372699\n",
            "Epoch 00027 | Loss 0.6497 | Time(s) 3.8420 | Accuracy: 66.583589\n",
            "Epoch 00028 | Loss 0.6059 | Time(s) 3.8393 | Accuracy: 66.391871\n",
            "Epoch 00029 | Loss 0.6233 | Time(s) 3.8364 | Accuracy: 65.778374\n",
            "Epoch 00030 | Loss 0.6660 | Time(s) 3.8345 | Accuracy: 65.452454\n",
            "Epoch 00031 | Loss 0.7249 | Time(s) 3.8312 | Accuracy: 64.819785\n",
            "Epoch 00032 | Loss 0.6978 | Time(s) 3.8290 | Accuracy: 65.557899\n",
            "Epoch 00033 | Loss 0.5928 | Time(s) 3.8307 | Accuracy: 65.615414\n",
            "Epoch 00034 | Loss 0.6055 | Time(s) 3.8291 | Accuracy: 65.740031\n",
            "Epoch 00035 | Loss 0.7544 | Time(s) 3.8291 | Accuracy: 66.650690\n",
            "Epoch 00036 | Loss 0.6009 | Time(s) 3.8265 | Accuracy: 65.835890\n",
            "Epoch 00037 | Loss 0.6578 | Time(s) 3.8255 | Accuracy: 66.305598\n",
            "Epoch 00038 | Loss 0.6724 | Time(s) 3.8241 | Accuracy: 65.653758\n",
            "Epoch 00039 | Loss 0.4414 | Time(s) 3.8238 | Accuracy: 65.279908\n",
            "Epoch 00040 | Loss 0.5993 | Time(s) 3.8266 | Accuracy: 65.596242\n",
            "Epoch 00041 | Loss 0.4721 | Time(s) 3.8275 | Accuracy: 65.845475\n",
            "Epoch 00042 | Loss 0.5639 | Time(s) 3.8244 | Accuracy: 66.152224\n",
            "Epoch 00043 | Loss 0.6463 | Time(s) 3.8245 | Accuracy: 66.200153\n",
            "Epoch 00044 | Loss 0.6126 | Time(s) 3.8233 | Accuracy: 64.877301\n",
            "Epoch 00045 | Loss 0.5375 | Time(s) 3.8234 | Accuracy: 65.625000\n",
            "Epoch 00046 | Loss 0.6069 | Time(s) 3.8197 | Accuracy: 65.749617\n",
            "Epoch 00047 | Loss 0.4346 | Time(s) 3.8182 | Accuracy: 65.366181\n",
            "Epoch 00048 | Loss 0.5991 | Time(s) 3.8170 | Accuracy: 66.008436\n",
            "Epoch 00049 | Loss 0.6325 | Time(s) 3.8162 | Accuracy: 65.577071\n",
            "Epoch 00050 | Loss 0.6900 | Time(s) 3.8160 | Accuracy: 64.685583\n",
            "Epoch 00051 | Loss 0.6938 | Time(s) 3.8151 | Accuracy: 64.321319\n",
            "Epoch 00052 | Loss 0.4056 | Time(s) 3.8141 | Accuracy: 64.781442\n",
            "Epoch 00053 | Loss 0.6756 | Time(s) 3.8118 | Accuracy: 65.864647\n",
            "Epoch 00054 | Loss 0.4538 | Time(s) 3.8111 | Accuracy: 64.819785\n",
            "Epoch 00055 | Loss 0.6076 | Time(s) 3.8099 | Accuracy: 64.963574\n",
            "Epoch 00056 | Loss 0.5537 | Time(s) 3.8084 | Accuracy: 65.011503\n",
            "Epoch 00057 | Loss 0.6930 | Time(s) 3.8062 | Accuracy: 64.838957\n",
            "Epoch 00058 | Loss 0.6196 | Time(s) 3.8032 | Accuracy: 64.532209\n",
            "Epoch 00059 | Loss 0.5818 | Time(s) 3.8019 | Accuracy: 64.906058\n",
            "Epoch 00060 | Loss 0.6405 | Time(s) 3.8003 | Accuracy: 65.740031\n",
            "Epoch 00061 | Loss 0.4405 | Time(s) 3.7987 | Accuracy: 65.845475\n",
            "Epoch 00062 | Loss 0.6275 | Time(s) 3.7979 | Accuracy: 65.864647\n",
            "Epoch 00063 | Loss 0.6174 | Time(s) 3.7974 | Accuracy: 65.941334\n",
            "Epoch 00064 | Loss 0.5460 | Time(s) 3.7984 | Accuracy: 66.257669\n",
            "Epoch 00065 | Loss 0.6051 | Time(s) 3.7986 | Accuracy: 66.219325\n",
            "Epoch 00066 | Loss 0.6073 | Time(s) 3.7973 | Accuracy: 65.318252\n",
            "Epoch 00067 | Loss 0.6156 | Time(s) 3.7965 | Accuracy: 65.538727\n",
            "Epoch 00068 | Loss 0.5801 | Time(s) 3.7961 | Accuracy: 66.056365\n",
            "Epoch 00069 | Loss 0.5962 | Time(s) 3.7956 | Accuracy: 66.353528\n",
            "Epoch 00070 | Loss 0.6523 | Time(s) 3.7948 | Accuracy: 65.989264\n",
            "Epoch 00071 | Loss 0.4219 | Time(s) 3.7934 | Accuracy: 65.433282\n",
            "Epoch 00072 | Loss 0.5739 | Time(s) 3.7945 | Accuracy: 65.740031\n",
            "Epoch 00073 | Loss 0.5873 | Time(s) 3.7951 | Accuracy: 66.018021\n",
            "Epoch 00074 | Loss 0.4384 | Time(s) 3.7928 | Accuracy: 65.692101\n",
            "Epoch 00075 | Loss 0.5989 | Time(s) 3.7919 | Accuracy: 65.797546\n",
            "Epoch 00076 | Loss 0.5746 | Time(s) 3.7912 | Accuracy: 65.605828\n",
            "Epoch 00077 | Loss 0.6019 | Time(s) 3.7895 | Accuracy: 66.113880\n",
            "Epoch 00078 | Loss 0.6015 | Time(s) 3.7881 | Accuracy: 65.759202\n",
            "Epoch 00079 | Loss 0.6005 | Time(s) 3.7867 | Accuracy: 65.950920\n",
            "Epoch 00080 | Loss 0.6159 | Time(s) 3.7861 | Accuracy: 65.835890\n",
            "Epoch 00081 | Loss 0.5744 | Time(s) 3.7875 | Accuracy: 66.161810\n",
            "Epoch 00082 | Loss 0.4325 | Time(s) 3.7872 | Accuracy: 66.008436\n",
            "Epoch 00083 | Loss 0.8434 | Time(s) 3.7854 | Accuracy: 66.008436\n",
            "Epoch 00084 | Loss 0.5782 | Time(s) 3.7838 | Accuracy: 65.979678\n",
            "Epoch 00085 | Loss 0.5886 | Time(s) 3.7834 | Accuracy: 65.864647\n",
            "Epoch 00086 | Loss 0.5665 | Time(s) 3.7825 | Accuracy: 65.500383\n",
            "Epoch 00087 | Loss 0.5475 | Time(s) 3.7823 | Accuracy: 65.356595\n",
            "Epoch 00088 | Loss 0.5516 | Time(s) 3.7815 | Accuracy: 65.701687\n",
            "Epoch 00089 | Loss 0.4319 | Time(s) 3.7817 | Accuracy: 65.577071\n",
            "Epoch 00090 | Loss 0.5989 | Time(s) 3.7804 | Accuracy: 65.950920\n",
            "Epoch 00091 | Loss 0.5764 | Time(s) 3.7799 | Accuracy: 65.893405\n",
            "Epoch 00092 | Loss 0.3744 | Time(s) 3.7789 | Accuracy: 66.372699\n",
            "Epoch 00093 | Loss 0.5853 | Time(s) 3.7782 | Accuracy: 66.343942\n",
            "Epoch 00094 | Loss 0.5755 | Time(s) 3.7769 | Accuracy: 66.526074\n",
            "Epoch 00095 | Loss 0.4847 | Time(s) 3.7773 | Accuracy: 66.094709\n",
            "Epoch 00096 | Loss 0.6006 | Time(s) 3.7757 | Accuracy: 66.065951\n",
            "Epoch 00097 | Loss 0.6951 | Time(s) 3.7759 | Accuracy: 66.324770\n",
            "Epoch 00098 | Loss 0.4941 | Time(s) 3.7763 | Accuracy: 66.142638\n",
            "Epoch 00099 | Loss 0.4366 | Time(s) 3.7752 | Accuracy: 65.644172\n",
            "Epoch 00100 | Loss 0.6460 | Time(s) 3.7751 | Accuracy: 66.238497\n",
            "Epoch 00101 | Loss 0.4367 | Time(s) 3.7743 | Accuracy: 65.720859\n",
            "Epoch 00102 | Loss 0.4295 | Time(s) 3.7735 | Accuracy: 65.375767\n",
            "Epoch 00103 | Loss 0.5378 | Time(s) 3.7726 | Accuracy: 65.270322\n",
            "Epoch 00104 | Loss 0.5841 | Time(s) 3.7725 | Accuracy: 65.279908\n",
            "Epoch 00105 | Loss 0.5997 | Time(s) 3.7732 | Accuracy: 64.752684\n",
            "Epoch 00106 | Loss 0.5980 | Time(s) 3.7737 | Accuracy: 64.628067\n",
            "Epoch 00107 | Loss 0.8012 | Time(s) 3.7742 | Accuracy: 65.088190\n",
            "Epoch 00108 | Loss 0.5120 | Time(s) 3.7731 | Accuracy: 65.145706\n",
            "Epoch 00109 | Loss 0.5136 | Time(s) 3.7723 | Accuracy: 65.423696\n",
            "Epoch 00110 | Loss 0.5744 | Time(s) 3.7710 | Accuracy: 65.030675\n",
            "Epoch 00111 | Loss 0.6753 | Time(s) 3.7698 | Accuracy: 65.116948\n",
            "Epoch 00112 | Loss 0.6180 | Time(s) 3.7693 | Accuracy: 65.318252\n",
            "Epoch 00113 | Loss 0.5602 | Time(s) 3.7689 | Accuracy: 65.136120\n",
            "Epoch 00114 | Loss 0.6133 | Time(s) 3.7692 | Accuracy: 65.701687\n",
            "Epoch 00115 | Loss 0.5452 | Time(s) 3.7677 | Accuracy: 65.500383\n",
            "Epoch 00116 | Loss 0.6111 | Time(s) 3.7676 | Accuracy: 65.577071\n",
            "Epoch 00117 | Loss 0.5133 | Time(s) 3.7664 | Accuracy: 65.145706\n",
            "Epoch 00118 | Loss 0.5484 | Time(s) 3.7651 | Accuracy: 65.471626\n",
            "Epoch 00119 | Loss 0.6717 | Time(s) 3.7638 | Accuracy: 65.711273\n",
            "Epoch 00120 | Loss 0.5554 | Time(s) 3.7633 | Accuracy: 64.915644\n",
            "Epoch 00121 | Loss 0.6857 | Time(s) 3.7623 | Accuracy: 65.289494\n",
            "Epoch 00122 | Loss 0.5242 | Time(s) 3.7618 | Accuracy: 65.366181\n",
            "Epoch 00123 | Loss 0.5412 | Time(s) 3.7609 | Accuracy: 65.423696\n",
            "Epoch 00124 | Loss 0.5366 | Time(s) 3.7599 | Accuracy: 65.414110\n",
            "Epoch 00125 | Loss 0.5776 | Time(s) 3.7587 | Accuracy: 65.807132\n",
            "Epoch 00126 | Loss 0.4130 | Time(s) 3.7584 | Accuracy: 66.018021\n",
            "Epoch 00127 | Loss 0.5868 | Time(s) 3.7576 | Accuracy: 66.018021\n",
            "Epoch 00128 | Loss 0.6268 | Time(s) 3.7564 | Accuracy: 65.500383\n",
            "Epoch 00129 | Loss 0.6522 | Time(s) 3.7559 | Accuracy: 64.886887\n",
            "Epoch 00130 | Loss 0.4543 | Time(s) 3.7551 | Accuracy: 65.299080\n",
            "Epoch 00131 | Loss 0.5535 | Time(s) 3.7542 | Accuracy: 65.730445\n",
            "Epoch 00132 | Loss 0.5756 | Time(s) 3.7526 | Accuracy: 65.462040\n",
            "Epoch 00133 | Loss 0.6944 | Time(s) 3.7523 | Accuracy: 64.982745\n",
            "Epoch 00134 | Loss 0.7054 | Time(s) 3.7513 | Accuracy: 66.200153\n",
            "Epoch 00135 | Loss 0.5916 | Time(s) 3.7506 | Accuracy: 66.276840\n",
            "Epoch 00136 | Loss 0.6064 | Time(s) 3.7497 | Accuracy: 66.238497\n",
            "Epoch 00137 | Loss 0.5185 | Time(s) 3.7486 | Accuracy: 65.672929\n",
            "Epoch 00138 | Loss 0.5026 | Time(s) 3.7483 | Accuracy: 65.874233\n",
            "Epoch 00139 | Loss 0.4085 | Time(s) 3.7479 | Accuracy: 65.970092\n",
            "Epoch 00140 | Loss 0.5433 | Time(s) 3.7473 | Accuracy: 65.308666\n",
            "Epoch 00141 | Loss 0.5281 | Time(s) 3.7469 | Accuracy: 65.078604\n",
            "Epoch 00142 | Loss 0.6813 | Time(s) 3.7458 | Accuracy: 65.462040\n",
            "Epoch 00143 | Loss 0.7813 | Time(s) 3.7450 | Accuracy: 65.711273\n",
            "Epoch 00144 | Loss 0.5752 | Time(s) 3.7447 | Accuracy: 65.212807\n",
            "Epoch 00145 | Loss 0.6312 | Time(s) 3.7440 | Accuracy: 64.743098\n",
            "Epoch 00146 | Loss 0.4864 | Time(s) 3.7441 | Accuracy: 65.021089\n",
            "Epoch 00147 | Loss 0.6304 | Time(s) 3.7439 | Accuracy: 65.097776\n",
            "Epoch 00148 | Loss 0.5680 | Time(s) 3.7432 | Accuracy: 65.874233\n",
            "Epoch 00149 | Loss 0.4566 | Time(s) 3.7422 | Accuracy: 65.548313\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.281888 seconds\n",
            "Epoch 00000 | Loss 1.8703 | Time(s) 3.6698 | Accuracy: 22.986963\n",
            "Epoch 00001 | Loss 1.5590 | Time(s) 3.6921 | Accuracy: 36.455138\n",
            "Epoch 00002 | Loss 1.5910 | Time(s) 3.6959 | Accuracy: 44.219709\n",
            "Epoch 00003 | Loss 1.2334 | Time(s) 3.6959 | Accuracy: 55.770706\n",
            "Epoch 00004 | Loss 0.9995 | Time(s) 3.7029 | Accuracy: 60.208972\n",
            "Epoch 00005 | Loss 1.1463 | Time(s) 3.7193 | Accuracy: 60.879985\n",
            "Epoch 00006 | Loss 0.9943 | Time(s) 3.7156 | Accuracy: 63.171012\n",
            "Epoch 00007 | Loss 0.7846 | Time(s) 3.7088 | Accuracy: 63.928298\n",
            "Epoch 00008 | Loss 0.9204 | Time(s) 3.7079 | Accuracy: 64.139187\n",
            "Epoch 00009 | Loss 0.8370 | Time(s) 3.7158 | Accuracy: 64.685583\n",
            "Epoch 00010 | Loss 0.9971 | Time(s) 3.7181 | Accuracy: 64.886887\n",
            "Epoch 00011 | Loss 0.8016 | Time(s) 3.7162 | Accuracy: 64.819785\n",
            "Epoch 00012 | Loss 0.6283 | Time(s) 3.7186 | Accuracy: 64.340491\n",
            "Epoch 00013 | Loss 0.9286 | Time(s) 3.7150 | Accuracy: 65.069018\n",
            "Epoch 00014 | Loss 0.6796 | Time(s) 3.7184 | Accuracy: 65.021089\n",
            "Epoch 00015 | Loss 0.6625 | Time(s) 3.7113 | Accuracy: 65.107362\n",
            "Epoch 00016 | Loss 0.7676 | Time(s) 3.7079 | Accuracy: 64.858129\n",
            "Epoch 00017 | Loss 0.6834 | Time(s) 3.7035 | Accuracy: 64.723926\n",
            "Epoch 00018 | Loss 0.6321 | Time(s) 3.7017 | Accuracy: 65.337423\n",
            "Epoch 00019 | Loss 0.6230 | Time(s) 3.6963 | Accuracy: 65.308666\n",
            "Epoch 00020 | Loss 0.7357 | Time(s) 3.6938 | Accuracy: 64.666411\n",
            "Epoch 00021 | Loss 0.5225 | Time(s) 3.6903 | Accuracy: 65.366181\n",
            "Epoch 00022 | Loss 1.0526 | Time(s) 3.6878 | Accuracy: 65.845475\n",
            "Epoch 00023 | Loss 0.5435 | Time(s) 3.6877 | Accuracy: 65.826304\n",
            "Epoch 00024 | Loss 0.9458 | Time(s) 3.6817 | Accuracy: 65.644172\n",
            "Epoch 00025 | Loss 1.1684 | Time(s) 3.6785 | Accuracy: 64.762270\n",
            "Epoch 00026 | Loss 0.5672 | Time(s) 3.6814 | Accuracy: 64.043328\n",
            "Epoch 00027 | Loss 0.5592 | Time(s) 3.6791 | Accuracy: 65.241564\n",
            "Epoch 00028 | Loss 0.6748 | Time(s) 3.6763 | Accuracy: 65.423696\n",
            "Epoch 00029 | Loss 0.6676 | Time(s) 3.6750 | Accuracy: 65.874233\n",
            "Epoch 00030 | Loss 0.5542 | Time(s) 3.6739 | Accuracy: 66.200153\n",
            "Epoch 00031 | Loss 0.6720 | Time(s) 3.6712 | Accuracy: 65.883819\n",
            "Epoch 00032 | Loss 0.6813 | Time(s) 3.6723 | Accuracy: 65.931748\n",
            "Epoch 00033 | Loss 0.5592 | Time(s) 3.6697 | Accuracy: 65.078604\n",
            "Epoch 00034 | Loss 0.7387 | Time(s) 3.6723 | Accuracy: 65.251150\n",
            "Epoch 00035 | Loss 0.9096 | Time(s) 3.6751 | Accuracy: 65.500383\n",
            "Epoch 00036 | Loss 0.8188 | Time(s) 3.6774 | Accuracy: 65.490798\n",
            "Epoch 00037 | Loss 0.5351 | Time(s) 3.6778 | Accuracy: 64.762270\n",
            "Epoch 00038 | Loss 0.6273 | Time(s) 3.6797 | Accuracy: 64.235046\n",
            "Epoch 00039 | Loss 0.5843 | Time(s) 3.6797 | Accuracy: 64.302147\n",
            "Epoch 00040 | Loss 0.5432 | Time(s) 3.6807 | Accuracy: 64.858129\n",
            "Epoch 00041 | Loss 0.6922 | Time(s) 3.6785 | Accuracy: 65.212807\n",
            "Epoch 00042 | Loss 0.5571 | Time(s) 3.6795 | Accuracy: 65.145706\n",
            "Epoch 00043 | Loss 0.4903 | Time(s) 3.6807 | Accuracy: 65.270322\n",
            "Epoch 00044 | Loss 0.7434 | Time(s) 3.6796 | Accuracy: 65.078604\n",
            "Epoch 00045 | Loss 0.6033 | Time(s) 3.6777 | Accuracy: 64.743098\n",
            "Epoch 00046 | Loss 0.5821 | Time(s) 3.6780 | Accuracy: 65.078604\n",
            "Epoch 00047 | Loss 0.8711 | Time(s) 3.6776 | Accuracy: 64.599310\n",
            "Epoch 00048 | Loss 0.5753 | Time(s) 3.6781 | Accuracy: 65.193635\n",
            "Epoch 00049 | Loss 0.6001 | Time(s) 3.6774 | Accuracy: 64.388420\n",
            "Epoch 00050 | Loss 0.5889 | Time(s) 3.6764 | Accuracy: 64.704755\n",
            "Epoch 00051 | Loss 0.7741 | Time(s) 3.6752 | Accuracy: 65.586656\n",
            "Epoch 00052 | Loss 0.7838 | Time(s) 3.6727 | Accuracy: 65.577071\n",
            "Epoch 00053 | Loss 0.6962 | Time(s) 3.6736 | Accuracy: 64.944402\n",
            "Epoch 00054 | Loss 0.8110 | Time(s) 3.6721 | Accuracy: 63.420245\n",
            "Epoch 00055 | Loss 0.5778 | Time(s) 3.6711 | Accuracy: 62.864264\n",
            "Epoch 00056 | Loss 0.7189 | Time(s) 3.6700 | Accuracy: 64.628067\n",
            "Epoch 00057 | Loss 0.7388 | Time(s) 3.6687 | Accuracy: 64.762270\n",
            "Epoch 00058 | Loss 0.5859 | Time(s) 3.6680 | Accuracy: 65.001917\n",
            "Epoch 00059 | Loss 0.6547 | Time(s) 3.6694 | Accuracy: 64.963574\n",
            "Epoch 00060 | Loss 0.7127 | Time(s) 3.6697 | Accuracy: 64.052914\n",
            "Epoch 00061 | Loss 0.6537 | Time(s) 3.6686 | Accuracy: 64.666411\n",
            "Epoch 00062 | Loss 1.1921 | Time(s) 3.6681 | Accuracy: 65.318252\n",
            "Epoch 00063 | Loss 0.6453 | Time(s) 3.6677 | Accuracy: 65.040261\n",
            "Epoch 00064 | Loss 0.5938 | Time(s) 3.6674 | Accuracy: 64.532209\n",
            "Epoch 00065 | Loss 0.8615 | Time(s) 3.6658 | Accuracy: 64.177531\n",
            "Epoch 00066 | Loss 0.5041 | Time(s) 3.6660 | Accuracy: 63.995399\n",
            "Epoch 00067 | Loss 0.4627 | Time(s) 3.6663 | Accuracy: 64.445936\n",
            "Epoch 00068 | Loss 0.5609 | Time(s) 3.6656 | Accuracy: 63.669479\n",
            "Epoch 00069 | Loss 0.5177 | Time(s) 3.6658 | Accuracy: 64.637653\n",
            "Epoch 00070 | Loss 0.6825 | Time(s) 3.6656 | Accuracy: 64.359663\n",
            "Epoch 00071 | Loss 0.6465 | Time(s) 3.6652 | Accuracy: 64.072086\n",
            "Epoch 00072 | Loss 0.9309 | Time(s) 3.6638 | Accuracy: 64.474693\n",
            "Epoch 00073 | Loss 0.4880 | Time(s) 3.6630 | Accuracy: 64.513037\n",
            "Epoch 00074 | Loss 0.9076 | Time(s) 3.6615 | Accuracy: 64.848543\n",
            "Epoch 00075 | Loss 0.8585 | Time(s) 3.6626 | Accuracy: 64.263804\n",
            "Epoch 00076 | Loss 0.7551 | Time(s) 3.6630 | Accuracy: 63.976227\n",
            "Epoch 00077 | Loss 0.5606 | Time(s) 3.6632 | Accuracy: 63.985813\n",
            "Epoch 00078 | Loss 0.4887 | Time(s) 3.6625 | Accuracy: 64.158359\n",
            "Epoch 00079 | Loss 0.5450 | Time(s) 3.6629 | Accuracy: 64.091258\n",
            "Epoch 00080 | Loss 0.5296 | Time(s) 3.6629 | Accuracy: 64.704755\n",
            "Epoch 00081 | Loss 0.5383 | Time(s) 3.6639 | Accuracy: 64.282975\n",
            "Epoch 00082 | Loss 0.5082 | Time(s) 3.6639 | Accuracy: 63.650307\n",
            "Epoch 00083 | Loss 0.5895 | Time(s) 3.6654 | Accuracy: 63.707822\n",
            "Epoch 00084 | Loss 0.8442 | Time(s) 3.6651 | Accuracy: 63.257285\n",
            "Epoch 00085 | Loss 0.5213 | Time(s) 3.6651 | Accuracy: 62.921779\n",
            "Epoch 00086 | Loss 0.5218 | Time(s) 3.6655 | Accuracy: 63.420245\n",
            "Epoch 00087 | Loss 0.6954 | Time(s) 3.6653 | Accuracy: 64.139187\n",
            "Epoch 00088 | Loss 0.4548 | Time(s) 3.6662 | Accuracy: 64.254218\n",
            "Epoch 00089 | Loss 0.4979 | Time(s) 3.6656 | Accuracy: 64.906058\n",
            "Epoch 00090 | Loss 0.6990 | Time(s) 3.6651 | Accuracy: 64.417178\n",
            "Epoch 00091 | Loss 0.4744 | Time(s) 3.6661 | Accuracy: 64.321319\n",
            "Epoch 00092 | Loss 0.8477 | Time(s) 3.6674 | Accuracy: 64.618482\n",
            "Epoch 00093 | Loss 0.7441 | Time(s) 3.6681 | Accuracy: 63.429831\n",
            "Epoch 00094 | Loss 0.5717 | Time(s) 3.6686 | Accuracy: 63.266871\n",
            "Epoch 00095 | Loss 0.4886 | Time(s) 3.6691 | Accuracy: 63.726994\n",
            "Epoch 00096 | Loss 0.6954 | Time(s) 3.6699 | Accuracy: 64.628067\n",
            "Epoch 00097 | Loss 0.7460 | Time(s) 3.6698 | Accuracy: 64.302147\n",
            "Epoch 00098 | Loss 0.5527 | Time(s) 3.6698 | Accuracy: 64.513037\n",
            "Epoch 00099 | Loss 0.7160 | Time(s) 3.6722 | Accuracy: 64.551380\n",
            "Epoch 00100 | Loss 0.6857 | Time(s) 3.6714 | Accuracy: 64.695169\n",
            "Epoch 00101 | Loss 0.5154 | Time(s) 3.6715 | Accuracy: 64.493865\n",
            "Epoch 00102 | Loss 0.7071 | Time(s) 3.6716 | Accuracy: 63.746166\n",
            "Epoch 00103 | Loss 0.5271 | Time(s) 3.6711 | Accuracy: 63.401074\n",
            "Epoch 00104 | Loss 0.5972 | Time(s) 3.6706 | Accuracy: 64.148773\n",
            "Epoch 00105 | Loss 0.4671 | Time(s) 3.6710 | Accuracy: 63.286043\n",
            "Epoch 00106 | Loss 0.4388 | Time(s) 3.6703 | Accuracy: 63.784509\n",
            "Epoch 00107 | Loss 0.7446 | Time(s) 3.6708 | Accuracy: 64.436350\n",
            "Epoch 00108 | Loss 0.6278 | Time(s) 3.6706 | Accuracy: 64.819785\n",
            "Epoch 00109 | Loss 0.7029 | Time(s) 3.6704 | Accuracy: 64.647239\n",
            "Epoch 00110 | Loss 0.6230 | Time(s) 3.6694 | Accuracy: 64.838957\n",
            "Epoch 00111 | Loss 0.4828 | Time(s) 3.6686 | Accuracy: 64.589724\n",
            "Epoch 00112 | Loss 0.5312 | Time(s) 3.6679 | Accuracy: 64.321319\n",
            "Epoch 00113 | Loss 0.4854 | Time(s) 3.6667 | Accuracy: 64.589724\n",
            "Epoch 00114 | Loss 0.4679 | Time(s) 3.6650 | Accuracy: 63.870782\n",
            "Epoch 00115 | Loss 0.5767 | Time(s) 3.6645 | Accuracy: 64.503451\n",
            "Epoch 00116 | Loss 0.5740 | Time(s) 3.6643 | Accuracy: 63.947469\n",
            "Epoch 00117 | Loss 0.5278 | Time(s) 3.6637 | Accuracy: 63.774923\n",
            "Epoch 00118 | Loss 0.5817 | Time(s) 3.6628 | Accuracy: 62.768405\n",
            "Epoch 00119 | Loss 0.8592 | Time(s) 3.6617 | Accuracy: 63.477761\n",
            "Epoch 00120 | Loss 0.8737 | Time(s) 3.6607 | Accuracy: 63.583206\n",
            "Epoch 00121 | Loss 1.0157 | Time(s) 3.6603 | Accuracy: 64.407592\n",
            "Epoch 00122 | Loss 0.6626 | Time(s) 3.6604 | Accuracy: 64.618482\n",
            "Epoch 00123 | Loss 0.6648 | Time(s) 3.6597 | Accuracy: 64.704755\n",
            "Epoch 00124 | Loss 0.5334 | Time(s) 3.6594 | Accuracy: 63.679064\n",
            "Epoch 00125 | Loss 0.5280 | Time(s) 3.6587 | Accuracy: 63.286043\n",
            "Epoch 00126 | Loss 0.5363 | Time(s) 3.6574 | Accuracy: 63.851610\n",
            "Epoch 00127 | Loss 0.5232 | Time(s) 3.6557 | Accuracy: 63.659893\n",
            "Epoch 00128 | Loss 0.7846 | Time(s) 3.6546 | Accuracy: 63.899540\n",
            "Epoch 00129 | Loss 0.5782 | Time(s) 3.6536 | Accuracy: 63.717408\n",
            "Epoch 00130 | Loss 0.6500 | Time(s) 3.6527 | Accuracy: 64.024156\n",
            "Epoch 00131 | Loss 0.6793 | Time(s) 3.6516 | Accuracy: 63.976227\n",
            "Epoch 00132 | Loss 0.8281 | Time(s) 3.6505 | Accuracy: 64.120015\n",
            "Epoch 00133 | Loss 0.5076 | Time(s) 3.6497 | Accuracy: 63.602377\n",
            "Epoch 00134 | Loss 0.4681 | Time(s) 3.6484 | Accuracy: 64.273390\n",
            "Epoch 00135 | Loss 0.6373 | Time(s) 3.6469 | Accuracy: 64.637653\n",
            "Epoch 00136 | Loss 0.4681 | Time(s) 3.6458 | Accuracy: 64.743098\n",
            "Epoch 00137 | Loss 0.5950 | Time(s) 3.6450 | Accuracy: 64.503451\n",
            "Epoch 00138 | Loss 0.4479 | Time(s) 3.6446 | Accuracy: 64.484279\n",
            "Epoch 00139 | Loss 0.6238 | Time(s) 3.6439 | Accuracy: 64.120015\n",
            "Epoch 00140 | Loss 0.4969 | Time(s) 3.6433 | Accuracy: 65.097776\n",
            "Epoch 00141 | Loss 0.5334 | Time(s) 3.6427 | Accuracy: 65.433282\n",
            "Epoch 00142 | Loss 0.6352 | Time(s) 3.6423 | Accuracy: 65.107362\n",
            "Epoch 00143 | Loss 0.5193 | Time(s) 3.6414 | Accuracy: 65.069018\n",
            "Epoch 00144 | Loss 0.4689 | Time(s) 3.6403 | Accuracy: 65.136120\n",
            "Epoch 00145 | Loss 0.8445 | Time(s) 3.6395 | Accuracy: 64.934816\n",
            "Epoch 00146 | Loss 0.5267 | Time(s) 3.6387 | Accuracy: 64.244632\n",
            "Epoch 00147 | Loss 0.8120 | Time(s) 3.6378 | Accuracy: 64.810199\n",
            "Epoch 00148 | Loss 0.6049 | Time(s) 3.6365 | Accuracy: 64.167945\n",
            "Epoch 00149 | Loss 0.6605 | Time(s) 3.6358 | Accuracy: 64.589724\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.192916 seconds\n",
            "Epoch 00000 | Loss 1.8466 | Time(s) 3.5499 | Accuracy: 19.996166\n",
            "Epoch 00001 | Loss 1.7221 | Time(s) 3.5931 | Accuracy: 33.723160\n",
            "Epoch 00002 | Loss 1.2598 | Time(s) 3.5727 | Accuracy: 47.402224\n",
            "Epoch 00003 | Loss 1.3030 | Time(s) 3.5691 | Accuracy: 55.761120\n",
            "Epoch 00004 | Loss 1.0576 | Time(s) 3.5859 | Accuracy: 59.940567\n",
            "Epoch 00005 | Loss 0.9879 | Time(s) 3.5827 | Accuracy: 67.992715\n",
            "Epoch 00006 | Loss 0.9343 | Time(s) 3.5816 | Accuracy: 70.993098\n",
            "Epoch 00007 | Loss 0.9617 | Time(s) 3.5788 | Accuracy: 71.635353\n",
            "Epoch 00008 | Loss 0.9368 | Time(s) 3.5753 | Accuracy: 72.795245\n",
            "Epoch 00009 | Loss 0.6453 | Time(s) 3.5689 | Accuracy: 73.552531\n",
            "Epoch 00010 | Loss 0.8088 | Time(s) 3.5678 | Accuracy: 74.884969\n",
            "Epoch 00011 | Loss 0.5148 | Time(s) 3.5623 | Accuracy: 74.932899\n",
            "Epoch 00012 | Loss 0.5854 | Time(s) 3.5624 | Accuracy: 74.856212\n",
            "Epoch 00013 | Loss 0.6909 | Time(s) 3.5665 | Accuracy: 74.894555\n",
            "Epoch 00014 | Loss 0.4700 | Time(s) 3.5741 | Accuracy: 75.680598\n",
            "Epoch 00015 | Loss 0.5052 | Time(s) 3.5708 | Accuracy: 76.131135\n",
            "Epoch 00016 | Loss 0.4282 | Time(s) 3.5695 | Accuracy: 76.457055\n",
            "Epoch 00017 | Loss 0.4287 | Time(s) 3.5706 | Accuracy: 76.802147\n",
            "Epoch 00018 | Loss 0.5943 | Time(s) 3.5690 | Accuracy: 76.878834\n",
            "Epoch 00019 | Loss 0.4318 | Time(s) 3.5704 | Accuracy: 76.955521\n",
            "Epoch 00020 | Loss 0.8172 | Time(s) 3.5746 | Accuracy: 76.878834\n",
            "Epoch 00021 | Loss 0.6368 | Time(s) 3.5728 | Accuracy: 76.993865\n",
            "Epoch 00022 | Loss 0.3847 | Time(s) 3.5710 | Accuracy: 76.955521\n",
            "Epoch 00023 | Loss 0.4200 | Time(s) 3.5717 | Accuracy: 76.782975\n",
            "Epoch 00024 | Loss 0.4845 | Time(s) 3.5690 | Accuracy: 76.878834\n",
            "Epoch 00025 | Loss 0.5541 | Time(s) 3.5644 | Accuracy: 75.901074\n",
            "Epoch 00026 | Loss 0.4439 | Time(s) 3.5620 | Accuracy: 76.140721\n",
            "Epoch 00027 | Loss 0.5030 | Time(s) 3.5634 | Accuracy: 76.715874\n",
            "Epoch 00028 | Loss 0.4490 | Time(s) 3.5645 | Accuracy: 76.389954\n",
            "Epoch 00029 | Loss 0.4809 | Time(s) 3.5637 | Accuracy: 77.013037\n",
            "Epoch 00030 | Loss 0.4553 | Time(s) 3.5649 | Accuracy: 76.418712\n",
            "Epoch 00031 | Loss 0.3706 | Time(s) 3.5671 | Accuracy: 76.658359\n",
            "Epoch 00032 | Loss 0.3610 | Time(s) 3.5666 | Accuracy: 76.476227\n",
            "Epoch 00033 | Loss 0.3571 | Time(s) 3.5681 | Accuracy: 77.013037\n",
            "Epoch 00034 | Loss 0.5127 | Time(s) 3.5677 | Accuracy: 77.022623\n",
            "Epoch 00035 | Loss 0.3583 | Time(s) 3.5685 | Accuracy: 77.156825\n",
            "Epoch 00036 | Loss 0.4673 | Time(s) 3.5704 | Accuracy: 77.425230\n",
            "Epoch 00037 | Loss 0.2722 | Time(s) 3.5713 | Accuracy: 77.223926\n",
            "Epoch 00038 | Loss 0.3318 | Time(s) 3.5720 | Accuracy: 76.993865\n",
            "Epoch 00039 | Loss 0.4527 | Time(s) 3.5733 | Accuracy: 77.108896\n",
            "Epoch 00040 | Loss 0.3597 | Time(s) 3.5759 | Accuracy: 77.367715\n",
            "Epoch 00041 | Loss 0.7278 | Time(s) 3.5776 | Accuracy: 76.342025\n",
            "Epoch 00042 | Loss 0.4044 | Time(s) 3.5793 | Accuracy: 76.418712\n",
            "Epoch 00043 | Loss 0.3544 | Time(s) 3.5794 | Accuracy: 76.945936\n",
            "Epoch 00044 | Loss 0.5316 | Time(s) 3.5788 | Accuracy: 77.425230\n",
            "Epoch 00045 | Loss 0.3533 | Time(s) 3.5786 | Accuracy: 77.022623\n",
            "Epoch 00046 | Loss 0.2573 | Time(s) 3.5772 | Accuracy: 77.540261\n",
            "Epoch 00047 | Loss 0.4867 | Time(s) 3.5799 | Accuracy: 77.118482\n",
            "Epoch 00048 | Loss 0.4276 | Time(s) 3.5809 | Accuracy: 76.821319\n",
            "Epoch 00049 | Loss 0.3607 | Time(s) 3.5841 | Accuracy: 76.850077\n",
            "Epoch 00050 | Loss 0.4738 | Time(s) 3.5864 | Accuracy: 75.690184\n",
            "Epoch 00051 | Loss 0.5089 | Time(s) 3.5867 | Accuracy: 76.169479\n",
            "Epoch 00052 | Loss 0.4722 | Time(s) 3.5871 | Accuracy: 76.092791\n",
            "Epoch 00053 | Loss 0.2819 | Time(s) 3.5865 | Accuracy: 76.562500\n",
            "Epoch 00054 | Loss 0.3860 | Time(s) 3.5881 | Accuracy: 77.128067\n",
            "Epoch 00055 | Loss 0.3431 | Time(s) 3.5889 | Accuracy: 76.715874\n",
            "Epoch 00056 | Loss 0.3901 | Time(s) 3.5908 | Accuracy: 75.479294\n",
            "Epoch 00057 | Loss 0.3170 | Time(s) 3.5920 | Accuracy: 76.121549\n",
            "Epoch 00058 | Loss 0.4102 | Time(s) 3.5918 | Accuracy: 76.735046\n",
            "Epoch 00059 | Loss 0.3850 | Time(s) 3.5905 | Accuracy: 76.322853\n",
            "Epoch 00060 | Loss 0.3270 | Time(s) 3.5900 | Accuracy: 76.725460\n",
            "Epoch 00061 | Loss 0.4897 | Time(s) 3.5892 | Accuracy: 76.236580\n",
            "Epoch 00062 | Loss 0.2547 | Time(s) 3.5899 | Accuracy: 76.198236\n",
            "Epoch 00063 | Loss 0.3748 | Time(s) 3.5896 | Accuracy: 76.869248\n",
            "Epoch 00064 | Loss 0.2662 | Time(s) 3.5910 | Accuracy: 76.399540\n",
            "Epoch 00065 | Loss 0.3550 | Time(s) 3.5910 | Accuracy: 76.744632\n",
            "Epoch 00066 | Loss 0.5105 | Time(s) 3.5909 | Accuracy: 77.358129\n",
            "Epoch 00067 | Loss 0.3853 | Time(s) 3.5913 | Accuracy: 76.217408\n",
            "Epoch 00068 | Loss 0.2826 | Time(s) 3.5913 | Accuracy: 76.485813\n",
            "Epoch 00069 | Loss 0.3471 | Time(s) 3.5911 | Accuracy: 76.457055\n",
            "Epoch 00070 | Loss 0.4074 | Time(s) 3.5915 | Accuracy: 76.514571\n",
            "Epoch 00071 | Loss 0.3887 | Time(s) 3.5911 | Accuracy: 75.872316\n",
            "Epoch 00072 | Loss 0.3336 | Time(s) 3.5907 | Accuracy: 75.824387\n",
            "Epoch 00073 | Loss 0.1898 | Time(s) 3.5915 | Accuracy: 76.715874\n",
            "Epoch 00074 | Loss 0.1877 | Time(s) 3.5900 | Accuracy: 76.332439\n",
            "Epoch 00075 | Loss 0.4179 | Time(s) 3.5886 | Accuracy: 76.811733\n",
            "Epoch 00076 | Loss 0.4136 | Time(s) 3.5890 | Accuracy: 77.080138\n",
            "Epoch 00077 | Loss 0.2343 | Time(s) 3.5881 | Accuracy: 76.917178\n",
            "Epoch 00078 | Loss 0.2331 | Time(s) 3.5876 | Accuracy: 77.022623\n",
            "Epoch 00079 | Loss 0.3781 | Time(s) 3.5872 | Accuracy: 77.271856\n",
            "Epoch 00080 | Loss 0.3670 | Time(s) 3.5865 | Accuracy: 77.051380\n",
            "Epoch 00081 | Loss 0.5588 | Time(s) 3.5876 | Accuracy: 76.821319\n",
            "Epoch 00082 | Loss 0.3939 | Time(s) 3.5872 | Accuracy: 77.137653\n",
            "Epoch 00083 | Loss 0.3784 | Time(s) 3.5869 | Accuracy: 77.051380\n",
            "Epoch 00084 | Loss 0.3726 | Time(s) 3.5873 | Accuracy: 76.677531\n",
            "Epoch 00085 | Loss 0.4266 | Time(s) 3.5868 | Accuracy: 76.322853\n",
            "Epoch 00086 | Loss 0.2945 | Time(s) 3.5869 | Accuracy: 76.476227\n",
            "Epoch 00087 | Loss 0.4727 | Time(s) 3.5874 | Accuracy: 76.159893\n",
            "Epoch 00088 | Loss 0.3979 | Time(s) 3.5867 | Accuracy: 76.188650\n",
            "Epoch 00089 | Loss 0.3934 | Time(s) 3.5868 | Accuracy: 76.610429\n",
            "Epoch 00090 | Loss 0.3397 | Time(s) 3.5876 | Accuracy: 75.862730\n",
            "Epoch 00091 | Loss 0.3909 | Time(s) 3.5880 | Accuracy: 76.361196\n",
            "Epoch 00092 | Loss 0.2879 | Time(s) 3.5872 | Accuracy: 76.552914\n",
            "Epoch 00093 | Loss 0.3073 | Time(s) 3.5874 | Accuracy: 76.313267\n",
            "Epoch 00094 | Loss 0.3674 | Time(s) 3.5869 | Accuracy: 76.111963\n",
            "Epoch 00095 | Loss 0.3057 | Time(s) 3.5865 | Accuracy: 75.709356\n",
            "Epoch 00096 | Loss 0.2974 | Time(s) 3.5866 | Accuracy: 76.217408\n",
            "Epoch 00097 | Loss 0.2813 | Time(s) 3.5869 | Accuracy: 76.437883\n",
            "Epoch 00098 | Loss 0.4164 | Time(s) 3.5870 | Accuracy: 76.332439\n",
            "Epoch 00099 | Loss 0.4561 | Time(s) 3.5862 | Accuracy: 76.150307\n",
            "Epoch 00100 | Loss 0.3475 | Time(s) 3.5865 | Accuracy: 76.840491\n",
            "Epoch 00101 | Loss 0.3710 | Time(s) 3.5865 | Accuracy: 76.735046\n",
            "Epoch 00102 | Loss 0.3086 | Time(s) 3.5862 | Accuracy: 76.466641\n",
            "Epoch 00103 | Loss 0.2856 | Time(s) 3.5862 | Accuracy: 76.706288\n",
            "Epoch 00104 | Loss 0.3584 | Time(s) 3.5867 | Accuracy: 76.131135\n",
            "Epoch 00105 | Loss 0.1967 | Time(s) 3.5869 | Accuracy: 76.792561\n",
            "Epoch 00106 | Loss 0.6264 | Time(s) 3.5875 | Accuracy: 76.850077\n",
            "Epoch 00107 | Loss 0.3474 | Time(s) 3.5875 | Accuracy: 76.466641\n",
            "Epoch 00108 | Loss 0.5844 | Time(s) 3.5878 | Accuracy: 76.457055\n",
            "Epoch 00109 | Loss 0.2374 | Time(s) 3.5870 | Accuracy: 75.795629\n",
            "Epoch 00110 | Loss 0.2132 | Time(s) 3.5867 | Accuracy: 75.325920\n",
            "Epoch 00111 | Loss 0.3188 | Time(s) 3.5863 | Accuracy: 75.776457\n",
            "Epoch 00112 | Loss 0.3213 | Time(s) 3.5868 | Accuracy: 76.303681\n",
            "Epoch 00113 | Loss 0.3107 | Time(s) 3.5870 | Accuracy: 76.466641\n",
            "Epoch 00114 | Loss 0.3033 | Time(s) 3.5888 | Accuracy: 76.485813\n",
            "Epoch 00115 | Loss 0.3936 | Time(s) 3.5888 | Accuracy: 76.782975\n",
            "Epoch 00116 | Loss 0.2782 | Time(s) 3.5891 | Accuracy: 76.744632\n",
            "Epoch 00117 | Loss 0.4307 | Time(s) 3.5889 | Accuracy: 76.687117\n",
            "Epoch 00118 | Loss 0.3030 | Time(s) 3.5883 | Accuracy: 76.878834\n",
            "Epoch 00119 | Loss 0.3390 | Time(s) 3.5879 | Accuracy: 76.945936\n",
            "Epoch 00120 | Loss 0.3784 | Time(s) 3.5879 | Accuracy: 76.677531\n",
            "Epoch 00121 | Loss 0.2989 | Time(s) 3.5875 | Accuracy: 76.562500\n",
            "Epoch 00122 | Loss 0.3113 | Time(s) 3.5875 | Accuracy: 76.437883\n",
            "Epoch 00123 | Loss 0.3059 | Time(s) 3.5880 | Accuracy: 76.111963\n",
            "Epoch 00124 | Loss 0.3428 | Time(s) 3.5876 | Accuracy: 76.591258\n",
            "Epoch 00125 | Loss 0.3178 | Time(s) 3.5869 | Accuracy: 76.936350\n",
            "Epoch 00126 | Loss 0.2097 | Time(s) 3.5860 | Accuracy: 76.677531\n",
            "Epoch 00127 | Loss 0.3149 | Time(s) 3.5854 | Accuracy: 76.993865\n",
            "Epoch 00128 | Loss 0.1772 | Time(s) 3.5845 | Accuracy: 76.389954\n",
            "Epoch 00129 | Loss 0.1853 | Time(s) 3.5854 | Accuracy: 76.658359\n",
            "Epoch 00130 | Loss 0.4374 | Time(s) 3.5853 | Accuracy: 77.271856\n",
            "Epoch 00131 | Loss 0.3027 | Time(s) 3.5861 | Accuracy: 77.070552\n",
            "Epoch 00132 | Loss 0.3611 | Time(s) 3.5869 | Accuracy: 76.725460\n",
            "Epoch 00133 | Loss 0.3055 | Time(s) 3.5870 | Accuracy: 76.581672\n",
            "Epoch 00134 | Loss 0.3339 | Time(s) 3.5867 | Accuracy: 75.766871\n",
            "Epoch 00135 | Loss 0.3603 | Time(s) 3.5863 | Accuracy: 76.217408\n",
            "Epoch 00136 | Loss 0.3030 | Time(s) 3.5859 | Accuracy: 76.802147\n",
            "Epoch 00137 | Loss 0.3706 | Time(s) 3.5857 | Accuracy: 76.380368\n",
            "Epoch 00138 | Loss 0.2800 | Time(s) 3.5855 | Accuracy: 76.121549\n",
            "Epoch 00139 | Loss 0.3889 | Time(s) 3.5855 | Accuracy: 76.284509\n",
            "Epoch 00140 | Loss 0.1703 | Time(s) 3.5855 | Accuracy: 76.073620\n",
            "Epoch 00141 | Loss 0.1572 | Time(s) 3.5849 | Accuracy: 76.006518\n",
            "Epoch 00142 | Loss 0.2836 | Time(s) 3.5848 | Accuracy: 75.881902\n",
            "Epoch 00143 | Loss 0.2979 | Time(s) 3.5846 | Accuracy: 76.226994\n",
            "Epoch 00144 | Loss 0.3211 | Time(s) 3.5844 | Accuracy: 76.735046\n",
            "Epoch 00145 | Loss 0.2714 | Time(s) 3.5843 | Accuracy: 76.600844\n",
            "Epoch 00146 | Loss 0.2928 | Time(s) 3.5838 | Accuracy: 76.428298\n",
            "Epoch 00147 | Loss 0.2856 | Time(s) 3.5835 | Accuracy: 76.696702\n",
            "Epoch 00148 | Loss 0.4378 | Time(s) 3.5835 | Accuracy: 76.965107\n",
            "Epoch 00149 | Loss 0.3031 | Time(s) 3.5829 | Accuracy: 76.629601\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.283046 seconds\n",
            "Epoch 00000 | Loss 1.8597 | Time(s) 3.5821 | Accuracy: 11.186733\n",
            "Epoch 00001 | Loss 1.7021 | Time(s) 3.5851 | Accuracy: 34.969325\n",
            "Epoch 00002 | Loss 1.5122 | Time(s) 3.5907 | Accuracy: 43.625383\n",
            "Epoch 00003 | Loss 1.3076 | Time(s) 3.6065 | Accuracy: 49.616564\n",
            "Epoch 00004 | Loss 1.1774 | Time(s) 3.6027 | Accuracy: 55.732362\n",
            "Epoch 00005 | Loss 1.3064 | Time(s) 3.6001 | Accuracy: 57.946702\n",
            "Epoch 00006 | Loss 0.8890 | Time(s) 3.5904 | Accuracy: 61.129218\n",
            "Epoch 00007 | Loss 0.6758 | Time(s) 3.5885 | Accuracy: 65.116948\n",
            "Epoch 00008 | Loss 0.6638 | Time(s) 3.5824 | Accuracy: 67.312117\n",
            "Epoch 00009 | Loss 0.9384 | Time(s) 3.5789 | Accuracy: 69.056748\n",
            "Epoch 00010 | Loss 0.5747 | Time(s) 3.5791 | Accuracy: 67.609279\n",
            "Epoch 00011 | Loss 0.6588 | Time(s) 3.5795 | Accuracy: 68.625383\n",
            "Epoch 00012 | Loss 0.5910 | Time(s) 3.5807 | Accuracy: 70.523390\n",
            "Epoch 00013 | Loss 0.6387 | Time(s) 3.5771 | Accuracy: 70.993098\n",
            "Epoch 00014 | Loss 0.7627 | Time(s) 3.5798 | Accuracy: 70.628834\n",
            "Epoch 00015 | Loss 0.9026 | Time(s) 3.5749 | Accuracy: 71.041028\n",
            "Epoch 00016 | Loss 0.6345 | Time(s) 3.5766 | Accuracy: 71.664110\n",
            "Epoch 00017 | Loss 0.4613 | Time(s) 3.5756 | Accuracy: 70.983512\n",
            "Epoch 00018 | Loss 0.4455 | Time(s) 3.5754 | Accuracy: 70.695936\n",
            "Epoch 00019 | Loss 0.7463 | Time(s) 3.5761 | Accuracy: 70.053681\n",
            "Epoch 00020 | Loss 0.6531 | Time(s) 3.5799 | Accuracy: 70.906825\n",
            "Epoch 00021 | Loss 0.7636 | Time(s) 3.5826 | Accuracy: 70.973926\n",
            "Epoch 00022 | Loss 0.7181 | Time(s) 3.5830 | Accuracy: 70.954755\n",
            "Epoch 00023 | Loss 1.0227 | Time(s) 3.5812 | Accuracy: 71.692868\n",
            "Epoch 00024 | Loss 0.4382 | Time(s) 3.5800 | Accuracy: 71.069785\n",
            "Epoch 00025 | Loss 0.4359 | Time(s) 3.5786 | Accuracy: 71.683282\n",
            "Epoch 00026 | Loss 0.5475 | Time(s) 3.5788 | Accuracy: 71.740798\n",
            "Epoch 00027 | Loss 0.4983 | Time(s) 3.5811 | Accuracy: 71.424463\n",
            "Epoch 00028 | Loss 0.4989 | Time(s) 3.5835 | Accuracy: 70.925997\n",
            "Epoch 00029 | Loss 0.6413 | Time(s) 3.5826 | Accuracy: 71.644939\n",
            "Epoch 00030 | Loss 0.6340 | Time(s) 3.5824 | Accuracy: 71.644939\n",
            "Epoch 00031 | Loss 0.3528 | Time(s) 3.5821 | Accuracy: 71.951687\n",
            "Epoch 00032 | Loss 0.4381 | Time(s) 3.5815 | Accuracy: 71.577837\n",
            "Epoch 00033 | Loss 0.3272 | Time(s) 3.5832 | Accuracy: 71.932515\n",
            "Epoch 00034 | Loss 0.3298 | Time(s) 3.5838 | Accuracy: 72.258436\n",
            "Epoch 00035 | Loss 0.4100 | Time(s) 3.5848 | Accuracy: 72.047546\n",
            "Epoch 00036 | Loss 0.4221 | Time(s) 3.5864 | Accuracy: 71.903758\n",
            "Epoch 00037 | Loss 0.6535 | Time(s) 3.5870 | Accuracy: 71.577837\n",
            "Epoch 00038 | Loss 0.4805 | Time(s) 3.5870 | Accuracy: 71.865414\n",
            "Epoch 00039 | Loss 0.6788 | Time(s) 3.5857 | Accuracy: 71.462807\n",
            "Epoch 00040 | Loss 0.7745 | Time(s) 3.5851 | Accuracy: 72.076304\n",
            "Epoch 00041 | Loss 0.4605 | Time(s) 3.5850 | Accuracy: 71.443635\n",
            "Epoch 00042 | Loss 0.7642 | Time(s) 3.5870 | Accuracy: 71.060199\n",
            "Epoch 00043 | Loss 0.4133 | Time(s) 3.5867 | Accuracy: 71.041028\n",
            "Epoch 00044 | Loss 0.3351 | Time(s) 3.5864 | Accuracy: 71.290261\n",
            "Epoch 00045 | Loss 0.5165 | Time(s) 3.5878 | Accuracy: 71.587423\n",
            "Epoch 00046 | Loss 0.4944 | Time(s) 3.5884 | Accuracy: 72.018788\n",
            "Epoch 00047 | Loss 0.4754 | Time(s) 3.5885 | Accuracy: 71.903758\n",
            "Epoch 00048 | Loss 0.4511 | Time(s) 3.5890 | Accuracy: 71.827071\n",
            "Epoch 00049 | Loss 0.4478 | Time(s) 3.5872 | Accuracy: 71.798313\n",
            "Epoch 00050 | Loss 0.4078 | Time(s) 3.5849 | Accuracy: 71.357362\n",
            "Epoch 00051 | Loss 0.9148 | Time(s) 3.5825 | Accuracy: 71.481979\n",
            "Epoch 00052 | Loss 0.7435 | Time(s) 3.5806 | Accuracy: 71.319018\n",
            "Epoch 00053 | Loss 0.7310 | Time(s) 3.5803 | Accuracy: 70.810966\n",
            "Epoch 00054 | Loss 0.5259 | Time(s) 3.5783 | Accuracy: 71.290261\n",
            "Epoch 00055 | Loss 0.4156 | Time(s) 3.5774 | Accuracy: 71.175230\n",
            "Epoch 00056 | Loss 0.4843 | Time(s) 3.5762 | Accuracy: 70.178298\n",
            "Epoch 00057 | Loss 0.4358 | Time(s) 3.5743 | Accuracy: 70.283742\n",
            "Epoch 00058 | Loss 0.4521 | Time(s) 3.5730 | Accuracy: 69.842791\n",
            "Epoch 00059 | Loss 0.6629 | Time(s) 3.5712 | Accuracy: 70.801380\n",
            "Epoch 00060 | Loss 0.4160 | Time(s) 3.5705 | Accuracy: 70.686350\n",
            "Epoch 00061 | Loss 0.4283 | Time(s) 3.5688 | Accuracy: 69.200537\n",
            "Epoch 00062 | Loss 0.5502 | Time(s) 3.5687 | Accuracy: 70.532975\n",
            "Epoch 00063 | Loss 0.4249 | Time(s) 3.5675 | Accuracy: 71.625767\n",
            "Epoch 00064 | Loss 0.4656 | Time(s) 3.5665 | Accuracy: 70.830138\n",
            "Epoch 00065 | Loss 0.8531 | Time(s) 3.5647 | Accuracy: 71.108129\n",
            "Epoch 00066 | Loss 0.5338 | Time(s) 3.5635 | Accuracy: 70.024923\n",
            "Epoch 00067 | Loss 0.8714 | Time(s) 3.5629 | Accuracy: 71.117715\n",
            "Epoch 00068 | Loss 0.4467 | Time(s) 3.5624 | Accuracy: 71.319018\n",
            "Epoch 00069 | Loss 0.3817 | Time(s) 3.5606 | Accuracy: 71.395706\n",
            "Epoch 00070 | Loss 0.6880 | Time(s) 3.5599 | Accuracy: 71.529908\n",
            "Epoch 00071 | Loss 0.6388 | Time(s) 3.5599 | Accuracy: 71.319018\n",
            "Epoch 00072 | Loss 0.6097 | Time(s) 3.5595 | Accuracy: 71.088957\n",
            "Epoch 00073 | Loss 0.4320 | Time(s) 3.5583 | Accuracy: 71.021856\n",
            "Epoch 00074 | Loss 0.5252 | Time(s) 3.5568 | Accuracy: 71.175230\n",
            "Epoch 00075 | Loss 0.3491 | Time(s) 3.5567 | Accuracy: 70.935583\n",
            "Epoch 00076 | Loss 0.6277 | Time(s) 3.5574 | Accuracy: 70.293328\n",
            "Epoch 00077 | Loss 0.4644 | Time(s) 3.5586 | Accuracy: 71.108129\n",
            "Epoch 00078 | Loss 0.3811 | Time(s) 3.5578 | Accuracy: 71.098543\n",
            "Epoch 00079 | Loss 0.4357 | Time(s) 3.5580 | Accuracy: 71.251917\n",
            "Epoch 00080 | Loss 0.6250 | Time(s) 3.5569 | Accuracy: 70.600077\n",
            "Epoch 00081 | Loss 0.5008 | Time(s) 3.5560 | Accuracy: 71.386120\n",
            "Epoch 00082 | Loss 0.3848 | Time(s) 3.5549 | Accuracy: 71.472393\n",
            "Epoch 00083 | Loss 0.6456 | Time(s) 3.5537 | Accuracy: 71.903758\n",
            "Epoch 00084 | Loss 0.4775 | Time(s) 3.5531 | Accuracy: 71.635353\n",
            "Epoch 00085 | Loss 0.3959 | Time(s) 3.5527 | Accuracy: 71.539494\n",
            "Epoch 00086 | Loss 0.4804 | Time(s) 3.5521 | Accuracy: 71.299847\n",
            "Epoch 00087 | Loss 0.5359 | Time(s) 3.5518 | Accuracy: 71.357362\n",
            "Epoch 00088 | Loss 0.4397 | Time(s) 3.5525 | Accuracy: 71.357362\n",
            "Epoch 00089 | Loss 0.5008 | Time(s) 3.5519 | Accuracy: 71.309433\n",
            "Epoch 00090 | Loss 0.5029 | Time(s) 3.5516 | Accuracy: 71.664110\n",
            "Epoch 00091 | Loss 0.4167 | Time(s) 3.5512 | Accuracy: 71.290261\n",
            "Epoch 00092 | Loss 0.3930 | Time(s) 3.5505 | Accuracy: 71.271089\n",
            "Epoch 00093 | Loss 0.4019 | Time(s) 3.5499 | Accuracy: 71.251917\n",
            "Epoch 00094 | Loss 0.4199 | Time(s) 3.5493 | Accuracy: 70.925997\n",
            "Epoch 00095 | Loss 0.4474 | Time(s) 3.5486 | Accuracy: 71.280675\n",
            "Epoch 00096 | Loss 0.3982 | Time(s) 3.5488 | Accuracy: 71.673696\n",
            "Epoch 00097 | Loss 0.4555 | Time(s) 3.5485 | Accuracy: 71.731212\n",
            "Epoch 00098 | Loss 0.3859 | Time(s) 3.5474 | Accuracy: 71.453221\n",
            "Epoch 00099 | Loss 0.2554 | Time(s) 3.5477 | Accuracy: 71.481979\n",
            "Epoch 00100 | Loss 0.2775 | Time(s) 3.5477 | Accuracy: 71.175230\n",
            "Epoch 00101 | Loss 0.5400 | Time(s) 3.5470 | Accuracy: 71.060199\n",
            "Epoch 00102 | Loss 0.2751 | Time(s) 3.5466 | Accuracy: 71.079371\n",
            "Epoch 00103 | Loss 0.3629 | Time(s) 3.5467 | Accuracy: 71.127301\n",
            "Epoch 00104 | Loss 0.4919 | Time(s) 3.5474 | Accuracy: 71.395706\n",
            "Epoch 00105 | Loss 0.4193 | Time(s) 3.5481 | Accuracy: 71.146472\n",
            "Epoch 00106 | Loss 0.2673 | Time(s) 3.5482 | Accuracy: 71.108129\n",
            "Epoch 00107 | Loss 0.3826 | Time(s) 3.5481 | Accuracy: 70.983512\n",
            "Epoch 00108 | Loss 0.5290 | Time(s) 3.5471 | Accuracy: 71.597009\n",
            "Epoch 00109 | Loss 0.4133 | Time(s) 3.5463 | Accuracy: 71.242331\n",
            "Epoch 00110 | Loss 0.4052 | Time(s) 3.5456 | Accuracy: 70.523390\n",
            "Epoch 00111 | Loss 0.4380 | Time(s) 3.5449 | Accuracy: 70.858896\n",
            "Epoch 00112 | Loss 0.4613 | Time(s) 3.5444 | Accuracy: 70.964340\n",
            "Epoch 00113 | Loss 0.3634 | Time(s) 3.5447 | Accuracy: 70.868482\n",
            "Epoch 00114 | Loss 0.2967 | Time(s) 3.5453 | Accuracy: 71.012270\n",
            "Epoch 00115 | Loss 0.4377 | Time(s) 3.5443 | Accuracy: 71.251917\n",
            "Epoch 00116 | Loss 0.4658 | Time(s) 3.5438 | Accuracy: 71.395706\n",
            "Epoch 00117 | Loss 0.4436 | Time(s) 3.5429 | Accuracy: 71.299847\n",
            "Epoch 00118 | Loss 0.2655 | Time(s) 3.5429 | Accuracy: 71.357362\n",
            "Epoch 00119 | Loss 0.5257 | Time(s) 3.5423 | Accuracy: 71.712040\n",
            "Epoch 00120 | Loss 0.3448 | Time(s) 3.5431 | Accuracy: 71.338190\n",
            "Epoch 00121 | Loss 0.3850 | Time(s) 3.5424 | Accuracy: 71.347776\n",
            "Epoch 00122 | Loss 0.3021 | Time(s) 3.5424 | Accuracy: 71.069785\n",
            "Epoch 00123 | Loss 0.3501 | Time(s) 3.5435 | Accuracy: 71.194402\n",
            "Epoch 00124 | Loss 0.4045 | Time(s) 3.5429 | Accuracy: 71.165644\n",
            "Epoch 00125 | Loss 0.6079 | Time(s) 3.5424 | Accuracy: 71.088957\n",
            "Epoch 00126 | Loss 0.2907 | Time(s) 3.5422 | Accuracy: 70.839724\n",
            "Epoch 00127 | Loss 0.5322 | Time(s) 3.5429 | Accuracy: 70.935583\n",
            "Epoch 00128 | Loss 0.2735 | Time(s) 3.5425 | Accuracy: 70.791794\n",
            "Epoch 00129 | Loss 0.4099 | Time(s) 3.5421 | Accuracy: 71.481979\n",
            "Epoch 00130 | Loss 0.4269 | Time(s) 3.5422 | Accuracy: 70.207055\n",
            "Epoch 00131 | Loss 0.4000 | Time(s) 3.5431 | Accuracy: 70.705521\n",
            "Epoch 00132 | Loss 0.3708 | Time(s) 3.5431 | Accuracy: 70.705521\n",
            "Epoch 00133 | Loss 0.4025 | Time(s) 3.5431 | Accuracy: 70.235813\n",
            "Epoch 00134 | Loss 0.4205 | Time(s) 3.5425 | Accuracy: 70.024923\n",
            "Epoch 00135 | Loss 0.3948 | Time(s) 3.5424 | Accuracy: 70.619248\n",
            "Epoch 00136 | Loss 0.4626 | Time(s) 3.5418 | Accuracy: 70.868482\n",
            "Epoch 00137 | Loss 0.6338 | Time(s) 3.5421 | Accuracy: 70.437117\n",
            "Epoch 00138 | Loss 0.7784 | Time(s) 3.5418 | Accuracy: 70.187883\n",
            "Epoch 00139 | Loss 0.4048 | Time(s) 3.5417 | Accuracy: 70.676764\n",
            "Epoch 00140 | Loss 0.6744 | Time(s) 3.5417 | Accuracy: 71.194402\n",
            "Epoch 00141 | Loss 0.4441 | Time(s) 3.5410 | Accuracy: 71.529908\n",
            "Epoch 00142 | Loss 0.4589 | Time(s) 3.5404 | Accuracy: 70.609663\n",
            "Epoch 00143 | Loss 0.4397 | Time(s) 3.5403 | Accuracy: 70.839724\n",
            "Epoch 00144 | Loss 0.4037 | Time(s) 3.5399 | Accuracy: 70.322086\n",
            "Epoch 00145 | Loss 0.5387 | Time(s) 3.5390 | Accuracy: 70.494632\n",
            "Epoch 00146 | Loss 0.4203 | Time(s) 3.5384 | Accuracy: 69.277224\n",
            "Epoch 00147 | Loss 0.3892 | Time(s) 3.5388 | Accuracy: 70.063267\n",
            "Epoch 00148 | Loss 0.4401 | Time(s) 3.5384 | Accuracy: 70.513804\n",
            "Epoch 00149 | Loss 0.7018 | Time(s) 3.5383 | Accuracy: 70.715107\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.062519 seconds\n",
            "Epoch 00000 | Loss 1.8653 | Time(s) 3.4935 | Accuracy: 29.351994\n",
            "Epoch 00001 | Loss 1.6700 | Time(s) 3.5462 | Accuracy: 30.138037\n",
            "Epoch 00002 | Loss 1.4191 | Time(s) 3.5275 | Accuracy: 36.723543\n",
            "Epoch 00003 | Loss 1.1664 | Time(s) 3.5358 | Accuracy: 48.888037\n",
            "Epoch 00004 | Loss 1.2243 | Time(s) 3.5440 | Accuracy: 53.345475\n",
            "Epoch 00005 | Loss 0.9451 | Time(s) 3.5458 | Accuracy: 58.368482\n",
            "Epoch 00006 | Loss 0.8056 | Time(s) 3.5480 | Accuracy: 68.328221\n",
            "Epoch 00007 | Loss 0.9296 | Time(s) 3.5449 | Accuracy: 68.903374\n",
            "Epoch 00008 | Loss 0.7670 | Time(s) 3.5474 | Accuracy: 70.024923\n",
            "Epoch 00009 | Loss 0.8558 | Time(s) 3.5436 | Accuracy: 69.948236\n",
            "Epoch 00010 | Loss 0.8266 | Time(s) 3.5383 | Accuracy: 70.475460\n",
            "Epoch 00011 | Loss 0.5298 | Time(s) 3.5364 | Accuracy: 70.111196\n",
            "Epoch 00012 | Loss 0.5199 | Time(s) 3.5349 | Accuracy: 71.050613\n",
            "Epoch 00013 | Loss 0.7310 | Time(s) 3.5405 | Accuracy: 70.916411\n",
            "Epoch 00014 | Loss 0.4446 | Time(s) 3.5389 | Accuracy: 70.667178\n",
            "Epoch 00015 | Loss 0.7637 | Time(s) 3.5361 | Accuracy: 70.293328\n",
            "Epoch 00016 | Loss 0.5733 | Time(s) 3.5347 | Accuracy: 70.187883\n",
            "Epoch 00017 | Loss 0.6795 | Time(s) 3.5325 | Accuracy: 70.724693\n",
            "Epoch 00018 | Loss 0.4565 | Time(s) 3.5295 | Accuracy: 70.494632\n",
            "Epoch 00019 | Loss 0.5111 | Time(s) 3.5261 | Accuracy: 70.868482\n",
            "Epoch 00020 | Loss 0.5222 | Time(s) 3.5260 | Accuracy: 71.347776\n",
            "Epoch 00021 | Loss 0.6240 | Time(s) 3.5261 | Accuracy: 71.520322\n",
            "Epoch 00022 | Loss 0.5613 | Time(s) 3.5283 | Accuracy: 71.712040\n",
            "Epoch 00023 | Loss 0.5187 | Time(s) 3.5282 | Accuracy: 71.501150\n",
            "Epoch 00024 | Loss 0.4444 | Time(s) 3.5239 | Accuracy: 71.366948\n",
            "Epoch 00025 | Loss 0.4437 | Time(s) 3.5233 | Accuracy: 71.472393\n",
            "Epoch 00026 | Loss 0.6026 | Time(s) 3.5242 | Accuracy: 71.980445\n",
            "Epoch 00027 | Loss 0.3721 | Time(s) 3.5222 | Accuracy: 71.846242\n",
            "Epoch 00028 | Loss 0.4088 | Time(s) 3.5213 | Accuracy: 71.654525\n",
            "Epoch 00029 | Loss 0.5556 | Time(s) 3.5268 | Accuracy: 71.424463\n",
            "Epoch 00030 | Loss 0.5189 | Time(s) 3.5254 | Accuracy: 71.510736\n",
            "Epoch 00031 | Loss 0.6623 | Time(s) 3.5233 | Accuracy: 70.810966\n",
            "Epoch 00032 | Loss 0.5367 | Time(s) 3.5245 | Accuracy: 71.434049\n",
            "Epoch 00033 | Loss 0.4190 | Time(s) 3.5236 | Accuracy: 70.830138\n",
            "Epoch 00034 | Loss 0.4681 | Time(s) 3.5230 | Accuracy: 71.568252\n",
            "Epoch 00035 | Loss 0.6862 | Time(s) 3.5251 | Accuracy: 71.712040\n",
            "Epoch 00036 | Loss 0.3446 | Time(s) 3.5250 | Accuracy: 71.376534\n",
            "Epoch 00037 | Loss 0.3770 | Time(s) 3.5255 | Accuracy: 71.261503\n",
            "Epoch 00038 | Loss 0.5078 | Time(s) 3.5266 | Accuracy: 70.858896\n",
            "Epoch 00039 | Loss 0.5193 | Time(s) 3.5255 | Accuracy: 71.213574\n",
            "Epoch 00040 | Loss 0.5390 | Time(s) 3.5237 | Accuracy: 70.945169\n",
            "Epoch 00041 | Loss 0.4668 | Time(s) 3.5264 | Accuracy: 70.849310\n",
            "Epoch 00042 | Loss 0.4566 | Time(s) 3.5252 | Accuracy: 70.935583\n",
            "Epoch 00043 | Loss 0.4324 | Time(s) 3.5249 | Accuracy: 71.798313\n",
            "Epoch 00044 | Loss 0.3765 | Time(s) 3.5256 | Accuracy: 71.769555\n",
            "Epoch 00045 | Loss 0.4896 | Time(s) 3.5272 | Accuracy: 71.683282\n",
            "Epoch 00046 | Loss 0.3332 | Time(s) 3.5272 | Accuracy: 71.136887\n",
            "Epoch 00047 | Loss 0.5607 | Time(s) 3.5275 | Accuracy: 71.309433\n",
            "Epoch 00048 | Loss 0.6652 | Time(s) 3.5266 | Accuracy: 70.590491\n",
            "Epoch 00049 | Loss 0.4683 | Time(s) 3.5259 | Accuracy: 70.264571\n",
            "Epoch 00050 | Loss 0.6320 | Time(s) 3.5255 | Accuracy: 70.945169\n",
            "Epoch 00051 | Loss 0.3571 | Time(s) 3.5255 | Accuracy: 71.069785\n",
            "Epoch 00052 | Loss 0.5013 | Time(s) 3.5264 | Accuracy: 71.501150\n",
            "Epoch 00053 | Loss 0.5604 | Time(s) 3.5251 | Accuracy: 70.504218\n",
            "Epoch 00054 | Loss 0.4138 | Time(s) 3.5259 | Accuracy: 70.743865\n",
            "Epoch 00055 | Loss 0.6252 | Time(s) 3.5254 | Accuracy: 71.280675\n",
            "Epoch 00056 | Loss 0.5422 | Time(s) 3.5260 | Accuracy: 71.414877\n",
            "Epoch 00057 | Loss 0.5518 | Time(s) 3.5249 | Accuracy: 71.088957\n",
            "Epoch 00058 | Loss 0.4205 | Time(s) 3.5244 | Accuracy: 71.414877\n",
            "Epoch 00059 | Loss 0.4106 | Time(s) 3.5263 | Accuracy: 71.280675\n",
            "Epoch 00060 | Loss 0.4437 | Time(s) 3.5273 | Accuracy: 71.347776\n",
            "Epoch 00061 | Loss 0.4433 | Time(s) 3.5278 | Accuracy: 71.184816\n",
            "Epoch 00062 | Loss 0.5666 | Time(s) 3.5278 | Accuracy: 71.309433\n",
            "Epoch 00063 | Loss 0.6632 | Time(s) 3.5290 | Accuracy: 71.031442\n",
            "Epoch 00064 | Loss 0.5543 | Time(s) 3.5284 | Accuracy: 70.878067\n",
            "Epoch 00065 | Loss 0.5670 | Time(s) 3.5288 | Accuracy: 71.146472\n",
            "Epoch 00066 | Loss 0.3778 | Time(s) 3.5287 | Accuracy: 71.357362\n",
            "Epoch 00067 | Loss 0.4845 | Time(s) 3.5289 | Accuracy: 70.945169\n",
            "Epoch 00068 | Loss 0.6907 | Time(s) 3.5278 | Accuracy: 70.801380\n",
            "Epoch 00069 | Loss 0.7066 | Time(s) 3.5282 | Accuracy: 71.069785\n",
            "Epoch 00070 | Loss 0.4859 | Time(s) 3.5271 | Accuracy: 70.657592\n",
            "Epoch 00071 | Loss 0.5015 | Time(s) 3.5271 | Accuracy: 70.513804\n",
            "Epoch 00072 | Loss 0.5270 | Time(s) 3.5265 | Accuracy: 70.283742\n",
            "Epoch 00073 | Loss 0.5196 | Time(s) 3.5274 | Accuracy: 70.341258\n",
            "Epoch 00074 | Loss 0.4648 | Time(s) 3.5268 | Accuracy: 70.341258\n",
            "Epoch 00075 | Loss 0.6590 | Time(s) 3.5261 | Accuracy: 70.648006\n",
            "Epoch 00076 | Loss 0.6483 | Time(s) 3.5257 | Accuracy: 70.552147\n",
            "Epoch 00077 | Loss 0.5406 | Time(s) 3.5248 | Accuracy: 70.983512\n",
            "Epoch 00078 | Loss 0.4009 | Time(s) 3.5240 | Accuracy: 70.839724\n",
            "Epoch 00079 | Loss 0.5746 | Time(s) 3.5242 | Accuracy: 70.331672\n",
            "Epoch 00080 | Loss 0.4889 | Time(s) 3.5250 | Accuracy: 70.379601\n",
            "Epoch 00081 | Loss 0.4082 | Time(s) 3.5251 | Accuracy: 70.283742\n",
            "Epoch 00082 | Loss 0.4275 | Time(s) 3.5256 | Accuracy: 70.494632\n",
            "Epoch 00083 | Loss 0.6091 | Time(s) 3.5253 | Accuracy: 70.695936\n",
            "Epoch 00084 | Loss 0.4589 | Time(s) 3.5254 | Accuracy: 70.609663\n",
            "Epoch 00085 | Loss 0.4492 | Time(s) 3.5250 | Accuracy: 70.302914\n",
            "Epoch 00086 | Loss 0.4342 | Time(s) 3.5248 | Accuracy: 70.676764\n",
            "Epoch 00087 | Loss 0.3395 | Time(s) 3.5254 | Accuracy: 70.168712\n",
            "Epoch 00088 | Loss 0.4869 | Time(s) 3.5268 | Accuracy: 70.993098\n",
            "Epoch 00089 | Loss 0.4482 | Time(s) 3.5266 | Accuracy: 70.935583\n",
            "Epoch 00090 | Loss 0.4390 | Time(s) 3.5258 | Accuracy: 71.146472\n",
            "Epoch 00091 | Loss 0.4472 | Time(s) 3.5257 | Accuracy: 70.427531\n",
            "Epoch 00092 | Loss 0.4149 | Time(s) 3.5258 | Accuracy: 70.590491\n",
            "Epoch 00093 | Loss 0.5520 | Time(s) 3.5258 | Accuracy: 70.820552\n",
            "Epoch 00094 | Loss 0.3524 | Time(s) 3.5264 | Accuracy: 71.366948\n",
            "Epoch 00095 | Loss 0.7392 | Time(s) 3.5261 | Accuracy: 70.187883\n",
            "Epoch 00096 | Loss 0.4927 | Time(s) 3.5272 | Accuracy: 69.651074\n",
            "Epoch 00097 | Loss 0.4226 | Time(s) 3.5277 | Accuracy: 70.159126\n",
            "Epoch 00098 | Loss 0.3735 | Time(s) 3.5283 | Accuracy: 69.948236\n",
            "Epoch 00099 | Loss 0.4590 | Time(s) 3.5296 | Accuracy: 70.465874\n",
            "Epoch 00100 | Loss 0.4668 | Time(s) 3.5307 | Accuracy: 71.127301\n",
            "Epoch 00101 | Loss 0.5899 | Time(s) 3.5318 | Accuracy: 71.213574\n",
            "Epoch 00102 | Loss 0.3875 | Time(s) 3.5322 | Accuracy: 71.041028\n",
            "Epoch 00103 | Loss 0.3890 | Time(s) 3.5325 | Accuracy: 71.156058\n",
            "Epoch 00104 | Loss 0.4896 | Time(s) 3.5326 | Accuracy: 70.350844\n",
            "Epoch 00105 | Loss 0.4474 | Time(s) 3.5327 | Accuracy: 70.619248\n",
            "Epoch 00106 | Loss 0.3923 | Time(s) 3.5328 | Accuracy: 70.254985\n",
            "Epoch 00107 | Loss 0.4151 | Time(s) 3.5325 | Accuracy: 70.456288\n",
            "Epoch 00108 | Loss 0.5149 | Time(s) 3.5326 | Accuracy: 70.350844\n",
            "Epoch 00109 | Loss 0.3807 | Time(s) 3.5326 | Accuracy: 70.954755\n",
            "Epoch 00110 | Loss 0.3561 | Time(s) 3.5324 | Accuracy: 70.801380\n",
            "Epoch 00111 | Loss 0.4146 | Time(s) 3.5328 | Accuracy: 70.609663\n",
            "Epoch 00112 | Loss 0.2692 | Time(s) 3.5328 | Accuracy: 70.446702\n",
            "Epoch 00113 | Loss 0.4122 | Time(s) 3.5342 | Accuracy: 70.782209\n",
            "Epoch 00114 | Loss 0.4296 | Time(s) 3.5342 | Accuracy: 70.571319\n",
            "Epoch 00115 | Loss 0.6663 | Time(s) 3.5342 | Accuracy: 70.494632\n",
            "Epoch 00116 | Loss 0.5193 | Time(s) 3.5343 | Accuracy: 70.753451\n",
            "Epoch 00117 | Loss 0.4142 | Time(s) 3.5339 | Accuracy: 70.178298\n",
            "Epoch 00118 | Loss 0.5553 | Time(s) 3.5338 | Accuracy: 70.763037\n",
            "Epoch 00119 | Loss 0.4709 | Time(s) 3.5336 | Accuracy: 70.753451\n",
            "Epoch 00120 | Loss 0.3486 | Time(s) 3.5335 | Accuracy: 69.861963\n",
            "Epoch 00121 | Loss 0.3543 | Time(s) 3.5334 | Accuracy: 70.523390\n",
            "Epoch 00122 | Loss 0.6854 | Time(s) 3.5340 | Accuracy: 70.494632\n",
            "Epoch 00123 | Loss 0.2673 | Time(s) 3.5351 | Accuracy: 70.523390\n",
            "Epoch 00124 | Loss 0.3531 | Time(s) 3.5350 | Accuracy: 70.571319\n",
            "Epoch 00125 | Loss 0.5329 | Time(s) 3.5348 | Accuracy: 69.794862\n",
            "Epoch 00126 | Loss 0.2803 | Time(s) 3.5354 | Accuracy: 69.651074\n",
            "Epoch 00127 | Loss 0.4176 | Time(s) 3.5349 | Accuracy: 70.734279\n",
            "Epoch 00128 | Loss 0.5420 | Time(s) 3.5352 | Accuracy: 70.331672\n",
            "Epoch 00129 | Loss 0.5147 | Time(s) 3.5354 | Accuracy: 69.603144\n",
            "Epoch 00130 | Loss 0.3901 | Time(s) 3.5361 | Accuracy: 70.705521\n",
            "Epoch 00131 | Loss 1.0201 | Time(s) 3.5363 | Accuracy: 70.782209\n",
            "Epoch 00132 | Loss 0.3711 | Time(s) 3.5362 | Accuracy: 70.149540\n",
            "Epoch 00133 | Loss 0.6044 | Time(s) 3.5378 | Accuracy: 70.322086\n",
            "Epoch 00134 | Loss 0.4076 | Time(s) 3.5380 | Accuracy: 70.945169\n",
            "Epoch 00135 | Loss 0.2785 | Time(s) 3.5384 | Accuracy: 71.213574\n",
            "Epoch 00136 | Loss 0.4248 | Time(s) 3.5383 | Accuracy: 71.127301\n",
            "Epoch 00137 | Loss 0.2766 | Time(s) 3.5386 | Accuracy: 70.973926\n",
            "Epoch 00138 | Loss 0.5448 | Time(s) 3.5393 | Accuracy: 71.213574\n",
            "Epoch 00139 | Loss 0.4771 | Time(s) 3.5402 | Accuracy: 70.906825\n",
            "Epoch 00140 | Loss 0.4775 | Time(s) 3.5411 | Accuracy: 70.628834\n",
            "Epoch 00141 | Loss 0.5856 | Time(s) 3.5412 | Accuracy: 69.363497\n",
            "Epoch 00142 | Loss 0.4397 | Time(s) 3.5410 | Accuracy: 70.082439\n",
            "Epoch 00143 | Loss 0.4866 | Time(s) 3.5406 | Accuracy: 70.868482\n",
            "Epoch 00144 | Loss 0.3291 | Time(s) 3.5414 | Accuracy: 70.849310\n",
            "Epoch 00145 | Loss 0.5419 | Time(s) 3.5414 | Accuracy: 71.002684\n",
            "Epoch 00146 | Loss 0.5191 | Time(s) 3.5416 | Accuracy: 70.648006\n",
            "Epoch 00147 | Loss 0.4448 | Time(s) 3.5417 | Accuracy: 70.839724\n",
            "Epoch 00148 | Loss 0.4466 | Time(s) 3.5416 | Accuracy: 70.235813\n",
            "Epoch 00149 | Loss 0.4233 | Time(s) 3.5413 | Accuracy: 70.207055\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.330015 seconds\n",
            "Epoch 00000 | Loss 1.8209 | Time(s) 3.6692 | Accuracy: 32.160660\n",
            "Epoch 00001 | Loss 1.5184 | Time(s) 3.5917 | Accuracy: 46.577837\n",
            "Epoch 00002 | Loss 1.2538 | Time(s) 3.5830 | Accuracy: 51.926764\n",
            "Epoch 00003 | Loss 1.0702 | Time(s) 3.5867 | Accuracy: 57.802914\n",
            "Epoch 00004 | Loss 1.0920 | Time(s) 3.5756 | Accuracy: 62.202837\n",
            "Epoch 00005 | Loss 1.0614 | Time(s) 3.5668 | Accuracy: 64.934816\n",
            "Epoch 00006 | Loss 0.9517 | Time(s) 3.5664 | Accuracy: 67.053298\n",
            "Epoch 00007 | Loss 1.0365 | Time(s) 3.5640 | Accuracy: 67.379218\n",
            "Epoch 00008 | Loss 0.8527 | Time(s) 3.5626 | Accuracy: 67.954371\n",
            "Epoch 00009 | Loss 0.9345 | Time(s) 3.5602 | Accuracy: 68.241948\n",
            "Epoch 00010 | Loss 0.7033 | Time(s) 3.5656 | Accuracy: 67.053298\n",
            "Epoch 00011 | Loss 0.8869 | Time(s) 3.5665 | Accuracy: 68.452837\n",
            "Epoch 00012 | Loss 0.9023 | Time(s) 3.5642 | Accuracy: 68.395322\n",
            "Epoch 00013 | Loss 0.9222 | Time(s) 3.5627 | Accuracy: 69.171779\n",
            "Epoch 00014 | Loss 0.8908 | Time(s) 3.5595 | Accuracy: 68.481595\n",
            "Epoch 00015 | Loss 0.7611 | Time(s) 3.5581 | Accuracy: 68.337807\n",
            "Epoch 00016 | Loss 0.7343 | Time(s) 3.5564 | Accuracy: 68.347393\n",
            "Epoch 00017 | Loss 0.7328 | Time(s) 3.5532 | Accuracy: 67.868098\n",
            "Epoch 00018 | Loss 0.8201 | Time(s) 3.5492 | Accuracy: 67.206672\n",
            "Epoch 00019 | Loss 0.8168 | Time(s) 3.5494 | Accuracy: 68.117331\n",
            "Epoch 00020 | Loss 0.7536 | Time(s) 3.5492 | Accuracy: 69.171779\n",
            "Epoch 00021 | Loss 0.8538 | Time(s) 3.5514 | Accuracy: 69.190951\n",
            "Epoch 00022 | Loss 0.6325 | Time(s) 3.5514 | Accuracy: 69.488113\n",
            "Epoch 00023 | Loss 0.9109 | Time(s) 3.5474 | Accuracy: 69.056748\n",
            "Epoch 00024 | Loss 0.7384 | Time(s) 3.5457 | Accuracy: 67.963957\n",
            "Epoch 00025 | Loss 0.8917 | Time(s) 3.5439 | Accuracy: 69.152607\n",
            "Epoch 00026 | Loss 0.8079 | Time(s) 3.5425 | Accuracy: 69.871549\n",
            "Epoch 00027 | Loss 0.8871 | Time(s) 3.5422 | Accuracy: 69.775690\n",
            "Epoch 00028 | Loss 0.6064 | Time(s) 3.5451 | Accuracy: 69.727761\n",
            "Epoch 00029 | Loss 0.7761 | Time(s) 3.5431 | Accuracy: 69.814034\n",
            "Epoch 00030 | Loss 0.7519 | Time(s) 3.5418 | Accuracy: 69.411426\n",
            "Epoch 00031 | Loss 0.7518 | Time(s) 3.5422 | Accuracy: 69.545629\n",
            "Epoch 00032 | Loss 0.5792 | Time(s) 3.5426 | Accuracy: 69.411426\n",
            "Epoch 00033 | Loss 0.7308 | Time(s) 3.5412 | Accuracy: 69.555215\n",
            "Epoch 00034 | Loss 0.8554 | Time(s) 3.5399 | Accuracy: 69.315567\n",
            "Epoch 00035 | Loss 0.6485 | Time(s) 3.5403 | Accuracy: 69.440184\n",
            "Epoch 00036 | Loss 0.8217 | Time(s) 3.5413 | Accuracy: 69.286810\n",
            "Epoch 00037 | Loss 0.7857 | Time(s) 3.5429 | Accuracy: 68.596626\n",
            "Epoch 00038 | Loss 0.9096 | Time(s) 3.5430 | Accuracy: 68.299463\n",
            "Epoch 00039 | Loss 0.7392 | Time(s) 3.5409 | Accuracy: 68.261120\n",
            "Epoch 00040 | Loss 0.7639 | Time(s) 3.5409 | Accuracy: 67.772239\n",
            "Epoch 00041 | Loss 0.7773 | Time(s) 3.5394 | Accuracy: 68.625383\n",
            "Epoch 00042 | Loss 0.6278 | Time(s) 3.5386 | Accuracy: 69.229294\n",
            "Epoch 00043 | Loss 0.8923 | Time(s) 3.5375 | Accuracy: 69.516871\n",
            "Epoch 00044 | Loss 0.6956 | Time(s) 3.5367 | Accuracy: 68.836273\n",
            "Epoch 00045 | Loss 0.7149 | Time(s) 3.5381 | Accuracy: 68.721242\n",
            "Epoch 00046 | Loss 0.5959 | Time(s) 3.5367 | Accuracy: 68.654141\n",
            "Epoch 00047 | Loss 0.6537 | Time(s) 3.5367 | Accuracy: 68.481595\n",
            "Epoch 00048 | Loss 0.7388 | Time(s) 3.5366 | Accuracy: 67.983129\n",
            "Epoch 00049 | Loss 0.6250 | Time(s) 3.5364 | Accuracy: 68.481595\n",
            "Epoch 00050 | Loss 0.7553 | Time(s) 3.5356 | Accuracy: 68.510353\n",
            "Epoch 00051 | Loss 0.8832 | Time(s) 3.5344 | Accuracy: 68.625383\n",
            "Epoch 00052 | Loss 0.8254 | Time(s) 3.5341 | Accuracy: 68.970475\n",
            "Epoch 00053 | Loss 0.6632 | Time(s) 3.5335 | Accuracy: 68.721242\n",
            "Epoch 00054 | Loss 0.6168 | Time(s) 3.5333 | Accuracy: 68.280291\n",
            "Epoch 00055 | Loss 0.6408 | Time(s) 3.5338 | Accuracy: 68.280291\n",
            "Epoch 00056 | Loss 0.5855 | Time(s) 3.5325 | Accuracy: 68.855445\n",
            "Epoch 00057 | Loss 0.6242 | Time(s) 3.5319 | Accuracy: 68.970475\n",
            "Epoch 00058 | Loss 0.7259 | Time(s) 3.5308 | Accuracy: 68.855445\n",
            "Epoch 00059 | Loss 0.6212 | Time(s) 3.5294 | Accuracy: 68.587040\n",
            "Epoch 00060 | Loss 0.6433 | Time(s) 3.5286 | Accuracy: 68.376150\n",
            "Epoch 00061 | Loss 0.7858 | Time(s) 3.5292 | Accuracy: 67.973543\n",
            "Epoch 00062 | Loss 0.6078 | Time(s) 3.5303 | Accuracy: 67.762653\n",
            "Epoch 00063 | Loss 0.8647 | Time(s) 3.5304 | Accuracy: 68.213190\n",
            "Epoch 00064 | Loss 0.5622 | Time(s) 3.5302 | Accuracy: 67.935199\n",
            "Epoch 00065 | Loss 0.5577 | Time(s) 3.5292 | Accuracy: 68.491181\n",
            "Epoch 00066 | Loss 0.6774 | Time(s) 3.5296 | Accuracy: 68.356979\n",
            "Epoch 00067 | Loss 0.7779 | Time(s) 3.5295 | Accuracy: 68.194018\n",
            "Epoch 00068 | Loss 0.5591 | Time(s) 3.5288 | Accuracy: 68.376150\n",
            "Epoch 00069 | Loss 0.7212 | Time(s) 3.5289 | Accuracy: 69.075920\n",
            "Epoch 00070 | Loss 0.6171 | Time(s) 3.5286 | Accuracy: 68.817101\n",
            "Epoch 00071 | Loss 0.7062 | Time(s) 3.5284 | Accuracy: 68.654141\n",
            "Epoch 00072 | Loss 0.7338 | Time(s) 3.5282 | Accuracy: 68.031058\n",
            "Epoch 00073 | Loss 0.7941 | Time(s) 3.5274 | Accuracy: 67.724310\n",
            "Epoch 00074 | Loss 0.7026 | Time(s) 3.5260 | Accuracy: 67.292945\n",
            "Epoch 00075 | Loss 0.8257 | Time(s) 3.5259 | Accuracy: 68.596626\n",
            "Epoch 00076 | Loss 0.7309 | Time(s) 3.5271 | Accuracy: 67.523006\n",
            "Epoch 00077 | Loss 0.8058 | Time(s) 3.5262 | Accuracy: 68.500767\n",
            "Epoch 00078 | Loss 0.7923 | Time(s) 3.5264 | Accuracy: 68.663727\n",
            "Epoch 00079 | Loss 0.7205 | Time(s) 3.5266 | Accuracy: 68.472009\n",
            "Epoch 00080 | Loss 0.7761 | Time(s) 3.5260 | Accuracy: 67.292945\n",
            "Epoch 00081 | Loss 0.6538 | Time(s) 3.5250 | Accuracy: 68.107745\n",
            "Epoch 00082 | Loss 0.6045 | Time(s) 3.5250 | Accuracy: 67.810583\n",
            "Epoch 00083 | Loss 0.7850 | Time(s) 3.5244 | Accuracy: 68.318635\n",
            "Epoch 00084 | Loss 0.6113 | Time(s) 3.5241 | Accuracy: 68.002301\n",
            "Epoch 00085 | Loss 0.6656 | Time(s) 3.5244 | Accuracy: 67.906442\n",
            "Epoch 00086 | Loss 0.6701 | Time(s) 3.5241 | Accuracy: 67.781825\n",
            "Epoch 00087 | Loss 0.5959 | Time(s) 3.5234 | Accuracy: 68.587040\n",
            "Epoch 00088 | Loss 0.9671 | Time(s) 3.5235 | Accuracy: 68.750000\n",
            "Epoch 00089 | Loss 0.7181 | Time(s) 3.5239 | Accuracy: 68.395322\n",
            "Epoch 00090 | Loss 0.6809 | Time(s) 3.5232 | Accuracy: 68.596626\n",
            "Epoch 00091 | Loss 0.7045 | Time(s) 3.5226 | Accuracy: 68.989647\n",
            "Epoch 00092 | Loss 0.5919 | Time(s) 3.5226 | Accuracy: 68.673313\n",
            "Epoch 00093 | Loss 0.7030 | Time(s) 3.5215 | Accuracy: 68.337807\n",
            "Epoch 00094 | Loss 0.6292 | Time(s) 3.5202 | Accuracy: 68.328221\n",
            "Epoch 00095 | Loss 0.7953 | Time(s) 3.5205 | Accuracy: 68.845859\n",
            "Epoch 00096 | Loss 0.5795 | Time(s) 3.5213 | Accuracy: 68.587040\n",
            "Epoch 00097 | Loss 0.6482 | Time(s) 3.5212 | Accuracy: 68.424080\n",
            "Epoch 00098 | Loss 0.5744 | Time(s) 3.5205 | Accuracy: 67.618865\n",
            "Epoch 00099 | Loss 0.8172 | Time(s) 3.5198 | Accuracy: 67.245015\n",
            "Epoch 00100 | Loss 0.7069 | Time(s) 3.5194 | Accuracy: 68.424080\n",
            "Epoch 00101 | Loss 0.5489 | Time(s) 3.5195 | Accuracy: 67.973543\n",
            "Epoch 00102 | Loss 0.6955 | Time(s) 3.5198 | Accuracy: 67.935199\n",
            "Epoch 00103 | Loss 0.8108 | Time(s) 3.5192 | Accuracy: 67.868098\n",
            "Epoch 00104 | Loss 0.7643 | Time(s) 3.5188 | Accuracy: 68.059816\n",
            "Epoch 00105 | Loss 0.7214 | Time(s) 3.5189 | Accuracy: 67.906442\n",
            "Epoch 00106 | Loss 0.5430 | Time(s) 3.5189 | Accuracy: 67.331288\n",
            "Epoch 00107 | Loss 0.6077 | Time(s) 3.5192 | Accuracy: 67.906442\n",
            "Epoch 00108 | Loss 0.7132 | Time(s) 3.5193 | Accuracy: 68.011887\n",
            "Epoch 00109 | Loss 0.6134 | Time(s) 3.5189 | Accuracy: 68.845859\n",
            "Epoch 00110 | Loss 0.7952 | Time(s) 3.5184 | Accuracy: 68.692485\n",
            "Epoch 00111 | Loss 0.5676 | Time(s) 3.5179 | Accuracy: 68.232362\n",
            "Epoch 00112 | Loss 0.7122 | Time(s) 3.5175 | Accuracy: 67.810583\n",
            "Epoch 00113 | Loss 0.8776 | Time(s) 3.5180 | Accuracy: 67.973543\n",
            "Epoch 00114 | Loss 0.6350 | Time(s) 3.5185 | Accuracy: 68.165261\n",
            "Epoch 00115 | Loss 0.7303 | Time(s) 3.5177 | Accuracy: 68.347393\n",
            "Epoch 00116 | Loss 0.6040 | Time(s) 3.5168 | Accuracy: 68.682899\n",
            "Epoch 00117 | Loss 0.5872 | Time(s) 3.5166 | Accuracy: 67.781825\n",
            "Epoch 00118 | Loss 0.5751 | Time(s) 3.5165 | Accuracy: 67.647623\n",
            "Epoch 00119 | Loss 0.7957 | Time(s) 3.5163 | Accuracy: 67.465491\n",
            "Epoch 00120 | Loss 0.6200 | Time(s) 3.5166 | Accuracy: 67.666794\n",
            "Epoch 00121 | Loss 0.5843 | Time(s) 3.5164 | Accuracy: 68.031058\n",
            "Epoch 00122 | Loss 0.6085 | Time(s) 3.5167 | Accuracy: 68.529525\n",
            "Epoch 00123 | Loss 0.6066 | Time(s) 3.5168 | Accuracy: 68.874617\n",
            "Epoch 00124 | Loss 0.5498 | Time(s) 3.5167 | Accuracy: 68.855445\n",
            "Epoch 00125 | Loss 0.7637 | Time(s) 3.5164 | Accuracy: 68.999233\n",
            "Epoch 00126 | Loss 0.6766 | Time(s) 3.5163 | Accuracy: 69.344325\n",
            "Epoch 00127 | Loss 0.7707 | Time(s) 3.5160 | Accuracy: 68.663727\n",
            "Epoch 00128 | Loss 0.6125 | Time(s) 3.5152 | Accuracy: 68.855445\n",
            "Epoch 00129 | Loss 0.6120 | Time(s) 3.5147 | Accuracy: 68.836273\n",
            "Epoch 00130 | Loss 0.6480 | Time(s) 3.5146 | Accuracy: 68.999233\n",
            "Epoch 00131 | Loss 0.6150 | Time(s) 3.5149 | Accuracy: 69.334739\n",
            "Epoch 00132 | Loss 0.7865 | Time(s) 3.5144 | Accuracy: 68.980061\n",
            "Epoch 00133 | Loss 0.6680 | Time(s) 3.5141 | Accuracy: 68.702071\n",
            "Epoch 00134 | Loss 0.6685 | Time(s) 3.5138 | Accuracy: 68.778758\n",
            "Epoch 00135 | Loss 0.6501 | Time(s) 3.5135 | Accuracy: 68.960890\n",
            "Epoch 00136 | Loss 0.6991 | Time(s) 3.5134 | Accuracy: 68.462423\n",
            "Epoch 00137 | Loss 0.6143 | Time(s) 3.5131 | Accuracy: 68.510353\n",
            "Epoch 00138 | Loss 0.7002 | Time(s) 3.5127 | Accuracy: 68.769172\n",
            "Epoch 00139 | Loss 0.6406 | Time(s) 3.5124 | Accuracy: 67.877684\n",
            "Epoch 00140 | Loss 0.8288 | Time(s) 3.5121 | Accuracy: 67.599693\n",
            "Epoch 00141 | Loss 0.8354 | Time(s) 3.5121 | Accuracy: 68.395322\n",
            "Epoch 00142 | Loss 0.8214 | Time(s) 3.5117 | Accuracy: 67.858512\n",
            "Epoch 00143 | Loss 0.6797 | Time(s) 3.5111 | Accuracy: 67.139571\n",
            "Epoch 00144 | Loss 0.8418 | Time(s) 3.5110 | Accuracy: 66.468558\n",
            "Epoch 00145 | Loss 0.6476 | Time(s) 3.5106 | Accuracy: 66.976610\n",
            "Epoch 00146 | Loss 0.6223 | Time(s) 3.5103 | Accuracy: 68.011887\n",
            "Epoch 00147 | Loss 0.7030 | Time(s) 3.5104 | Accuracy: 68.673313\n",
            "Epoch 00148 | Loss 0.8762 | Time(s) 3.5102 | Accuracy: 68.836273\n",
            "Epoch 00149 | Loss 0.5873 | Time(s) 3.5102 | Accuracy: 68.548696\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.142720 seconds\n",
            "Epoch 00000 | Loss 1.8787 | Time(s) 3.5671 | Accuracy: 19.603144\n",
            "Epoch 00001 | Loss 1.6884 | Time(s) 3.5316 | Accuracy: 28.422163\n",
            "Epoch 00002 | Loss 1.4444 | Time(s) 3.5512 | Accuracy: 40.586656\n",
            "Epoch 00003 | Loss 1.4040 | Time(s) 3.5456 | Accuracy: 45.964340\n",
            "Epoch 00004 | Loss 1.2270 | Time(s) 3.5539 | Accuracy: 48.514187\n",
            "Epoch 00005 | Loss 1.2459 | Time(s) 3.5640 | Accuracy: 50.105445\n",
            "Epoch 00006 | Loss 1.2385 | Time(s) 3.5472 | Accuracy: 50.335506\n",
            "Epoch 00007 | Loss 1.1156 | Time(s) 3.5398 | Accuracy: 50.546396\n",
            "Epoch 00008 | Loss 1.1911 | Time(s) 3.5432 | Accuracy: 50.824387\n",
            "Epoch 00009 | Loss 1.1349 | Time(s) 3.5550 | Accuracy: 50.872316\n",
            "Epoch 00010 | Loss 1.0647 | Time(s) 3.5446 | Accuracy: 49.932899\n",
            "Epoch 00011 | Loss 1.0257 | Time(s) 3.5464 | Accuracy: 49.472776\n",
            "Epoch 00012 | Loss 0.9798 | Time(s) 3.5493 | Accuracy: 49.779525\n",
            "Epoch 00013 | Loss 1.0497 | Time(s) 3.5462 | Accuracy: 50.594325\n",
            "Epoch 00014 | Loss 1.0895 | Time(s) 3.5430 | Accuracy: 50.613497\n",
            "Epoch 00015 | Loss 0.9499 | Time(s) 3.5383 | Accuracy: 50.191718\n",
            "Epoch 00016 | Loss 1.0045 | Time(s) 3.5359 | Accuracy: 49.050997\n",
            "Epoch 00017 | Loss 1.1317 | Time(s) 3.5339 | Accuracy: 49.041411\n",
            "Epoch 00018 | Loss 0.9502 | Time(s) 3.5272 | Accuracy: 49.348160\n",
            "Epoch 00019 | Loss 0.9060 | Time(s) 3.5375 | Accuracy: 49.875383\n",
            "Epoch 00020 | Loss 0.8984 | Time(s) 3.5393 | Accuracy: 50.738113\n",
            "Epoch 00021 | Loss 0.8706 | Time(s) 3.5405 | Accuracy: 50.929831\n",
            "Epoch 00022 | Loss 0.8385 | Time(s) 3.5387 | Accuracy: 50.651840\n",
            "Epoch 00023 | Loss 1.0560 | Time(s) 3.5354 | Accuracy: 49.865798\n",
            "Epoch 00024 | Loss 1.0313 | Time(s) 3.5309 | Accuracy: 50.162960\n",
            "Epoch 00025 | Loss 1.1326 | Time(s) 3.5313 | Accuracy: 50.316334\n",
            "Epoch 00026 | Loss 1.1334 | Time(s) 3.5310 | Accuracy: 50.488880\n",
            "Epoch 00027 | Loss 0.9744 | Time(s) 3.5273 | Accuracy: 50.862730\n",
            "Epoch 00028 | Loss 0.8161 | Time(s) 3.5265 | Accuracy: 51.083206\n",
            "Epoch 00029 | Loss 0.8139 | Time(s) 3.5262 | Accuracy: 50.766871\n",
            "Epoch 00030 | Loss 0.8138 | Time(s) 3.5249 | Accuracy: 50.431365\n",
            "Epoch 00031 | Loss 1.0593 | Time(s) 3.5243 | Accuracy: 50.239647\n",
            "Epoch 00032 | Loss 0.8896 | Time(s) 3.5253 | Accuracy: 50.143788\n",
            "Epoch 00033 | Loss 0.9326 | Time(s) 3.5233 | Accuracy: 50.057515\n",
            "Epoch 00034 | Loss 0.8486 | Time(s) 3.5224 | Accuracy: 50.297163\n",
            "Epoch 00035 | Loss 0.8618 | Time(s) 3.5216 | Accuracy: 51.131135\n",
            "Epoch 00036 | Loss 0.8561 | Time(s) 3.5204 | Accuracy: 51.044862\n",
            "Epoch 00037 | Loss 1.1502 | Time(s) 3.5183 | Accuracy: 51.016104\n",
            "Epoch 00038 | Loss 0.7911 | Time(s) 3.5183 | Accuracy: 51.111963\n",
            "Epoch 00039 | Loss 1.1164 | Time(s) 3.5184 | Accuracy: 50.786043\n",
            "Epoch 00040 | Loss 0.9974 | Time(s) 3.5156 | Accuracy: 50.277991\n",
            "Epoch 00041 | Loss 1.0564 | Time(s) 3.5133 | Accuracy: 50.210890\n",
            "Epoch 00042 | Loss 1.0015 | Time(s) 3.5120 | Accuracy: 50.833972\n",
            "Epoch 00043 | Loss 0.8230 | Time(s) 3.5113 | Accuracy: 50.718942\n",
            "Epoch 00044 | Loss 1.0479 | Time(s) 3.5095 | Accuracy: 50.833972\n",
            "Epoch 00045 | Loss 0.7909 | Time(s) 3.5096 | Accuracy: 50.440951\n",
            "Epoch 00046 | Loss 0.8780 | Time(s) 3.5101 | Accuracy: 50.527224\n",
            "Epoch 00047 | Loss 0.9421 | Time(s) 3.5096 | Accuracy: 51.025690\n",
            "Epoch 00048 | Loss 0.9415 | Time(s) 3.5082 | Accuracy: 50.968175\n",
            "Epoch 00049 | Loss 0.9120 | Time(s) 3.5072 | Accuracy: 51.169479\n",
            "Epoch 00050 | Loss 1.0471 | Time(s) 3.5059 | Accuracy: 50.354678\n",
            "Epoch 00051 | Loss 1.0122 | Time(s) 3.5055 | Accuracy: 49.242715\n",
            "Epoch 00052 | Loss 1.0803 | Time(s) 3.5054 | Accuracy: 49.472776\n",
            "Epoch 00053 | Loss 0.7974 | Time(s) 3.5068 | Accuracy: 50.450537\n",
            "Epoch 00054 | Loss 0.8617 | Time(s) 3.5064 | Accuracy: 50.738113\n",
            "Epoch 00055 | Loss 0.8982 | Time(s) 3.5066 | Accuracy: 50.939417\n",
            "Epoch 00056 | Loss 0.9664 | Time(s) 3.5068 | Accuracy: 51.121549\n",
            "Epoch 00057 | Loss 1.0599 | Time(s) 3.5066 | Accuracy: 50.412193\n",
            "Epoch 00058 | Loss 0.9905 | Time(s) 3.5058 | Accuracy: 50.258819\n",
            "Epoch 00059 | Loss 0.9029 | Time(s) 3.5059 | Accuracy: 50.172546\n",
            "Epoch 00060 | Loss 1.0775 | Time(s) 3.5058 | Accuracy: 50.383436\n",
            "Epoch 00061 | Loss 1.0412 | Time(s) 3.5064 | Accuracy: 50.469709\n",
            "Epoch 00062 | Loss 1.1511 | Time(s) 3.5061 | Accuracy: 51.150307\n",
            "Epoch 00063 | Loss 0.7918 | Time(s) 3.5060 | Accuracy: 50.872316\n",
            "Epoch 00064 | Loss 0.8380 | Time(s) 3.5063 | Accuracy: 50.843558\n",
            "Epoch 00065 | Loss 1.0077 | Time(s) 3.5065 | Accuracy: 50.306748\n",
            "Epoch 00066 | Loss 1.0740 | Time(s) 3.5053 | Accuracy: 49.731595\n",
            "Epoch 00067 | Loss 0.8961 | Time(s) 3.5057 | Accuracy: 50.038344\n",
            "Epoch 00068 | Loss 0.9197 | Time(s) 3.5060 | Accuracy: 50.201304\n",
            "Epoch 00069 | Loss 0.9995 | Time(s) 3.5048 | Accuracy: 50.996933\n",
            "Epoch 00070 | Loss 1.0005 | Time(s) 3.5045 | Accuracy: 50.853144\n",
            "Epoch 00071 | Loss 0.8001 | Time(s) 3.5047 | Accuracy: 50.297163\n",
            "Epoch 00072 | Loss 0.7929 | Time(s) 3.5043 | Accuracy: 50.210890\n",
            "Epoch 00073 | Loss 0.9782 | Time(s) 3.5035 | Accuracy: 50.642255\n",
            "Epoch 00074 | Loss 0.8520 | Time(s) 3.5042 | Accuracy: 50.555982\n",
            "Epoch 00075 | Loss 0.9914 | Time(s) 3.5039 | Accuracy: 50.067101\n",
            "Epoch 00076 | Loss 0.8069 | Time(s) 3.5027 | Accuracy: 49.884969\n",
            "Epoch 00077 | Loss 0.9973 | Time(s) 3.5019 | Accuracy: 49.779525\n",
            "Epoch 00078 | Loss 0.9616 | Time(s) 3.5011 | Accuracy: 49.980828\n",
            "Epoch 00079 | Loss 1.0862 | Time(s) 3.5016 | Accuracy: 50.431365\n",
            "Epoch 00080 | Loss 0.8513 | Time(s) 3.5013 | Accuracy: 50.584739\n",
            "Epoch 00081 | Loss 0.9816 | Time(s) 3.5021 | Accuracy: 50.699770\n",
            "Epoch 00082 | Loss 0.9840 | Time(s) 3.5016 | Accuracy: 50.881902\n",
            "Epoch 00083 | Loss 1.1033 | Time(s) 3.5010 | Accuracy: 50.153374\n",
            "Epoch 00084 | Loss 0.8912 | Time(s) 3.5008 | Accuracy: 49.789110\n",
            "Epoch 00085 | Loss 0.9773 | Time(s) 3.5008 | Accuracy: 49.894555\n",
            "Epoch 00086 | Loss 0.9894 | Time(s) 3.4998 | Accuracy: 50.239647\n",
            "Epoch 00087 | Loss 1.0966 | Time(s) 3.4998 | Accuracy: 50.555982\n",
            "Epoch 00088 | Loss 0.9544 | Time(s) 3.4991 | Accuracy: 50.527224\n",
            "Epoch 00089 | Loss 0.9870 | Time(s) 3.4985 | Accuracy: 50.076687\n",
            "Epoch 00090 | Loss 0.8380 | Time(s) 3.4985 | Accuracy: 49.606979\n",
            "Epoch 00091 | Loss 0.8093 | Time(s) 3.4991 | Accuracy: 49.616564\n",
            "Epoch 00092 | Loss 0.9533 | Time(s) 3.4989 | Accuracy: 50.162960\n",
            "Epoch 00093 | Loss 0.7684 | Time(s) 3.4983 | Accuracy: 49.875383\n",
            "Epoch 00094 | Loss 0.8051 | Time(s) 3.4986 | Accuracy: 49.952071\n",
            "Epoch 00095 | Loss 0.9480 | Time(s) 3.5003 | Accuracy: 50.603911\n",
            "Epoch 00096 | Loss 0.8424 | Time(s) 3.5001 | Accuracy: 50.354678\n",
            "Epoch 00097 | Loss 0.9535 | Time(s) 3.5006 | Accuracy: 49.798696\n",
            "Epoch 00098 | Loss 0.8658 | Time(s) 3.5008 | Accuracy: 50.076687\n",
            "Epoch 00099 | Loss 1.0985 | Time(s) 3.5005 | Accuracy: 50.584739\n",
            "Epoch 00100 | Loss 0.7792 | Time(s) 3.5008 | Accuracy: 49.741181\n",
            "Epoch 00101 | Loss 0.8788 | Time(s) 3.5007 | Accuracy: 50.373850\n",
            "Epoch 00102 | Loss 0.9166 | Time(s) 3.5011 | Accuracy: 50.153374\n",
            "Epoch 00103 | Loss 0.9957 | Time(s) 3.5016 | Accuracy: 49.827454\n",
            "Epoch 00104 | Loss 0.9898 | Time(s) 3.5016 | Accuracy: 50.000000\n",
            "Epoch 00105 | Loss 1.0067 | Time(s) 3.5016 | Accuracy: 49.242715\n",
            "Epoch 00106 | Loss 1.0682 | Time(s) 3.5020 | Accuracy: 49.645322\n",
            "Epoch 00107 | Loss 0.8675 | Time(s) 3.5028 | Accuracy: 49.856212\n",
            "Epoch 00108 | Loss 0.8675 | Time(s) 3.5030 | Accuracy: 50.153374\n",
            "Epoch 00109 | Loss 0.8981 | Time(s) 3.5044 | Accuracy: 50.028758\n",
            "Epoch 00110 | Loss 0.7688 | Time(s) 3.5041 | Accuracy: 50.067101\n",
            "Epoch 00111 | Loss 1.0027 | Time(s) 3.5043 | Accuracy: 49.348160\n",
            "Epoch 00112 | Loss 1.1056 | Time(s) 3.5041 | Accuracy: 48.677147\n",
            "Epoch 00113 | Loss 0.8993 | Time(s) 3.5039 | Accuracy: 48.964724\n",
            "Epoch 00114 | Loss 1.0971 | Time(s) 3.5037 | Accuracy: 49.626150\n",
            "Epoch 00115 | Loss 0.8152 | Time(s) 3.5041 | Accuracy: 50.000000\n",
            "Epoch 00116 | Loss 0.8844 | Time(s) 3.5039 | Accuracy: 50.364264\n",
            "Epoch 00117 | Loss 0.9633 | Time(s) 3.5040 | Accuracy: 50.402607\n",
            "Epoch 00118 | Loss 0.8447 | Time(s) 3.5040 | Accuracy: 49.693252\n",
            "Epoch 00119 | Loss 0.9625 | Time(s) 3.5036 | Accuracy: 49.616564\n",
            "Epoch 00120 | Loss 0.9539 | Time(s) 3.5031 | Accuracy: 49.559049\n",
            "Epoch 00121 | Loss 0.9768 | Time(s) 3.5027 | Accuracy: 49.894555\n",
            "Epoch 00122 | Loss 1.0309 | Time(s) 3.5031 | Accuracy: 49.453604\n",
            "Epoch 00123 | Loss 0.9662 | Time(s) 3.5034 | Accuracy: 49.185199\n",
            "Epoch 00124 | Loss 0.9467 | Time(s) 3.5043 | Accuracy: 49.012653\n",
            "Epoch 00125 | Loss 0.9741 | Time(s) 3.5044 | Accuracy: 48.725077\n",
            "Epoch 00126 | Loss 0.8038 | Time(s) 3.5039 | Accuracy: 48.217025\n",
            "Epoch 00127 | Loss 0.8623 | Time(s) 3.5037 | Accuracy: 49.118098\n",
            "Epoch 00128 | Loss 0.9676 | Time(s) 3.5033 | Accuracy: 49.961656\n",
            "Epoch 00129 | Loss 1.0998 | Time(s) 3.5029 | Accuracy: 50.162960\n",
            "Epoch 00130 | Loss 0.9832 | Time(s) 3.5027 | Accuracy: 50.182132\n",
            "Epoch 00131 | Loss 1.0007 | Time(s) 3.5024 | Accuracy: 49.760353\n",
            "Epoch 00132 | Loss 0.9257 | Time(s) 3.5025 | Accuracy: 49.079755\n",
            "Epoch 00133 | Loss 0.9057 | Time(s) 3.5024 | Accuracy: 48.332055\n",
            "Epoch 00134 | Loss 0.8980 | Time(s) 3.5020 | Accuracy: 48.638804\n",
            "Epoch 00135 | Loss 1.0140 | Time(s) 3.5020 | Accuracy: 49.789110\n",
            "Epoch 00136 | Loss 0.9863 | Time(s) 3.5022 | Accuracy: 50.009586\n",
            "Epoch 00137 | Loss 0.9713 | Time(s) 3.5019 | Accuracy: 49.798696\n",
            "Epoch 00138 | Loss 0.9963 | Time(s) 3.5014 | Accuracy: 49.261887\n",
            "Epoch 00139 | Loss 0.7992 | Time(s) 3.5012 | Accuracy: 48.351227\n",
            "Epoch 00140 | Loss 1.0956 | Time(s) 3.5010 | Accuracy: 49.194785\n",
            "Epoch 00141 | Loss 0.9586 | Time(s) 3.5011 | Accuracy: 50.009586\n",
            "Epoch 00142 | Loss 0.8253 | Time(s) 3.5011 | Accuracy: 50.076687\n",
            "Epoch 00143 | Loss 0.8207 | Time(s) 3.5009 | Accuracy: 50.325920\n",
            "Epoch 00144 | Loss 0.7614 | Time(s) 3.5009 | Accuracy: 50.191718\n",
            "Epoch 00145 | Loss 1.0361 | Time(s) 3.5007 | Accuracy: 49.568635\n",
            "Epoch 00146 | Loss 0.9016 | Time(s) 3.5002 | Accuracy: 50.038344\n",
            "Epoch 00147 | Loss 0.8588 | Time(s) 3.5004 | Accuracy: 50.153374\n",
            "Epoch 00148 | Loss 1.0503 | Time(s) 3.5009 | Accuracy: 50.230061\n",
            "Epoch 00149 | Loss 0.9545 | Time(s) 3.5017 | Accuracy: 49.760353\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.120654 seconds\n",
            "Epoch 00000 | Loss 1.7991 | Time(s) 3.5531 | Accuracy: 26.102377\n",
            "Epoch 00001 | Loss 1.7448 | Time(s) 3.5032 | Accuracy: 30.243482\n",
            "Epoch 00002 | Loss 1.6105 | Time(s) 3.5165 | Accuracy: 37.384969\n",
            "Epoch 00003 | Loss 1.3474 | Time(s) 3.5137 | Accuracy: 45.370015\n",
            "Epoch 00004 | Loss 1.6052 | Time(s) 3.5094 | Accuracy: 47.776074\n",
            "Epoch 00005 | Loss 1.1216 | Time(s) 3.5159 | Accuracy: 50.949003\n",
            "Epoch 00006 | Loss 1.2330 | Time(s) 3.5306 | Accuracy: 52.904525\n",
            "Epoch 00007 | Loss 1.1566 | Time(s) 3.5167 | Accuracy: 53.268788\n",
            "Epoch 00008 | Loss 1.1471 | Time(s) 3.5133 | Accuracy: 53.748083\n",
            "Epoch 00009 | Loss 1.0197 | Time(s) 3.5073 | Accuracy: 53.240031\n",
            "Epoch 00010 | Loss 1.0829 | Time(s) 3.5029 | Accuracy: 53.748083\n",
            "Epoch 00011 | Loss 0.9731 | Time(s) 3.4956 | Accuracy: 54.093175\n",
            "Epoch 00012 | Loss 0.8947 | Time(s) 3.4918 | Accuracy: 54.284893\n",
            "Epoch 00013 | Loss 0.9867 | Time(s) 3.4895 | Accuracy: 53.633052\n",
            "Epoch 00014 | Loss 1.1920 | Time(s) 3.4905 | Accuracy: 53.326304\n",
            "Epoch 00015 | Loss 1.1559 | Time(s) 3.4873 | Accuracy: 54.304064\n",
            "Epoch 00016 | Loss 1.0414 | Time(s) 3.4852 | Accuracy: 54.610813\n",
            "Epoch 00017 | Loss 0.8909 | Time(s) 3.4833 | Accuracy: 54.735429\n",
            "Epoch 00018 | Loss 0.8474 | Time(s) 3.4844 | Accuracy: 54.351994\n",
            "Epoch 00019 | Loss 0.8904 | Time(s) 3.4823 | Accuracy: 53.086656\n",
            "Epoch 00020 | Loss 0.8690 | Time(s) 3.4877 | Accuracy: 54.476610\n",
            "Epoch 00021 | Loss 0.9751 | Time(s) 3.4873 | Accuracy: 54.917561\n",
            "Epoch 00022 | Loss 0.8251 | Time(s) 3.4882 | Accuracy: 54.390337\n",
            "Epoch 00023 | Loss 0.8429 | Time(s) 3.4903 | Accuracy: 54.371166\n",
            "Epoch 00024 | Loss 0.8409 | Time(s) 3.4899 | Accuracy: 53.805598\n",
            "Epoch 00025 | Loss 0.7340 | Time(s) 3.4911 | Accuracy: 53.930215\n",
            "Epoch 00026 | Loss 1.0670 | Time(s) 3.4905 | Accuracy: 53.757669\n",
            "Epoch 00027 | Loss 0.9936 | Time(s) 3.4886 | Accuracy: 53.863113\n",
            "Epoch 00028 | Loss 1.0430 | Time(s) 3.4913 | Accuracy: 54.879218\n",
            "Epoch 00029 | Loss 0.9776 | Time(s) 3.4915 | Accuracy: 53.518021\n",
            "Epoch 00030 | Loss 0.9420 | Time(s) 3.4917 | Accuracy: 53.805598\n",
            "Epoch 00031 | Loss 1.0570 | Time(s) 3.4917 | Accuracy: 52.434816\n",
            "Epoch 00032 | Loss 0.8716 | Time(s) 3.4909 | Accuracy: 52.597776\n",
            "Epoch 00033 | Loss 0.8362 | Time(s) 3.4897 | Accuracy: 53.671396\n",
            "Epoch 00034 | Loss 1.0309 | Time(s) 3.4871 | Accuracy: 53.527607\n",
            "Epoch 00035 | Loss 0.7238 | Time(s) 3.4880 | Accuracy: 53.565951\n",
            "Epoch 00036 | Loss 0.7364 | Time(s) 3.4884 | Accuracy: 54.160276\n",
            "Epoch 00037 | Loss 0.7201 | Time(s) 3.4873 | Accuracy: 53.997316\n",
            "Epoch 00038 | Loss 0.7257 | Time(s) 3.4881 | Accuracy: 53.882285\n",
            "Epoch 00039 | Loss 0.8066 | Time(s) 3.4881 | Accuracy: 53.939801\n",
            "Epoch 00040 | Loss 0.9754 | Time(s) 3.4883 | Accuracy: 53.891871\n",
            "Epoch 00041 | Loss 0.8909 | Time(s) 3.4904 | Accuracy: 53.316718\n",
            "Epoch 00042 | Loss 0.8663 | Time(s) 3.4899 | Accuracy: 53.479678\n",
            "Epoch 00043 | Loss 0.9567 | Time(s) 3.4883 | Accuracy: 53.479678\n",
            "Epoch 00044 | Loss 0.8181 | Time(s) 3.4866 | Accuracy: 53.891871\n",
            "Epoch 00045 | Loss 0.7394 | Time(s) 3.4858 | Accuracy: 53.863113\n",
            "Epoch 00046 | Loss 0.7135 | Time(s) 3.4842 | Accuracy: 54.323236\n",
            "Epoch 00047 | Loss 0.8189 | Time(s) 3.4832 | Accuracy: 53.278374\n",
            "Epoch 00048 | Loss 0.8045 | Time(s) 3.4835 | Accuracy: 53.613880\n",
            "Epoch 00049 | Loss 0.8305 | Time(s) 3.4830 | Accuracy: 53.594709\n",
            "Epoch 00050 | Loss 0.7563 | Time(s) 3.4820 | Accuracy: 53.786426\n",
            "Epoch 00051 | Loss 0.8008 | Time(s) 3.4817 | Accuracy: 53.939801\n",
            "Epoch 00052 | Loss 0.7508 | Time(s) 3.4810 | Accuracy: 53.326304\n",
            "Epoch 00053 | Loss 0.8120 | Time(s) 3.4799 | Accuracy: 52.588190\n",
            "Epoch 00054 | Loss 0.8084 | Time(s) 3.4806 | Accuracy: 53.498850\n",
            "Epoch 00055 | Loss 0.8516 | Time(s) 3.4804 | Accuracy: 52.933282\n",
            "Epoch 00056 | Loss 0.8369 | Time(s) 3.4814 | Accuracy: 52.818252\n",
            "Epoch 00057 | Loss 0.8258 | Time(s) 3.4824 | Accuracy: 53.115414\n",
            "Epoch 00058 | Loss 0.8065 | Time(s) 3.4813 | Accuracy: 53.556365\n",
            "Epoch 00059 | Loss 0.6708 | Time(s) 3.4805 | Accuracy: 53.402991\n",
            "Epoch 00060 | Loss 0.7054 | Time(s) 3.4815 | Accuracy: 53.565951\n",
            "Epoch 00061 | Loss 0.7615 | Time(s) 3.4816 | Accuracy: 53.824770\n",
            "Epoch 00062 | Loss 0.6758 | Time(s) 3.4808 | Accuracy: 54.112347\n",
            "Epoch 00063 | Loss 1.0489 | Time(s) 3.4800 | Accuracy: 54.179448\n",
            "Epoch 00064 | Loss 0.6832 | Time(s) 3.4809 | Accuracy: 53.604294\n",
            "Epoch 00065 | Loss 0.9160 | Time(s) 3.4805 | Accuracy: 53.613880\n",
            "Epoch 00066 | Loss 0.6872 | Time(s) 3.4811 | Accuracy: 53.307132\n",
            "Epoch 00067 | Loss 0.9204 | Time(s) 3.4802 | Accuracy: 53.431748\n",
            "Epoch 00068 | Loss 0.8125 | Time(s) 3.4791 | Accuracy: 53.834356\n",
            "Epoch 00069 | Loss 1.0363 | Time(s) 3.4789 | Accuracy: 53.767255\n",
            "Epoch 00070 | Loss 0.7349 | Time(s) 3.4790 | Accuracy: 54.150690\n",
            "Epoch 00071 | Loss 0.7719 | Time(s) 3.4780 | Accuracy: 54.390337\n",
            "Epoch 00072 | Loss 0.7861 | Time(s) 3.4784 | Accuracy: 53.853528\n",
            "Epoch 00073 | Loss 0.6980 | Time(s) 3.4776 | Accuracy: 53.038727\n",
            "Epoch 00074 | Loss 0.7467 | Time(s) 3.4779 | Accuracy: 53.029141\n",
            "Epoch 00075 | Loss 0.6984 | Time(s) 3.4783 | Accuracy: 53.230445\n",
            "Epoch 00076 | Loss 0.8005 | Time(s) 3.4780 | Accuracy: 53.661810\n",
            "Epoch 00077 | Loss 0.9957 | Time(s) 3.4770 | Accuracy: 53.997316\n",
            "Epoch 00078 | Loss 0.7755 | Time(s) 3.4763 | Accuracy: 53.728911\n",
            "Epoch 00079 | Loss 0.9190 | Time(s) 3.4757 | Accuracy: 53.211273\n",
            "Epoch 00080 | Loss 0.7854 | Time(s) 3.4748 | Accuracy: 52.693635\n",
            "Epoch 00081 | Loss 1.0190 | Time(s) 3.4748 | Accuracy: 53.700153\n",
            "Epoch 00082 | Loss 0.9364 | Time(s) 3.4750 | Accuracy: 53.834356\n",
            "Epoch 00083 | Loss 0.7188 | Time(s) 3.4760 | Accuracy: 53.412577\n",
            "Epoch 00084 | Loss 0.7319 | Time(s) 3.4768 | Accuracy: 53.201687\n",
            "Epoch 00085 | Loss 0.8288 | Time(s) 3.4768 | Accuracy: 53.201687\n",
            "Epoch 00086 | Loss 0.7294 | Time(s) 3.4768 | Accuracy: 53.470092\n",
            "Epoch 00087 | Loss 0.9922 | Time(s) 3.4776 | Accuracy: 52.952454\n",
            "Epoch 00088 | Loss 0.6996 | Time(s) 3.4778 | Accuracy: 53.690567\n",
            "Epoch 00089 | Loss 0.7947 | Time(s) 3.4775 | Accuracy: 54.064417\n",
            "Epoch 00090 | Loss 0.8069 | Time(s) 3.4774 | Accuracy: 54.026074\n",
            "Epoch 00091 | Loss 0.9058 | Time(s) 3.4776 | Accuracy: 54.054831\n",
            "Epoch 00092 | Loss 0.6893 | Time(s) 3.4783 | Accuracy: 53.374233\n",
            "Epoch 00093 | Loss 0.9019 | Time(s) 3.4781 | Accuracy: 53.029141\n",
            "Epoch 00094 | Loss 0.9156 | Time(s) 3.4777 | Accuracy: 53.086656\n",
            "Epoch 00095 | Loss 0.8159 | Time(s) 3.4771 | Accuracy: 52.655291\n",
            "Epoch 00096 | Loss 0.8269 | Time(s) 3.4769 | Accuracy: 52.770322\n",
            "Epoch 00097 | Loss 0.8084 | Time(s) 3.4760 | Accuracy: 53.287960\n",
            "Epoch 00098 | Loss 0.8200 | Time(s) 3.4755 | Accuracy: 52.003451\n",
            "Epoch 00099 | Loss 0.7096 | Time(s) 3.4756 | Accuracy: 52.147239\n",
            "Epoch 00100 | Loss 1.1540 | Time(s) 3.4760 | Accuracy: 51.543328\n",
            "Epoch 00101 | Loss 0.7726 | Time(s) 3.4754 | Accuracy: 50.565567\n",
            "Epoch 00102 | Loss 0.6875 | Time(s) 3.4747 | Accuracy: 51.457055\n",
            "Epoch 00103 | Loss 1.0851 | Time(s) 3.4743 | Accuracy: 52.818252\n",
            "Epoch 00104 | Loss 0.8693 | Time(s) 3.4736 | Accuracy: 52.214340\n",
            "Epoch 00105 | Loss 1.0015 | Time(s) 3.4736 | Accuracy: 52.501917\n",
            "Epoch 00106 | Loss 0.9478 | Time(s) 3.4730 | Accuracy: 52.569018\n",
            "Epoch 00107 | Loss 0.8075 | Time(s) 3.4728 | Accuracy: 52.779908\n",
            "Epoch 00108 | Loss 0.7820 | Time(s) 3.4726 | Accuracy: 53.086656\n",
            "Epoch 00109 | Loss 0.9953 | Time(s) 3.4731 | Accuracy: 53.556365\n",
            "Epoch 00110 | Loss 0.7128 | Time(s) 3.4734 | Accuracy: 52.847009\n",
            "Epoch 00111 | Loss 0.7966 | Time(s) 3.4730 | Accuracy: 52.962040\n",
            "Epoch 00112 | Loss 0.9319 | Time(s) 3.4723 | Accuracy: 52.597776\n",
            "Epoch 00113 | Loss 0.7884 | Time(s) 3.4723 | Accuracy: 52.252684\n",
            "Epoch 00114 | Loss 0.7825 | Time(s) 3.4721 | Accuracy: 53.402991\n",
            "Epoch 00115 | Loss 0.9091 | Time(s) 3.4713 | Accuracy: 53.776840\n",
            "Epoch 00116 | Loss 0.7783 | Time(s) 3.4707 | Accuracy: 53.355061\n",
            "Epoch 00117 | Loss 0.7956 | Time(s) 3.4708 | Accuracy: 53.402991\n",
            "Epoch 00118 | Loss 0.9241 | Time(s) 3.4717 | Accuracy: 53.594709\n",
            "Epoch 00119 | Loss 0.6918 | Time(s) 3.4712 | Accuracy: 53.891871\n",
            "Epoch 00120 | Loss 0.6418 | Time(s) 3.4712 | Accuracy: 53.767255\n",
            "Epoch 00121 | Loss 0.6938 | Time(s) 3.4709 | Accuracy: 54.064417\n",
            "Epoch 00122 | Loss 0.7455 | Time(s) 3.4706 | Accuracy: 53.671396\n",
            "Epoch 00123 | Loss 0.9178 | Time(s) 3.4704 | Accuracy: 53.575537\n",
            "Epoch 00124 | Loss 0.6964 | Time(s) 3.4705 | Accuracy: 53.585123\n",
            "Epoch 00125 | Loss 0.7859 | Time(s) 3.4702 | Accuracy: 53.009969\n",
            "Epoch 00126 | Loss 0.8534 | Time(s) 3.4701 | Accuracy: 53.125000\n",
            "Epoch 00127 | Loss 0.9477 | Time(s) 3.4700 | Accuracy: 52.904525\n",
            "Epoch 00128 | Loss 0.7526 | Time(s) 3.4700 | Accuracy: 52.837423\n",
            "Epoch 00129 | Loss 0.7998 | Time(s) 3.4702 | Accuracy: 53.700153\n",
            "Epoch 00130 | Loss 0.9110 | Time(s) 3.4697 | Accuracy: 54.112347\n",
            "Epoch 00131 | Loss 0.7489 | Time(s) 3.4697 | Accuracy: 54.026074\n",
            "Epoch 00132 | Loss 0.8884 | Time(s) 3.4694 | Accuracy: 53.594709\n",
            "Epoch 00133 | Loss 0.9072 | Time(s) 3.4692 | Accuracy: 53.901457\n",
            "Epoch 00134 | Loss 0.9077 | Time(s) 3.4687 | Accuracy: 53.671396\n",
            "Epoch 00135 | Loss 0.7882 | Time(s) 3.4697 | Accuracy: 53.642638\n",
            "Epoch 00136 | Loss 0.8673 | Time(s) 3.4696 | Accuracy: 53.326304\n",
            "Epoch 00137 | Loss 0.9001 | Time(s) 3.4691 | Accuracy: 53.355061\n",
            "Epoch 00138 | Loss 0.6394 | Time(s) 3.4688 | Accuracy: 53.182515\n",
            "Epoch 00139 | Loss 0.8024 | Time(s) 3.4695 | Accuracy: 53.719325\n",
            "Epoch 00140 | Loss 0.7997 | Time(s) 3.4693 | Accuracy: 53.700153\n",
            "Epoch 00141 | Loss 0.9039 | Time(s) 3.4691 | Accuracy: 53.374233\n",
            "Epoch 00142 | Loss 0.7760 | Time(s) 3.4686 | Accuracy: 53.125000\n",
            "Epoch 00143 | Loss 0.7427 | Time(s) 3.4686 | Accuracy: 53.470092\n",
            "Epoch 00144 | Loss 0.7923 | Time(s) 3.4686 | Accuracy: 53.757669\n",
            "Epoch 00145 | Loss 0.7983 | Time(s) 3.4688 | Accuracy: 53.872699\n",
            "Epoch 00146 | Loss 0.7881 | Time(s) 3.4683 | Accuracy: 53.987730\n",
            "Epoch 00147 | Loss 0.6817 | Time(s) 3.4681 | Accuracy: 53.824770\n",
            "Epoch 00148 | Loss 0.6952 | Time(s) 3.4677 | Accuracy: 53.431748\n",
            "Epoch 00149 | Loss 0.8798 | Time(s) 3.4673 | Accuracy: 53.585123\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.021658 seconds\n",
            "Epoch 00000 | Loss 1.8230 | Time(s) 3.5227 | Accuracy: 18.194018\n",
            "Epoch 00001 | Loss 1.5719 | Time(s) 3.4603 | Accuracy: 27.779908\n",
            "Epoch 00002 | Loss 1.4179 | Time(s) 3.4423 | Accuracy: 47.383052\n",
            "Epoch 00003 | Loss 1.0554 | Time(s) 3.4582 | Accuracy: 64.704755\n",
            "Epoch 00004 | Loss 1.0529 | Time(s) 3.4625 | Accuracy: 66.765721\n",
            "Epoch 00005 | Loss 0.8565 | Time(s) 3.4637 | Accuracy: 67.436733\n",
            "Epoch 00006 | Loss 0.7045 | Time(s) 3.4709 | Accuracy: 70.417945\n",
            "Epoch 00007 | Loss 0.7053 | Time(s) 3.4729 | Accuracy: 71.232745\n",
            "Epoch 00008 | Loss 0.7171 | Time(s) 3.4792 | Accuracy: 71.213574\n",
            "Epoch 00009 | Loss 0.6627 | Time(s) 3.4903 | Accuracy: 72.919862\n",
            "Epoch 00010 | Loss 0.5025 | Time(s) 3.4864 | Accuracy: 72.565184\n",
            "Epoch 00011 | Loss 0.5749 | Time(s) 3.4817 | Accuracy: 73.399156\n",
            "Epoch 00012 | Loss 0.6684 | Time(s) 3.4783 | Accuracy: 73.571702\n",
            "Epoch 00013 | Loss 0.7338 | Time(s) 3.4804 | Accuracy: 72.967791\n",
            "Epoch 00014 | Loss 0.5213 | Time(s) 3.4773 | Accuracy: 73.648390\n",
            "Epoch 00015 | Loss 0.5477 | Time(s) 3.4735 | Accuracy: 73.725077\n",
            "Epoch 00016 | Loss 0.4850 | Time(s) 3.4707 | Accuracy: 73.974310\n",
            "Epoch 00017 | Loss 0.5307 | Time(s) 3.4742 | Accuracy: 74.693252\n",
            "Epoch 00018 | Loss 0.5646 | Time(s) 3.4752 | Accuracy: 73.725077\n",
            "Epoch 00019 | Loss 0.4427 | Time(s) 3.4733 | Accuracy: 74.722009\n",
            "Epoch 00020 | Loss 0.5093 | Time(s) 3.4702 | Accuracy: 74.252301\n",
            "Epoch 00021 | Loss 0.4897 | Time(s) 3.4731 | Accuracy: 73.820936\n",
            "Epoch 00022 | Loss 0.4575 | Time(s) 3.4733 | Accuracy: 72.306365\n",
            "Epoch 00023 | Loss 0.4064 | Time(s) 3.4754 | Accuracy: 73.792178\n",
            "Epoch 00024 | Loss 0.4467 | Time(s) 3.4753 | Accuracy: 74.089340\n",
            "Epoch 00025 | Loss 0.3877 | Time(s) 3.4785 | Accuracy: 73.935966\n",
            "Epoch 00026 | Loss 0.3731 | Time(s) 3.4781 | Accuracy: 74.376917\n",
            "Epoch 00027 | Loss 0.3832 | Time(s) 3.4779 | Accuracy: 74.098926\n",
            "Epoch 00028 | Loss 0.2625 | Time(s) 3.4755 | Accuracy: 74.185199\n",
            "Epoch 00029 | Loss 0.4821 | Time(s) 3.4741 | Accuracy: 73.916794\n",
            "Epoch 00030 | Loss 0.3458 | Time(s) 3.4751 | Accuracy: 74.300230\n",
            "Epoch 00031 | Loss 0.5402 | Time(s) 3.4755 | Accuracy: 74.261887\n",
            "Epoch 00032 | Loss 0.4500 | Time(s) 3.4737 | Accuracy: 74.319402\n",
            "Epoch 00033 | Loss 0.4025 | Time(s) 3.4746 | Accuracy: 74.424847\n",
            "Epoch 00034 | Loss 0.2629 | Time(s) 3.4771 | Accuracy: 74.204371\n",
            "Epoch 00035 | Loss 0.3737 | Time(s) 3.4767 | Accuracy: 73.868865\n",
            "Epoch 00036 | Loss 0.4499 | Time(s) 3.4761 | Accuracy: 74.233129\n",
            "Epoch 00037 | Loss 0.4580 | Time(s) 3.4752 | Accuracy: 73.638804\n",
            "Epoch 00038 | Loss 0.4323 | Time(s) 3.4769 | Accuracy: 74.060583\n",
            "Epoch 00039 | Loss 0.4281 | Time(s) 3.4755 | Accuracy: 73.926380\n",
            "Epoch 00040 | Loss 0.3559 | Time(s) 3.4756 | Accuracy: 73.974310\n",
            "Epoch 00041 | Loss 0.4129 | Time(s) 3.4756 | Accuracy: 73.744248\n",
            "Epoch 00042 | Loss 0.3148 | Time(s) 3.4774 | Accuracy: 73.686733\n",
            "Epoch 00043 | Loss 0.7682 | Time(s) 3.4780 | Accuracy: 73.974310\n",
            "Epoch 00044 | Loss 0.3451 | Time(s) 3.4778 | Accuracy: 74.041411\n",
            "Epoch 00045 | Loss 0.4393 | Time(s) 3.4765 | Accuracy: 73.715491\n",
            "Epoch 00046 | Loss 0.4440 | Time(s) 3.4751 | Accuracy: 73.610046\n",
            "Epoch 00047 | Loss 0.4330 | Time(s) 3.4771 | Accuracy: 73.149923\n",
            "Epoch 00048 | Loss 0.4282 | Time(s) 3.4771 | Accuracy: 73.274540\n",
            "Epoch 00049 | Loss 0.3314 | Time(s) 3.4759 | Accuracy: 73.734663\n",
            "Epoch 00050 | Loss 0.3451 | Time(s) 3.4762 | Accuracy: 73.888037\n",
            "Epoch 00051 | Loss 1.0828 | Time(s) 3.4776 | Accuracy: 73.542945\n",
            "Epoch 00052 | Loss 0.4222 | Time(s) 3.4777 | Accuracy: 73.466258\n",
            "Epoch 00053 | Loss 0.4254 | Time(s) 3.4766 | Accuracy: 73.351227\n",
            "Epoch 00054 | Loss 0.3220 | Time(s) 3.4757 | Accuracy: 72.632285\n",
            "Epoch 00055 | Loss 0.4748 | Time(s) 3.4750 | Accuracy: 73.408742\n",
            "Epoch 00056 | Loss 0.4155 | Time(s) 3.4744 | Accuracy: 72.593942\n",
            "Epoch 00057 | Loss 0.5491 | Time(s) 3.4740 | Accuracy: 73.379985\n",
            "Epoch 00058 | Loss 0.4082 | Time(s) 3.4748 | Accuracy: 73.188267\n",
            "Epoch 00059 | Loss 0.3684 | Time(s) 3.4751 | Accuracy: 72.862347\n",
            "Epoch 00060 | Loss 0.3246 | Time(s) 3.4748 | Accuracy: 73.648390\n",
            "Epoch 00061 | Loss 0.8638 | Time(s) 3.4760 | Accuracy: 73.888037\n",
            "Epoch 00062 | Loss 0.3283 | Time(s) 3.4754 | Accuracy: 73.945552\n",
            "Epoch 00063 | Loss 0.3302 | Time(s) 3.4744 | Accuracy: 74.098926\n",
            "Epoch 00064 | Loss 0.3709 | Time(s) 3.4744 | Accuracy: 74.031825\n",
            "Epoch 00065 | Loss 0.3299 | Time(s) 3.4748 | Accuracy: 74.003067\n",
            "Epoch 00066 | Loss 0.3744 | Time(s) 3.4753 | Accuracy: 73.686733\n",
            "Epoch 00067 | Loss 0.6890 | Time(s) 3.4746 | Accuracy: 73.303298\n",
            "Epoch 00068 | Loss 0.3001 | Time(s) 3.4749 | Accuracy: 73.840107\n",
            "Epoch 00069 | Loss 0.3924 | Time(s) 3.4755 | Accuracy: 73.897623\n",
            "Epoch 00070 | Loss 0.8499 | Time(s) 3.4755 | Accuracy: 74.098926\n",
            "Epoch 00071 | Loss 0.3786 | Time(s) 3.4759 | Accuracy: 73.811350\n",
            "Epoch 00072 | Loss 0.3408 | Time(s) 3.4751 | Accuracy: 74.050997\n",
            "Epoch 00073 | Loss 0.3910 | Time(s) 3.4744 | Accuracy: 73.140337\n",
            "Epoch 00074 | Loss 0.3455 | Time(s) 3.4736 | Accuracy: 73.629218\n",
            "Epoch 00075 | Loss 0.3740 | Time(s) 3.4735 | Accuracy: 73.207439\n",
            "Epoch 00076 | Loss 0.3246 | Time(s) 3.4722 | Accuracy: 72.939034\n",
            "Epoch 00077 | Loss 0.4844 | Time(s) 3.4720 | Accuracy: 73.379985\n",
            "Epoch 00078 | Loss 0.4046 | Time(s) 3.4717 | Accuracy: 73.303298\n",
            "Epoch 00079 | Loss 0.4182 | Time(s) 3.4717 | Accuracy: 73.485429\n",
            "Epoch 00080 | Loss 0.3226 | Time(s) 3.4711 | Accuracy: 73.610046\n",
            "Epoch 00081 | Loss 0.4199 | Time(s) 3.4708 | Accuracy: 73.485429\n",
            "Epoch 00082 | Loss 0.3805 | Time(s) 3.4701 | Accuracy: 72.986963\n",
            "Epoch 00083 | Loss 0.3855 | Time(s) 3.4697 | Accuracy: 72.756902\n",
            "Epoch 00084 | Loss 0.3111 | Time(s) 3.4693 | Accuracy: 73.025307\n",
            "Epoch 00085 | Loss 0.2506 | Time(s) 3.4687 | Accuracy: 73.351227\n",
            "Epoch 00086 | Loss 0.3166 | Time(s) 3.4689 | Accuracy: 73.063650\n",
            "Epoch 00087 | Loss 0.3299 | Time(s) 3.4685 | Accuracy: 73.025307\n",
            "Epoch 00088 | Loss 0.3133 | Time(s) 3.4690 | Accuracy: 72.574770\n",
            "Epoch 00089 | Loss 0.4108 | Time(s) 3.4687 | Accuracy: 72.670629\n",
            "Epoch 00090 | Loss 0.3196 | Time(s) 3.4694 | Accuracy: 72.728144\n",
            "Epoch 00091 | Loss 0.3358 | Time(s) 3.4694 | Accuracy: 72.977377\n",
            "Epoch 00092 | Loss 0.3225 | Time(s) 3.4683 | Accuracy: 73.034893\n",
            "Epoch 00093 | Loss 0.3361 | Time(s) 3.4684 | Accuracy: 72.986963\n",
            "Epoch 00094 | Loss 0.3006 | Time(s) 3.4685 | Accuracy: 72.421396\n",
            "Epoch 00095 | Loss 0.5283 | Time(s) 3.4686 | Accuracy: 72.536426\n",
            "Epoch 00096 | Loss 0.4142 | Time(s) 3.4686 | Accuracy: 73.418328\n",
            "Epoch 00097 | Loss 0.6424 | Time(s) 3.4687 | Accuracy: 74.166028\n",
            "Epoch 00098 | Loss 0.2725 | Time(s) 3.4686 | Accuracy: 73.610046\n",
            "Epoch 00099 | Loss 0.3265 | Time(s) 3.4685 | Accuracy: 73.600460\n",
            "Epoch 00100 | Loss 0.3518 | Time(s) 3.4678 | Accuracy: 74.003067\n",
            "Epoch 00101 | Loss 0.3679 | Time(s) 3.4675 | Accuracy: 73.514187\n",
            "Epoch 00102 | Loss 0.3919 | Time(s) 3.4677 | Accuracy: 73.351227\n",
            "Epoch 00103 | Loss 0.3268 | Time(s) 3.4677 | Accuracy: 73.207439\n",
            "Epoch 00104 | Loss 0.6284 | Time(s) 3.4674 | Accuracy: 73.006135\n",
            "Epoch 00105 | Loss 0.3098 | Time(s) 3.4672 | Accuracy: 73.255368\n",
            "Epoch 00106 | Loss 0.3737 | Time(s) 3.4664 | Accuracy: 73.207439\n",
            "Epoch 00107 | Loss 0.2045 | Time(s) 3.4658 | Accuracy: 73.312883\n",
            "Epoch 00108 | Loss 0.1928 | Time(s) 3.4658 | Accuracy: 73.571702\n",
            "Epoch 00109 | Loss 0.3434 | Time(s) 3.4657 | Accuracy: 72.948620\n",
            "Epoch 00110 | Loss 0.6036 | Time(s) 3.4657 | Accuracy: 73.034893\n",
            "Epoch 00111 | Loss 0.3404 | Time(s) 3.4657 | Accuracy: 73.178681\n",
            "Epoch 00112 | Loss 0.2598 | Time(s) 3.4663 | Accuracy: 72.996549\n",
            "Epoch 00113 | Loss 0.3361 | Time(s) 3.4675 | Accuracy: 73.197853\n",
            "Epoch 00114 | Loss 0.3734 | Time(s) 3.4672 | Accuracy: 73.312883\n",
            "Epoch 00115 | Loss 0.5740 | Time(s) 3.4669 | Accuracy: 72.344709\n",
            "Epoch 00116 | Loss 0.3364 | Time(s) 3.4665 | Accuracy: 72.440567\n",
            "Epoch 00117 | Loss 0.3454 | Time(s) 3.4663 | Accuracy: 73.130752\n",
            "Epoch 00118 | Loss 0.3386 | Time(s) 3.4659 | Accuracy: 72.574770\n",
            "Epoch 00119 | Loss 0.2898 | Time(s) 3.4660 | Accuracy: 72.996549\n",
            "Epoch 00120 | Loss 0.3605 | Time(s) 3.4670 | Accuracy: 73.034893\n",
            "Epoch 00121 | Loss 0.3362 | Time(s) 3.4674 | Accuracy: 73.341641\n",
            "Epoch 00122 | Loss 0.3522 | Time(s) 3.4671 | Accuracy: 73.370399\n",
            "Epoch 00123 | Loss 0.2180 | Time(s) 3.4670 | Accuracy: 73.236196\n",
            "Epoch 00124 | Loss 0.8235 | Time(s) 3.4671 | Accuracy: 73.341641\n",
            "Epoch 00125 | Loss 0.2999 | Time(s) 3.4675 | Accuracy: 73.542945\n",
            "Epoch 00126 | Loss 0.4567 | Time(s) 3.4673 | Accuracy: 72.603528\n",
            "Epoch 00127 | Loss 0.3228 | Time(s) 3.4671 | Accuracy: 73.149923\n",
            "Epoch 00128 | Loss 0.4366 | Time(s) 3.4666 | Accuracy: 72.661043\n",
            "Epoch 00129 | Loss 0.2621 | Time(s) 3.4676 | Accuracy: 72.680215\n",
            "Epoch 00130 | Loss 0.3695 | Time(s) 3.4677 | Accuracy: 72.996549\n",
            "Epoch 00131 | Loss 0.3595 | Time(s) 3.4682 | Accuracy: 72.613113\n",
            "Epoch 00132 | Loss 0.3284 | Time(s) 3.4683 | Accuracy: 73.006135\n",
            "Epoch 00133 | Loss 0.3145 | Time(s) 3.4683 | Accuracy: 72.948620\n",
            "Epoch 00134 | Loss 0.3138 | Time(s) 3.4684 | Accuracy: 73.073236\n",
            "Epoch 00135 | Loss 0.8861 | Time(s) 3.4680 | Accuracy: 72.766488\n",
            "Epoch 00136 | Loss 0.2145 | Time(s) 3.4679 | Accuracy: 72.900690\n",
            "Epoch 00137 | Loss 0.3692 | Time(s) 3.4677 | Accuracy: 72.459739\n",
            "Epoch 00138 | Loss 0.3347 | Time(s) 3.4681 | Accuracy: 72.708972\n",
            "Epoch 00139 | Loss 0.3649 | Time(s) 3.4682 | Accuracy: 73.006135\n",
            "Epoch 00140 | Loss 0.3241 | Time(s) 3.4680 | Accuracy: 72.910276\n",
            "Epoch 00141 | Loss 0.3316 | Time(s) 3.4676 | Accuracy: 72.478911\n",
            "Epoch 00142 | Loss 0.3132 | Time(s) 3.4676 | Accuracy: 72.536426\n",
            "Epoch 00143 | Loss 0.2914 | Time(s) 3.4671 | Accuracy: 72.843175\n",
            "Epoch 00144 | Loss 0.2791 | Time(s) 3.4671 | Accuracy: 72.785660\n",
            "Epoch 00145 | Loss 0.2917 | Time(s) 3.4667 | Accuracy: 72.498083\n",
            "Epoch 00146 | Loss 0.3209 | Time(s) 3.4664 | Accuracy: 72.536426\n",
            "Epoch 00147 | Loss 0.3085 | Time(s) 3.4663 | Accuracy: 72.766488\n",
            "Epoch 00148 | Loss 0.5192 | Time(s) 3.4660 | Accuracy: 72.708972\n",
            "Epoch 00149 | Loss 0.1990 | Time(s) 3.4657 | Accuracy: 72.737730\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.004696 seconds\n",
            "Epoch 00000 | Loss 1.9060 | Time(s) 3.4875 | Accuracy: 16.746549\n",
            "Epoch 00001 | Loss 1.6561 | Time(s) 3.4828 | Accuracy: 32.850844\n",
            "Epoch 00002 | Loss 1.2846 | Time(s) 3.4717 | Accuracy: 47.373466\n",
            "Epoch 00003 | Loss 1.4180 | Time(s) 3.4694 | Accuracy: 59.212040\n",
            "Epoch 00004 | Loss 1.0937 | Time(s) 3.4661 | Accuracy: 61.464724\n",
            "Epoch 00005 | Loss 1.1058 | Time(s) 3.4754 | Accuracy: 63.209356\n",
            "Epoch 00006 | Loss 0.8905 | Time(s) 3.4654 | Accuracy: 66.315184\n",
            "Epoch 00007 | Loss 0.7881 | Time(s) 3.4610 | Accuracy: 69.746933\n",
            "Epoch 00008 | Loss 0.8659 | Time(s) 3.4588 | Accuracy: 71.587423\n",
            "Epoch 00009 | Loss 0.8773 | Time(s) 3.4727 | Accuracy: 70.676764\n",
            "Epoch 00010 | Loss 0.6104 | Time(s) 3.4728 | Accuracy: 71.750383\n",
            "Epoch 00011 | Loss 0.6384 | Time(s) 3.4799 | Accuracy: 74.022239\n",
            "Epoch 00012 | Loss 0.7129 | Time(s) 3.4832 | Accuracy: 73.974310\n",
            "Epoch 00013 | Loss 0.9164 | Time(s) 3.4786 | Accuracy: 74.146856\n",
            "Epoch 00014 | Loss 0.6624 | Time(s) 3.4880 | Accuracy: 74.904141\n",
            "Epoch 00015 | Loss 0.5186 | Time(s) 3.4867 | Accuracy: 74.798696\n",
            "Epoch 00016 | Loss 0.8904 | Time(s) 3.4848 | Accuracy: 75.872316\n",
            "Epoch 00017 | Loss 0.5913 | Time(s) 3.4807 | Accuracy: 76.524156\n",
            "Epoch 00018 | Loss 0.4891 | Time(s) 3.4806 | Accuracy: 75.786043\n",
            "Epoch 00019 | Loss 0.5349 | Time(s) 3.4787 | Accuracy: 76.064034\n",
            "Epoch 00020 | Loss 0.6023 | Time(s) 3.4782 | Accuracy: 76.342025\n",
            "Epoch 00021 | Loss 0.4679 | Time(s) 3.4788 | Accuracy: 76.284509\n",
            "Epoch 00022 | Loss 0.5079 | Time(s) 3.4777 | Accuracy: 76.246166\n",
            "Epoch 00023 | Loss 0.5697 | Time(s) 3.4752 | Accuracy: 76.840491\n",
            "Epoch 00024 | Loss 0.4490 | Time(s) 3.4759 | Accuracy: 77.396472\n",
            "Epoch 00025 | Loss 0.5438 | Time(s) 3.4746 | Accuracy: 77.271856\n",
            "Epoch 00026 | Loss 0.6380 | Time(s) 3.4739 | Accuracy: 77.319785\n",
            "Epoch 00027 | Loss 0.5848 | Time(s) 3.4737 | Accuracy: 75.565567\n",
            "Epoch 00028 | Loss 0.5630 | Time(s) 3.4765 | Accuracy: 75.354678\n",
            "Epoch 00029 | Loss 0.8557 | Time(s) 3.4774 | Accuracy: 76.428298\n",
            "Epoch 00030 | Loss 0.6883 | Time(s) 3.4771 | Accuracy: 77.003451\n",
            "Epoch 00031 | Loss 0.4510 | Time(s) 3.4780 | Accuracy: 77.444402\n",
            "Epoch 00032 | Loss 0.6134 | Time(s) 3.4801 | Accuracy: 76.773390\n",
            "Epoch 00033 | Loss 0.6562 | Time(s) 3.4816 | Accuracy: 77.089724\n",
            "Epoch 00034 | Loss 0.4698 | Time(s) 3.4825 | Accuracy: 76.591258\n",
            "Epoch 00035 | Loss 0.6837 | Time(s) 3.4821 | Accuracy: 76.064034\n",
            "Epoch 00036 | Loss 0.4237 | Time(s) 3.4818 | Accuracy: 76.524156\n",
            "Epoch 00037 | Loss 0.5192 | Time(s) 3.4826 | Accuracy: 76.361196\n",
            "Epoch 00038 | Loss 0.6520 | Time(s) 3.4819 | Accuracy: 76.667945\n",
            "Epoch 00039 | Loss 0.5003 | Time(s) 3.4806 | Accuracy: 75.412193\n",
            "Epoch 00040 | Loss 0.4762 | Time(s) 3.4803 | Accuracy: 75.220475\n",
            "Epoch 00041 | Loss 0.4552 | Time(s) 3.4797 | Accuracy: 76.735046\n",
            "Epoch 00042 | Loss 0.3864 | Time(s) 3.4805 | Accuracy: 78.335890\n",
            "Epoch 00043 | Loss 0.3855 | Time(s) 3.4797 | Accuracy: 77.971626\n",
            "Epoch 00044 | Loss 0.5069 | Time(s) 3.4799 | Accuracy: 77.291028\n",
            "Epoch 00045 | Loss 0.3878 | Time(s) 3.4804 | Accuracy: 77.214340\n",
            "Epoch 00046 | Loss 0.3864 | Time(s) 3.4814 | Accuracy: 77.147239\n",
            "Epoch 00047 | Loss 0.9392 | Time(s) 3.4823 | Accuracy: 76.389954\n",
            "Epoch 00048 | Loss 0.4506 | Time(s) 3.4824 | Accuracy: 77.530675\n",
            "Epoch 00049 | Loss 0.4545 | Time(s) 3.4829 | Accuracy: 78.402991\n",
            "Epoch 00050 | Loss 0.5806 | Time(s) 3.4834 | Accuracy: 77.952454\n",
            "Epoch 00051 | Loss 0.5699 | Time(s) 3.4820 | Accuracy: 77.041794\n",
            "Epoch 00052 | Loss 0.4374 | Time(s) 3.4804 | Accuracy: 75.920245\n",
            "Epoch 00053 | Loss 0.3897 | Time(s) 3.4797 | Accuracy: 76.485813\n",
            "Epoch 00054 | Loss 0.4040 | Time(s) 3.4795 | Accuracy: 76.016104\n",
            "Epoch 00055 | Loss 0.4646 | Time(s) 3.4788 | Accuracy: 76.898006\n",
            "Epoch 00056 | Loss 0.4919 | Time(s) 3.4785 | Accuracy: 77.156825\n",
            "Epoch 00057 | Loss 0.3959 | Time(s) 3.4782 | Accuracy: 76.284509\n",
            "Epoch 00058 | Loss 0.3704 | Time(s) 3.4783 | Accuracy: 76.620015\n",
            "Epoch 00059 | Loss 0.5753 | Time(s) 3.4785 | Accuracy: 76.639187\n",
            "Epoch 00060 | Loss 0.6186 | Time(s) 3.4779 | Accuracy: 75.862730\n",
            "Epoch 00061 | Loss 0.3970 | Time(s) 3.4783 | Accuracy: 75.872316\n",
            "Epoch 00062 | Loss 0.6249 | Time(s) 3.4772 | Accuracy: 76.984279\n",
            "Epoch 00063 | Loss 0.4293 | Time(s) 3.4778 | Accuracy: 77.099310\n",
            "Epoch 00064 | Loss 0.4462 | Time(s) 3.4788 | Accuracy: 77.616948\n",
            "Epoch 00065 | Loss 0.4064 | Time(s) 3.4782 | Accuracy: 77.195169\n",
            "Epoch 00066 | Loss 0.5951 | Time(s) 3.4783 | Accuracy: 76.629601\n",
            "Epoch 00067 | Loss 0.3490 | Time(s) 3.4786 | Accuracy: 77.914110\n",
            "Epoch 00068 | Loss 0.3831 | Time(s) 3.4791 | Accuracy: 77.837423\n",
            "Epoch 00069 | Loss 0.5804 | Time(s) 3.4785 | Accuracy: 77.137653\n",
            "Epoch 00070 | Loss 0.3523 | Time(s) 3.4782 | Accuracy: 76.342025\n",
            "Epoch 00071 | Loss 0.5230 | Time(s) 3.4775 | Accuracy: 76.399540\n",
            "Epoch 00072 | Loss 0.5048 | Time(s) 3.4771 | Accuracy: 77.453988\n",
            "Epoch 00073 | Loss 0.5610 | Time(s) 3.4764 | Accuracy: 77.329371\n",
            "Epoch 00074 | Loss 0.5314 | Time(s) 3.4755 | Accuracy: 77.492331\n",
            "Epoch 00075 | Loss 0.5222 | Time(s) 3.4755 | Accuracy: 77.223926\n",
            "Epoch 00076 | Loss 0.3628 | Time(s) 3.4752 | Accuracy: 77.262270\n",
            "Epoch 00077 | Loss 0.3380 | Time(s) 3.4749 | Accuracy: 77.243098\n",
            "Epoch 00078 | Loss 0.3359 | Time(s) 3.4746 | Accuracy: 77.080138\n",
            "Epoch 00079 | Loss 0.3780 | Time(s) 3.4747 | Accuracy: 76.955521\n",
            "Epoch 00080 | Loss 0.4447 | Time(s) 3.4745 | Accuracy: 76.361196\n",
            "Epoch 00081 | Loss 0.4120 | Time(s) 3.4745 | Accuracy: 76.246166\n",
            "Epoch 00082 | Loss 0.4458 | Time(s) 3.4742 | Accuracy: 76.610429\n",
            "Epoch 00083 | Loss 0.3098 | Time(s) 3.4738 | Accuracy: 77.271856\n",
            "Epoch 00084 | Loss 0.4805 | Time(s) 3.4731 | Accuracy: 76.121549\n",
            "Epoch 00085 | Loss 0.3748 | Time(s) 3.4725 | Accuracy: 75.853144\n",
            "Epoch 00086 | Loss 0.4433 | Time(s) 3.4726 | Accuracy: 75.977761\n",
            "Epoch 00087 | Loss 0.5012 | Time(s) 3.4731 | Accuracy: 76.830905\n",
            "Epoch 00088 | Loss 0.4019 | Time(s) 3.4737 | Accuracy: 76.706288\n",
            "Epoch 00089 | Loss 0.3510 | Time(s) 3.4756 | Accuracy: 76.284509\n",
            "Epoch 00090 | Loss 0.4388 | Time(s) 3.4768 | Accuracy: 76.351610\n",
            "Epoch 00091 | Loss 0.6216 | Time(s) 3.4762 | Accuracy: 77.300613\n",
            "Epoch 00092 | Loss 0.4035 | Time(s) 3.4759 | Accuracy: 77.664877\n",
            "Epoch 00093 | Loss 0.2954 | Time(s) 3.4760 | Accuracy: 78.009969\n",
            "Epoch 00094 | Loss 0.5080 | Time(s) 3.4754 | Accuracy: 77.808666\n",
            "Epoch 00095 | Loss 0.4010 | Time(s) 3.4750 | Accuracy: 76.131135\n",
            "Epoch 00096 | Loss 0.4292 | Time(s) 3.4750 | Accuracy: 76.121549\n",
            "Epoch 00097 | Loss 0.2968 | Time(s) 3.4750 | Accuracy: 76.629601\n",
            "Epoch 00098 | Loss 0.3164 | Time(s) 3.4753 | Accuracy: 76.811733\n",
            "Epoch 00099 | Loss 0.5040 | Time(s) 3.4754 | Accuracy: 76.600844\n",
            "Epoch 00100 | Loss 0.3967 | Time(s) 3.4750 | Accuracy: 76.965107\n",
            "Epoch 00101 | Loss 0.5023 | Time(s) 3.4748 | Accuracy: 77.041794\n",
            "Epoch 00102 | Loss 0.6395 | Time(s) 3.4743 | Accuracy: 77.195169\n",
            "Epoch 00103 | Loss 0.3669 | Time(s) 3.4737 | Accuracy: 77.070552\n",
            "Epoch 00104 | Loss 0.4071 | Time(s) 3.4730 | Accuracy: 76.802147\n",
            "Epoch 00105 | Loss 0.5682 | Time(s) 3.4727 | Accuracy: 76.342025\n",
            "Epoch 00106 | Loss 0.5295 | Time(s) 3.4734 | Accuracy: 76.687117\n",
            "Epoch 00107 | Loss 0.3654 | Time(s) 3.4732 | Accuracy: 76.907592\n",
            "Epoch 00108 | Loss 0.5180 | Time(s) 3.4724 | Accuracy: 77.291028\n",
            "Epoch 00109 | Loss 0.5863 | Time(s) 3.4719 | Accuracy: 77.569018\n",
            "Epoch 00110 | Loss 0.4853 | Time(s) 3.4714 | Accuracy: 76.380368\n",
            "Epoch 00111 | Loss 0.3728 | Time(s) 3.4711 | Accuracy: 76.226994\n",
            "Epoch 00112 | Loss 0.6600 | Time(s) 3.4705 | Accuracy: 76.830905\n",
            "Epoch 00113 | Loss 0.4990 | Time(s) 3.4703 | Accuracy: 76.581672\n",
            "Epoch 00114 | Loss 0.3873 | Time(s) 3.4703 | Accuracy: 77.252684\n",
            "Epoch 00115 | Loss 0.5341 | Time(s) 3.4706 | Accuracy: 77.003451\n",
            "Epoch 00116 | Loss 0.3494 | Time(s) 3.4710 | Accuracy: 76.792561\n",
            "Epoch 00117 | Loss 0.3407 | Time(s) 3.4704 | Accuracy: 77.156825\n",
            "Epoch 00118 | Loss 0.4836 | Time(s) 3.4699 | Accuracy: 76.639187\n",
            "Epoch 00119 | Loss 0.5262 | Time(s) 3.4694 | Accuracy: 76.485813\n",
            "Epoch 00120 | Loss 0.3759 | Time(s) 3.4698 | Accuracy: 76.600844\n",
            "Epoch 00121 | Loss 0.3736 | Time(s) 3.4693 | Accuracy: 76.380368\n",
            "Epoch 00122 | Loss 0.3458 | Time(s) 3.4688 | Accuracy: 76.610429\n",
            "Epoch 00123 | Loss 0.6040 | Time(s) 3.4688 | Accuracy: 76.936350\n",
            "Epoch 00124 | Loss 0.3723 | Time(s) 3.4692 | Accuracy: 77.300613\n",
            "Epoch 00125 | Loss 0.3512 | Time(s) 3.4687 | Accuracy: 77.453988\n",
            "Epoch 00126 | Loss 0.5408 | Time(s) 3.4684 | Accuracy: 77.942868\n",
            "Epoch 00127 | Loss 0.4915 | Time(s) 3.4683 | Accuracy: 77.511503\n",
            "Epoch 00128 | Loss 0.3498 | Time(s) 3.4685 | Accuracy: 77.060966\n",
            "Epoch 00129 | Loss 0.4476 | Time(s) 3.4685 | Accuracy: 77.473160\n",
            "Epoch 00130 | Loss 0.5555 | Time(s) 3.4686 | Accuracy: 77.569018\n",
            "Epoch 00131 | Loss 0.4715 | Time(s) 3.4691 | Accuracy: 77.501917\n",
            "Epoch 00132 | Loss 0.4691 | Time(s) 3.4693 | Accuracy: 77.329371\n",
            "Epoch 00133 | Loss 0.3535 | Time(s) 3.4693 | Accuracy: 77.827837\n",
            "Epoch 00134 | Loss 0.5289 | Time(s) 3.4694 | Accuracy: 78.134586\n",
            "Epoch 00135 | Loss 0.5018 | Time(s) 3.4689 | Accuracy: 76.945936\n",
            "Epoch 00136 | Loss 0.5173 | Time(s) 3.4693 | Accuracy: 77.358129\n",
            "Epoch 00137 | Loss 0.3396 | Time(s) 3.4694 | Accuracy: 77.166411\n",
            "Epoch 00138 | Loss 0.5111 | Time(s) 3.4693 | Accuracy: 76.159893\n",
            "Epoch 00139 | Loss 0.3606 | Time(s) 3.4692 | Accuracy: 75.642255\n",
            "Epoch 00140 | Loss 0.5480 | Time(s) 3.4693 | Accuracy: 75.910660\n",
            "Epoch 00141 | Loss 0.3470 | Time(s) 3.4701 | Accuracy: 76.600844\n",
            "Epoch 00142 | Loss 0.3561 | Time(s) 3.4706 | Accuracy: 77.137653\n",
            "Epoch 00143 | Loss 0.4512 | Time(s) 3.4704 | Accuracy: 77.185583\n",
            "Epoch 00144 | Loss 0.4319 | Time(s) 3.4703 | Accuracy: 77.223926\n",
            "Epoch 00145 | Loss 0.3384 | Time(s) 3.4705 | Accuracy: 77.329371\n",
            "Epoch 00146 | Loss 0.4917 | Time(s) 3.4706 | Accuracy: 77.607362\n",
            "Epoch 00147 | Loss 0.3581 | Time(s) 3.4703 | Accuracy: 78.297546\n",
            "Epoch 00148 | Loss 0.5057 | Time(s) 3.4703 | Accuracy: 77.894939\n",
            "Epoch 00149 | Loss 0.5728 | Time(s) 3.4703 | Accuracy: 77.885353\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.144682 seconds\n",
            "Epoch 00000 | Loss 1.8841 | Time(s) 3.4228 | Accuracy: 13.353144\n",
            "Epoch 00001 | Loss 1.8391 | Time(s) 3.4418 | Accuracy: 31.825153\n",
            "Epoch 00002 | Loss 1.6173 | Time(s) 3.4451 | Accuracy: 41.075537\n",
            "Epoch 00003 | Loss 1.4459 | Time(s) 3.4682 | Accuracy: 48.159509\n",
            "Epoch 00004 | Loss 1.2694 | Time(s) 3.4615 | Accuracy: 54.601227\n",
            "Epoch 00005 | Loss 1.0441 | Time(s) 3.4658 | Accuracy: 54.697086\n",
            "Epoch 00006 | Loss 1.1329 | Time(s) 3.4603 | Accuracy: 55.243482\n",
            "Epoch 00007 | Loss 0.9716 | Time(s) 3.4490 | Accuracy: 56.115798\n",
            "Epoch 00008 | Loss 1.1198 | Time(s) 3.4398 | Accuracy: 55.933666\n",
            "Epoch 00009 | Loss 1.4526 | Time(s) 3.4329 | Accuracy: 55.483129\n",
            "Epoch 00010 | Loss 1.1297 | Time(s) 3.4337 | Accuracy: 56.412960\n",
            "Epoch 00011 | Loss 0.7972 | Time(s) 3.4300 | Accuracy: 55.550230\n",
            "Epoch 00012 | Loss 0.8180 | Time(s) 3.4257 | Accuracy: 57.620782\n",
            "Epoch 00013 | Loss 1.0150 | Time(s) 3.4223 | Accuracy: 57.620782\n",
            "Epoch 00014 | Loss 0.8070 | Time(s) 3.4248 | Accuracy: 56.911426\n",
            "Epoch 00015 | Loss 0.7248 | Time(s) 3.4286 | Accuracy: 57.381135\n",
            "Epoch 00016 | Loss 0.8953 | Time(s) 3.4277 | Accuracy: 57.716641\n",
            "Epoch 00017 | Loss 0.7558 | Time(s) 3.4266 | Accuracy: 58.320552\n",
            "Epoch 00018 | Loss 0.8797 | Time(s) 3.4250 | Accuracy: 58.684816\n",
            "Epoch 00019 | Loss 0.7605 | Time(s) 3.4265 | Accuracy: 58.167178\n",
            "Epoch 00020 | Loss 0.8177 | Time(s) 3.4243 | Accuracy: 58.052147\n",
            "Epoch 00021 | Loss 0.7906 | Time(s) 3.4232 | Accuracy: 57.937117\n",
            "Epoch 00022 | Loss 0.6734 | Time(s) 3.4211 | Accuracy: 58.157592\n",
            "Epoch 00023 | Loss 0.7413 | Time(s) 3.4237 | Accuracy: 58.358896\n",
            "Epoch 00024 | Loss 0.9753 | Time(s) 3.4283 | Accuracy: 58.358896\n",
            "Epoch 00025 | Loss 0.7306 | Time(s) 3.4286 | Accuracy: 58.521856\n",
            "Epoch 00026 | Loss 0.8645 | Time(s) 3.4270 | Accuracy: 58.138420\n",
            "Epoch 00027 | Loss 0.6572 | Time(s) 3.4287 | Accuracy: 57.870015\n",
            "Epoch 00028 | Loss 0.8725 | Time(s) 3.4310 | Accuracy: 57.898773\n",
            "Epoch 00029 | Loss 0.7553 | Time(s) 3.4320 | Accuracy: 57.707055\n",
            "Epoch 00030 | Loss 1.0481 | Time(s) 3.4312 | Accuracy: 57.553681\n",
            "Epoch 00031 | Loss 0.8469 | Time(s) 3.4340 | Accuracy: 57.563267\n",
            "Epoch 00032 | Loss 0.7285 | Time(s) 3.4368 | Accuracy: 57.572853\n",
            "Epoch 00033 | Loss 1.0007 | Time(s) 3.4364 | Accuracy: 57.783742\n",
            "Epoch 00034 | Loss 0.8057 | Time(s) 3.4351 | Accuracy: 57.822086\n",
            "Epoch 00035 | Loss 0.9004 | Time(s) 3.4336 | Accuracy: 57.438650\n",
            "Epoch 00036 | Loss 0.7728 | Time(s) 3.4348 | Accuracy: 57.218175\n",
            "Epoch 00037 | Loss 0.9065 | Time(s) 3.4334 | Accuracy: 56.489647\n",
            "Epoch 00038 | Loss 0.8607 | Time(s) 3.4327 | Accuracy: 56.403374\n",
            "Epoch 00039 | Loss 0.8890 | Time(s) 3.4324 | Accuracy: 57.045629\n",
            "Epoch 00040 | Loss 0.9986 | Time(s) 3.4340 | Accuracy: 57.400307\n",
            "Epoch 00041 | Loss 1.5004 | Time(s) 3.4334 | Accuracy: 57.697469\n",
            "Epoch 00042 | Loss 1.0008 | Time(s) 3.4326 | Accuracy: 57.419479\n",
            "Epoch 00043 | Loss 0.7894 | Time(s) 3.4325 | Accuracy: 57.007285\n",
            "Epoch 00044 | Loss 0.8689 | Time(s) 3.4328 | Accuracy: 56.719709\n",
            "Epoch 00045 | Loss 0.8094 | Time(s) 3.4340 | Accuracy: 55.828221\n",
            "Epoch 00046 | Loss 0.7299 | Time(s) 3.4332 | Accuracy: 56.374617\n",
            "Epoch 00047 | Loss 0.7100 | Time(s) 3.4344 | Accuracy: 57.793328\n",
            "Epoch 00048 | Loss 0.8308 | Time(s) 3.4353 | Accuracy: 57.831672\n",
            "Epoch 00049 | Loss 0.8263 | Time(s) 3.4370 | Accuracy: 57.917945\n",
            "Epoch 00050 | Loss 0.7490 | Time(s) 3.4402 | Accuracy: 57.812500\n",
            "Epoch 00051 | Loss 0.8491 | Time(s) 3.4402 | Accuracy: 58.042561\n",
            "Epoch 00052 | Loss 0.6971 | Time(s) 3.4394 | Accuracy: 57.429064\n",
            "Epoch 00053 | Loss 0.7484 | Time(s) 3.4389 | Accuracy: 57.122316\n",
            "Epoch 00054 | Loss 0.8475 | Time(s) 3.4397 | Accuracy: 57.342791\n",
            "Epoch 00055 | Loss 0.7089 | Time(s) 3.4395 | Accuracy: 57.601610\n",
            "Epoch 00056 | Loss 1.0896 | Time(s) 3.4394 | Accuracy: 57.400307\n",
            "Epoch 00057 | Loss 0.8529 | Time(s) 3.4393 | Accuracy: 57.889187\n",
            "Epoch 00058 | Loss 0.7428 | Time(s) 3.4406 | Accuracy: 58.061733\n",
            "Epoch 00059 | Loss 0.8443 | Time(s) 3.4399 | Accuracy: 57.697469\n",
            "Epoch 00060 | Loss 0.6681 | Time(s) 3.4404 | Accuracy: 57.160660\n",
            "Epoch 00061 | Loss 0.7215 | Time(s) 3.4394 | Accuracy: 57.409893\n",
            "Epoch 00062 | Loss 0.6219 | Time(s) 3.4400 | Accuracy: 57.151074\n",
            "Epoch 00063 | Loss 0.6653 | Time(s) 3.4398 | Accuracy: 57.246933\n",
            "Epoch 00064 | Loss 0.7928 | Time(s) 3.4393 | Accuracy: 57.208589\n",
            "Epoch 00065 | Loss 0.8202 | Time(s) 3.4388 | Accuracy: 56.949770\n",
            "Epoch 00066 | Loss 0.7126 | Time(s) 3.4398 | Accuracy: 57.083972\n",
            "Epoch 00067 | Loss 0.7049 | Time(s) 3.4406 | Accuracy: 57.189417\n",
            "Epoch 00068 | Loss 0.6699 | Time(s) 3.4410 | Accuracy: 57.208589\n",
            "Epoch 00069 | Loss 0.7178 | Time(s) 3.4404 | Accuracy: 57.544095\n",
            "Epoch 00070 | Loss 1.0339 | Time(s) 3.4402 | Accuracy: 57.476994\n",
            "Epoch 00071 | Loss 0.7023 | Time(s) 3.4398 | Accuracy: 57.160660\n",
            "Epoch 00072 | Loss 0.7929 | Time(s) 3.4401 | Accuracy: 57.515337\n",
            "Epoch 00073 | Loss 0.6330 | Time(s) 3.4400 | Accuracy: 57.429064\n",
            "Epoch 00074 | Loss 0.6687 | Time(s) 3.4403 | Accuracy: 56.834739\n",
            "Epoch 00075 | Loss 0.6489 | Time(s) 3.4423 | Accuracy: 57.160660\n",
            "Epoch 00076 | Loss 1.2551 | Time(s) 3.4429 | Accuracy: 57.333206\n",
            "Epoch 00077 | Loss 0.7394 | Time(s) 3.4432 | Accuracy: 56.988113\n",
            "Epoch 00078 | Loss 1.0114 | Time(s) 3.4428 | Accuracy: 56.940184\n",
            "Epoch 00079 | Loss 0.7707 | Time(s) 3.4429 | Accuracy: 57.304448\n",
            "Epoch 00080 | Loss 0.8823 | Time(s) 3.4439 | Accuracy: 57.630368\n",
            "Epoch 00081 | Loss 0.8437 | Time(s) 3.4435 | Accuracy: 56.767638\n",
            "Epoch 00082 | Loss 0.6450 | Time(s) 3.4443 | Accuracy: 56.825153\n",
            "Epoch 00083 | Loss 0.6710 | Time(s) 3.4439 | Accuracy: 57.074387\n",
            "Epoch 00084 | Loss 0.8287 | Time(s) 3.4446 | Accuracy: 57.093558\n",
            "Epoch 00085 | Loss 1.2443 | Time(s) 3.4448 | Accuracy: 57.294862\n",
            "Epoch 00086 | Loss 0.7734 | Time(s) 3.4448 | Accuracy: 57.735813\n",
            "Epoch 00087 | Loss 0.8046 | Time(s) 3.4449 | Accuracy: 56.988113\n",
            "Epoch 00088 | Loss 0.7207 | Time(s) 3.4444 | Accuracy: 56.508819\n",
            "Epoch 00089 | Loss 0.8441 | Time(s) 3.4461 | Accuracy: 57.333206\n",
            "Epoch 00090 | Loss 0.6893 | Time(s) 3.4455 | Accuracy: 57.342791\n",
            "Epoch 00091 | Loss 1.1403 | Time(s) 3.4455 | Accuracy: 57.409893\n",
            "Epoch 00092 | Loss 0.6568 | Time(s) 3.4454 | Accuracy: 57.342791\n",
            "Epoch 00093 | Loss 0.8009 | Time(s) 3.4469 | Accuracy: 57.467408\n",
            "Epoch 00094 | Loss 0.8034 | Time(s) 3.4467 | Accuracy: 57.227761\n",
            "Epoch 00095 | Loss 0.8065 | Time(s) 3.4478 | Accuracy: 56.863497\n",
            "Epoch 00096 | Loss 0.6911 | Time(s) 3.4503 | Accuracy: 56.834739\n",
            "Epoch 00097 | Loss 0.6617 | Time(s) 3.4534 | Accuracy: 57.103144\n",
            "Epoch 00098 | Loss 0.7715 | Time(s) 3.4578 | Accuracy: 57.179831\n",
            "Epoch 00099 | Loss 0.6785 | Time(s) 3.4626 | Accuracy: 56.892255\n",
            "Epoch 00100 | Loss 0.8049 | Time(s) 3.4642 | Accuracy: 56.671779\n",
            "Epoch 00101 | Loss 1.1056 | Time(s) 3.4651 | Accuracy: 57.333206\n",
            "Epoch 00102 | Loss 0.7200 | Time(s) 3.4667 | Accuracy: 57.199003\n",
            "Epoch 00103 | Loss 1.0064 | Time(s) 3.4682 | Accuracy: 57.285276\n",
            "Epoch 00104 | Loss 0.6988 | Time(s) 3.4691 | Accuracy: 57.199003\n",
            "Epoch 00105 | Loss 0.7947 | Time(s) 3.4692 | Accuracy: 57.160660\n",
            "Epoch 00106 | Loss 0.7572 | Time(s) 3.4686 | Accuracy: 57.189417\n",
            "Epoch 00107 | Loss 0.6693 | Time(s) 3.4684 | Accuracy: 57.151074\n",
            "Epoch 00108 | Loss 0.8014 | Time(s) 3.4678 | Accuracy: 56.623850\n",
            "Epoch 00109 | Loss 0.6965 | Time(s) 3.4682 | Accuracy: 57.026457\n",
            "Epoch 00110 | Loss 0.6684 | Time(s) 3.4681 | Accuracy: 57.275690\n",
            "Epoch 00111 | Loss 0.6431 | Time(s) 3.4681 | Accuracy: 57.227761\n",
            "Epoch 00112 | Loss 0.6977 | Time(s) 3.4680 | Accuracy: 57.572853\n",
            "Epoch 00113 | Loss 0.7939 | Time(s) 3.4677 | Accuracy: 57.208589\n",
            "Epoch 00114 | Loss 0.9857 | Time(s) 3.4678 | Accuracy: 57.476994\n",
            "Epoch 00115 | Loss 0.6374 | Time(s) 3.4676 | Accuracy: 57.467408\n",
            "Epoch 00116 | Loss 0.7048 | Time(s) 3.4679 | Accuracy: 57.189417\n",
            "Epoch 00117 | Loss 0.7815 | Time(s) 3.4674 | Accuracy: 57.036043\n",
            "Epoch 00118 | Loss 0.5891 | Time(s) 3.4676 | Accuracy: 56.930598\n",
            "Epoch 00119 | Loss 0.8108 | Time(s) 3.4678 | Accuracy: 57.007285\n",
            "Epoch 00120 | Loss 0.6047 | Time(s) 3.4672 | Accuracy: 56.968942\n",
            "Epoch 00121 | Loss 0.7706 | Time(s) 3.4668 | Accuracy: 56.719709\n",
            "Epoch 00122 | Loss 0.7636 | Time(s) 3.4663 | Accuracy: 56.518405\n",
            "Epoch 00123 | Loss 0.7426 | Time(s) 3.4664 | Accuracy: 56.643021\n",
            "Epoch 00124 | Loss 0.8414 | Time(s) 3.4659 | Accuracy: 56.978528\n",
            "Epoch 00125 | Loss 0.6401 | Time(s) 3.4659 | Accuracy: 57.304448\n",
            "Epoch 00126 | Loss 0.9105 | Time(s) 3.4657 | Accuracy: 57.390721\n",
            "Epoch 00127 | Loss 0.6218 | Time(s) 3.4656 | Accuracy: 57.275690\n",
            "Epoch 00128 | Loss 0.8298 | Time(s) 3.4647 | Accuracy: 57.074387\n",
            "Epoch 00129 | Loss 0.7463 | Time(s) 3.4644 | Accuracy: 57.045629\n",
            "Epoch 00130 | Loss 0.6529 | Time(s) 3.4642 | Accuracy: 57.016871\n",
            "Epoch 00131 | Loss 0.7785 | Time(s) 3.4643 | Accuracy: 57.160660\n",
            "Epoch 00132 | Loss 0.5910 | Time(s) 3.4639 | Accuracy: 56.758052\n",
            "Epoch 00133 | Loss 0.7127 | Time(s) 3.4642 | Accuracy: 56.681365\n",
            "Epoch 00134 | Loss 0.7360 | Time(s) 3.4647 | Accuracy: 56.988113\n",
            "Epoch 00135 | Loss 0.6874 | Time(s) 3.4649 | Accuracy: 57.055215\n",
            "Epoch 00136 | Loss 0.7430 | Time(s) 3.4650 | Accuracy: 56.988113\n",
            "Epoch 00137 | Loss 0.5964 | Time(s) 3.4646 | Accuracy: 56.575920\n",
            "Epoch 00138 | Loss 0.7416 | Time(s) 3.4644 | Accuracy: 57.266104\n",
            "Epoch 00139 | Loss 0.7436 | Time(s) 3.4645 | Accuracy: 57.093558\n",
            "Epoch 00140 | Loss 0.6865 | Time(s) 3.4642 | Accuracy: 56.940184\n",
            "Epoch 00141 | Loss 0.6540 | Time(s) 3.4641 | Accuracy: 57.170245\n",
            "Epoch 00142 | Loss 0.6739 | Time(s) 3.4641 | Accuracy: 56.786810\n",
            "Epoch 00143 | Loss 0.7502 | Time(s) 3.4637 | Accuracy: 56.384202\n",
            "Epoch 00144 | Loss 0.8051 | Time(s) 3.4643 | Accuracy: 57.036043\n",
            "Epoch 00145 | Loss 0.6509 | Time(s) 3.4643 | Accuracy: 57.026457\n",
            "Epoch 00146 | Loss 0.7205 | Time(s) 3.4638 | Accuracy: 56.825153\n",
            "Epoch 00147 | Loss 0.6488 | Time(s) 3.4633 | Accuracy: 57.093558\n",
            "Epoch 00148 | Loss 0.6531 | Time(s) 3.4632 | Accuracy: 57.016871\n",
            "Epoch 00149 | Loss 0.9520 | Time(s) 3.4632 | Accuracy: 57.151074\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.024025 seconds\n",
            "Epoch 00000 | Loss 1.9184 | Time(s) 3.4808 | Accuracy: 16.113880\n",
            "Epoch 00001 | Loss 1.8245 | Time(s) 3.4734 | Accuracy: 27.578604\n",
            "Epoch 00002 | Loss 1.6656 | Time(s) 3.4810 | Accuracy: 29.380752\n",
            "Epoch 00003 | Loss 1.4700 | Time(s) 3.4702 | Accuracy: 31.758052\n",
            "Epoch 00004 | Loss 1.4989 | Time(s) 3.4594 | Accuracy: 36.761887\n",
            "Epoch 00005 | Loss 1.5319 | Time(s) 3.4590 | Accuracy: 37.538344\n",
            "Epoch 00006 | Loss 1.5860 | Time(s) 3.4547 | Accuracy: 37.873850\n",
            "Epoch 00007 | Loss 1.5201 | Time(s) 3.4642 | Accuracy: 38.650307\n",
            "Epoch 00008 | Loss 1.5067 | Time(s) 3.4584 | Accuracy: 38.410660\n",
            "Epoch 00009 | Loss 1.3725 | Time(s) 3.4646 | Accuracy: 38.247699\n",
            "Epoch 00010 | Loss 1.3485 | Time(s) 3.4577 | Accuracy: 38.477761\n",
            "Epoch 00011 | Loss 1.4443 | Time(s) 3.4573 | Accuracy: 38.199770\n",
            "Epoch 00012 | Loss 1.2902 | Time(s) 3.4580 | Accuracy: 38.391488\n",
            "Epoch 00013 | Loss 1.3486 | Time(s) 3.4607 | Accuracy: 38.525690\n",
            "Epoch 00014 | Loss 1.4233 | Time(s) 3.4558 | Accuracy: 38.535276\n",
            "Epoch 00015 | Loss 1.4635 | Time(s) 3.4559 | Accuracy: 38.842025\n",
            "Epoch 00016 | Loss 1.5799 | Time(s) 3.4533 | Accuracy: 39.043328\n",
            "Epoch 00017 | Loss 1.5670 | Time(s) 3.4598 | Accuracy: 39.196702\n",
            "Epoch 00018 | Loss 1.5204 | Time(s) 3.4590 | Accuracy: 38.976227\n",
            "Epoch 00019 | Loss 1.3357 | Time(s) 3.4544 | Accuracy: 38.544862\n",
            "Epoch 00020 | Loss 1.2630 | Time(s) 3.4518 | Accuracy: 38.065567\n",
            "Epoch 00021 | Loss 1.4177 | Time(s) 3.4484 | Accuracy: 38.621549\n",
            "Epoch 00022 | Loss 1.3121 | Time(s) 3.4490 | Accuracy: 38.506518\n",
            "Epoch 00023 | Loss 1.4637 | Time(s) 3.4495 | Accuracy: 38.180598\n",
            "Epoch 00024 | Loss 1.4299 | Time(s) 3.4484 | Accuracy: 38.784509\n",
            "Epoch 00025 | Loss 1.2595 | Time(s) 3.4462 | Accuracy: 38.180598\n",
            "Epoch 00026 | Loss 1.4083 | Time(s) 3.4498 | Accuracy: 38.151840\n",
            "Epoch 00027 | Loss 1.3193 | Time(s) 3.4509 | Accuracy: 38.583206\n",
            "Epoch 00028 | Loss 1.3126 | Time(s) 3.4512 | Accuracy: 38.861196\n",
            "Epoch 00029 | Loss 1.5716 | Time(s) 3.4502 | Accuracy: 39.139187\n",
            "Epoch 00030 | Loss 1.5027 | Time(s) 3.4494 | Accuracy: 39.052914\n",
            "Epoch 00031 | Loss 1.4564 | Time(s) 3.4484 | Accuracy: 38.880368\n",
            "Epoch 00032 | Loss 1.4192 | Time(s) 3.4469 | Accuracy: 38.889954\n",
            "Epoch 00033 | Loss 1.3299 | Time(s) 3.4474 | Accuracy: 38.717408\n",
            "Epoch 00034 | Loss 1.4596 | Time(s) 3.4472 | Accuracy: 38.535276\n",
            "Epoch 00035 | Loss 1.3034 | Time(s) 3.4481 | Accuracy: 38.410660\n",
            "Epoch 00036 | Loss 1.2490 | Time(s) 3.4470 | Accuracy: 38.525690\n",
            "Epoch 00037 | Loss 1.2169 | Time(s) 3.4463 | Accuracy: 39.052914\n",
            "Epoch 00038 | Loss 1.2775 | Time(s) 3.4447 | Accuracy: 38.410660\n",
            "Epoch 00039 | Loss 1.2996 | Time(s) 3.4458 | Accuracy: 38.516104\n",
            "Epoch 00040 | Loss 1.4499 | Time(s) 3.4445 | Accuracy: 38.707822\n",
            "Epoch 00041 | Loss 1.2443 | Time(s) 3.4434 | Accuracy: 38.401074\n",
            "Epoch 00042 | Loss 1.4484 | Time(s) 3.4423 | Accuracy: 38.842025\n",
            "Epoch 00043 | Loss 1.5090 | Time(s) 3.4442 | Accuracy: 38.669479\n",
            "Epoch 00044 | Loss 1.3062 | Time(s) 3.4438 | Accuracy: 38.429831\n",
            "Epoch 00045 | Loss 1.3742 | Time(s) 3.4438 | Accuracy: 38.698236\n",
            "Epoch 00046 | Loss 1.4303 | Time(s) 3.4426 | Accuracy: 38.832439\n",
            "Epoch 00047 | Loss 1.3686 | Time(s) 3.4425 | Accuracy: 38.506518\n",
            "Epoch 00048 | Loss 1.4290 | Time(s) 3.4447 | Accuracy: 38.640721\n",
            "Epoch 00049 | Loss 1.5223 | Time(s) 3.4440 | Accuracy: 38.247699\n",
            "Epoch 00050 | Loss 1.4578 | Time(s) 3.4427 | Accuracy: 38.439417\n",
            "Epoch 00051 | Loss 1.2607 | Time(s) 3.4426 | Accuracy: 38.698236\n",
            "Epoch 00052 | Loss 1.2818 | Time(s) 3.4438 | Accuracy: 38.899540\n",
            "Epoch 00053 | Loss 1.4159 | Time(s) 3.4432 | Accuracy: 38.918712\n",
            "Epoch 00054 | Loss 1.3890 | Time(s) 3.4424 | Accuracy: 38.726994\n",
            "Epoch 00055 | Loss 1.3377 | Time(s) 3.4419 | Accuracy: 38.602377\n",
            "Epoch 00056 | Loss 1.3727 | Time(s) 3.4412 | Accuracy: 38.861196\n",
            "Epoch 00057 | Loss 1.4442 | Time(s) 3.4407 | Accuracy: 38.669479\n",
            "Epoch 00058 | Loss 1.3143 | Time(s) 3.4400 | Accuracy: 38.621549\n",
            "Epoch 00059 | Loss 1.4640 | Time(s) 3.4407 | Accuracy: 38.736580\n",
            "Epoch 00060 | Loss 1.3079 | Time(s) 3.4396 | Accuracy: 38.544862\n",
            "Epoch 00061 | Loss 1.4307 | Time(s) 3.4402 | Accuracy: 38.458589\n",
            "Epoch 00062 | Loss 1.3768 | Time(s) 3.4396 | Accuracy: 38.218942\n",
            "Epoch 00063 | Loss 1.4136 | Time(s) 3.4388 | Accuracy: 38.410660\n",
            "Epoch 00064 | Loss 1.5519 | Time(s) 3.4377 | Accuracy: 38.842025\n",
            "Epoch 00065 | Loss 1.3095 | Time(s) 3.4374 | Accuracy: 38.381902\n",
            "Epoch 00066 | Loss 1.5027 | Time(s) 3.4368 | Accuracy: 38.995399\n",
            "Epoch 00067 | Loss 1.2949 | Time(s) 3.4362 | Accuracy: 39.024156\n",
            "Epoch 00068 | Loss 1.3736 | Time(s) 3.4357 | Accuracy: 38.468175\n",
            "Epoch 00069 | Loss 1.3550 | Time(s) 3.4360 | Accuracy: 38.305215\n",
            "Epoch 00070 | Loss 1.2943 | Time(s) 3.4367 | Accuracy: 38.573620\n",
            "Epoch 00071 | Loss 1.5570 | Time(s) 3.4373 | Accuracy: 38.832439\n",
            "Epoch 00072 | Loss 1.4499 | Time(s) 3.4364 | Accuracy: 38.774923\n",
            "Epoch 00073 | Loss 1.5087 | Time(s) 3.4373 | Accuracy: 38.937883\n",
            "Epoch 00074 | Loss 1.4427 | Time(s) 3.4380 | Accuracy: 38.410660\n",
            "Epoch 00075 | Loss 1.2868 | Time(s) 3.4376 | Accuracy: 38.659893\n",
            "Epoch 00076 | Loss 1.3292 | Time(s) 3.4389 | Accuracy: 38.468175\n",
            "Epoch 00077 | Loss 1.3560 | Time(s) 3.4391 | Accuracy: 38.276457\n",
            "Epoch 00078 | Loss 1.2868 | Time(s) 3.4409 | Accuracy: 38.506518\n",
            "Epoch 00079 | Loss 1.2937 | Time(s) 3.4407 | Accuracy: 38.583206\n",
            "Epoch 00080 | Loss 1.2865 | Time(s) 3.4407 | Accuracy: 38.554448\n",
            "Epoch 00081 | Loss 1.5134 | Time(s) 3.4405 | Accuracy: 38.468175\n",
            "Epoch 00082 | Loss 1.4618 | Time(s) 3.4407 | Accuracy: 37.969709\n",
            "Epoch 00083 | Loss 1.2578 | Time(s) 3.4410 | Accuracy: 38.506518\n",
            "Epoch 00084 | Loss 1.2976 | Time(s) 3.4400 | Accuracy: 38.525690\n",
            "Epoch 00085 | Loss 1.2888 | Time(s) 3.4391 | Accuracy: 39.004985\n",
            "Epoch 00086 | Loss 1.4205 | Time(s) 3.4390 | Accuracy: 38.899540\n",
            "Epoch 00087 | Loss 1.3020 | Time(s) 3.4399 | Accuracy: 38.688650\n",
            "Epoch 00088 | Loss 1.4542 | Time(s) 3.4405 | Accuracy: 37.979294\n",
            "Epoch 00089 | Loss 1.3569 | Time(s) 3.4413 | Accuracy: 37.020706\n",
            "Epoch 00090 | Loss 1.4462 | Time(s) 3.4407 | Accuracy: 38.103911\n",
            "Epoch 00091 | Loss 1.2846 | Time(s) 3.4403 | Accuracy: 38.784509\n",
            "Epoch 00092 | Loss 1.4406 | Time(s) 3.4401 | Accuracy: 38.842025\n",
            "Epoch 00093 | Loss 1.2857 | Time(s) 3.4399 | Accuracy: 38.506518\n",
            "Epoch 00094 | Loss 1.3694 | Time(s) 3.4395 | Accuracy: 38.343558\n",
            "Epoch 00095 | Loss 1.3856 | Time(s) 3.4397 | Accuracy: 37.662960\n",
            "Epoch 00096 | Loss 1.4819 | Time(s) 3.4401 | Accuracy: 37.509586\n",
            "Epoch 00097 | Loss 1.5182 | Time(s) 3.4393 | Accuracy: 37.452071\n",
            "Epoch 00098 | Loss 1.2855 | Time(s) 3.4389 | Accuracy: 37.921779\n",
            "Epoch 00099 | Loss 1.3636 | Time(s) 3.4386 | Accuracy: 38.401074\n",
            "Epoch 00100 | Loss 1.3223 | Time(s) 3.4385 | Accuracy: 38.161426\n",
            "Epoch 00101 | Loss 1.2731 | Time(s) 3.4394 | Accuracy: 38.468175\n",
            "Epoch 00102 | Loss 1.3599 | Time(s) 3.4395 | Accuracy: 38.094325\n",
            "Epoch 00103 | Loss 1.3023 | Time(s) 3.4399 | Accuracy: 37.317868\n",
            "Epoch 00104 | Loss 1.4328 | Time(s) 3.4408 | Accuracy: 38.075153\n",
            "Epoch 00105 | Loss 1.4232 | Time(s) 3.4412 | Accuracy: 37.979294\n",
            "Epoch 00106 | Loss 1.4232 | Time(s) 3.4406 | Accuracy: 38.353144\n",
            "Epoch 00107 | Loss 1.3438 | Time(s) 3.4409 | Accuracy: 38.688650\n",
            "Epoch 00108 | Loss 1.2639 | Time(s) 3.4406 | Accuracy: 38.957055\n",
            "Epoch 00109 | Loss 1.3267 | Time(s) 3.4405 | Accuracy: 38.784509\n",
            "Epoch 00110 | Loss 1.2274 | Time(s) 3.4417 | Accuracy: 38.554448\n",
            "Epoch 00111 | Loss 1.2850 | Time(s) 3.4415 | Accuracy: 38.449003\n",
            "Epoch 00112 | Loss 1.6223 | Time(s) 3.4424 | Accuracy: 38.372316\n",
            "Epoch 00113 | Loss 1.3319 | Time(s) 3.4427 | Accuracy: 38.573620\n",
            "Epoch 00114 | Loss 1.4660 | Time(s) 3.4422 | Accuracy: 38.286043\n",
            "Epoch 00115 | Loss 1.4371 | Time(s) 3.4417 | Accuracy: 37.586273\n",
            "Epoch 00116 | Loss 1.4552 | Time(s) 3.4421 | Accuracy: 38.171012\n",
            "Epoch 00117 | Loss 1.2754 | Time(s) 3.4419 | Accuracy: 38.084739\n",
            "Epoch 00118 | Loss 1.3879 | Time(s) 3.4420 | Accuracy: 38.592791\n",
            "Epoch 00119 | Loss 1.4626 | Time(s) 3.4417 | Accuracy: 38.832439\n",
            "Epoch 00120 | Loss 1.4203 | Time(s) 3.4421 | Accuracy: 38.496933\n",
            "Epoch 00121 | Loss 1.3524 | Time(s) 3.4415 | Accuracy: 38.449003\n",
            "Epoch 00122 | Loss 1.4410 | Time(s) 3.4417 | Accuracy: 38.429831\n",
            "Epoch 00123 | Loss 1.2926 | Time(s) 3.4418 | Accuracy: 38.142255\n",
            "Epoch 00124 | Loss 1.4853 | Time(s) 3.4412 | Accuracy: 38.314801\n",
            "Epoch 00125 | Loss 1.3274 | Time(s) 3.4408 | Accuracy: 37.902607\n",
            "Epoch 00126 | Loss 1.3995 | Time(s) 3.4407 | Accuracy: 38.343558\n",
            "Epoch 00127 | Loss 1.4457 | Time(s) 3.4402 | Accuracy: 38.496933\n",
            "Epoch 00128 | Loss 1.3658 | Time(s) 3.4401 | Accuracy: 38.410660\n",
            "Epoch 00129 | Loss 1.3505 | Time(s) 3.4397 | Accuracy: 38.477761\n",
            "Epoch 00130 | Loss 1.3663 | Time(s) 3.4398 | Accuracy: 38.602377\n",
            "Epoch 00131 | Loss 1.4214 | Time(s) 3.4401 | Accuracy: 38.621549\n",
            "Epoch 00132 | Loss 1.3460 | Time(s) 3.4401 | Accuracy: 38.535276\n",
            "Epoch 00133 | Loss 1.2731 | Time(s) 3.4404 | Accuracy: 38.822853\n",
            "Epoch 00134 | Loss 1.2268 | Time(s) 3.4401 | Accuracy: 38.822853\n",
            "Epoch 00135 | Loss 1.4015 | Time(s) 3.4400 | Accuracy: 39.062500\n",
            "Epoch 00136 | Loss 1.3680 | Time(s) 3.4404 | Accuracy: 38.899540\n",
            "Epoch 00137 | Loss 1.4414 | Time(s) 3.4406 | Accuracy: 38.372316\n",
            "Epoch 00138 | Loss 1.2335 | Time(s) 3.4402 | Accuracy: 38.151840\n",
            "Epoch 00139 | Loss 1.3319 | Time(s) 3.4408 | Accuracy: 38.496933\n",
            "Epoch 00140 | Loss 1.3627 | Time(s) 3.4404 | Accuracy: 38.094325\n",
            "Epoch 00141 | Loss 1.4791 | Time(s) 3.4405 | Accuracy: 38.209356\n",
            "Epoch 00142 | Loss 1.4821 | Time(s) 3.4402 | Accuracy: 38.401074\n",
            "Epoch 00143 | Loss 1.4027 | Time(s) 3.4397 | Accuracy: 38.650307\n",
            "Epoch 00144 | Loss 1.5536 | Time(s) 3.4395 | Accuracy: 38.842025\n",
            "Epoch 00145 | Loss 1.3081 | Time(s) 3.4394 | Accuracy: 38.688650\n",
            "Epoch 00146 | Loss 1.4385 | Time(s) 3.4388 | Accuracy: 38.669479\n",
            "Epoch 00147 | Loss 1.3903 | Time(s) 3.4384 | Accuracy: 38.084739\n",
            "Epoch 00148 | Loss 1.4539 | Time(s) 3.4389 | Accuracy: 38.190184\n",
            "Epoch 00149 | Loss 1.2098 | Time(s) 3.4386 | Accuracy: 38.611963\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "4.926095 seconds\n",
            "Epoch 00000 | Loss 1.8076 | Time(s) 3.5009 | Accuracy: 27.664877\n",
            "Epoch 00001 | Loss 1.4559 | Time(s) 3.4617 | Accuracy: 41.458972\n",
            "Epoch 00002 | Loss 0.9792 | Time(s) 3.4754 | Accuracy: 49.300230\n",
            "Epoch 00003 | Loss 0.9655 | Time(s) 3.4763 | Accuracy: 64.944402\n",
            "Epoch 00004 | Loss 0.9564 | Time(s) 3.4717 | Accuracy: 69.804448\n",
            "Epoch 00005 | Loss 0.6805 | Time(s) 3.4662 | Accuracy: 70.782209\n",
            "Epoch 00006 | Loss 0.8335 | Time(s) 3.4566 | Accuracy: 71.481979\n",
            "Epoch 00007 | Loss 0.6163 | Time(s) 3.4506 | Accuracy: 72.728144\n",
            "Epoch 00008 | Loss 0.8985 | Time(s) 3.4446 | Accuracy: 73.159509\n",
            "Epoch 00009 | Loss 0.6400 | Time(s) 3.4423 | Accuracy: 73.197853\n",
            "Epoch 00010 | Loss 0.4100 | Time(s) 3.4409 | Accuracy: 73.600460\n",
            "Epoch 00011 | Loss 0.5426 | Time(s) 3.4403 | Accuracy: 73.696319\n",
            "Epoch 00012 | Loss 0.4711 | Time(s) 3.4373 | Accuracy: 73.792178\n",
            "Epoch 00013 | Loss 0.4893 | Time(s) 3.4421 | Accuracy: 73.303298\n",
            "Epoch 00014 | Loss 0.8706 | Time(s) 3.4450 | Accuracy: 73.389571\n",
            "Epoch 00015 | Loss 0.5353 | Time(s) 3.4443 | Accuracy: 73.725077\n",
            "Epoch 00016 | Loss 0.6793 | Time(s) 3.4418 | Accuracy: 73.648390\n",
            "Epoch 00017 | Loss 0.7647 | Time(s) 3.4429 | Accuracy: 72.824003\n",
            "Epoch 00018 | Loss 0.4437 | Time(s) 3.4435 | Accuracy: 72.689801\n",
            "Epoch 00019 | Loss 1.0543 | Time(s) 3.4439 | Accuracy: 73.322469\n",
            "Epoch 00020 | Loss 0.5049 | Time(s) 3.4435 | Accuracy: 73.485429\n",
            "Epoch 00021 | Loss 0.5584 | Time(s) 3.4437 | Accuracy: 71.750383\n",
            "Epoch 00022 | Loss 0.4641 | Time(s) 3.4465 | Accuracy: 73.801764\n",
            "Epoch 00023 | Loss 0.4464 | Time(s) 3.4458 | Accuracy: 74.127684\n",
            "Epoch 00024 | Loss 0.3448 | Time(s) 3.4436 | Accuracy: 74.089340\n",
            "Epoch 00025 | Loss 0.3744 | Time(s) 3.4420 | Accuracy: 73.773006\n",
            "Epoch 00026 | Loss 0.4193 | Time(s) 3.4413 | Accuracy: 73.667561\n",
            "Epoch 00027 | Loss 0.5776 | Time(s) 3.4411 | Accuracy: 73.849693\n",
            "Epoch 00028 | Loss 0.3593 | Time(s) 3.4389 | Accuracy: 74.511120\n",
            "Epoch 00029 | Loss 0.6922 | Time(s) 3.4452 | Accuracy: 74.405675\n",
            "Epoch 00030 | Loss 0.6513 | Time(s) 3.4488 | Accuracy: 73.820936\n",
            "Epoch 00031 | Loss 0.5413 | Time(s) 3.4495 | Accuracy: 74.587807\n",
            "Epoch 00032 | Loss 0.8082 | Time(s) 3.4478 | Accuracy: 74.012653\n",
            "Epoch 00033 | Loss 0.4089 | Time(s) 3.4476 | Accuracy: 74.367331\n",
            "Epoch 00034 | Loss 0.3977 | Time(s) 3.4459 | Accuracy: 74.031825\n",
            "Epoch 00035 | Loss 0.3523 | Time(s) 3.4447 | Accuracy: 74.146856\n",
            "Epoch 00036 | Loss 0.4589 | Time(s) 3.4433 | Accuracy: 74.578221\n",
            "Epoch 00037 | Loss 0.7035 | Time(s) 3.4452 | Accuracy: 74.434433\n",
            "Epoch 00038 | Loss 0.3679 | Time(s) 3.4476 | Accuracy: 74.348160\n",
            "Epoch 00039 | Loss 0.3535 | Time(s) 3.4531 | Accuracy: 74.223543\n",
            "Epoch 00040 | Loss 0.3638 | Time(s) 3.4551 | Accuracy: 73.696319\n",
            "Epoch 00041 | Loss 0.8334 | Time(s) 3.4554 | Accuracy: 74.022239\n",
            "Epoch 00042 | Loss 0.4928 | Time(s) 3.4548 | Accuracy: 73.619632\n",
            "Epoch 00043 | Loss 0.3379 | Time(s) 3.4550 | Accuracy: 73.763420\n",
            "Epoch 00044 | Loss 0.4651 | Time(s) 3.4570 | Accuracy: 73.638804\n",
            "Epoch 00045 | Loss 0.4400 | Time(s) 3.4554 | Accuracy: 74.357745\n",
            "Epoch 00046 | Loss 0.4314 | Time(s) 3.4558 | Accuracy: 73.351227\n",
            "Epoch 00047 | Loss 0.4377 | Time(s) 3.4573 | Accuracy: 73.773006\n",
            "Epoch 00048 | Loss 0.3597 | Time(s) 3.4594 | Accuracy: 74.089340\n",
            "Epoch 00049 | Loss 0.4657 | Time(s) 3.4577 | Accuracy: 74.098926\n",
            "Epoch 00050 | Loss 0.3981 | Time(s) 3.4573 | Accuracy: 74.424847\n",
            "Epoch 00051 | Loss 0.3788 | Time(s) 3.4570 | Accuracy: 74.606979\n",
            "Epoch 00052 | Loss 0.7072 | Time(s) 3.4565 | Accuracy: 74.309816\n",
            "Epoch 00053 | Loss 0.4274 | Time(s) 3.4562 | Accuracy: 74.041411\n",
            "Epoch 00054 | Loss 0.4711 | Time(s) 3.4558 | Accuracy: 74.396089\n",
            "Epoch 00055 | Loss 0.3992 | Time(s) 3.4555 | Accuracy: 73.514187\n",
            "Epoch 00056 | Loss 0.4479 | Time(s) 3.4568 | Accuracy: 74.127684\n",
            "Epoch 00057 | Loss 0.3281 | Time(s) 3.4563 | Accuracy: 74.386503\n",
            "Epoch 00058 | Loss 0.4552 | Time(s) 3.4558 | Accuracy: 74.031825\n",
            "Epoch 00059 | Loss 0.7652 | Time(s) 3.4558 | Accuracy: 74.405675\n",
            "Epoch 00060 | Loss 0.3695 | Time(s) 3.4543 | Accuracy: 73.284126\n",
            "Epoch 00061 | Loss 0.5395 | Time(s) 3.4541 | Accuracy: 72.967791\n",
            "Epoch 00062 | Loss 0.4522 | Time(s) 3.4531 | Accuracy: 71.894172\n",
            "Epoch 00063 | Loss 0.3501 | Time(s) 3.4527 | Accuracy: 73.130752\n",
            "Epoch 00064 | Loss 0.5127 | Time(s) 3.4520 | Accuracy: 73.945552\n",
            "Epoch 00065 | Loss 0.3353 | Time(s) 3.4539 | Accuracy: 72.632285\n",
            "Epoch 00066 | Loss 0.8309 | Time(s) 3.4551 | Accuracy: 74.405675\n",
            "Epoch 00067 | Loss 0.3884 | Time(s) 3.4546 | Accuracy: 73.830521\n",
            "Epoch 00068 | Loss 0.3783 | Time(s) 3.4546 | Accuracy: 73.801764\n",
            "Epoch 00069 | Loss 0.3253 | Time(s) 3.4551 | Accuracy: 74.098926\n",
            "Epoch 00070 | Loss 0.3105 | Time(s) 3.4545 | Accuracy: 74.252301\n",
            "Epoch 00071 | Loss 0.4119 | Time(s) 3.4548 | Accuracy: 74.003067\n",
            "Epoch 00072 | Loss 0.3547 | Time(s) 3.4563 | Accuracy: 73.974310\n",
            "Epoch 00073 | Loss 0.3652 | Time(s) 3.4568 | Accuracy: 73.686733\n",
            "Epoch 00074 | Loss 0.7814 | Time(s) 3.4586 | Accuracy: 73.082822\n",
            "Epoch 00075 | Loss 0.3172 | Time(s) 3.4584 | Accuracy: 73.466258\n",
            "Epoch 00076 | Loss 0.4486 | Time(s) 3.4585 | Accuracy: 74.166028\n",
            "Epoch 00077 | Loss 0.3261 | Time(s) 3.4576 | Accuracy: 73.236196\n",
            "Epoch 00078 | Loss 0.4488 | Time(s) 3.4576 | Accuracy: 73.495015\n",
            "Epoch 00079 | Loss 0.4080 | Time(s) 3.4572 | Accuracy: 73.197853\n",
            "Epoch 00080 | Loss 0.4010 | Time(s) 3.4571 | Accuracy: 73.926380\n",
            "Epoch 00081 | Loss 0.3712 | Time(s) 3.4567 | Accuracy: 73.514187\n",
            "Epoch 00082 | Loss 0.3389 | Time(s) 3.4575 | Accuracy: 74.472776\n",
            "Epoch 00083 | Loss 0.3418 | Time(s) 3.4582 | Accuracy: 73.370399\n",
            "Epoch 00084 | Loss 0.2952 | Time(s) 3.4575 | Accuracy: 73.830521\n",
            "Epoch 00085 | Loss 0.3019 | Time(s) 3.4573 | Accuracy: 73.840107\n",
            "Epoch 00086 | Loss 0.6667 | Time(s) 3.4569 | Accuracy: 73.610046\n",
            "Epoch 00087 | Loss 0.7172 | Time(s) 3.4579 | Accuracy: 73.408742\n",
            "Epoch 00088 | Loss 0.3931 | Time(s) 3.4574 | Accuracy: 73.859279\n",
            "Epoch 00089 | Loss 0.3439 | Time(s) 3.4576 | Accuracy: 74.539877\n",
            "Epoch 00090 | Loss 0.3030 | Time(s) 3.4574 | Accuracy: 74.070169\n",
            "Epoch 00091 | Loss 0.2979 | Time(s) 3.4574 | Accuracy: 74.050997\n",
            "Epoch 00092 | Loss 0.3751 | Time(s) 3.4578 | Accuracy: 74.501534\n",
            "Epoch 00093 | Loss 0.2264 | Time(s) 3.4571 | Accuracy: 73.648390\n",
            "Epoch 00094 | Loss 0.3894 | Time(s) 3.4566 | Accuracy: 74.319402\n",
            "Epoch 00095 | Loss 0.2958 | Time(s) 3.4560 | Accuracy: 73.983896\n",
            "Epoch 00096 | Loss 0.3896 | Time(s) 3.4555 | Accuracy: 73.974310\n",
            "Epoch 00097 | Loss 0.3069 | Time(s) 3.4550 | Accuracy: 73.341641\n",
            "Epoch 00098 | Loss 0.6064 | Time(s) 3.4548 | Accuracy: 73.773006\n",
            "Epoch 00099 | Loss 0.4052 | Time(s) 3.4547 | Accuracy: 73.274540\n",
            "Epoch 00100 | Loss 0.2732 | Time(s) 3.4549 | Accuracy: 74.089340\n",
            "Epoch 00101 | Loss 0.3039 | Time(s) 3.4552 | Accuracy: 74.396089\n",
            "Epoch 00102 | Loss 0.2007 | Time(s) 3.4559 | Accuracy: 73.705905\n",
            "Epoch 00103 | Loss 0.2247 | Time(s) 3.4564 | Accuracy: 73.840107\n",
            "Epoch 00104 | Loss 0.3189 | Time(s) 3.4565 | Accuracy: 74.453604\n",
            "Epoch 00105 | Loss 0.2904 | Time(s) 3.4566 | Accuracy: 74.012653\n",
            "Epoch 00106 | Loss 0.3287 | Time(s) 3.4567 | Accuracy: 73.744248\n",
            "Epoch 00107 | Loss 0.1961 | Time(s) 3.4574 | Accuracy: 73.600460\n",
            "Epoch 00108 | Loss 0.2876 | Time(s) 3.4589 | Accuracy: 73.715491\n",
            "Epoch 00109 | Loss 0.3073 | Time(s) 3.4596 | Accuracy: 73.705905\n",
            "Epoch 00110 | Loss 0.6670 | Time(s) 3.4597 | Accuracy: 73.935966\n",
            "Epoch 00111 | Loss 0.6021 | Time(s) 3.4600 | Accuracy: 73.878451\n",
            "Epoch 00112 | Loss 0.3004 | Time(s) 3.4596 | Accuracy: 73.667561\n",
            "Epoch 00113 | Loss 0.3368 | Time(s) 3.4598 | Accuracy: 73.159509\n",
            "Epoch 00114 | Loss 0.2393 | Time(s) 3.4595 | Accuracy: 73.169095\n",
            "Epoch 00115 | Loss 0.2831 | Time(s) 3.4593 | Accuracy: 73.648390\n",
            "Epoch 00116 | Loss 0.3788 | Time(s) 3.4589 | Accuracy: 74.118098\n",
            "Epoch 00117 | Loss 0.3009 | Time(s) 3.4599 | Accuracy: 73.744248\n",
            "Epoch 00118 | Loss 0.3919 | Time(s) 3.4601 | Accuracy: 73.916794\n",
            "Epoch 00119 | Loss 0.4064 | Time(s) 3.4597 | Accuracy: 73.811350\n",
            "Epoch 00120 | Loss 0.2986 | Time(s) 3.4595 | Accuracy: 73.217025\n",
            "Epoch 00121 | Loss 0.4115 | Time(s) 3.4594 | Accuracy: 73.332055\n",
            "Epoch 00122 | Loss 0.2852 | Time(s) 3.4594 | Accuracy: 73.888037\n",
            "Epoch 00123 | Loss 0.2120 | Time(s) 3.4598 | Accuracy: 74.175613\n",
            "Epoch 00124 | Loss 0.3554 | Time(s) 3.4599 | Accuracy: 74.444018\n",
            "Epoch 00125 | Loss 0.3718 | Time(s) 3.4607 | Accuracy: 74.482362\n",
            "Epoch 00126 | Loss 0.3596 | Time(s) 3.4609 | Accuracy: 74.166028\n",
            "Epoch 00127 | Loss 0.3304 | Time(s) 3.4613 | Accuracy: 74.118098\n",
            "Epoch 00128 | Loss 0.2658 | Time(s) 3.4617 | Accuracy: 74.098926\n",
            "Epoch 00129 | Loss 0.3848 | Time(s) 3.4620 | Accuracy: 74.166028\n",
            "Epoch 00130 | Loss 0.3318 | Time(s) 3.4623 | Accuracy: 74.127684\n",
            "Epoch 00131 | Loss 0.3503 | Time(s) 3.4624 | Accuracy: 74.290644\n",
            "Epoch 00132 | Loss 0.3538 | Time(s) 3.4624 | Accuracy: 74.511120\n",
            "Epoch 00133 | Loss 0.2867 | Time(s) 3.4625 | Accuracy: 73.868865\n",
            "Epoch 00134 | Loss 0.3255 | Time(s) 3.4627 | Accuracy: 74.386503\n",
            "Epoch 00135 | Loss 0.2565 | Time(s) 3.4628 | Accuracy: 74.578221\n",
            "Epoch 00136 | Loss 0.3927 | Time(s) 3.4626 | Accuracy: 74.434433\n",
            "Epoch 00137 | Loss 0.3604 | Time(s) 3.4628 | Accuracy: 74.290644\n",
            "Epoch 00138 | Loss 0.3155 | Time(s) 3.4630 | Accuracy: 74.242715\n",
            "Epoch 00139 | Loss 0.3500 | Time(s) 3.4634 | Accuracy: 74.041411\n",
            "Epoch 00140 | Loss 0.2577 | Time(s) 3.4633 | Accuracy: 73.907209\n",
            "Epoch 00141 | Loss 0.2666 | Time(s) 3.4637 | Accuracy: 74.003067\n",
            "Epoch 00142 | Loss 0.2886 | Time(s) 3.4644 | Accuracy: 73.907209\n",
            "Epoch 00143 | Loss 0.3010 | Time(s) 3.4647 | Accuracy: 73.801764\n",
            "Epoch 00144 | Loss 0.2605 | Time(s) 3.4654 | Accuracy: 73.284126\n",
            "Epoch 00145 | Loss 0.3053 | Time(s) 3.4652 | Accuracy: 73.466258\n",
            "Epoch 00146 | Loss 0.2917 | Time(s) 3.4651 | Accuracy: 73.533359\n",
            "Epoch 00147 | Loss 0.2700 | Time(s) 3.4657 | Accuracy: 73.859279\n",
            "Epoch 00148 | Loss 0.2153 | Time(s) 3.4658 | Accuracy: 73.427914\n",
            "Epoch 00149 | Loss 0.3705 | Time(s) 3.4656 | Accuracy: 72.852761\n",
            "Results stored\n",
            "Starting new training cycle\n",
            "\n",
            "DGLGraph(num_nodes=2708, num_edges=13264,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "5.205130 seconds\n",
            "Epoch 00000 | Loss 1.8549 | Time(s) 3.5943 | Accuracy: 30.099693\n",
            "Epoch 00001 | Loss 1.6588 | Time(s) 3.5297 | Accuracy: 30.166794\n",
            "Epoch 00002 | Loss 1.4763 | Time(s) 3.5128 | Accuracy: 33.934049\n",
            "Epoch 00003 | Loss 1.2904 | Time(s) 3.5146 | Accuracy: 40.989264\n",
            "Epoch 00004 | Loss 1.1593 | Time(s) 3.5212 | Accuracy: 45.619248\n",
            "Epoch 00005 | Loss 1.1741 | Time(s) 3.5291 | Accuracy: 51.236580\n",
            "Epoch 00006 | Loss 1.2310 | Time(s) 3.5208 | Accuracy: 55.157209\n",
            "Epoch 00007 | Loss 1.0015 | Time(s) 3.5363 | Accuracy: 56.537577\n",
            "Epoch 00008 | Loss 1.0797 | Time(s) 3.5454 | Accuracy: 57.342791\n",
            "Epoch 00009 | Loss 0.9607 | Time(s) 3.5470 | Accuracy: 57.850844\n",
            "Epoch 00010 | Loss 0.7958 | Time(s) 3.5431 | Accuracy: 58.406825\n",
            "Epoch 00011 | Loss 0.8832 | Time(s) 3.5348 | Accuracy: 58.847776\n",
            "Epoch 00012 | Loss 0.7748 | Time(s) 3.5302 | Accuracy: 59.422929\n",
            "Epoch 00013 | Loss 0.7394 | Time(s) 3.5223 | Accuracy: 60.046012\n",
            "Epoch 00014 | Loss 0.7150 | Time(s) 3.5168 | Accuracy: 60.132285\n",
            "Epoch 00015 | Loss 0.6512 | Time(s) 3.5181 | Accuracy: 60.324003\n",
            "Epoch 00016 | Loss 0.7635 | Time(s) 3.5180 | Accuracy: 59.825537\n",
            "Epoch 00017 | Loss 1.1854 | Time(s) 3.5152 | Accuracy: 59.998083\n",
            "Epoch 00018 | Loss 0.7930 | Time(s) 3.5142 | Accuracy: 59.959739\n",
            "Epoch 00019 | Loss 0.6880 | Time(s) 3.5093 | Accuracy: 59.614647\n",
            "Epoch 00020 | Loss 0.8064 | Time(s) 3.5122 | Accuracy: 59.643405\n",
            "Epoch 00021 | Loss 0.7950 | Time(s) 3.5105 | Accuracy: 59.758436\n",
            "Epoch 00022 | Loss 0.8522 | Time(s) 3.5104 | Accuracy: 59.557132\n",
            "Epoch 00023 | Loss 0.6830 | Time(s) 3.5085 | Accuracy: 59.432515\n",
            "Epoch 00024 | Loss 0.6699 | Time(s) 3.5083 | Accuracy: 59.279141\n",
            "Epoch 00025 | Loss 0.8610 | Time(s) 3.5108 | Accuracy: 59.097009\n",
            "Epoch 00026 | Loss 0.5454 | Time(s) 3.5135 | Accuracy: 59.394172\n",
            "Epoch 00027 | Loss 0.7013 | Time(s) 3.5127 | Accuracy: 59.106595\n",
            "Epoch 00028 | Loss 0.8182 | Time(s) 3.5111 | Accuracy: 59.154525\n",
            "Epoch 00029 | Loss 0.6509 | Time(s) 3.5121 | Accuracy: 59.231212\n",
            "Epoch 00030 | Loss 1.0813 | Time(s) 3.5118 | Accuracy: 59.221626\n",
            "Epoch 00031 | Loss 0.5654 | Time(s) 3.5098 | Accuracy: 59.576304\n",
            "Epoch 00032 | Loss 0.8336 | Time(s) 3.5093 | Accuracy: 59.930982\n",
            "Epoch 00033 | Loss 0.7499 | Time(s) 3.5087 | Accuracy: 59.768021\n",
            "Epoch 00034 | Loss 0.7204 | Time(s) 3.5064 | Accuracy: 59.518788\n",
            "Epoch 00035 | Loss 0.7548 | Time(s) 3.5062 | Accuracy: 59.758436\n",
            "Epoch 00036 | Loss 0.7600 | Time(s) 3.5056 | Accuracy: 60.084356\n",
            "Epoch 00037 | Loss 0.6436 | Time(s) 3.5051 | Accuracy: 59.978911\n",
            "Epoch 00038 | Loss 1.1655 | Time(s) 3.5056 | Accuracy: 59.883052\n",
            "Epoch 00039 | Loss 0.5997 | Time(s) 3.5054 | Accuracy: 59.739264\n",
            "Epoch 00040 | Loss 0.5969 | Time(s) 3.5044 | Accuracy: 59.710506\n",
            "Epoch 00041 | Loss 0.7116 | Time(s) 3.5057 | Accuracy: 59.327071\n",
            "Epoch 00042 | Loss 0.5463 | Time(s) 3.5069 | Accuracy: 59.672163\n",
            "Epoch 00043 | Loss 0.5553 | Time(s) 3.5057 | Accuracy: 59.720092\n",
            "Epoch 00044 | Loss 0.6503 | Time(s) 3.5050 | Accuracy: 59.451687\n",
            "Epoch 00045 | Loss 0.7855 | Time(s) 3.5041 | Accuracy: 59.988497\n",
            "Epoch 00046 | Loss 0.6991 | Time(s) 3.5073 | Accuracy: 59.557132\n",
            "Epoch 00047 | Loss 0.7997 | Time(s) 3.5061 | Accuracy: 59.854294\n",
            "Epoch 00048 | Loss 1.2056 | Time(s) 3.5058 | Accuracy: 59.911810\n",
            "Epoch 00049 | Loss 0.5868 | Time(s) 3.5052 | Accuracy: 60.141871\n",
            "Epoch 00050 | Loss 1.1023 | Time(s) 3.5060 | Accuracy: 59.672163\n",
            "Epoch 00051 | Loss 0.6833 | Time(s) 3.5040 | Accuracy: 59.825537\n",
            "Epoch 00052 | Loss 0.6872 | Time(s) 3.5031 | Accuracy: 59.135353\n",
            "Epoch 00053 | Loss 0.5214 | Time(s) 3.5024 | Accuracy: 59.029908\n",
            "Epoch 00054 | Loss 0.6472 | Time(s) 3.5024 | Accuracy: 59.317485\n",
            "Epoch 00055 | Loss 0.7718 | Time(s) 3.5024 | Accuracy: 60.256902\n",
            "Epoch 00056 | Loss 0.5435 | Time(s) 3.5034 | Accuracy: 59.681748\n",
            "Epoch 00057 | Loss 0.7035 | Time(s) 3.5034 | Accuracy: 59.796779\n",
            "Epoch 00058 | Loss 0.6452 | Time(s) 3.5041 | Accuracy: 59.998083\n",
            "Epoch 00059 | Loss 0.7407 | Time(s) 3.5046 | Accuracy: 59.566718\n",
            "Epoch 00060 | Loss 0.6845 | Time(s) 3.5047 | Accuracy: 59.614647\n",
            "Epoch 00061 | Loss 0.5971 | Time(s) 3.5048 | Accuracy: 59.480445\n",
            "Epoch 00062 | Loss 0.5577 | Time(s) 3.5053 | Accuracy: 59.566718\n",
            "Epoch 00063 | Loss 1.2485 | Time(s) 3.5053 | Accuracy: 59.691334\n",
            "Epoch 00064 | Loss 0.5725 | Time(s) 3.5057 | Accuracy: 59.164110\n",
            "Epoch 00065 | Loss 0.7713 | Time(s) 3.5059 | Accuracy: 59.001150\n",
            "Epoch 00066 | Loss 0.5566 | Time(s) 3.5055 | Accuracy: 59.835123\n",
            "Epoch 00067 | Loss 0.5528 | Time(s) 3.5061 | Accuracy: 59.892638\n",
            "Epoch 00068 | Loss 1.0726 | Time(s) 3.5050 | Accuracy: 59.911810\n",
            "Epoch 00069 | Loss 0.7426 | Time(s) 3.5047 | Accuracy: 60.007669\n",
            "Epoch 00070 | Loss 0.6337 | Time(s) 3.5048 | Accuracy: 60.247316\n",
            "Epoch 00071 | Loss 0.7288 | Time(s) 3.5043 | Accuracy: 59.825537\n",
            "Epoch 00072 | Loss 0.9850 | Time(s) 3.5039 | Accuracy: 59.624233\n",
            "Epoch 00073 | Loss 0.7700 | Time(s) 3.5041 | Accuracy: 59.950153\n",
            "Epoch 00074 | Loss 0.6741 | Time(s) 3.5039 | Accuracy: 59.930982\n",
            "Epoch 00075 | Loss 0.7084 | Time(s) 3.5038 | Accuracy: 60.237730\n",
            "Epoch 00076 | Loss 0.8930 | Time(s) 3.5038 | Accuracy: 59.930982\n",
            "Epoch 00077 | Loss 0.5287 | Time(s) 3.5029 | Accuracy: 59.490031\n",
            "Epoch 00078 | Loss 0.5370 | Time(s) 3.5031 | Accuracy: 59.902224\n",
            "Epoch 00079 | Loss 0.5351 | Time(s) 3.5023 | Accuracy: 59.394172\n",
            "Epoch 00080 | Loss 0.7299 | Time(s) 3.5028 | Accuracy: 59.873466\n",
            "Epoch 00081 | Loss 0.7273 | Time(s) 3.5023 | Accuracy: 60.036426\n",
            "Epoch 00082 | Loss 0.8981 | Time(s) 3.5016 | Accuracy: 59.662577\n",
            "Epoch 00083 | Loss 0.7460 | Time(s) 3.5007 | Accuracy: 59.633819\n",
            "Epoch 00084 | Loss 0.5293 | Time(s) 3.5009 | Accuracy: 59.029908\n",
            "Epoch 00085 | Loss 0.7268 | Time(s) 3.5020 | Accuracy: 59.499617\n",
            "Epoch 00086 | Loss 0.5522 | Time(s) 3.5015 | Accuracy: 59.259969\n",
            "Epoch 00087 | Loss 0.5591 | Time(s) 3.5017 | Accuracy: 59.595475\n",
            "Epoch 00088 | Loss 0.5549 | Time(s) 3.5027 | Accuracy: 59.576304\n",
            "Epoch 00089 | Loss 0.7693 | Time(s) 3.5028 | Accuracy: 59.643405\n",
            "Epoch 00090 | Loss 0.6301 | Time(s) 3.5027 | Accuracy: 59.739264\n",
            "Epoch 00091 | Loss 0.5658 | Time(s) 3.5031 | Accuracy: 60.017255\n",
            "Epoch 00092 | Loss 0.5800 | Time(s) 3.5040 | Accuracy: 59.863880\n",
            "Epoch 00093 | Loss 0.5171 | Time(s) 3.5042 | Accuracy: 59.921396\n",
            "Epoch 00094 | Loss 0.6133 | Time(s) 3.5055 | Accuracy: 59.950153\n",
            "Epoch 00095 | Loss 0.7198 | Time(s) 3.5055 | Accuracy: 60.103528\n",
            "Epoch 00096 | Loss 0.8972 | Time(s) 3.5044 | Accuracy: 59.432515\n",
            "Epoch 00097 | Loss 0.9945 | Time(s) 3.5039 | Accuracy: 59.758436\n",
            "Epoch 00098 | Loss 0.6950 | Time(s) 3.5034 | Accuracy: 59.787193\n",
            "Epoch 00099 | Loss 0.7186 | Time(s) 3.5028 | Accuracy: 60.084356\n",
            "Epoch 00100 | Loss 0.6447 | Time(s) 3.5032 | Accuracy: 59.825537\n",
            "Epoch 00101 | Loss 0.8565 | Time(s) 3.5042 | Accuracy: 59.585890\n",
            "Epoch 00102 | Loss 0.5568 | Time(s) 3.5042 | Accuracy: 59.365414\n",
            "Epoch 00103 | Loss 0.6489 | Time(s) 3.5041 | Accuracy: 59.672163\n",
            "Epoch 00104 | Loss 0.5428 | Time(s) 3.5034 | Accuracy: 59.375000\n",
            "Epoch 00105 | Loss 0.6419 | Time(s) 3.5033 | Accuracy: 60.065184\n",
            "Epoch 00106 | Loss 0.7725 | Time(s) 3.5029 | Accuracy: 60.046012\n",
            "Epoch 00107 | Loss 0.9170 | Time(s) 3.5026 | Accuracy: 60.343175\n",
            "Epoch 00108 | Loss 0.6334 | Time(s) 3.5029 | Accuracy: 60.208972\n",
            "Epoch 00109 | Loss 0.6476 | Time(s) 3.5036 | Accuracy: 60.007669\n",
            "Epoch 00110 | Loss 0.6262 | Time(s) 3.5041 | Accuracy: 59.815951\n",
            "Epoch 00111 | Loss 0.6437 | Time(s) 3.5037 | Accuracy: 59.796779\n",
            "Epoch 00112 | Loss 0.7400 | Time(s) 3.5034 | Accuracy: 59.652991\n",
            "Epoch 00113 | Loss 0.5363 | Time(s) 3.5032 | Accuracy: 59.451687\n",
            "Epoch 00114 | Loss 0.7029 | Time(s) 3.5029 | Accuracy: 59.480445\n",
            "Epoch 00115 | Loss 0.5999 | Time(s) 3.5026 | Accuracy: 59.787193\n",
            "Epoch 00116 | Loss 0.7175 | Time(s) 3.5028 | Accuracy: 60.055598\n",
            "Epoch 00117 | Loss 0.7467 | Time(s) 3.5027 | Accuracy: 59.652991\n",
            "Epoch 00118 | Loss 0.5023 | Time(s) 3.5029 | Accuracy: 59.825537\n",
            "Epoch 00119 | Loss 0.6421 | Time(s) 3.5027 | Accuracy: 59.777607\n",
            "Epoch 00120 | Loss 0.7470 | Time(s) 3.5021 | Accuracy: 59.422929\n",
            "Epoch 00121 | Loss 0.6352 | Time(s) 3.5012 | Accuracy: 59.413344\n",
            "Epoch 00122 | Loss 0.6112 | Time(s) 3.5016 | Accuracy: 59.058666\n",
            "Epoch 00123 | Loss 0.5317 | Time(s) 3.5015 | Accuracy: 58.838190\n",
            "Epoch 00124 | Loss 1.1871 | Time(s) 3.5009 | Accuracy: 59.978911\n",
            "Epoch 00125 | Loss 0.6228 | Time(s) 3.5010 | Accuracy: 59.595475\n",
            "Epoch 00126 | Loss 0.6198 | Time(s) 3.5009 | Accuracy: 59.672163\n",
            "Epoch 00127 | Loss 0.6442 | Time(s) 3.5010 | Accuracy: 59.336656\n",
            "Epoch 00128 | Loss 0.5172 | Time(s) 3.5017 | Accuracy: 59.614647\n",
            "Epoch 00129 | Loss 0.6480 | Time(s) 3.5015 | Accuracy: 59.490031\n",
            "Epoch 00130 | Loss 0.7088 | Time(s) 3.5012 | Accuracy: 59.662577\n",
            "Epoch 00131 | Loss 0.5490 | Time(s) 3.5010 | Accuracy: 60.046012\n",
            "Epoch 00132 | Loss 0.7827 | Time(s) 3.5012 | Accuracy: 59.662577\n",
            "Epoch 00133 | Loss 0.7459 | Time(s) 3.5004 | Accuracy: 59.672163\n",
            "Epoch 00134 | Loss 0.6268 | Time(s) 3.5005 | Accuracy: 59.576304\n",
            "Epoch 00135 | Loss 0.9478 | Time(s) 3.5004 | Accuracy: 59.394172\n",
            "Epoch 00136 | Loss 0.9128 | Time(s) 3.5006 | Accuracy: 58.876534\n",
            "Epoch 00137 | Loss 0.7084 | Time(s) 3.4999 | Accuracy: 58.636887\n",
            "Epoch 00138 | Loss 0.6787 | Time(s) 3.5002 | Accuracy: 59.097009\n",
            "Epoch 00139 | Loss 1.1503 | Time(s) 3.5001 | Accuracy: 59.595475\n",
            "Epoch 00140 | Loss 0.7634 | Time(s) 3.4997 | Accuracy: 59.518788\n",
            "Epoch 00141 | Loss 0.5780 | Time(s) 3.4996 | Accuracy: 59.470859\n",
            "Epoch 00142 | Loss 0.5879 | Time(s) 3.4997 | Accuracy: 58.991564\n",
            "Epoch 00143 | Loss 0.7080 | Time(s) 3.4990 | Accuracy: 59.557132\n",
            "Epoch 00144 | Loss 0.5300 | Time(s) 3.4993 | Accuracy: 59.787193\n",
            "Epoch 00145 | Loss 0.8768 | Time(s) 3.4991 | Accuracy: 59.403758\n",
            "Epoch 00146 | Loss 0.4800 | Time(s) 3.4988 | Accuracy: 59.394172\n",
            "Epoch 00147 | Loss 0.6857 | Time(s) 3.4980 | Accuracy: 58.857362\n",
            "Epoch 00148 | Loss 0.6295 | Time(s) 3.4974 | Accuracy: 59.346242\n",
            "Epoch 00149 | Loss 0.6939 | Time(s) 3.4985 | Accuracy: 59.576304\n",
            "Results stored\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjvSIfKTdIgA",
        "colab_type": "text"
      },
      "source": [
        "#On graphic (our algorithm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HJAqZbH4Makd",
        "colab": {}
      },
      "source": [
        "accPointsCora_our = [0]*n_of_epochs\n",
        "lossPointsCora_our = [0]*n_of_epochs\n",
        "\n",
        "for d in range(n_of_training_cycles):\n",
        "  for i in range(n_of_epochs):\n",
        "    accPointsCora_our[i] = accPointsCora_our[i] + averageAccCora_our[d][i]\n",
        "    lossPointsCora_our[i] = lossPointsCora_our[i] + averageLossCora_our[d][i]\n",
        "\n",
        "for i in range(n_of_epochs):\n",
        "  accPointsCora_our[i] = accPointsCora_our[i]/n_of_training_cycles\n",
        "  lossPointsCora_our[i] = lossPointsCora_our[i]/n_of_training_cycles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wkuOEgTMrDI",
        "colab_type": "code",
        "outputId": "50fb998e-ad3f-4b31-dfb1-ff766e00f1d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "maxAccCora_our = np.argmax(accPointsCora_our)\n",
        "maxAccCora_our"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLpUCy3YdMdo",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of our algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v9sNpqyQboC",
        "colab_type": "code",
        "outputId": "bd549413-9afa-4389-e625-5b8b488d560f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "axisX = range(n_of_epochs)\n",
        "\n",
        "plt.plot(axisX, accPointsCora_our, color='orange', label='Cora')\n",
        "#plt.plot(axisX, pointsPubMed, color='blue', label='PubMed')\n",
        "plt.plot([maxAccCora_our], accPointsCora_our[maxAccCora_our], marker='o', color='red')\n",
        "#plt.plot([maxAccPubMed], pointsPubMed[maxAccPubMed], marker='o', color='blue')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAlxEJFIKcBGRSCnARUQipQAXEYnU/we6XDMaq+FlQQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "46bae544-7d4f-4c5b-f99a-02e6f04911e6",
        "id": "WaxZKGbNQpGw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Max accuracy Cora at {:03d} epochs with value {:05f}\"\n",
        "  .format(maxAccCora_our, accPointsCora_our[maxAccCora_our]))\n",
        "#print(\"Max accuracy PubMed at {:03d} epochs with value {:05f}\"\n",
        "#  .format(maxAccPubMed, pointsPubMed[maxAccPubMed]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max accuracy Cora at 036 epochs with value 64.810199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdFEyVh0dQow",
        "colab_type": "text"
      },
      "source": [
        "Loss values of our algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cb2ae9e1-2796-4443-c8e4-71c46240963f",
        "id": "wCO9VsNgQ8bC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(axisX, lossPointsCora_our, color='orange', label='Cora')\n",
        "#plt.plot(axisX, pointsLossPubMed, color='blue', label='PubMed')\n",
        "plt.plot([maxAccCora_our], lossPointsCora_our[maxAccCora_our], marker='o', color='red')\n",
        "#plt.plot([maxAccPubMed], pointsLossPubMed[maxAccPubMed].item(), marker='o',color='blue')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7339d17e-f0db-4d97-ff1c-3cf994f94a71",
        "id": "wi2Qzd5YRGdg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"For Cora, at epoch {:03d}, loss was {:05f}\"\n",
        "  .format(maxAccCora_our, lossPointsCora_our[maxAccCora_our]))\n",
        "#print(\"For PubMed, at epoch {:03d}, loss was {:05f}\"\n",
        "#  .format(maxAccPubMed, pointsLossPubMed[maxAccPubMed]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Cora, at epoch 036, loss was 0.671697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdOKWGe-SB94",
        "colab_type": "text"
      },
      "source": [
        "#Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jej5As7dUUs",
        "colab_type": "text"
      },
      "source": [
        "Comparison between accuracy of both algorithms. The red dots show the maximum values reached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4jkhpiISEL5",
        "colab_type": "code",
        "outputId": "f94f35d9-fad2-4da6-e418-bdae41074c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(axisX, accPointsCora, color='orange', label='Cora')\n",
        "plt.plot(axisX, accPointsCora_our, color='blue', label='Our Cora')\n",
        "plt.plot([maxAccCora], accPointsCora[maxAccCora], marker='o', color ='red')\n",
        "plt.plot([maxAccCora_our], accPointsCora_our[maxAccCora_our], marker='o', color='red')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZRU9Z338fe3941maRYRxG5FWdQA\nCqiDiURNooyJWxL1ZGYwjxmynUQycZL4mMxMJomJmZwxiz5mmGzGYRKMo6NxkkwQJR41yiIiyCY7\njQIN0vte9Xv++N6mFxroxm6qbvfndU6dqnvrVtX33qr7ub/61b23LISAiIjET0aqCxARkZOjABcR\niSkFuIhITCnARURiSgEuIhJTWafyxUaOHBlKS0tP5UuKiMTe6tWrD4YQRnUdf0oDvLS0lFWrVp3K\nlxQRiT0z29XdeHWhiIjElAJcRCSmFOAiIjGlABcRiSkFuIhITCnARfrC4sVQWgoZGX69eHGqK5JB\n4JTuRigyIC1eDAsWQH29D+/a5cMAH/tY6uqSAU8BLu3qy6F6E9TthvyxcNpVkJHdu+dIJiDZBC1V\nULvTr4fPgPwxx3lMK9TugNDqr1d0FlgPvhw2V0LVBki2QO4IyBnul8wCMGufLtHk07ZU+nVIQHZx\n+yUjG1pqvO7MAh9urfXnzT8dMnKgYS/UvOHTJRogMw8ycv25vrywPbyPLMt6H//BmTDk3M719EYI\nULMVqjdA3S6v74wbILekw/1b/L0bco6/b40HvMbCMsjI9GmaD0Oy2ecptPoyD61AgLwxkDOi+xoT\njT7/luHvbcNeH84dCRlpHh/1e6HpkL+vAJbZfkk2Q2s9EPz9tqzO1+Dv7ZFLq8+/md+fkQMWTZeo\ng5Za/8wkGn1ZZWRDTgnkjfRllTXk5D8Dx5Hm74D0i/py2L8cDjwHTRX+Ya563QOio5wRUDIbsgqh\nqAxO/0sYcRGEJFSug12/9oCe+iUPgdULfRzdnGO+6GwPnjFX+mPfXu2h0nTQwynR2D5t3mgYew2M\nmuPhn2zylbFhr9detRGq1kP9nu7nLyPbawevr+Nz95pBVgG01h17kr3HGn8QnpoMhWf6ciyeCiR9\nni0bcoZCS7XPU/YQGHq+r+wE36AdehkOrfDl1NHKT8PwaX67fi807uv+9TML/LXrdx+/foDMfCg4\nAwrGebi3VENDuQegZfjybK6MQj9aLpm5Ph8ZWR58+afDsPNh2AU+L0Vn+4amch3seMjns3gK5J/m\n9bRGodcWfgSvN+80f89bG3xDRBLyx/n7cOB5/6yOeS+cPs/nrep1yCz0jTdJaK6C/U/7xj1dZGTD\n1Wtg2Hl9+rR2Kv/QYebMmUFHYqZAohH2LYPyJ2D/M1C7zcdnD4PCCd4iKTobRr8bhr3LV+SqDR7G\nNZu9pVK7zYO+o8z89tZrVhEkG2HiJ6FgvA8XnunXb6/219+3tD0ACsuilt8wGHqer/iZ+b4i73sG\n3voDNL999Lxk5nuL9khQnOfjmg/79M2H2y8h+PPnDPN5bbu2TGit8XBvqfb5yi72VlVrvbdSs4f4\ndPV7oOltKJ7kl5zh3vpONHm4WBbMuB7K3zq61vFj4Zmvwb6n4fBaqN3u43OGe6uupco3jgXjPXQ6\nBrFl+LyVXOyX4dN8mTWUw87/hMrXvL6cEn/fis7ybwiN+325ZuT4NHW7oLDUL5l57WFrWX47BH/d\n+j1+aXjTH5tV5IFcMN4/P00HPcSLSj3gmyral1Vo8eu63VC1zoO6q+yh/r5Vb/Jl3/YaWUWQHV2H\nJNTt9NfKyPH3NTPfH9+4HwhQNBGGToX9z/rzAOSO8vewpar9MzLyUhh3LRRM8A0NdG5Rtz0/1uEb\nSYtfJ1ui9yDTv8FYVnvLneD3J1va14esIn8fs4p8GROib32HfF7aLlO+5N8UT4KZrQ4hzDxqvAI8\nzTRX+coRkkDwFSwj20M1M6d9uvo3Yd8ffYWo3+uBVnKJf6jr9/jzNB+Gt1fCwZc8bLKGwGlXwOi5\nMGauh3VPuirAQ3rfUqjZ5it+/uneAkq2wMbvejhd8E++ch1L09se5sMu8FbY8YTgG43Da6OQG+dh\nkj2sX76KviNd+8ABCgpg0aLOfeCJpig4M304mfDl3zY/TYeiEDIPpeyiUzYLfaq5Eiqjb0hNFd6i\nHvdByMr39zXZ0vmz3FUIR7/HyRb/DLYFYKLRP0tFZ3m3ERy9PAcQBXi6CklvTWxdBG/90ftpu2MZ\n/jUydxQQ4PAaH5+RDbmjvXvhqMdkeUiPugxOv8a/dra1RqRvLV4Md98Nu3fDhAnwrW/pB0zpMwrw\ndNHW//z2ar8cXuPdBjkj4Iyb/IeovDHRVzYDzPsDa3dEXy8PeevjtCtg3IegeLK3iBsP+PPlDPev\njW1f9Qdga0RksDlWgOtHzL7WeMB/HDz8qg8Pu8DDuPI1eGspHHrJx2fmw/DpcNZt3kIef13Uf3aS\n8kZ7K1tEBg0F+MlorfPWbrLFf2UvOMNbvFv/DdZ8yVvUFvVzhoRfWwYMmw7TvuV7cww9L/13wxKR\ntHbCBDGzScCSDqPOAv4B+GU0vhTYCXw0hHC46+MHjJCEvU/Bpn+Fihc67E4VySyARL3vO/2ub0a7\neRlUb/THFk/xH3FERPrICQM8hLAZmA5gZpn4Xq+PA18BloUQvmNmX4mGv9yPtaZGstV3p9vwHd/f\ntLAUptzp3R5ZRb57UN0u32OiZDaU/U3nfufh01NWuogMbL39Dn8lsC2EsMvMrgPmRuMfApYT5wA/\nvNb3Bqlc610do9/j+yJv/TcP6KHnwaUPw5m3qOtDRNJCb5PoFuBX0e0xIYS2oxf2Ad0eK21mC4AF\nABMmTDiZGvtXCLDun2D9P/twbgls/0X7/aPnwkU/9IMCerrPtIjIKdDjADezHOBDwF1d7wshBDPr\ndn/EEMIiYBH4boQnWWf/SLbCqs/6PthnfRze9Q0/YKRmm+9JMvISGDol1VWKiHSrNy3wa4BXQgj7\no+H9ZjY2hPCWmY0FDvR9ef2otQFevNUPLz/vbg/vtr7rIWf7RUQkjfWmT+BW2rtPAJ4E5ke35wNP\n9FVR/a5hPzz7Pih/Ei76EUz7pg54EZHY6VEL3MwKgfcBn+ww+jvAI2Z2O7AL+Gjfl9cP9vw3rFjg\nJzG6bAlM+EiqKxIROSk9CvAQQh1Q0mXcIXyvlHhINMOaO2HLj3zXvkuf7fNTO4qInEqDY3+4pkPw\n3PVQ8TxMWgjT7z3+2dBERGJg4Ad4CPDyJ/zE+H/xn1B6a6orEhHpEwM/wHf+B5T/N8z4F4W3iAwo\nA/vIlPpyWPU5P+x90hdSXY2ISJ8a2AG++Yd+5sBLftH+LygiIgPEwA3wkIRdv4KxV+ugHBEZkAZu\ngB94zrtQSvW3ViIyMA3cAN/5H3661/EfSnUlIiL9YmAGeKIRdj8K42+ArIJUVyMi0i8GZoC/+Tto\nqVL3iYgMaAMzwLf+BPJPh9Pic6S/iEhvDbwAr93h/6Rz9icG1z/nLF4MpaWQkeHXixenuiIR6WcD\nL+G2/rufGvbsT6S6klNn8WJYsADq63141y4fBviYupFEBqqBFeCJZtj+Mzj9L6HwjJSV0doKlZVQ\nXQ11dT6cmQlDh8K4cT7Njh1w6BAUFPj9u3bB7t1+XVkJJSVw+ukwbRpccIEPt7bCCy/ASy9BMgmJ\nBGzdCvcuuZuxzfWdi6ivh7vvVoCLDGADK8D3PgGN+2Hip/rl6Rsb4cUXYeRIOO88D+WWFnjySfj3\nf4eNG+HwYaipOfZzZGS0P647BQUwfDgcPAhNTZ0fl5UFzc2dpx8/HsY07+72ucKu3Tz6G/iLv4Ci\nImho8Ofdt89rfe012L7dNxwFBTBxYvslMxPefBPy8+HCC72WpUth7VooL4ecHLj6anj3u2HECN8w\nnXlm//wvxvbt8POf+/xPmgRz58Jpp3WZ1+AbzPJy+MMf4Fe/gtpamDnTp7/hBt8IJhJ+yUnDk1E2\nNfkGecsWr3XOHH8fRI7FQjh1f1M5c+bMsGrVqv57gedvgQPL4fq9fXLo/I4d8Mc/wqZNvlL96U/e\nogYoLvZwe/ttD+MJEzwoRozwAB4+3KcpLPTgSSQ83Hft8pb0uefCmDG+UTDzx595pq+4Zh5IFRUe\nmBs2ePA2Nnpgzp0LeXleR04O3ue9a9dR9e+2Mzkz7Dzm/JWUeB1nnOEN9q1bPSy7biTa5OTA9Ole\n6+HD8NxznTdEZ5wBl10GU6b4ZdYsH7djB2ze7PPw1lu+8di61V+nLVDN4Jxz/BvHtGle14oV8Nhj\n8MQTfn8y6cslM9M3HqWlXsf27f4eVVa21zJ7tof8ihW+wcrK8o3Mm296zUOH+uvNm+cb47bHz57t\nG8VVq+D11325JJM+7rTT/P2vrPRLXR0MGQLDhnlNWVlw1VVw+eW+wU0k/LXfiv76OzfXPy979/qG\nZu/e9uffvNlfs+NGe/RoD/GRI32Z/PVf+2fqeJJJ2LbNPw55eTBqlC/LnmxYEwn/jD/7rH/Lq6/3\nebr6avjUp/wzfbzXranxy9atsGaNNwrmzfPPQJtdu/w9LC314fp6n/eiIp+34mKoqoKnnvLPfmkp\nlJW1f95ranwZTZni71tzM+zZ45+T3/7Wl+vbb8Pkyb6ufOAD/p7s3w9PP+2NkOXLfeNeUADvfz98\n+9u+7vVURYV/lidOhOzso+9ftQr+5398fc3I8M/Z5Mm+7rTNR2+Z2eoQwsyjxg+YAE+2wmOjYdyH\n4NJf9OqhIXhQP/usr/CVlR4MO3f6/YWFcNZZHk7z5vn9L77oH/gRI3wlu+aaFLaWuvaBAxQU0Prg\nItZM+RgvveShlZ/voT1mjH+oxo49esVOJHyFSCa9C6emBl55xT+Ic+b4h75NdbVvXKqqPDSWL4eX\nX/YWfZusLN9gdXT66R4q+fm+zNrCbuNGD+OOxoyBj38cPvc5X9YbN8JvfuOzXFvr4Tlhgq/QZWUe\n0jNn+vODv7dr1sCSJb5yT5jg81BR4fP15z/7vJp5wDY2tr/26NEe0OCPbQvXoiJ/3cJCXz6Vlf4c\nLS0+H2PH+jzt2+fDxzJkiD9X2wZ8zhyYMcNr37kTHn3UNyIVFXDggE972WW+4aiq8uUfgm9ciop8\ng7BjR3sjo83kyXDjje3TNTb6t7Fksn2jeOiQL9Pdu732adN8eVdXw8qV/riJEz2Axo3z55w0ycct\nWwYPPugbx+5MmODv48GDXp8Z3HQTTJ0KDzzgr92dgoLOH+njMWtvPBQXe/i/+KIvi8zM9vdh3Di4\n8kp/bw8dgl//2pfBtdd6PePG+ftSVeUbli1b/NLY6BuTmhr/5greoDnvPF9WpaVe68sv+0aw7f62\nBgrAunVw/vk9m5+j52+gB3jFi7B0DsxZAmf2/N/dEgn4zGdg0SLfms6Y4W9uYSFceqkH9sSJMfjL\nzMWLvc97925fY771rZT1f9fXe/CsXOlBNGmSr1hjxniL8HityOpq/6Bv2gTvehdcdJEHSn+pqPAN\n1qRJHuDr1nlYX3SRb2jaJJNeW1GRb5S6U1/v3WlPPNEedOPG+fNkZHgIDB/uQdoWFD21ahX86Eew\nfr0vv6FD/ToEr7e21p+ztNSX29lne+t061bfeD33nE97PFddBX/7t94Y6Vjb2rXtAd3Y6K3obds6\nb5ze/36/DBniH78LL/SA/O1v/bNw4IBvsOfO9dbwj37kYXjttfBXf+Ubv+pqv2Rmesv5ggu8Nb17\nt9+fTPo8Z2X5cti40UO+pMRDue33pTbNzT7fS5f6t4CrrvL3ueO6vGcP/PM/e+Nj+3Z/jTYFBb4x\nnTTJ389du/y13/tefw/Xr/dls3atz1Neno//9KfhE5/wWltbfaO1aZPP08l23Q38AF/7NdhwD9x0\nEHKO812vg4YG/1r6X/8FX/4y/MM/dG5higwUTU3tv8/k53vYZGV5mLX9vpKf3/Pna272wNuyxUNu\n8uTe1VNV5d9cetN10d+amvxbQk2Nb6jHjet5w6219dgb9r5wrAAfOD9ivvk7GHlpj8P7jTfgwx/2\nr0P33QcLF/ZzfSIplJvrffhdf/w9WTk5Htq9De42Q4f6JZ3k5h7diu+p/gzv4xkYB/I07IPDr8DY\na044aWUlfPOb/hW5vBx+9zuFt4jE08AI8Lf+169Pn3fMSVpa4Hvf869sX/ua7ymwZo3394mIxNHA\n6EKpeMG7ToZP6/bubdvggx/0Hz3mzfMW+IwZp7hGEZE+NjACvHoDDD0f7OgvFCH4HnZvveW/iF97\nbQrqExHpB/HvQgkBKl+Hoed1e/cjj8Azz8A99yi8RWRgiX+AN+6DlkoYOvWou2pq4O/+zvdJbTu3\nk4jIQBH/LpSq1/26mxb4D37gBx889pjOKSEiA0/8W+BVG/y6Swu8qQnuv9/3Mrn44hTUJSLSzwZA\ngL8OOSMgb0yn0b/+tR/e+oUvpKguEZF+1qMAN7NhZvaomW0ys41mdqmZjTCzpWb2RnTds0Mg+1rV\nBm99dzjmNQQ/uvL88/38ByIiA1FPW+A/AP4QQpgMTAM2Al8BloUQzgGWRcOnVgjeAu/S//2nP/kJ\nZhYujMFJqERETtIJA9zMhgLvAX4KEEJoDiFUAtcBD0WTPQRc319FHlPjfmg+fFT/929/6yfr0Z/R\niMhA1pMWeBlQAfzczNaY2U/MrBAYE0KITlXPPmBMdw82swVmtsrMVlVUVPRN1W2OsQfKihW+6+DJ\nnjxdRCQOehLgWcCFwIMhhBlAHV26S4Kfk7bb89KGEBaFEGaGEGaOGjXqndbbWTd7oLS2+on6Z83q\n25cSEUk3PQnwcqA8hPByNPwoHuj7zWwsQHR9oH9KPI7qzZA9FPLaz5G5YYOfWH/27FNejYjIKXXC\nAA8h7AP2mNmkaNSVwAbgSWB+NG4+8ES/VHg8DW9CwfhOv1SuXOnXaoGLyEDX0yMxPwcsNrMcYDvw\ncTz8HzGz24FdQM//x6yvNO7r1PoG7/8eNsz/Bk1EZCDrUYCHEF4Fjvo7H7w1njoN+2DUnE6jVqzw\n1rd2HxSRgS6+R2KGAI1vQX57C7yhwf+UVv3fIjIYxDfAW6oh0dipC2XNGv+nbPV/i8hgEN8Ab9zn\n1x0CfMUKv1YLXEQGg/gGeEMU4Pljj4x68UWYMAHGjj3GY0REBpD4BnhbCzzqAw8BXngBLrsshTWJ\niJxC8Q3whugo/qgLZedO//OGOXOO/RARkYEkvgHeuA8ycvzf6PHWNyjARWTwiG+AN0QH8UQ7fD//\nPBQX+znARUQGg/gGeOO+TvuAv/ACXHqp/vtSRAaP+AZ4w1tH+r8PH4b16/UDpogMLvEN8A4t8D//\n2Uep/1tEBpN4BniyFRorjrTAX3rJu050AI+IDCbxDPCmCiAcOYjnjTfgzDOhsDC1ZYmInErxDPCG\nzofR79wJpaUpq0ZEJCViGuDRQTz57QFeVpa6ckREUiGeAd7hRFYNDbBvn1rgIjL4xDvA809j926/\nqQAXkcEmngHesA+yh0FmHjt2+CgFuIgMNvEM8MYDkDca8P5vUB+4iAw+8QzwpoOQOxLwAM/O1jnA\nRWTwiWeANx+C3BLAA/zMMyEjnnMiInLS4hl7XVrg6v8WkcEopgHeuQWu/m8RGYziF+Ct9ZBogJwS\n6uth/361wEVkcIpfgDcd8uvckeza5TcV4CIyGMUwwA/6dW7JkV0IFeAiMhjFL8Cb21vg2gdcRAaz\n+AX4kS4Ub4Hn5sKYMSmtSEQkJWIY4G1dKCOpqIDRo7UPuIgMTvGLvrYWeM4IKith6NDUliMikipZ\nPZnIzHYCNUACaA0hzDSzEcASoBTYCXw0hHC4f8rsoOkgZA+FjCyqqhTgIjJ49aYF/t4QwvQQwsxo\n+CvAshDCOcCyaLj/NR06chSmAlxEBrN30oVyHfBQdPsh4Pp3Xk4PNB08chRmZSUMG3ZKXlVEJO30\nNMAD8EczW21mC6JxY0II0X+bsQ/odl8QM1tgZqvMbFVFRcU7LJfoRFZqgYuI9KgPHLgshLDXzEYD\nS81sU8c7QwjBzEJ3DwwhLAIWAcycObPbaXql6SAUTyUEBbiIDG49aoGHEPZG1weAx4HZwH4zGwsQ\nXR/oryI7ifrAGxqgpUVdKCIyeJ0wwM2s0MyGtN0G3g+sB54E5keTzQee6K8ij0g0QWst5JZQVeWj\n1AIXkcGqJ10oY4DHzaxt+v8MIfzBzFYCj5jZ7cAu4KP9V2akw4msFOAiMtidMMBDCNuBad2MPwRc\n2R9FHVOHE1lVRT+fqgtFRAareB2J2dx+HpTKSr+pFriIDFbxCvAO50FRF4qIDHYxC/C286DoR0wR\nkZgFeHsfeFsXivrARWSwilmAH4KsIsjMpaoKMjOhsDDVRYmIpEbMArz9PChVVVBcDL53o4jI4BOv\nAG+thexiQCeyEhGJV4AnmiAjF9B5UERE4hXgySbIVICLiEDcAjzReKQFrr9TE5HBLl4BnuzchaI+\ncBEZzOIV4IkmyMwD1IUiIhKvAI/6wJNJBbiISLwCPNoLpbYWQlAXiogMbvEK8KgFrvOgiIjELcCj\nvVB0KlkRkbgFeJcWuLpQRGQwi0+AhxD1geepC0VEhFgFeCsQ1AcuIhKJT4AnmvxafeAiIkCsArzR\nr9UHLiICxCnAk+0t8KoqyMmBvLzUliQikkrxC/DMPJ3ISkSEOAV4onMLXN0nIjLYxSfAj7TAc3Ue\nFBER4hTgXfZCUYCLyGAXowDvvBeKulBEZLCLT4B32QtFLXARGeziE+AJ7YUiItJRfAI8aoG3hlzq\n6hTgIiI9DnAzyzSzNWb2VDRcZmYvm9lWM1tiZjn9VyZHWuDVtfmA+sBFRHrTAr8D2Nhh+F7gvhDC\nROAwcHtfFnaUqAVeGQW4WuAiMtj1KMDNbDzwl8BPomEDrgAejSZ5CLi+Pwo8ItoLparG/5VeAS4i\ng11PW+DfB74EJKPhEqAyhNAaDZcD47p7oJktMLNVZraqoqLi5CuNWuBVtR7g6kIRkcHuhAFuZtcC\nB0IIq0/mBUIIi0IIM0MIM0eNGnUyT+GiPvCqGu9qVwtcRAa7rB5MMwf4kJnNA/KAYuAHwDAzy4pa\n4eOBvf1XJu194NXZgAJcROSELfAQwl0hhPEhhFLgFuCZEMLHgGeBD0eTzQee6LcqwVvglkVVtZes\nLhQRGezeyX7gXwb+zsy24n3iP+2bko6hyx8aFxf366uJiKS9nnShHBFCWA4sj25vB2b3fUnHkGg8\nciKrggLIzj5lrywikpbidSRmZp7OgyIiEolPgCea9GcOIiIdxCfAoz5wnchKRMTFJ8A7tMAV4CIi\ncQrwDnuhqAtFRCROAd5hLxS1wEVEYhXg2gtFRKSj+AR4sonG1iKamtSFIiICvTyQJ6WSTVQ1DwfU\nAhcRgTi1wBNNVNV701sBLiISqwBvpKrBk1sBLiISpwBPNlFZ58mtPnARkTgFeKKJqnq1wEVE2sQn\nwJNNVNUXAQpwERGIS4CHAMlmquo8wNWFIiISlwBPNgNQWVeEGQwZkuJ6RETSQDwCPNEIQFVtAUOG\nQEY8qhYR6VfxiMLoD42r6vLVfSIiEolHgCc8wKtr89V9IiISiUeARy3wusYciopSXIuISJqIR4BH\nLfC6hmwKC1Nci4hImohHgCcV4CIiXcUjwKO9UOrqFeAiIm3iEeBHWuBZFBSkuBYRkTQRjwBv6wOv\nz1QLXEQkEo8ATyrARUS6ikeAJ5pobs2mtdUU4CIikXgEeLKJuiZPbgW4iIiLR4AnGqlrVICLiHQU\nkwBXC1xEpKsTBriZ5ZnZCjNba2avm9nXo/FlZvaymW01syVmltNvVaoLRUTkKD1pgTcBV4QQpgHT\ngavN7BLgXuC+EMJE4DBwe79VqQAXETnKCQM8uNpoMDu6BOAK4NFo/EPA9f1SIagLRUSkGz3qAzez\nTDN7FTgALAW2AZUhhNZoknJg3DEeu8DMVpnZqoqKipOrMtFIXbP/EaYCXETE9SjAQwiJEMJ0YDww\nG5jc0xcIISwKIcwMIcwcNWrUyVWZbKKuxf/JQQEuIuJ6tRdKCKESeBa4FBhmZlnRXeOBvX1cW7tE\nk1rgIiJd9GQvlFFmNiy6nQ+8D9iIB/mHo8nmA0/0V5Ekm6hrLgYU4CIibbJOPAljgYfMLBMP/EdC\nCE+Z2Qbg12b2TWAN8NN+qzLRRF2z/5eaAlxExJ0wwEMIrwEzuhm/He8P73/JJuqahpCbC5mZp+QV\nReQktLS0UF5eTmNjY6pLiaW8vDzGjx9PdnZ2j6bvSQs89RKN1DUVqfUtkubKy8sZMmQIpaWlmFmq\ny4mVEAKHDh2ivLycsrKyHj0mHofSj7+euuzzFeAiaa6xsZGSkhKF90kwM0pKSnr17SUeLfCJn6Au\nS/3fInGg8D55vV128WiBA3V1CnARkY5iE+D19QpwEemZffv2ccstt3D22Wdz0UUXMW/ePLZs2ZLq\nsvpcbAJcLXAR6YkQAjfccANz585l27ZtrF69mm9/+9vs37//hI9tbW094TTpJB594HiAl5amugoR\n6bHVC+Hwq337nMOnw0XfP+4kzz77LNnZ2XzqU586Mm7atGmEEPj7v/97fv/732NmfPWrX+Xmm29m\n+fLlfO1rX2P48OFs2rSJLVu2cP3117Nnzx4aGxu54447WLBgQd/ORx+JVYCrBS4iJ7J+/Xouuuii\no8Y/9thjvPrqq6xdu5aDBw8ya9Ys3vOe9wDwyiuvsH79+iO77/3sZz9jxIgRNDQ0MGvWLG666SZK\nSkpO6Xz0hAJcRPrHCVrKp9rzzz/PrbfeSmZmJmPGjOHyyy9n5cqVFBcXM3v27E77Xv/whz/k8ccf\nB2DPnj288cYbaRng6gMXkQHlvPPOY/Xq1b16TGGHcFm+fDlPP/00f/7zn1m7di0zZsxI2yNLYxHg\niQQ0NkJBQaorEZF0d8UVV9DU1MSiRYuOjHvttdcYNmwYS5YsIZFIUFFRwXPPPcfs2UefDaSqqorh\nw4dTUFDApk2beOmll05l+b0Siy6U+nq/VgtcRE7EzHj88cdZuHAh9957L3l5eZSWlvL973+f2tpa\npk2bhpnx3e9+l9NOO41Nm4YN59oAAAl0SURBVDZ1evzVV1/Nj3/8Y6ZMmcKkSZO45JJLUjQnJ2Yh\nhFP2YjNnzgyrVq3q9eP27YOxY+GBB+Azn+mHwkSkT2zcuJEpU6akuoxY624ZmtnqEMLMrtPGogul\nrs6v1QIXEWmnABcRiSkFuIhITCnARURiSgEuIhJTCnARkZhSgIvIgFJeXs51113HOeecw9lnn80d\nd9xBc3PzO37e733ve0yePJnp06cza9YsfvnLX/ZBte+MAlxEBowQAjfeeCPXX389b7zxBlu2bKG2\ntpa77767V8+TSCQ6Df/4xz9m6dKlrFixgldffZVly5bRm2Nouj5fX4nFkZgKcJH4WbgQXu3js8lO\nnw7fP845sp555hny8vL4+Mc/DkBmZib33XcfZWVlfP3rX+eRRx5h1apV3H///QBce+213Hnnncyd\nO5eioiI++clP8vTTT/PAAw9w2WWXHXnee+65h+XLl1NcXAxAcXEx8+fPB2DZsmXceeedtLa2MmvW\nLB588EFyc3MpLS3l5ptvZunSpXzpS1+ipqaGRYsW0dzczMSJE3n44YcpeIfnB4lNCzwzE3JyUl2J\niKSz119//ahTyRYXFzNhwgS2bt163MfW1dVx8cUXs3bt2k7hXV1dTU1NDWedddZRj2lsbOS2225j\nyZIlrFu3jtbWVh588MEj95eUlPDKK69wyy23cOONN7Jy5UrWrl3LlClT+OlPf/oO5zZGLfDCQtB/\npYrEx/FayukoMzOTm266qVeP2bx5M2VlZZx77rkAzJ8/nwceeICFCxcCcPPNNx+Zdv369Xz1q1+l\nsrKS2tpaPvCBD7zjmmPTAlf3iYicyNSpU486lWx1dTW7d+9m4sSJZGVlkUwmj9zX8TSxeXl5ZGZm\nHvWcxcXFFBUVsX379l7X0/E0tbfddhv3338/69at4x//8R/75BS1CnARGTCuvPJK6uvrj+whkkgk\n+OIXv8htt91GQUEBpaWlvPrqqySTSfbs2cOKFSt69Lx33XUXn/3sZ6murgagtraWX/7yl0yaNImd\nO3ce6Z55+OGHufzyy7t9jpqaGsaOHUtLSwuLFy/ug7lVgIvIANJ2Ktnf/OY3nHPOOZx77rnk5eVx\nzz33ADBnzhzKysqYOnUqn//857nwwgt79Lyf/vSnee9738usWbM4//zzefe7301GRgZ5eXn8/Oc/\n5yMf+QgXXHABGRkZnf6Ls6NvfOMbXHzxxcyZM4fJkyf3zfzG4XSy3/42VFXBd77TD0WJSJ/R6WTf\nud6cTjYWP2LedVeqKxARST8n7EIxszPM7Fkz22Bmr5vZHdH4EWa21MzeiK6H93+5IiLSpid94K3A\nF0MIU4FLgM+a2VTgK8CyEMI5wLJoWEQGuVPZLTvQ9HbZnTDAQwhvhRBeiW7XABuBccB1wEPRZA8B\n1/fqlUVkwMnLy+PQoUMK8ZMQQuDQoUPk5eX1+DG96gM3s1JgBvAyMCaE8FZ01z5gzDEeswBYADBh\nwoTevJyIxMz48eMpLy+noqIi1aXEUl5eHuPHj+/x9D0OcDMrAv4LWBhCqLYOh0WGEIKZdbvJDSEs\nAhaB74XS48pEJHays7MpKytLdRmDRo/2AzezbDy8F4cQHotG7zezsdH9Y4ED/VOiiIh0pyd7oRjw\nU2BjCOFfO9z1JDA/uj0feKLvyxMRkWPpSRfKHOCvgXVm1nZyyP8LfAd4xMxuB3YBH+2fEkVEpDun\n9EhMM6vAw/5kjAQO9mE5/UE19o10rzHd6wPV2FfSpcYzQwijuo48pQH+TpjZqu4OJU0nqrFvpHuN\n6V4fqMa+ku41xuJkViIicjQFuIhITMUpwBeluoAeUI19I91rTPf6QDX2lbSuMTZ94CIi0lmcWuAi\nItKBAlxEJKZiEeBmdrWZbTazrWaW8tPWxukc6WaWaWZrzOypaLjMzF6OluUSM8tJcX3DzOxRM9tk\nZhvN7NJ0W45m9oXofV5vZr8ys7xUL0cz+5mZHTCz9R3GdbvczP0wqvU1M+vZ/4j1T43/Er3Xr5nZ\n42Y2rMN9d0U1bjazd/6X7SdZY4f7vmhmwcxGRsMpWY7Hk/YBbmaZwAPANcBU4NbofOSpFKdzpN+B\nnwK4zb3AfSGEicBh4PaUVNXuB8AfQgiTgWl4rWmzHM1sHPB5YGYI4XwgE7iF1C/HXwBXdxl3rOV2\nDXBOdFkAPJjCGpcC54cQ3gVsAe4CiNafW4Dzosf8v2jdT0WNmNkZwPuB3R1Gp2o5HlsIIa0vwKXA\n/3YYvgu4K9V1danxCeB9wGZgbDRuLLA5xXWNx1fkK4CnAMOPKsvqbtmmoL6hwA6iH9M7jE+b5Yif\n+34PMAI/9cRTwAfSYTkCpcD6Ey034N+AW7ub7lTX2OW+G/AT5B21XgP/C1yaqhqBR/EGxU5gZKqX\n47Euad8Cp30FalMejUsLJ3OO9FPo+8CXgGQ0XAJUhhBao+FUL8syoAL4edTN8xMzKySNlmMIYS/w\nPbwl9hZQBawmvZZjm2Mtt3Rdh/4P8PvodtrUaGbXAXtDCGu73JU2NbaJQ4Cnra7nSO94X/BNdMr2\n0TSza4EDIYTVqaqhB7KAC4EHQwgzgDq6dJekwXIcjv/7VBlwOlBIN1+5002ql9uJmNndeFfk4lTX\n0pGZFeAn6/uHVNfSE3EI8L3AGR2Gx0fjUioG50ifA3zIzHYCv8a7UX4ADDOztrNQpnpZlgPlIYSX\no+FH8UBPp+V4FbAjhFARQmgBHsOXbTotxzbHWm5ptQ6Z2W3AtcDHog0NpE+NZ+Mb67XRujMeeMXM\nTiN9ajwiDgG+Ejgn+tU/B/+h48lUFmSW/udIDyHcFUIYH0IoxZfZMyGEjwHPAh+OJkt1jfuAPWY2\nKRp1JbCBNFqOeNfJJWZWEL3vbTWmzXLs4FjL7Ungb6K9KC4Bqjp0tZxSZnY13q33oRBCfYe7ngRu\nMbNcMyvDfyhccarrCyGsCyGMDiGURutOOXBh9FlNm+V4RCo74HvxI8M8/BfrbcDdaVDPZfjX09eA\nV6PLPLyPeRnwBvA0MCLVtUb1zgWeim6fha8YW4HfALkprm06sCpalv8NDE+35Qh8HdgErAceBnJT\nvRyBX+F98i14yNx+rOWG/3j9QLT+rMP3qElVjVvxfuS29ebHHaa/O6pxM3BNqmrscv9O2n/ETMly\nPN5Fh9KLiMRUHLpQRESkGwpwEZGYUoCLiMSUAlxEJKYU4CIiMaUAFxGJKQW4iEhM/X9sUrsNHn5N\nMQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX2zNuYpdfHI",
        "colab_type": "text"
      },
      "source": [
        "Comparison between the loss values of both algorithm. The red dots shows the loss values when the accuracy is at its maximum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WAxIo0lSv28",
        "colab_type": "code",
        "outputId": "1860e728-26c7-4cce-fe7d-c0d771257e34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(axisX, lossPointsCora, color='orange', label='Cora')\n",
        "plt.plot(axisX, lossPointsCora_our, color='blue', label='Our Cora')\n",
        "plt.plot([maxAccCora], lossPointsCora[maxAccCora], marker='o', color ='red')\n",
        "plt.plot([maxAccCora_our], lossPointsCora_our[maxAccCora_our], marker='o', color='red')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCXxrQ1MBmwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}