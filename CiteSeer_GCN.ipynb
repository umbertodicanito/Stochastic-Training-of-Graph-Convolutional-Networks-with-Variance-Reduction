{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "CiteSeer_GCN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umbertodicanito/Stochastic-Training-of-Graph-Convolutional-Networks-with-Variance-Reduction/blob/master/CiteSeer_GCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inaEyeyeN3mP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4C3py11yrk_",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh4yOJOUN5kV",
        "colab_type": "code",
        "outputId": "463e505c-9e92-4111-c399-58ddb5d55fc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install dgl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/ba/d15ce7fb56958f21d4e9815f96344d92c4982f3fb933a0e987e78cb787e5/dgl-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.17.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl) (4.4.1)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVHZxjokN3mX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dgl\n",
        "import dgl.function as fn\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from dgl import DGLGraph\n",
        "from google.colab import files\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gcn_msg = fn.copy_src(src='h', out='m')\n",
        "gcn_reduce = fn.sum(msg='m', out='h')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbLw1KjvIXxt",
        "colab_type": "text"
      },
      "source": [
        "#Building matrices for algorithm 1 execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us006QFON3ml",
        "colab_type": "code",
        "outputId": "f00ff189-8343-449f-d9b4-6c8ff40fdb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from dgl.data import citation_graph as citegrh\n",
        "import networkx as nx\n",
        "def load_citeseer_data():\n",
        "    data = citegrh.load_citeseer()\n",
        "    features = th.FloatTensor(data.features)\n",
        "    labels = th.LongTensor(data.labels)\n",
        "    mask = th.ByteTensor(data.train_mask)\n",
        "    g = data.graph\n",
        "    print(g)\n",
        "    # add self loop\n",
        "    g.remove_edges_from(nx.selfloop_edges(g))\n",
        "    g = DGLGraph(g)\n",
        "    g.add_edges(g.nodes(), g.nodes())\n",
        "    return g, features, labels, mask\n",
        "    \n",
        "#get data\n",
        "g, features, labels, mask = load_citeseer_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.dgl/citeseer.zip from https://s3.us-east-2.amazonaws.com/dgl.ai/dataset/citeseer.zip...\n",
            "Extracting file to /root/.dgl/citeseer\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/data/citation_graph.py:140: RuntimeWarning: divide by zero encountered in power\n",
            "  r_inv = np.power(rowsum, -1).flatten()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXSXEsLe4LRU",
        "colab_type": "code",
        "outputId": "81a0f852-685f-4249-bcc2-cdaa68acafaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "plain_deg_matrix = th.tensor(np.zeros((3327,3327)))\n",
        "for i in range(3327):\n",
        "  d = len(g.adjacency_matrix()[i]._indices()[0])\n",
        "  plain_deg_matrix[i][i] = d"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
            "  warnings.warn(msg, warn_type)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooyB0ahY4_4h",
        "colab_type": "code",
        "outputId": "7d51b06e-8425-4424-8fc6-a96e78c805f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "plain_deg_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 6., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 2.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 4., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 2., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 2.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6-kv5AzIcsG",
        "colab_type": "code",
        "outputId": "9d17be6c-40ef-4837-bfaf-5e0e8d3cfced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import math\n",
        "deg_matrix = th.tensor(np.zeros((3327,3327)))\n",
        "for i in range(3327):\n",
        "  d = len(g.adjacency_matrix()[i]._indices()[0])\n",
        "  deg_matrix[i][i] = math.pow(d,-0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
            "  warnings.warn(msg, warn_type)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv2IXZxXbUuy",
        "colab_type": "text"
      },
      "source": [
        "This is the diagonal degree matrix.\n",
        "This means that the degree of a node `'v'` with value `'d'`, is stored at `D[u][u]=d`, whereas all the other values of the matrix (except the diagonal) are equal to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoKiD3PhU3qr",
        "colab_type": "code",
        "outputId": "53acb259-46ae-4496-e465-d850aaa5f230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "deg_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7071, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.4082, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.7071,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.5000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.7071, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.7071]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saOTwTNqeGUY",
        "colab_type": "code",
        "outputId": "4982f133-ef11-4d9b-e6b4-228318f4b866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "g.adjacency_matrix().to_dense()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
            "  warnings.warn(msg, warn_type)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THUMmsrHbPnT",
        "colab_type": "text"
      },
      "source": [
        "This is the propagation matrix P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RJv6E9_az-g",
        "colab_type": "code",
        "outputId": "703ed330-6c31-44d8-82c4-7dc0e20ef9d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "P = th.mm(th.mm(deg_matrix.float(),g.adjacency_matrix().to_dense().float()),deg_matrix.float())\n",
        "print(P.shape)\n",
        "print(P)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
            "  warnings.warn(msg, warn_type)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3327, 3327])\n",
            "tensor([[0.5000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.1667, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.5000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.2500, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wjPK7kubzpg",
        "colab_type": "text"
      },
      "source": [
        "The object `g` allows us to get more easily the neighboors nodes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ-KmVf99CMB",
        "colab_type": "code",
        "outputId": "10d15c41-e604-478a-cc7d-5d8d51975d7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "r = random.randint(0,3326)\n",
        "print(\"Node \" + str(r))\n",
        "g.adjacency_matrix()[r]._indices()[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Node 1967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 285,  582,  637,  721, 2066, 2312, 2672, 1967])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8fm-73C-T-D",
        "colab_type": "code",
        "outputId": "f730e53f-d7d0-4303-fbbf-9dedfb9e8250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "a = list(g.adjacency_matrix()[r]._indices()[0].numpy())\n",
        "a.remove(r)\n",
        "print(type(a))\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "[285, 582, 637, 721, 2066, 2312, 2672]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNOMUjH6b_Px",
        "colab_type": "text"
      },
      "source": [
        "This is a simple method used to transforma a list into a torch.Tensor object corresponding to a mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TETrYuIvCrij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createMask(array):\n",
        "  a = []\n",
        "  for i in range(3327):\n",
        "    if i in array:\n",
        "      a.append(1)\n",
        "    else:\n",
        "      a.append(0)\n",
        "  m = th.ByteTensor(a)\n",
        "  return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nJTtgo-w2MU",
        "colab_type": "text"
      },
      "source": [
        "#Implementing algorithm 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taLcl787s7zF",
        "colab_type": "text"
      },
      "source": [
        "The following algorithm is used in order to retrive the receptive fields of each layer and the propagation matrices for each layer, just for the selected minibath of nodes.\n",
        "\n",
        "The algorithm is used in algorithm for training with CV approach.\n",
        "\n",
        "Pseudo-code:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "r_L = V_B\n",
        "for layer l = L - 1 to 0 do\n",
        "  r_l = 0\n",
        "  P'_l = 0\n",
        "  for each node u in r_l+1 do\n",
        "    r_l = r_l + {u}\n",
        "    P'_uu^l = P'_uu^l + P_uu*n(u)/D_l\n",
        "    for D_l - 1 random neighbors v in n(u) do\n",
        "      r_l = r_l + {v}\n",
        "      P'_uv^l = P'_uv^l + P_uv*n(u)/D_l\n",
        "    end for\n",
        "  end for\n",
        "end for\n",
        "```\n",
        "where\n",
        "\n",
        "\n",
        "*   r_L: the receptive field of layer L\n",
        "*   V_B: the minibatch set (a subset of nodes)\n",
        "*   P'_l: propagation matrix of the layer l\n",
        "*   P'_uv^l = P_uv^l * n(u)/D_l, if v is in n'(u)_l, otherwise 0\n",
        "*   n(u): neighbors of u\n",
        "*   n'(u): random subset of n(u)\n",
        "*   D_l: neighbors for each node at layer l\n",
        "\n",
        "Notice that, since we do not use MINIbatches, n(u)/D_l is always equal to 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "30EzN1TiVV-A",
        "colab": {}
      },
      "source": [
        "import time\n",
        "#implementation of the above algorithm#\n",
        "\n",
        "#minibatch = th.ByteTensor(...) of 0,1 boolean (it is a mask)\n",
        "\n",
        "#returning: the receptive fields and the propagation matrices\n",
        "def algOne(minibatch):\n",
        "  t0 = time.time()\n",
        "  rL = minibatch\n",
        "  l = 2\n",
        "  n = 2\n",
        "\n",
        "  receptiveField = dict()\n",
        "  propagationMatrix = dict()\n",
        "\n",
        "  receptiveField[l] = rL\n",
        "\n",
        "  #first for-loop\n",
        "  while l > 0:\n",
        "    #init\n",
        "    field = []\n",
        "    matrixP = np.zeros((3327,3327))\n",
        "    #second for-loop\n",
        "    k = 0\n",
        "    passedMask = False\n",
        "    for nodeValue in receptiveField[l]:\n",
        "      if nodeValue == 1:\n",
        "        node = k\n",
        "\n",
        "        if node not in field:\n",
        "          field.append(node)\n",
        "\n",
        "        matrixP[node][node] = matrixP[node][node] + P[node][node] * plain_deg_matrix[node][node] / n\n",
        "\n",
        "        #collecting n random neighbor\n",
        "        subset = []\n",
        "        a = list(g.adjacency_matrix()[node]._indices()[0].numpy())\n",
        "        a.remove(node)\n",
        "        if len(a) <= n:\n",
        "          subset = a\n",
        "        else:\n",
        "          subset = random.sample(a, k=n)\n",
        "\n",
        "        #last for-loop\n",
        "        for neighbor in subset:\n",
        "          if neighbor not in field:\n",
        "            field.append(neighbor)\n",
        "          matrixP[node][neighbor] = matrixP[node][neighbor] + P[node][neighbor] * plain_deg_matrix[node][node] / n\n",
        "\n",
        "      k = k + 1\n",
        "      \n",
        "    #updating level\n",
        "    l = l - 1\n",
        "\n",
        "    #convert field (array of nodes) to a mask\n",
        "    receptiveField[l] = createMask(field).detach()\n",
        "    propagationMatrix[l] = th.FloatTensor(matrixP).detach()\n",
        "  \n",
        "  #print(time.time() - t0)\n",
        "  return [receptiveField, propagationMatrix]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1GVRCyIN3mW",
        "colab_type": "text"
      },
      "source": [
        "#Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrKmDjqXcIuC",
        "colab_type": "text"
      },
      "source": [
        "Some commond parameters used to train the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45EUaxAcD04F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_of_training_cycles = 15\n",
        "n_of_epochs = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45QJRof3cNIN",
        "colab_type": "text"
      },
      "source": [
        "This methods creates some random masks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVcFLcl8V8vY",
        "colab_type": "code",
        "outputId": "44ad9483-5f04-4b43-b7e6-d9a753c71da3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#random mask\n",
        "masks = []\n",
        "n_masks = 10\n",
        "size_masks = 100\n",
        "a = range(3327)\n",
        "for i in range(n_masks):\n",
        "  mask = np.zeros(3327)\n",
        "  sub = random.sample(a,k=size_masks)\n",
        "  for s in sub:\n",
        "    mask[s] = 1\n",
        "  m = th.ByteTensor(mask)\n",
        "  masks.append(m)\n",
        "\n",
        "print(\"Generated \" + str(n_masks) + \" random masks with size \" + str(size_masks))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated 10 random masks with size 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgeKlv_CN3ma",
        "colab_type": "text"
      },
      "source": [
        "We then define the node UDF for ``apply_nodes``, which is a fully-connected layer:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcTM-w1gN3mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NodeApplyModule(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, activation):\n",
        "        super(NodeApplyModule, self).__init__()\n",
        "        self.linear = nn.Linear(in_feats, out_feats)\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, node):\n",
        "        z = self.linear(node.data['h'])\n",
        "        h = self.activation(z)\n",
        "        return {'h' : h}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD1DNkN8N3md",
        "colab_type": "text"
      },
      "source": [
        "We then proceed to define the GCN module. A GCN layer essentially performs\n",
        "message passing on all the nodes then applies the `NodeApplyModule`. Note\n",
        "that we omitted the dropout in the paper for simplicity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQy_eUuWN3me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, activation):\n",
        "        super(GCN, self).__init__()\n",
        "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
        "\n",
        "    def forward(self, g, feature):\n",
        "        g.ndata['h'] = feature\n",
        "        g.update_all(gcn_msg, gcn_reduce)\n",
        "        g.apply_nodes(func=self.apply_mod)\n",
        "        return g.ndata.pop('h')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEMMI4CXN3mh",
        "colab_type": "text"
      },
      "source": [
        "The forward function is essentially the same as any other commonly seen NNs\n",
        "model in PyTorch.  We can initialize GCN like any ``nn.Module``. For example,\n",
        "let's define a simple neural network consisting of two GCN layers. Suppose we\n",
        "are training the classifier for the CiteSeer dataset (the input feature size is\n",
        "3703 and the number of classes is 6).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVVOgunmN3mh",
        "colab_type": "code",
        "outputId": "3962f696-2130-4930-c9ed-20b2a1be7d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.gcn1 = GCN(3703, 40, F.relu)\n",
        "        self.gcn2 = GCN(40, 6, F.relu)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.gcn1(g, features)\n",
        "        x = self.gcn2(g, x)\n",
        "        return x\n",
        "        \n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (gcn1): GCN(\n",
            "    (apply_mod): NodeApplyModule(\n",
            "      (linear): Linear(in_features=3703, out_features=40, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (gcn2): GCN(\n",
            "    (apply_mod): NodeApplyModule(\n",
            "      (linear): Linear(in_features=40, out_features=6, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V5DJfryN3mk",
        "colab_type": "text"
      },
      "source": [
        "We load the CiteSeer dataset using DGL's built-in data module.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFzGHVDwN3mn",
        "colab_type": "text"
      },
      "source": [
        "We then train the network as follows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9z-t8-jmRLM",
        "colab_type": "text"
      },
      "source": [
        "This is the implementation of a standard GCN with 2 layers (+ 1 input layer). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0RwjiSi5Fz5",
        "colab_type": "text"
      },
      "source": [
        "TEST --------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJSEARJJ9MWr",
        "colab_type": "text"
      },
      "source": [
        "In order to get the most effective learning rate for the CiteSeer set, running these cells multiple times will show comparison of performance between 4 different learning rates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53dK1Oeb6gwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrAccTest = dict()\n",
        "lrLossTest = dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sAwautQX5zYG",
        "colab": {}
      },
      "source": [
        "def updatePoints(index,accCS,lossCS, acc, loss):\n",
        "  accPointsTest = [0]*30\n",
        "  lossPointsTest = [0]*30\n",
        "\n",
        "  for d in range(3):\n",
        "    for i in range(30):\n",
        "      accPointsTest[i] = accPointsTest[i] + accCS[d][i]\n",
        "      lossPointsTest[i] = lossPointsTest[i] + lossCS[d][i]\n",
        "\n",
        "  for i in range(30):\n",
        "    accPointsTest[i] = accPointsTest[i]/3\n",
        "    lossPointsTest[i] = lossPointsTest[i]/3\n",
        "  \n",
        "  acc[index] = accPointsTest\n",
        "  loss[index] = lossPointsTest\n",
        "  return [acc,loss]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlaqREoy5FRb",
        "colab_type": "code",
        "outputId": "a049e86a-3ee2-445f-aaa3-32d05e478f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "import collections\n",
        "import numpy as np\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#init counters\n",
        "lrs = [1e-1, 1e-2, 1e-3, 1e-4]\n",
        "for actualLR in lrs:\n",
        "  testAccCS = []\n",
        "  testLossCS = []\n",
        "  for t in range(3):\n",
        "    print(\"Starting new training\")\n",
        "    #get data from DGL\n",
        "    net = Net()\n",
        "    g, features, labels, mask = load_citeseer_data()\n",
        "    print(g)\n",
        "\n",
        "    #point to show on graph\n",
        "    pointsCiteSeer=dict()\n",
        "    pointsLossCiteSeer=dict()\n",
        "\n",
        "    #the number of masks to get when training per epoch\n",
        "    n_masks_to_try = 4\n",
        "    #initializing the optimizer (optimizer takes care of optimize the learining rate during training)\n",
        "    optimizer = th.optim.Adam(net.parameters(), lr=actualLR)\n",
        "    optimizer.state = collections.defaultdict(dict)\n",
        "\n",
        "    #dur is just an array to store the duration in order to show them later\n",
        "    dur = []\n",
        "\n",
        "    for epoch in range(30):\n",
        "        t0 = time.time()\n",
        "\n",
        "        #getting only some masks (4)\n",
        "        masksToTry = random.sample(masks,n_masks_to_try)\n",
        "\n",
        "        for m in masksToTry:\n",
        "            #calling 'net(...)' it asks to the GCN to compute the forward    \n",
        "\n",
        "            logits = net(g, features)\n",
        "            logp = F.log_softmax(logits, 1)\n",
        "\n",
        "            #compute loss like the negative log likelihood loss\n",
        "            loss = F.nll_loss(logp[m], labels[m])\n",
        "            \n",
        "            #Since the backward() function accumulates gradients, and you \n",
        "            #don’t want to mix up gradients between minibatch, you have \n",
        "            #to zero them out at the start of a new minibatch. This is \n",
        "            #exactly like how a general (additive) accumulator variable is \n",
        "            #initialized to 0 in code.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #update network weights by loss\n",
        "            loss.backward()\n",
        "\n",
        "            #update optimizer's values after backward\n",
        "            optimizer.step()\n",
        "\n",
        "            #computing accuracy\n",
        "            i = 0\n",
        "            matched = 0\n",
        "            while i < 3327:\n",
        "              if m[i] == 0:\n",
        "                #getting index of the maximum\n",
        "                j = 0\n",
        "                max = None\n",
        "                jMax = 0\n",
        "                for a in logp[i]:\n",
        "                  if max==None:\n",
        "                    max = a.item()\n",
        "                    jMax = j\n",
        "                  elif max < a.item():\n",
        "                    max = a.item()\n",
        "                    jMax = j\n",
        "                  j = j + 1\n",
        "                if jMax == labels[i]:\n",
        "                  matched = matched + 1\n",
        "              i = i + 1\n",
        "            acc = matched/(3327-size_masks)*100\n",
        "\n",
        "            if epoch not in pointsCiteSeer:\n",
        "              pointsCiteSeer[epoch] = 0\n",
        "              pointsLossCiteSeer[epoch] = 0\n",
        "            pointsCiteSeer[epoch] = pointsCiteSeer[epoch] + acc\n",
        "            pointsLossCiteSeer[epoch] = pointsLossCiteSeer[epoch] + loss.item()\n",
        "            \n",
        "        dur.append(time.time() - t0)\n",
        "        \n",
        "        #computing the average of the accuracy and the loss\n",
        "        pointsCiteSeer[epoch] = pointsCiteSeer[epoch]/n_masks_to_try\n",
        "        pointsLossCiteSeer[epoch] = pointsLossCiteSeer[epoch]/n_masks_to_try\n",
        "\n",
        "        print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f} | Accuracy: {:.6f} %\".format(\n",
        "                epoch, loss.item(), np.mean(dur), pointsCiteSeer[epoch]))\n",
        "    #storing results    \n",
        "    testAccCS.append(pointsCiteSeer)\n",
        "    testLossCS.append(pointsLossCiteSeer)\n",
        "    print(\"Results stored.\")\n",
        "  print(\"New learning rate...\")\n",
        "  r = updatePoints(actualLR,testAccCS,testLossCS, lrAccTest, lrLossTest)\n",
        "  lrAccTest = r[0]\n",
        "  lrLossTest = r[1]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 2.2088 | Time(s) 2.6612 | Accuracy: 20.537651 %\n",
            "Epoch 00001 | Loss 1.6446 | Time(s) 2.5940 | Accuracy: 14.758289 %\n",
            "Epoch 00002 | Loss 1.5794 | Time(s) 2.5599 | Accuracy: 17.105671 %\n",
            "Epoch 00003 | Loss 1.6883 | Time(s) 2.5443 | Accuracy: 27.835451 %\n",
            "Epoch 00004 | Loss 1.4132 | Time(s) 2.5417 | Accuracy: 30.082120 %\n",
            "Epoch 00005 | Loss 1.4902 | Time(s) 2.5433 | Accuracy: 31.848466 %\n",
            "Epoch 00006 | Loss 1.2668 | Time(s) 2.5370 | Accuracy: 32.444995 %\n",
            "Epoch 00007 | Loss 1.2001 | Time(s) 2.5320 | Accuracy: 34.071893 %\n",
            "Epoch 00008 | Loss 1.2998 | Time(s) 2.5284 | Accuracy: 36.202355 %\n",
            "Epoch 00009 | Loss 1.3690 | Time(s) 2.5256 | Accuracy: 37.077781 %\n",
            "Epoch 00010 | Loss 1.3696 | Time(s) 2.5253 | Accuracy: 35.667803 %\n",
            "Epoch 00011 | Loss 1.3094 | Time(s) 2.5232 | Accuracy: 36.589712 %\n",
            "Epoch 00012 | Loss 1.0754 | Time(s) 2.5214 | Accuracy: 36.791137 %\n",
            "Epoch 00013 | Loss 1.0574 | Time(s) 2.5195 | Accuracy: 37.039046 %\n",
            "Epoch 00014 | Loss 1.0885 | Time(s) 2.5184 | Accuracy: 37.674311 %\n",
            "Epoch 00015 | Loss 1.1809 | Time(s) 2.5179 | Accuracy: 37.914472 %\n",
            "Epoch 00016 | Loss 1.2046 | Time(s) 2.5181 | Accuracy: 37.929966 %\n",
            "Epoch 00017 | Loss 1.1705 | Time(s) 2.5193 | Accuracy: 37.937713 %\n",
            "Epoch 00018 | Loss 1.2282 | Time(s) 2.5219 | Accuracy: 38.208863 %\n",
            "Epoch 00019 | Loss 1.3284 | Time(s) 2.5238 | Accuracy: 38.115897 %\n",
            "Epoch 00020 | Loss 1.0259 | Time(s) 2.5247 | Accuracy: 37.914472 %\n",
            "Epoch 00021 | Loss 1.2716 | Time(s) 2.5245 | Accuracy: 37.991943 %\n",
            "Epoch 00022 | Loss 1.0085 | Time(s) 2.5253 | Accuracy: 38.030679 %\n",
            "Epoch 00023 | Loss 1.0353 | Time(s) 2.5256 | Accuracy: 38.170127 %\n",
            "Epoch 00024 | Loss 1.2083 | Time(s) 2.5256 | Accuracy: 38.317323 %\n",
            "Epoch 00025 | Loss 1.3923 | Time(s) 2.5257 | Accuracy: 38.634955 %\n",
            "Epoch 00026 | Loss 1.2673 | Time(s) 2.5267 | Accuracy: 38.146886 %\n",
            "Epoch 00027 | Loss 1.2621 | Time(s) 2.5263 | Accuracy: 37.480632 %\n",
            "Epoch 00028 | Loss 1.2522 | Time(s) 2.5262 | Accuracy: 37.759529 %\n",
            "Epoch 00029 | Loss 1.2358 | Time(s) 2.5258 | Accuracy: 37.720793 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7918 | Time(s) 2.5758 | Accuracy: 14.487140 %\n",
            "Epoch 00001 | Loss 1.7927 | Time(s) 2.5463 | Accuracy: 7.933065 %\n",
            "Epoch 00002 | Loss 1.7918 | Time(s) 2.5355 | Accuracy: 7.971800 %\n",
            "Epoch 00003 | Loss 1.7918 | Time(s) 2.5299 | Accuracy: 7.948559 %\n",
            "Epoch 00004 | Loss 1.7918 | Time(s) 2.5304 | Accuracy: 7.847846 %\n",
            "Epoch 00005 | Loss 1.7918 | Time(s) 2.5286 | Accuracy: 7.948559 %\n",
            "Epoch 00006 | Loss 1.7918 | Time(s) 2.5276 | Accuracy: 7.971800 %\n",
            "Epoch 00007 | Loss 1.7918 | Time(s) 2.5271 | Accuracy: 7.971800 %\n",
            "Epoch 00008 | Loss 1.7918 | Time(s) 2.5293 | Accuracy: 7.878835 %\n",
            "Epoch 00009 | Loss 1.7918 | Time(s) 2.5303 | Accuracy: 7.956306 %\n",
            "Epoch 00010 | Loss 1.7918 | Time(s) 2.5314 | Accuracy: 7.925318 %\n",
            "Epoch 00011 | Loss 1.7918 | Time(s) 2.5322 | Accuracy: 7.886582 %\n",
            "Epoch 00012 | Loss 1.7918 | Time(s) 2.5350 | Accuracy: 7.940812 %\n",
            "Epoch 00013 | Loss 1.7918 | Time(s) 2.5358 | Accuracy: 7.971800 %\n",
            "Epoch 00014 | Loss 1.7918 | Time(s) 2.5354 | Accuracy: 7.894329 %\n",
            "Epoch 00015 | Loss 1.7918 | Time(s) 2.5345 | Accuracy: 7.917570 %\n",
            "Epoch 00016 | Loss 1.7918 | Time(s) 2.5358 | Accuracy: 7.917570 %\n",
            "Epoch 00017 | Loss 1.7918 | Time(s) 2.5379 | Accuracy: 7.855593 %\n",
            "Epoch 00018 | Loss 1.7918 | Time(s) 2.5390 | Accuracy: 7.964053 %\n",
            "Epoch 00019 | Loss 1.7918 | Time(s) 2.5361 | Accuracy: 7.940812 %\n",
            "Epoch 00020 | Loss 1.7918 | Time(s) 2.5343 | Accuracy: 7.871088 %\n",
            "Epoch 00021 | Loss 1.7918 | Time(s) 2.5338 | Accuracy: 7.995042 %\n",
            "Epoch 00022 | Loss 1.7918 | Time(s) 2.5343 | Accuracy: 7.940812 %\n",
            "Epoch 00023 | Loss 1.7918 | Time(s) 2.5336 | Accuracy: 7.956306 %\n",
            "Epoch 00024 | Loss 1.7918 | Time(s) 2.5341 | Accuracy: 7.871088 %\n",
            "Epoch 00025 | Loss 1.7918 | Time(s) 2.5337 | Accuracy: 7.956306 %\n",
            "Epoch 00026 | Loss 1.7918 | Time(s) 2.5328 | Accuracy: 7.956306 %\n",
            "Epoch 00027 | Loss 1.7918 | Time(s) 2.5328 | Accuracy: 7.925318 %\n",
            "Epoch 00028 | Loss 1.7918 | Time(s) 2.5333 | Accuracy: 7.940812 %\n",
            "Epoch 00029 | Loss 1.7918 | Time(s) 2.5329 | Accuracy: 7.964053 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7918 | Time(s) 2.5255 | Accuracy: 11.589712 %\n",
            "Epoch 00001 | Loss 1.7918 | Time(s) 2.5227 | Accuracy: 7.925318 %\n",
            "Epoch 00002 | Loss 1.7918 | Time(s) 2.5298 | Accuracy: 7.964053 %\n",
            "Epoch 00003 | Loss 1.7918 | Time(s) 2.5282 | Accuracy: 7.886582 %\n",
            "Epoch 00004 | Loss 1.7918 | Time(s) 2.5263 | Accuracy: 7.894329 %\n",
            "Epoch 00005 | Loss 1.7918 | Time(s) 2.5283 | Accuracy: 7.902076 %\n",
            "Epoch 00006 | Loss 1.7918 | Time(s) 2.5315 | Accuracy: 7.948559 %\n",
            "Epoch 00007 | Loss 1.7918 | Time(s) 2.5307 | Accuracy: 7.886582 %\n",
            "Epoch 00008 | Loss 1.7918 | Time(s) 2.5269 | Accuracy: 7.855593 %\n",
            "Epoch 00009 | Loss 1.7918 | Time(s) 2.5275 | Accuracy: 7.894329 %\n",
            "Epoch 00010 | Loss 1.7918 | Time(s) 2.5295 | Accuracy: 7.878835 %\n",
            "Epoch 00011 | Loss 1.7918 | Time(s) 2.5288 | Accuracy: 7.902076 %\n",
            "Epoch 00012 | Loss 1.7918 | Time(s) 2.5281 | Accuracy: 7.909823 %\n",
            "Epoch 00013 | Loss 1.7918 | Time(s) 2.5274 | Accuracy: 7.964053 %\n",
            "Epoch 00014 | Loss 1.7918 | Time(s) 2.5303 | Accuracy: 7.902076 %\n",
            "Epoch 00015 | Loss 1.7918 | Time(s) 2.5314 | Accuracy: 7.847846 %\n",
            "Epoch 00016 | Loss 1.7918 | Time(s) 2.5261 | Accuracy: 7.933065 %\n",
            "Epoch 00017 | Loss 1.7918 | Time(s) 2.5244 | Accuracy: 7.902076 %\n",
            "Epoch 00018 | Loss 1.7918 | Time(s) 2.5244 | Accuracy: 7.917570 %\n",
            "Epoch 00019 | Loss 1.7918 | Time(s) 2.5240 | Accuracy: 7.933065 %\n",
            "Epoch 00020 | Loss 1.7918 | Time(s) 2.5243 | Accuracy: 7.933065 %\n",
            "Epoch 00021 | Loss 1.7918 | Time(s) 2.5236 | Accuracy: 7.886582 %\n",
            "Epoch 00022 | Loss 1.7918 | Time(s) 2.5237 | Accuracy: 7.971800 %\n",
            "Epoch 00023 | Loss 1.7918 | Time(s) 2.5238 | Accuracy: 7.886582 %\n",
            "Epoch 00024 | Loss 1.7918 | Time(s) 2.5235 | Accuracy: 7.902076 %\n",
            "Epoch 00025 | Loss 1.7918 | Time(s) 2.5232 | Accuracy: 7.948559 %\n",
            "Epoch 00026 | Loss 1.7918 | Time(s) 2.5228 | Accuracy: 7.886582 %\n",
            "Epoch 00027 | Loss 1.7918 | Time(s) 2.5235 | Accuracy: 7.925318 %\n",
            "Epoch 00028 | Loss 1.7918 | Time(s) 2.5238 | Accuracy: 7.894329 %\n",
            "Epoch 00029 | Loss 1.7918 | Time(s) 2.5232 | Accuracy: 7.917570 %\n",
            "Results stored.\n",
            "New learning rate...\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.6293 | Time(s) 2.6153 | Accuracy: 21.002479 %\n",
            "Epoch 00001 | Loss 1.5371 | Time(s) 2.5812 | Accuracy: 52.169197 %\n",
            "Epoch 00002 | Loss 1.2620 | Time(s) 2.5755 | Accuracy: 56.639293 %\n",
            "Epoch 00003 | Loss 1.3143 | Time(s) 2.5699 | Accuracy: 58.026030 %\n",
            "Epoch 00004 | Loss 1.2255 | Time(s) 2.5678 | Accuracy: 59.405020 %\n",
            "Epoch 00005 | Loss 1.3989 | Time(s) 2.5710 | Accuracy: 59.885342 %\n",
            "Epoch 00006 | Loss 0.9672 | Time(s) 2.5684 | Accuracy: 60.799504 %\n",
            "Epoch 00007 | Loss 0.9842 | Time(s) 2.5669 | Accuracy: 62.062287 %\n",
            "Epoch 00008 | Loss 0.9078 | Time(s) 2.5663 | Accuracy: 61.667183 %\n",
            "Epoch 00009 | Loss 1.0514 | Time(s) 2.5704 | Accuracy: 62.542609 %\n",
            "Epoch 00010 | Loss 0.9276 | Time(s) 2.5693 | Accuracy: 62.790518 %\n",
            "Epoch 00011 | Loss 0.8356 | Time(s) 2.5677 | Accuracy: 62.697552 %\n",
            "Epoch 00012 | Loss 0.9430 | Time(s) 2.5658 | Accuracy: 63.472265 %\n",
            "Epoch 00013 | Loss 0.6769 | Time(s) 2.5658 | Accuracy: 64.099783 %\n",
            "Epoch 00014 | Loss 0.6456 | Time(s) 2.5647 | Accuracy: 63.929346 %\n",
            "Epoch 00015 | Loss 0.6079 | Time(s) 2.5638 | Accuracy: 63.572978 %\n",
            "Epoch 00016 | Loss 0.5095 | Time(s) 2.5620 | Accuracy: 65.432290 %\n",
            "Epoch 00017 | Loss 0.5959 | Time(s) 2.5618 | Accuracy: 65.486520 %\n",
            "Epoch 00018 | Loss 0.6570 | Time(s) 2.5607 | Accuracy: 64.820267 %\n",
            "Epoch 00019 | Loss 0.4965 | Time(s) 2.5600 | Accuracy: 64.982956 %\n",
            "Epoch 00020 | Loss 0.7598 | Time(s) 2.5601 | Accuracy: 64.982956 %\n",
            "Epoch 00021 | Loss 0.5698 | Time(s) 2.5615 | Accuracy: 64.913232 %\n",
            "Epoch 00022 | Loss 0.5181 | Time(s) 2.5608 | Accuracy: 65.393554 %\n",
            "Epoch 00023 | Loss 0.4697 | Time(s) 2.5606 | Accuracy: 65.385807 %\n",
            "Epoch 00024 | Loss 0.3521 | Time(s) 2.5603 | Accuracy: 65.579486 %\n",
            "Epoch 00025 | Loss 0.6161 | Time(s) 2.5602 | Accuracy: 65.749923 %\n",
            "Epoch 00026 | Loss 0.4066 | Time(s) 2.5607 | Accuracy: 65.502014 %\n",
            "Epoch 00027 | Loss 0.3901 | Time(s) 2.5603 | Accuracy: 65.502014 %\n",
            "Epoch 00028 | Loss 0.3692 | Time(s) 2.5606 | Accuracy: 65.145646 %\n",
            "Epoch 00029 | Loss 0.4867 | Time(s) 2.5603 | Accuracy: 64.580105 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7024 | Time(s) 2.5355 | Accuracy: 20.498915 %\n",
            "Epoch 00001 | Loss 1.5607 | Time(s) 2.5411 | Accuracy: 28.083359 %\n",
            "Epoch 00002 | Loss 1.4331 | Time(s) 2.5445 | Accuracy: 35.110009 %\n",
            "Epoch 00003 | Loss 1.5236 | Time(s) 2.5442 | Accuracy: 36.628447 %\n",
            "Epoch 00004 | Loss 1.4729 | Time(s) 2.5389 | Accuracy: 37.317942 %\n",
            "Epoch 00005 | Loss 1.2735 | Time(s) 2.5381 | Accuracy: 35.605826 %\n",
            "Epoch 00006 | Loss 1.3790 | Time(s) 2.5341 | Accuracy: 38.123644 %\n",
            "Epoch 00007 | Loss 1.3796 | Time(s) 2.5379 | Accuracy: 37.674311 %\n",
            "Epoch 00008 | Loss 1.3523 | Time(s) 2.5355 | Accuracy: 37.395414 %\n",
            "Epoch 00009 | Loss 1.1833 | Time(s) 2.5354 | Accuracy: 37.604586 %\n",
            "Epoch 00010 | Loss 1.2652 | Time(s) 2.5350 | Accuracy: 37.945460 %\n",
            "Epoch 00011 | Loss 1.2816 | Time(s) 2.5352 | Accuracy: 38.743415 %\n",
            "Epoch 00012 | Loss 1.2663 | Time(s) 2.5333 | Accuracy: 39.363186 %\n",
            "Epoch 00013 | Loss 1.2337 | Time(s) 2.5321 | Accuracy: 39.363186 %\n",
            "Epoch 00014 | Loss 1.0181 | Time(s) 2.5324 | Accuracy: 38.999070 %\n",
            "Epoch 00015 | Loss 1.1797 | Time(s) 2.5351 | Accuracy: 39.665324 %\n",
            "Epoch 00016 | Loss 1.1787 | Time(s) 2.5353 | Accuracy: 39.425163 %\n",
            "Epoch 00017 | Loss 1.1146 | Time(s) 2.5358 | Accuracy: 39.665324 %\n",
            "Epoch 00018 | Loss 1.3158 | Time(s) 2.5361 | Accuracy: 39.766037 %\n",
            "Epoch 00019 | Loss 1.2222 | Time(s) 2.5374 | Accuracy: 38.449024 %\n",
            "Epoch 00020 | Loss 1.0888 | Time(s) 2.5375 | Accuracy: 39.123024 %\n",
            "Epoch 00021 | Loss 1.1218 | Time(s) 2.5369 | Accuracy: 39.417416 %\n",
            "Epoch 00022 | Loss 1.0284 | Time(s) 2.5364 | Accuracy: 39.045553 %\n",
            "Epoch 00023 | Loss 1.2045 | Time(s) 2.5361 | Accuracy: 39.092036 %\n",
            "Epoch 00024 | Loss 0.9785 | Time(s) 2.5360 | Accuracy: 39.556864 %\n",
            "Epoch 00025 | Loss 1.2532 | Time(s) 2.5356 | Accuracy: 39.851255 %\n",
            "Epoch 00026 | Loss 1.0289 | Time(s) 2.5375 | Accuracy: 39.502634 %\n",
            "Epoch 00027 | Loss 1.0759 | Time(s) 2.5368 | Accuracy: 39.208243 %\n",
            "Epoch 00028 | Loss 1.1595 | Time(s) 2.5374 | Accuracy: 39.277967 %\n",
            "Epoch 00029 | Loss 1.0007 | Time(s) 2.5370 | Accuracy: 39.487140 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7067 | Time(s) 2.5670 | Accuracy: 27.099473 %\n",
            "Epoch 00001 | Loss 1.5255 | Time(s) 2.5558 | Accuracy: 42.826154 %\n",
            "Epoch 00002 | Loss 1.4666 | Time(s) 2.5643 | Accuracy: 47.056089 %\n",
            "Epoch 00003 | Loss 1.2568 | Time(s) 2.5585 | Accuracy: 47.823055 %\n",
            "Epoch 00004 | Loss 1.3993 | Time(s) 2.5538 | Accuracy: 47.226526 %\n",
            "Epoch 00005 | Loss 1.1598 | Time(s) 2.5456 | Accuracy: 48.256895 %\n",
            "Epoch 00006 | Loss 1.0398 | Time(s) 2.5481 | Accuracy: 47.699101 %\n",
            "Epoch 00007 | Loss 1.1674 | Time(s) 2.5450 | Accuracy: 48.992873 %\n",
            "Epoch 00008 | Loss 1.1063 | Time(s) 2.5451 | Accuracy: 49.488689 %\n",
            "Epoch 00009 | Loss 1.0056 | Time(s) 2.5441 | Accuracy: 49.186551 %\n",
            "Epoch 00010 | Loss 0.8071 | Time(s) 2.5476 | Accuracy: 48.806941 %\n",
            "Epoch 00011 | Loss 0.9906 | Time(s) 2.5452 | Accuracy: 49.101333 %\n",
            "Epoch 00012 | Loss 1.0120 | Time(s) 2.5437 | Accuracy: 49.418965 %\n",
            "Epoch 00013 | Loss 0.8703 | Time(s) 2.5410 | Accuracy: 49.434459 %\n",
            "Epoch 00014 | Loss 0.8532 | Time(s) 2.5412 | Accuracy: 49.310505 %\n",
            "Epoch 00015 | Loss 0.9457 | Time(s) 2.5393 | Accuracy: 49.442206 %\n",
            "Epoch 00016 | Loss 0.9461 | Time(s) 2.5381 | Accuracy: 49.635885 %\n",
            "Epoch 00017 | Loss 0.7058 | Time(s) 2.5373 | Accuracy: 49.705609 %\n",
            "Epoch 00018 | Loss 0.6902 | Time(s) 2.5369 | Accuracy: 49.302758 %\n",
            "Epoch 00019 | Loss 0.8389 | Time(s) 2.5357 | Accuracy: 49.287264 %\n",
            "Epoch 00020 | Loss 0.8278 | Time(s) 2.5351 | Accuracy: 49.271769 %\n",
            "Epoch 00021 | Loss 0.9474 | Time(s) 2.5342 | Accuracy: 49.132321 %\n",
            "Epoch 00022 | Loss 0.8957 | Time(s) 2.5336 | Accuracy: 49.256275 %\n",
            "Epoch 00023 | Loss 0.6872 | Time(s) 2.5327 | Accuracy: 49.054850 %\n",
            "Epoch 00024 | Loss 0.9525 | Time(s) 2.5319 | Accuracy: 49.418965 %\n",
            "Epoch 00025 | Loss 0.8391 | Time(s) 2.5315 | Accuracy: 49.062597 %\n",
            "Epoch 00026 | Loss 0.8206 | Time(s) 2.5319 | Accuracy: 48.938643 %\n",
            "Epoch 00027 | Loss 0.7742 | Time(s) 2.5313 | Accuracy: 48.814689 %\n",
            "Epoch 00028 | Loss 0.7960 | Time(s) 2.5306 | Accuracy: 49.085838 %\n",
            "Epoch 00029 | Loss 0.7639 | Time(s) 2.5298 | Accuracy: 48.915401 %\n",
            "Results stored.\n",
            "New learning rate...\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7734 | Time(s) 2.5276 | Accuracy: 30.299039 %\n",
            "Epoch 00001 | Loss 1.6840 | Time(s) 2.5243 | Accuracy: 34.350790 %\n",
            "Epoch 00002 | Loss 1.6358 | Time(s) 2.5275 | Accuracy: 39.006817 %\n",
            "Epoch 00003 | Loss 1.6836 | Time(s) 2.5289 | Accuracy: 44.243880 %\n",
            "Epoch 00004 | Loss 1.6521 | Time(s) 2.5300 | Accuracy: 47.699101 %\n",
            "Epoch 00005 | Loss 1.6181 | Time(s) 2.5301 | Accuracy: 50.805702 %\n",
            "Epoch 00006 | Loss 1.4744 | Time(s) 2.5303 | Accuracy: 53.308026 %\n",
            "Epoch 00007 | Loss 1.5617 | Time(s) 2.5291 | Accuracy: 53.416486 %\n",
            "Epoch 00008 | Loss 1.4804 | Time(s) 2.5300 | Accuracy: 54.872947 %\n",
            "Epoch 00009 | Loss 1.3637 | Time(s) 2.5282 | Accuracy: 55.562442 %\n",
            "Epoch 00010 | Loss 1.3681 | Time(s) 2.5268 | Accuracy: 56.050511 %\n",
            "Epoch 00011 | Loss 1.4102 | Time(s) 2.5270 | Accuracy: 56.608305 %\n",
            "Epoch 00012 | Loss 1.3926 | Time(s) 2.5293 | Accuracy: 57.228076 %\n",
            "Epoch 00013 | Loss 1.2431 | Time(s) 2.5308 | Accuracy: 58.297180 %\n",
            "Epoch 00014 | Loss 1.3276 | Time(s) 2.5309 | Accuracy: 60.218469 %\n",
            "Epoch 00015 | Loss 1.1839 | Time(s) 2.5300 | Accuracy: 61.535482 %\n",
            "Epoch 00016 | Loss 1.1951 | Time(s) 2.5289 | Accuracy: 62.976449 %\n",
            "Epoch 00017 | Loss 1.2388 | Time(s) 2.5312 | Accuracy: 64.223737 %\n",
            "Epoch 00018 | Loss 1.1410 | Time(s) 2.5310 | Accuracy: 64.920979 %\n",
            "Epoch 00019 | Loss 1.2992 | Time(s) 2.5312 | Accuracy: 65.959095 %\n",
            "Epoch 00020 | Loss 1.1923 | Time(s) 2.5305 | Accuracy: 67.159901 %\n",
            "Epoch 00021 | Loss 1.1508 | Time(s) 2.5307 | Accuracy: 67.454292 %\n",
            "Epoch 00022 | Loss 1.1965 | Time(s) 2.5304 | Accuracy: 67.981097 %\n",
            "Epoch 00023 | Loss 1.1244 | Time(s) 2.5297 | Accuracy: 69.073443 %\n",
            "Epoch 00024 | Loss 1.0014 | Time(s) 2.5289 | Accuracy: 70.553145 %\n",
            "Epoch 00025 | Loss 0.9694 | Time(s) 2.5296 | Accuracy: 71.970871 %\n",
            "Epoch 00026 | Loss 1.0372 | Time(s) 2.5292 | Accuracy: 72.017354 %\n",
            "Epoch 00027 | Loss 0.8953 | Time(s) 2.5296 | Accuracy: 70.708088 %\n",
            "Epoch 00028 | Loss 0.8661 | Time(s) 2.5289 | Accuracy: 69.987605 %\n",
            "Epoch 00029 | Loss 1.0649 | Time(s) 2.5296 | Accuracy: 70.568640 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7841 | Time(s) 2.5166 | Accuracy: 13.077161 %\n",
            "Epoch 00001 | Loss 1.7637 | Time(s) 2.5202 | Accuracy: 26.828324 %\n",
            "Epoch 00002 | Loss 1.6625 | Time(s) 2.5178 | Accuracy: 31.747753 %\n",
            "Epoch 00003 | Loss 1.6110 | Time(s) 2.5203 | Accuracy: 36.473505 %\n",
            "Epoch 00004 | Loss 1.6763 | Time(s) 2.5207 | Accuracy: 40.114658 %\n",
            "Epoch 00005 | Loss 1.6526 | Time(s) 2.5202 | Accuracy: 42.051441 %\n",
            "Epoch 00006 | Loss 1.5822 | Time(s) 2.5220 | Accuracy: 43.538891 %\n",
            "Epoch 00007 | Loss 1.6109 | Time(s) 2.5242 | Accuracy: 44.662225 %\n",
            "Epoch 00008 | Loss 1.5788 | Time(s) 2.5257 | Accuracy: 45.204524 %\n",
            "Epoch 00009 | Loss 1.5138 | Time(s) 2.5263 | Accuracy: 47.722343 %\n",
            "Epoch 00010 | Loss 1.5367 | Time(s) 2.5288 | Accuracy: 50.999380 %\n",
            "Epoch 00011 | Loss 1.4682 | Time(s) 2.5322 | Accuracy: 54.934924 %\n",
            "Epoch 00012 | Loss 1.4774 | Time(s) 2.5314 | Accuracy: 57.127363 %\n",
            "Epoch 00013 | Loss 1.4531 | Time(s) 2.5310 | Accuracy: 58.033778 %\n",
            "Epoch 00014 | Loss 1.3672 | Time(s) 2.5310 | Accuracy: 59.707158 %\n",
            "Epoch 00015 | Loss 1.4855 | Time(s) 2.5307 | Accuracy: 60.140998 %\n",
            "Epoch 00016 | Loss 1.3578 | Time(s) 2.5310 | Accuracy: 60.605826 %\n",
            "Epoch 00017 | Loss 1.2725 | Time(s) 2.5302 | Accuracy: 61.179114 %\n",
            "Epoch 00018 | Loss 1.2919 | Time(s) 2.5303 | Accuracy: 61.930586 %\n",
            "Epoch 00019 | Loss 1.2242 | Time(s) 2.5309 | Accuracy: 62.395414 %\n",
            "Epoch 00020 | Loss 1.2924 | Time(s) 2.5328 | Accuracy: 62.186241 %\n",
            "Epoch 00021 | Loss 1.2486 | Time(s) 2.5326 | Accuracy: 62.294701 %\n",
            "Epoch 00023 | Loss 1.1376 | Time(s) 2.5325 | Accuracy: 62.441896 %\n",
            "Epoch 00024 | Loss 1.3657 | Time(s) 2.5328 | Accuracy: 62.240471 %\n",
            "Epoch 00025 | Loss 1.1878 | Time(s) 2.5339 | Accuracy: 62.132011 %\n",
            "Epoch 00026 | Loss 1.1662 | Time(s) 2.5337 | Accuracy: 62.550356 %\n",
            "Epoch 00027 | Loss 1.1021 | Time(s) 2.5333 | Accuracy: 62.705299 %\n",
            "Epoch 00028 | Loss 1.1287 | Time(s) 2.5332 | Accuracy: 63.301828 %\n",
            "Epoch 00029 | Loss 1.2875 | Time(s) 2.5336 | Accuracy: 63.875116 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7195 | Time(s) 2.5475 | Accuracy: 26.673381 %\n",
            "Epoch 00001 | Loss 1.6901 | Time(s) 2.5349 | Accuracy: 31.732259 %\n",
            "Epoch 00002 | Loss 1.6939 | Time(s) 2.5306 | Accuracy: 36.519988 %\n",
            "Epoch 00003 | Loss 1.6115 | Time(s) 2.5353 | Accuracy: 38.735668 %\n",
            "Epoch 00004 | Loss 1.6334 | Time(s) 2.5310 | Accuracy: 40.788658 %\n",
            "Epoch 00005 | Loss 1.6321 | Time(s) 2.5336 | Accuracy: 41.973970 %\n",
            "Epoch 00006 | Loss 1.5274 | Time(s) 2.5331 | Accuracy: 44.530524 %\n",
            "Epoch 00007 | Loss 1.5363 | Time(s) 2.5355 | Accuracy: 46.908894 %\n",
            "Epoch 00008 | Loss 1.5190 | Time(s) 2.5337 | Accuracy: 47.606136 %\n",
            "Epoch 00009 | Loss 1.4898 | Time(s) 2.5311 | Accuracy: 48.876666 %\n",
            "Epoch 00010 | Loss 1.4460 | Time(s) 2.5308 | Accuracy: 50.511311 %\n",
            "Epoch 00011 | Loss 1.5153 | Time(s) 2.5292 | Accuracy: 52.688255 %\n",
            "Epoch 00012 | Loss 1.3676 | Time(s) 2.5294 | Accuracy: 54.028509 %\n",
            "Epoch 00013 | Loss 1.3519 | Time(s) 2.5278 | Accuracy: 54.516579 %\n",
            "Epoch 00014 | Loss 1.3663 | Time(s) 2.5291 | Accuracy: 54.795476 %\n",
            "Epoch 00015 | Loss 1.4409 | Time(s) 2.5283 | Accuracy: 55.229315 %\n",
            "Epoch 00016 | Loss 1.3059 | Time(s) 2.5294 | Accuracy: 56.127983 %\n",
            "Epoch 00017 | Loss 1.3021 | Time(s) 2.5299 | Accuracy: 57.088627 %\n",
            "Epoch 00018 | Loss 1.3761 | Time(s) 2.5308 | Accuracy: 57.669662 %\n",
            "Epoch 00019 | Loss 1.2429 | Time(s) 2.5299 | Accuracy: 58.304927 %\n",
            "Epoch 00020 | Loss 1.2285 | Time(s) 2.5307 | Accuracy: 58.490858 %\n",
            "Epoch 00021 | Loss 1.1399 | Time(s) 2.5296 | Accuracy: 59.056399 %\n",
            "Epoch 00022 | Loss 1.1143 | Time(s) 2.5290 | Accuracy: 59.319802 %\n",
            "Epoch 00023 | Loss 1.1903 | Time(s) 2.5283 | Accuracy: 59.800124 %\n",
            "Epoch 00024 | Loss 1.1394 | Time(s) 2.5285 | Accuracy: 60.055779 %\n",
            "Epoch 00025 | Loss 1.0548 | Time(s) 2.5278 | Accuracy: 60.272699 %\n",
            "Epoch 00026 | Loss 1.1252 | Time(s) 2.5272 | Accuracy: 60.543849 %\n",
            "Epoch 00027 | Loss 1.1231 | Time(s) 2.5261 | Accuracy: 60.528355 %\n",
            "Epoch 00028 | Loss 1.0946 | Time(s) 2.5262 | Accuracy: 61.093895 %\n",
            "Epoch 00029 | Loss 1.1939 | Time(s) 2.5259 | Accuracy: 61.179114 %\n",
            "Results stored.\n",
            "New learning rate...\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7957 | Time(s) 2.5228 | Accuracy: 9.908584 %\n",
            "Epoch 00001 | Loss 1.7931 | Time(s) 2.5104 | Accuracy: 13.696932 %\n",
            "Epoch 00002 | Loss 1.7953 | Time(s) 2.5094 | Accuracy: 15.990084 %\n",
            "Epoch 00003 | Loss 1.7895 | Time(s) 2.5085 | Accuracy: 17.252866 %\n",
            "Epoch 00004 | Loss 1.7861 | Time(s) 2.5075 | Accuracy: 18.469166 %\n",
            "Epoch 00005 | Loss 1.7917 | Time(s) 2.5077 | Accuracy: 19.336845 %\n",
            "Epoch 00006 | Loss 1.7891 | Time(s) 2.5140 | Accuracy: 19.910133 %\n",
            "Epoch 00007 | Loss 1.7804 | Time(s) 2.5146 | Accuracy: 20.088317 %\n",
            "Epoch 00008 | Loss 1.7885 | Time(s) 2.5178 | Accuracy: 19.646731 %\n",
            "Epoch 00009 | Loss 1.7763 | Time(s) 2.5159 | Accuracy: 19.259374 %\n",
            "Epoch 00010 | Loss 1.7865 | Time(s) 2.5172 | Accuracy: 18.988224 %\n",
            "Epoch 00011 | Loss 1.7795 | Time(s) 2.5184 | Accuracy: 18.693833 %\n",
            "Epoch 00012 | Loss 1.7790 | Time(s) 2.5175 | Accuracy: 18.546638 %\n",
            "Epoch 00013 | Loss 1.7682 | Time(s) 2.5163 | Accuracy: 18.500155 %\n",
            "Epoch 00014 | Loss 1.7778 | Time(s) 2.5162 | Accuracy: 18.546638 %\n",
            "Epoch 00015 | Loss 1.7730 | Time(s) 2.5164 | Accuracy: 18.662845 %\n",
            "Epoch 00016 | Loss 1.7596 | Time(s) 2.5171 | Accuracy: 18.701580 %\n",
            "Epoch 00017 | Loss 1.7710 | Time(s) 2.5167 | Accuracy: 19.910133 %\n",
            "Epoch 00018 | Loss 1.7609 | Time(s) 2.5180 | Accuracy: 22.427952 %\n",
            "Epoch 00019 | Loss 1.7526 | Time(s) 2.5183 | Accuracy: 24.202045 %\n",
            "Epoch 00020 | Loss 1.7229 | Time(s) 2.5189 | Accuracy: 25.224667 %\n",
            "Epoch 00021 | Loss 1.7255 | Time(s) 2.5181 | Accuracy: 25.968392 %\n",
            "Epoch 00022 | Loss 1.7275 | Time(s) 2.5176 | Accuracy: 26.479703 %\n",
            "Epoch 00023 | Loss 1.7061 | Time(s) 2.5187 | Accuracy: 26.921289 %\n",
            "Epoch 00024 | Loss 1.6640 | Time(s) 2.5186 | Accuracy: 27.370623 %\n",
            "Epoch 00025 | Loss 1.6958 | Time(s) 2.5186 | Accuracy: 27.726991 %\n",
            "Epoch 00026 | Loss 1.7119 | Time(s) 2.5176 | Accuracy: 28.346762 %\n",
            "Epoch 00027 | Loss 1.6772 | Time(s) 2.5182 | Accuracy: 28.858073 %\n",
            "Epoch 00028 | Loss 1.7317 | Time(s) 2.5177 | Accuracy: 29.082739 %\n",
            "Epoch 00029 | Loss 1.7064 | Time(s) 2.5179 | Accuracy: 29.400372 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7941 | Time(s) 2.5150 | Accuracy: 18.848776 %\n",
            "Epoch 00001 | Loss 1.7872 | Time(s) 2.5410 | Accuracy: 20.909513 %\n",
            "Epoch 00002 | Loss 1.7706 | Time(s) 2.5286 | Accuracy: 21.064456 %\n",
            "Epoch 00003 | Loss 1.7803 | Time(s) 2.5236 | Accuracy: 20.901766 %\n",
            "Epoch 00004 | Loss 1.7739 | Time(s) 2.5221 | Accuracy: 20.847536 %\n",
            "Epoch 00005 | Loss 1.7665 | Time(s) 2.5227 | Accuracy: 20.917261 %\n",
            "Epoch 00006 | Loss 1.7722 | Time(s) 2.5202 | Accuracy: 21.033468 %\n",
            "Epoch 00007 | Loss 1.7669 | Time(s) 2.5173 | Accuracy: 21.095445 %\n",
            "Epoch 00008 | Loss 1.7368 | Time(s) 2.5158 | Accuracy: 21.103192 %\n",
            "Epoch 00009 | Loss 1.7433 | Time(s) 2.5149 | Accuracy: 21.188410 %\n",
            "Epoch 00010 | Loss 1.7525 | Time(s) 2.5158 | Accuracy: 21.258134 %\n",
            "Epoch 00011 | Loss 1.7305 | Time(s) 2.5152 | Accuracy: 21.258134 %\n",
            "Epoch 00012 | Loss 1.7434 | Time(s) 2.5156 | Accuracy: 21.289123 %\n",
            "Epoch 00013 | Loss 1.7213 | Time(s) 2.5183 | Accuracy: 21.351100 %\n",
            "Epoch 00014 | Loss 1.7342 | Time(s) 2.5181 | Accuracy: 21.792687 %\n",
            "Epoch 00015 | Loss 1.6725 | Time(s) 2.5178 | Accuracy: 22.133561 %\n",
            "Epoch 00016 | Loss 1.7321 | Time(s) 2.5173 | Accuracy: 22.466687 %\n",
            "Epoch 00017 | Loss 1.7250 | Time(s) 2.5184 | Accuracy: 22.730090 %\n",
            "Epoch 00018 | Loss 1.7206 | Time(s) 2.5175 | Accuracy: 23.404090 %\n",
            "Epoch 00019 | Loss 1.7140 | Time(s) 2.5173 | Accuracy: 24.124574 %\n",
            "Epoch 00020 | Loss 1.6852 | Time(s) 2.5175 | Accuracy: 24.961264 %\n",
            "Epoch 00021 | Loss 1.6331 | Time(s) 2.5179 | Accuracy: 25.666253 %\n",
            "Epoch 00022 | Loss 1.6762 | Time(s) 2.5175 | Accuracy: 26.510691 %\n",
            "Epoch 00023 | Loss 1.6509 | Time(s) 2.5175 | Accuracy: 27.587543 %\n",
            "Epoch 00024 | Loss 1.6627 | Time(s) 2.5174 | Accuracy: 28.455222 %\n",
            "Epoch 00025 | Loss 1.6541 | Time(s) 2.5188 | Accuracy: 28.997521 %\n",
            "Epoch 00026 | Loss 1.6066 | Time(s) 2.5185 | Accuracy: 29.733499 %\n",
            "Epoch 00027 | Loss 1.6541 | Time(s) 2.5189 | Accuracy: 30.484971 %\n",
            "Epoch 00028 | Loss 1.6300 | Time(s) 2.5186 | Accuracy: 31.042764 %\n",
            "Epoch 00029 | Loss 1.6909 | Time(s) 2.5193 | Accuracy: 31.871707 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7935 | Time(s) 2.5468 | Accuracy: 15.641463 %\n",
            "Epoch 00001 | Loss 1.7925 | Time(s) 2.5338 | Accuracy: 15.935854 %\n",
            "Epoch 00002 | Loss 1.7895 | Time(s) 2.5283 | Accuracy: 16.230245 %\n",
            "Epoch 00003 | Loss 1.7912 | Time(s) 2.5341 | Accuracy: 16.702820 %\n",
            "Epoch 00004 | Loss 1.7898 | Time(s) 2.5329 | Accuracy: 17.206384 %\n",
            "Epoch 00005 | Loss 1.7854 | Time(s) 2.5336 | Accuracy: 17.500775 %\n",
            "Epoch 00006 | Loss 1.7837 | Time(s) 2.5328 | Accuracy: 17.764177 %\n",
            "Epoch 00007 | Loss 1.7811 | Time(s) 2.5347 | Accuracy: 17.849396 %\n",
            "Epoch 00008 | Loss 1.7811 | Time(s) 2.5336 | Accuracy: 18.198017 %\n",
            "Epoch 00009 | Loss 1.7841 | Time(s) 2.5332 | Accuracy: 18.786799 %\n",
            "Epoch 00010 | Loss 1.7875 | Time(s) 2.5358 | Accuracy: 19.251627 %\n",
            "Epoch 00011 | Loss 1.7857 | Time(s) 2.5385 | Accuracy: 20.460180 %\n",
            "Epoch 00012 | Loss 1.7787 | Time(s) 2.5383 | Accuracy: 21.451813 %\n",
            "Epoch 00013 | Loss 1.7793 | Time(s) 2.5373 | Accuracy: 22.296250 %\n",
            "Epoch 00014 | Loss 1.7658 | Time(s) 2.5366 | Accuracy: 23.156182 %\n",
            "Epoch 00015 | Loss 1.7794 | Time(s) 2.5367 | Accuracy: 24.395724 %\n",
            "Epoch 00016 | Loss 1.7693 | Time(s) 2.5362 | Accuracy: 25.480322 %\n",
            "Epoch 00017 | Loss 1.7669 | Time(s) 2.5359 | Accuracy: 26.588162 %\n",
            "Epoch 00018 | Loss 1.7606 | Time(s) 2.5366 | Accuracy: 27.649520 %\n",
            "Epoch 00019 | Loss 1.7464 | Time(s) 2.5361 | Accuracy: 28.501704 %\n",
            "Epoch 00020 | Loss 1.7573 | Time(s) 2.5374 | Accuracy: 29.648280 %\n",
            "Epoch 00021 | Loss 1.7543 | Time(s) 2.5371 | Accuracy: 30.585683 %\n",
            "Epoch 00022 | Loss 1.7511 | Time(s) 2.5381 | Accuracy: 31.112488 %\n",
            "Epoch 00023 | Loss 1.7284 | Time(s) 2.5378 | Accuracy: 31.732259 %\n",
            "Epoch 00024 | Loss 1.7439 | Time(s) 2.5390 | Accuracy: 32.313294 %\n",
            "Epoch 00025 | Loss 1.7259 | Time(s) 2.5383 | Accuracy: 33.033778 %\n",
            "Epoch 00026 | Loss 1.7126 | Time(s) 2.5383 | Accuracy: 33.653548 %\n",
            "Epoch 00027 | Loss 1.7181 | Time(s) 2.5379 | Accuracy: 34.451503 %\n",
            "Epoch 00028 | Loss 1.7336 | Time(s) 2.5388 | Accuracy: 35.055779 %\n",
            "Epoch 00029 | Loss 1.7206 | Time(s) 2.5387 | Accuracy: 35.683297 %\n",
            "Results stored.\n",
            "New learning rate...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Simlx8ur7sgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "axisX = range(30)\n",
        "colors = dict()\n",
        "#lrs = [1e-1, 1e-2, 1e-3, 1e-4]\n",
        "colors[1e-1] = \"red\"\n",
        "colors[1e-2] = \"orange\"\n",
        "colors[1e-3] = \"blue\"\n",
        "colors[1e-4] = \"green\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BcuvuOK9ALs",
        "colab_type": "code",
        "outputId": "ba4be1da-72dd-4b0f-c21c-9726e2766e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "for lr in lrs:\n",
        "  plt.plot(axisX, lrAccTest[lr], color = colors[lr], label=str(lr))\n",
        "plt.ylabel(\"Accuracy score\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA4BSSgWo/w/zoO4ZsoeGYwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpQULOcc8fka",
        "colab_type": "code",
        "outputId": "35c65aed-42e7-4199-d59b-c2670116b144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "for lr in lrs:\n",
        "  plt.plot(axisX, lrLossTest[lr], color = colors[lr], label=str(lr))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nURTFh/h/UKAp5iSw0QIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70XUAV7w5Jsf",
        "colab_type": "text"
      },
      "source": [
        "TEST ^^^^^^^^^^^^^^^^^^^^^^^^^"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3SQOrzeN3mo",
        "colab_type": "code",
        "outputId": "6a730b14-59d8-44bc-9aa2-84edbecd5fc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "import collections\n",
        "import numpy as np\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#init counters\n",
        "averageAccCiteSeer = []\n",
        "averageLossCiteSeer = []\n",
        "\n",
        "for t in range(n_of_training_cycles):\n",
        "  print(\"Starting new training\")\n",
        "  #get data from DGL\n",
        "  net = Net()\n",
        "  g, features, labels, mask = load_citeseer_data()\n",
        "  print(g)\n",
        "\n",
        "  #point to show on graph\n",
        "  pointsCiteSeer=dict()\n",
        "  pointsLossCiteSeer=dict()\n",
        "\n",
        "  #the number of masks to get when training per epoch\n",
        "  n_masks_to_try = 4\n",
        "  #initializing the optimizer (optimizer takes care of optimize the learining rate during training)\n",
        "  optimizer = th.optim.Adam(net.parameters(), lr=2e-3)\n",
        "  optimizer.state = collections.defaultdict(dict)\n",
        "\n",
        "  #dur is just an array to store the duration in order to show them later\n",
        "  dur = []\n",
        "\n",
        "  #this 'for' cycles on 200 epochs\n",
        "  for epoch in range(n_of_epochs):\n",
        "      t0 = time.time()\n",
        "\n",
        "      #getting only some masks (4)\n",
        "      masksToTry = random.sample(masks,n_masks_to_try)\n",
        "\n",
        "      for m in masksToTry:\n",
        "          #calling 'net(...)' it asks to the GCN to compute the forward    \n",
        "\n",
        "          logits = net(g, features)\n",
        "          logp = F.log_softmax(logits, 1)\n",
        "\n",
        "          #compute loss like the negative log likelihood loss\n",
        "          loss = F.nll_loss(logp[m], labels[m])\n",
        "          \n",
        "          #Since the backward() function accumulates gradients, and you \n",
        "          #don’t want to mix up gradients between minibatch, you have \n",
        "          #to zero them out at the start of a new minibatch. This is \n",
        "          #exactly like how a general (additive) accumulator variable is \n",
        "          #initialized to 0 in code.\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          #update network weights by loss\n",
        "          loss.backward()\n",
        "\n",
        "          #update optimizer's values after backward\n",
        "          optimizer.step()\n",
        "\n",
        "          #computing accuracy\n",
        "          i = 0\n",
        "          matched = 0\n",
        "          while i < 3327:\n",
        "            if m[i] == 0:\n",
        "              #getting index of the maximum\n",
        "              j = 0\n",
        "              max = None\n",
        "              jMax = 0\n",
        "              for a in logp[i]:\n",
        "                if max==None:\n",
        "                  max = a.item()\n",
        "                  jMax = j\n",
        "                elif max < a.item():\n",
        "                  max = a.item()\n",
        "                  jMax = j\n",
        "                j = j + 1\n",
        "              if jMax == labels[i]:\n",
        "                matched = matched + 1\n",
        "            i = i + 1\n",
        "          acc = matched/(3327-size_masks)*100\n",
        "\n",
        "          if epoch not in pointsCiteSeer:\n",
        "            pointsCiteSeer[epoch] = 0\n",
        "            pointsLossCiteSeer[epoch] = 0\n",
        "          pointsCiteSeer[epoch] = pointsCiteSeer[epoch] + acc\n",
        "          pointsLossCiteSeer[epoch] = pointsLossCiteSeer[epoch] + loss.item()\n",
        "          \n",
        "      dur.append(time.time() - t0)\n",
        "      \n",
        "      #computing the average of the accuracy and the loss\n",
        "      pointsCiteSeer[epoch] = pointsCiteSeer[epoch]/n_masks_to_try\n",
        "      pointsLossCiteSeer[epoch] = pointsLossCiteSeer[epoch]/n_masks_to_try\n",
        "\n",
        "      print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f} | Accuracy: {:.6f} %\".format(\n",
        "              epoch, loss.item(), np.mean(dur), pointsCiteSeer[epoch]))\n",
        "  #storing results    \n",
        "  averageAccCiteSeer.append(pointsCiteSeer)\n",
        "  averageLossCiteSeer.append(pointsLossCiteSeer)\n",
        "  print(\"Results stored.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7861 | Time(s) 2.4925 | Accuracy: 21.087698 %\n",
            "Epoch 00001 | Loss 1.7612 | Time(s) 2.4954 | Accuracy: 28.199566 %\n",
            "Epoch 00002 | Loss 1.7194 | Time(s) 2.5169 | Accuracy: 33.746514 %\n",
            "Epoch 00003 | Loss 1.7088 | Time(s) 2.5104 | Accuracy: 35.706539 %\n",
            "Epoch 00004 | Loss 1.5936 | Time(s) 2.5070 | Accuracy: 36.690425 %\n",
            "Epoch 00005 | Loss 1.5727 | Time(s) 2.5149 | Accuracy: 37.387667 %\n",
            "Epoch 00006 | Loss 1.4993 | Time(s) 2.5225 | Accuracy: 37.790518 %\n",
            "Epoch 00007 | Loss 1.4771 | Time(s) 2.5246 | Accuracy: 38.727921 %\n",
            "Epoch 00008 | Loss 1.5272 | Time(s) 2.5184 | Accuracy: 39.115277 %\n",
            "Epoch 00009 | Loss 1.4025 | Time(s) 2.5170 | Accuracy: 39.990703 %\n",
            "Epoch 00010 | Loss 1.3303 | Time(s) 2.5189 | Accuracy: 41.547877 %\n",
            "Epoch 00011 | Loss 1.3971 | Time(s) 2.5210 | Accuracy: 44.166408 %\n",
            "Epoch 00012 | Loss 1.3306 | Time(s) 2.5196 | Accuracy: 48.946390 %\n",
            "Epoch 00013 | Loss 1.3044 | Time(s) 2.5193 | Accuracy: 53.315773 %\n",
            "Epoch 00014 | Loss 1.4403 | Time(s) 2.5247 | Accuracy: 55.717385 %\n",
            "Epoch 00015 | Loss 1.2924 | Time(s) 2.5273 | Accuracy: 57.080880 %\n",
            "Epoch 00016 | Loss 1.1332 | Time(s) 2.5272 | Accuracy: 58.049272 %\n",
            "Epoch 00017 | Loss 1.2890 | Time(s) 2.5298 | Accuracy: 58.963434 %\n",
            "Epoch 00018 | Loss 1.0523 | Time(s) 2.5298 | Accuracy: 59.265572 %\n",
            "Epoch 00019 | Loss 1.0984 | Time(s) 2.5280 | Accuracy: 59.962814 %\n",
            "Epoch 00020 | Loss 1.2266 | Time(s) 2.5292 | Accuracy: 60.923458 %\n",
            "Epoch 00021 | Loss 1.1867 | Time(s) 2.5295 | Accuracy: 60.791757 %\n",
            "Epoch 00022 | Loss 1.1415 | Time(s) 2.5315 | Accuracy: 61.024171 %\n",
            "Epoch 00023 | Loss 1.0785 | Time(s) 2.5299 | Accuracy: 61.163619 %\n",
            "Epoch 00024 | Loss 0.9596 | Time(s) 2.5293 | Accuracy: 61.806632 %\n",
            "Epoch 00025 | Loss 0.9496 | Time(s) 2.5282 | Accuracy: 61.953827 %\n",
            "Epoch 00026 | Loss 1.0812 | Time(s) 2.5289 | Accuracy: 62.008057 %\n",
            "Epoch 00027 | Loss 0.9125 | Time(s) 2.5299 | Accuracy: 61.953827 %\n",
            "Epoch 00028 | Loss 0.9157 | Time(s) 2.5296 | Accuracy: 61.326309 %\n",
            "Epoch 00029 | Loss 0.9815 | Time(s) 2.5289 | Accuracy: 61.845367 %\n",
            "Epoch 00030 | Loss 0.8451 | Time(s) 2.5284 | Accuracy: 62.248218 %\n",
            "Epoch 00031 | Loss 0.8978 | Time(s) 2.5277 | Accuracy: 62.271460 %\n",
            "Epoch 00032 | Loss 0.9084 | Time(s) 2.5278 | Accuracy: 62.271460 %\n",
            "Epoch 00033 | Loss 0.8266 | Time(s) 2.5270 | Accuracy: 62.201735 %\n",
            "Epoch 00034 | Loss 0.8287 | Time(s) 2.5278 | Accuracy: 62.139758 %\n",
            "Epoch 00035 | Loss 1.0144 | Time(s) 2.5273 | Accuracy: 62.085528 %\n",
            "Epoch 00036 | Loss 0.8043 | Time(s) 2.5259 | Accuracy: 62.294701 %\n",
            "Epoch 00037 | Loss 0.7959 | Time(s) 2.5245 | Accuracy: 62.333437 %\n",
            "Epoch 00038 | Loss 0.6666 | Time(s) 2.5246 | Accuracy: 62.248218 %\n",
            "Epoch 00039 | Loss 0.6536 | Time(s) 2.5246 | Accuracy: 62.232724 %\n",
            "Epoch 00040 | Loss 0.7656 | Time(s) 2.5245 | Accuracy: 62.333437 %\n",
            "Epoch 00041 | Loss 0.7606 | Time(s) 2.5239 | Accuracy: 62.263712 %\n",
            "Epoch 00042 | Loss 0.8235 | Time(s) 2.5244 | Accuracy: 62.248218 %\n",
            "Epoch 00043 | Loss 0.6130 | Time(s) 2.5241 | Accuracy: 62.341184 %\n",
            "Epoch 00044 | Loss 0.7113 | Time(s) 2.5234 | Accuracy: 62.255965 %\n",
            "Epoch 00045 | Loss 0.7242 | Time(s) 2.5235 | Accuracy: 62.147505 %\n",
            "Epoch 00046 | Loss 0.9412 | Time(s) 2.5247 | Accuracy: 62.085528 %\n",
            "Epoch 00047 | Loss 0.9170 | Time(s) 2.5243 | Accuracy: 62.178494 %\n",
            "Epoch 00048 | Loss 0.5667 | Time(s) 2.5230 | Accuracy: 62.008057 %\n",
            "Epoch 00049 | Loss 0.6881 | Time(s) 2.5228 | Accuracy: 62.178494 %\n",
            "Epoch 00050 | Loss 0.6860 | Time(s) 2.5233 | Accuracy: 62.224977 %\n",
            "Epoch 00051 | Loss 0.6503 | Time(s) 2.5238 | Accuracy: 62.077781 %\n",
            "Epoch 00052 | Loss 0.6736 | Time(s) 2.5231 | Accuracy: 62.046793 %\n",
            "Epoch 00053 | Loss 0.6309 | Time(s) 2.5227 | Accuracy: 62.139758 %\n",
            "Epoch 00054 | Loss 0.8051 | Time(s) 2.5226 | Accuracy: 62.240471 %\n",
            "Epoch 00055 | Loss 0.6685 | Time(s) 2.5232 | Accuracy: 62.224977 %\n",
            "Epoch 00056 | Loss 0.5910 | Time(s) 2.5224 | Accuracy: 62.046793 %\n",
            "Epoch 00057 | Loss 0.5026 | Time(s) 2.5223 | Accuracy: 62.015804 %\n",
            "Epoch 00058 | Loss 0.6844 | Time(s) 2.5225 | Accuracy: 62.232724 %\n",
            "Epoch 00059 | Loss 0.8112 | Time(s) 2.5221 | Accuracy: 62.224977 %\n",
            "Epoch 00060 | Loss 0.6625 | Time(s) 2.5214 | Accuracy: 62.147505 %\n",
            "Epoch 00061 | Loss 0.7416 | Time(s) 2.5205 | Accuracy: 62.163000 %\n",
            "Epoch 00062 | Loss 0.7491 | Time(s) 2.5208 | Accuracy: 62.155253 %\n",
            "Epoch 00063 | Loss 0.6206 | Time(s) 2.5202 | Accuracy: 62.364425 %\n",
            "Epoch 00064 | Loss 0.7347 | Time(s) 2.5203 | Accuracy: 62.240471 %\n",
            "Epoch 00065 | Loss 0.6228 | Time(s) 2.5204 | Accuracy: 62.387667 %\n",
            "Epoch 00066 | Loss 0.7597 | Time(s) 2.5198 | Accuracy: 62.589092 %\n",
            "Epoch 00067 | Loss 0.6377 | Time(s) 2.5200 | Accuracy: 62.542609 %\n",
            "Epoch 00068 | Loss 0.4350 | Time(s) 2.5196 | Accuracy: 62.434149 %\n",
            "Epoch 00069 | Loss 0.6982 | Time(s) 2.5189 | Accuracy: 62.565851 %\n",
            "Epoch 00070 | Loss 0.4294 | Time(s) 2.5192 | Accuracy: 62.666563 %\n",
            "Epoch 00071 | Loss 0.6944 | Time(s) 2.5196 | Accuracy: 62.527115 %\n",
            "Epoch 00072 | Loss 0.6128 | Time(s) 2.5209 | Accuracy: 62.403161 %\n",
            "Epoch 00073 | Loss 0.4223 | Time(s) 2.5201 | Accuracy: 62.790518 %\n",
            "Epoch 00074 | Loss 0.6239 | Time(s) 2.5196 | Accuracy: 62.713046 %\n",
            "Epoch 00075 | Loss 0.6693 | Time(s) 2.5199 | Accuracy: 62.465138 %\n",
            "Epoch 00076 | Loss 0.5740 | Time(s) 2.5189 | Accuracy: 62.403161 %\n",
            "Epoch 00077 | Loss 0.5708 | Time(s) 2.5189 | Accuracy: 62.209482 %\n",
            "Epoch 00078 | Loss 0.6395 | Time(s) 2.5183 | Accuracy: 62.372172 %\n",
            "Epoch 00079 | Loss 0.5918 | Time(s) 2.5173 | Accuracy: 62.364425 %\n",
            "Epoch 00080 | Loss 0.4045 | Time(s) 2.5172 | Accuracy: 62.348931 %\n",
            "Epoch 00081 | Loss 0.7274 | Time(s) 2.5172 | Accuracy: 62.519368 %\n",
            "Epoch 00082 | Loss 0.5667 | Time(s) 2.5168 | Accuracy: 62.527115 %\n",
            "Epoch 00083 | Loss 0.7019 | Time(s) 2.5168 | Accuracy: 62.387667 %\n",
            "Epoch 00084 | Loss 0.5897 | Time(s) 2.5167 | Accuracy: 62.286954 %\n",
            "Epoch 00085 | Loss 0.6337 | Time(s) 2.5163 | Accuracy: 62.643322 %\n",
            "Epoch 00086 | Loss 0.6319 | Time(s) 2.5160 | Accuracy: 62.581345 %\n",
            "Epoch 00087 | Loss 0.5651 | Time(s) 2.5160 | Accuracy: 62.705299 %\n",
            "Epoch 00088 | Loss 0.5355 | Time(s) 2.5160 | Accuracy: 62.418655 %\n",
            "Epoch 00089 | Loss 0.6247 | Time(s) 2.5160 | Accuracy: 62.302448 %\n",
            "Epoch 00090 | Loss 0.6270 | Time(s) 2.5152 | Accuracy: 62.387667 %\n",
            "Epoch 00091 | Loss 0.5927 | Time(s) 2.5150 | Accuracy: 62.348931 %\n",
            "Epoch 00092 | Loss 0.5868 | Time(s) 2.5149 | Accuracy: 61.992563 %\n",
            "Epoch 00093 | Loss 0.5542 | Time(s) 2.5149 | Accuracy: 62.286954 %\n",
            "Epoch 00094 | Loss 0.7012 | Time(s) 2.5147 | Accuracy: 62.387667 %\n",
            "Epoch 00095 | Loss 0.6196 | Time(s) 2.5145 | Accuracy: 62.279207 %\n",
            "Epoch 00096 | Loss 0.6680 | Time(s) 2.5147 | Accuracy: 62.465138 %\n",
            "Epoch 00097 | Loss 0.5968 | Time(s) 2.5147 | Accuracy: 62.472885 %\n",
            "Epoch 00098 | Loss 0.6635 | Time(s) 2.5145 | Accuracy: 62.348931 %\n",
            "Epoch 00099 | Loss 0.5475 | Time(s) 2.5148 | Accuracy: 62.372172 %\n",
            "Epoch 00100 | Loss 0.6100 | Time(s) 2.5148 | Accuracy: 62.480632 %\n",
            "Epoch 00101 | Loss 0.6284 | Time(s) 2.5143 | Accuracy: 62.658816 %\n",
            "Epoch 00102 | Loss 0.5788 | Time(s) 2.5143 | Accuracy: 62.511621 %\n",
            "Epoch 00103 | Loss 0.5787 | Time(s) 2.5140 | Accuracy: 62.348931 %\n",
            "Epoch 00104 | Loss 0.6208 | Time(s) 2.5138 | Accuracy: 62.550356 %\n",
            "Epoch 00105 | Loss 0.6185 | Time(s) 2.5141 | Accuracy: 62.573598 %\n",
            "Epoch 00106 | Loss 0.5880 | Time(s) 2.5140 | Accuracy: 62.620081 %\n",
            "Epoch 00107 | Loss 0.5710 | Time(s) 2.5139 | Accuracy: 62.356678 %\n",
            "Epoch 00108 | Loss 0.5784 | Time(s) 2.5138 | Accuracy: 62.271460 %\n",
            "Epoch 00109 | Loss 0.4719 | Time(s) 2.5132 | Accuracy: 62.232724 %\n",
            "Epoch 00110 | Loss 0.3741 | Time(s) 2.5140 | Accuracy: 62.472885 %\n",
            "Epoch 00111 | Loss 0.6315 | Time(s) 2.5138 | Accuracy: 62.682058 %\n",
            "Epoch 00112 | Loss 0.3732 | Time(s) 2.5136 | Accuracy: 62.503874 %\n",
            "Epoch 00113 | Loss 0.5813 | Time(s) 2.5137 | Accuracy: 62.519368 %\n",
            "Epoch 00114 | Loss 0.5803 | Time(s) 2.5136 | Accuracy: 62.542609 %\n",
            "Epoch 00115 | Loss 0.5752 | Time(s) 2.5134 | Accuracy: 62.612333 %\n",
            "Epoch 00116 | Loss 0.5704 | Time(s) 2.5132 | Accuracy: 62.759529 %\n",
            "Epoch 00117 | Loss 0.5381 | Time(s) 2.5128 | Accuracy: 62.558104 %\n",
            "Epoch 00118 | Loss 0.5705 | Time(s) 2.5127 | Accuracy: 62.286954 %\n",
            "Epoch 00119 | Loss 0.6025 | Time(s) 2.5128 | Accuracy: 62.372172 %\n",
            "Epoch 00120 | Loss 0.5689 | Time(s) 2.5126 | Accuracy: 62.395414 %\n",
            "Epoch 00121 | Loss 0.5379 | Time(s) 2.5125 | Accuracy: 62.387667 %\n",
            "Epoch 00122 | Loss 0.6266 | Time(s) 2.5126 | Accuracy: 62.542609 %\n",
            "Epoch 00123 | Loss 0.6634 | Time(s) 2.5128 | Accuracy: 62.527115 %\n",
            "Epoch 00124 | Loss 0.5771 | Time(s) 2.5126 | Accuracy: 62.550356 %\n",
            "Epoch 00125 | Loss 0.6605 | Time(s) 2.5124 | Accuracy: 62.333437 %\n",
            "Epoch 00126 | Loss 0.5276 | Time(s) 2.5122 | Accuracy: 62.108770 %\n",
            "Epoch 00127 | Loss 0.5253 | Time(s) 2.5120 | Accuracy: 62.155253 %\n",
            "Epoch 00128 | Loss 0.6049 | Time(s) 2.5118 | Accuracy: 62.279207 %\n",
            "Epoch 00129 | Loss 0.5967 | Time(s) 2.5118 | Accuracy: 62.108770 %\n",
            "Epoch 00130 | Loss 0.5685 | Time(s) 2.5116 | Accuracy: 62.147505 %\n",
            "Epoch 00131 | Loss 0.6145 | Time(s) 2.5119 | Accuracy: 62.201735 %\n",
            "Epoch 00132 | Loss 0.5575 | Time(s) 2.5118 | Accuracy: 61.853114 %\n",
            "Epoch 00133 | Loss 0.5860 | Time(s) 2.5115 | Accuracy: 61.868609 %\n",
            "Epoch 00134 | Loss 0.3703 | Time(s) 2.5122 | Accuracy: 62.008057 %\n",
            "Epoch 00135 | Loss 0.5358 | Time(s) 2.5122 | Accuracy: 61.961574 %\n",
            "Epoch 00136 | Loss 0.5909 | Time(s) 2.5122 | Accuracy: 62.070034 %\n",
            "Epoch 00137 | Loss 0.5782 | Time(s) 2.5125 | Accuracy: 62.217230 %\n",
            "Epoch 00138 | Loss 0.5897 | Time(s) 2.5127 | Accuracy: 62.534862 %\n",
            "Epoch 00139 | Loss 0.6457 | Time(s) 2.5124 | Accuracy: 62.627828 %\n",
            "Epoch 00140 | Loss 0.5769 | Time(s) 2.5122 | Accuracy: 62.403161 %\n",
            "Epoch 00141 | Loss 0.5681 | Time(s) 2.5117 | Accuracy: 62.488379 %\n",
            "Epoch 00142 | Loss 0.5530 | Time(s) 2.5117 | Accuracy: 62.426402 %\n",
            "Epoch 00143 | Loss 0.5568 | Time(s) 2.5117 | Accuracy: 61.791137 %\n",
            "Epoch 00144 | Loss 0.5213 | Time(s) 2.5116 | Accuracy: 61.930586 %\n",
            "Epoch 00145 | Loss 0.5196 | Time(s) 2.5114 | Accuracy: 62.511621 %\n",
            "Epoch 00146 | Loss 0.5607 | Time(s) 2.5117 | Accuracy: 62.403161 %\n",
            "Epoch 00147 | Loss 0.5554 | Time(s) 2.5114 | Accuracy: 62.310195 %\n",
            "Epoch 00148 | Loss 0.5520 | Time(s) 2.5113 | Accuracy: 62.286954 %\n",
            "Epoch 00149 | Loss 0.4413 | Time(s) 2.5111 | Accuracy: 62.147505 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7887 | Time(s) 2.5330 | Accuracy: 17.245119 %\n",
            "Epoch 00001 | Loss 1.7844 | Time(s) 2.5018 | Accuracy: 17.818407 %\n",
            "Epoch 00002 | Loss 1.7603 | Time(s) 2.5013 | Accuracy: 17.919120 %\n",
            "Epoch 00003 | Loss 1.7688 | Time(s) 2.4992 | Accuracy: 17.996591 %\n",
            "Epoch 00004 | Loss 1.7590 | Time(s) 2.5038 | Accuracy: 18.143787 %\n",
            "Epoch 00005 | Loss 1.7655 | Time(s) 2.5002 | Accuracy: 18.236752 %\n",
            "Epoch 00006 | Loss 1.7206 | Time(s) 2.4940 | Accuracy: 18.531143 %\n",
            "Epoch 00007 | Loss 1.7051 | Time(s) 2.4956 | Accuracy: 18.314224 %\n",
            "Epoch 00008 | Loss 1.7016 | Time(s) 2.5053 | Accuracy: 18.352959 %\n",
            "Epoch 00009 | Loss 1.6356 | Time(s) 2.4999 | Accuracy: 18.213511 %\n",
            "Epoch 00010 | Loss 1.6742 | Time(s) 2.4974 | Accuracy: 18.368454 %\n",
            "Epoch 00011 | Loss 1.7094 | Time(s) 2.5000 | Accuracy: 20.452433 %\n",
            "Epoch 00012 | Loss 1.6784 | Time(s) 2.4945 | Accuracy: 23.682987 %\n",
            "Epoch 00013 | Loss 1.6681 | Time(s) 2.4964 | Accuracy: 26.626898 %\n",
            "Epoch 00014 | Loss 1.5743 | Time(s) 2.4942 | Accuracy: 27.688255 %\n",
            "Epoch 00015 | Loss 1.6589 | Time(s) 2.4952 | Accuracy: 28.075612 %\n",
            "Epoch 00016 | Loss 1.4663 | Time(s) 2.4947 | Accuracy: 29.183452 %\n",
            "Epoch 00017 | Loss 1.5042 | Time(s) 2.4930 | Accuracy: 30.484971 %\n",
            "Epoch 00018 | Loss 1.5177 | Time(s) 2.4942 | Accuracy: 30.717385 %\n",
            "Epoch 00019 | Loss 1.5394 | Time(s) 2.4920 | Accuracy: 30.601178 %\n",
            "Epoch 00020 | Loss 1.5649 | Time(s) 2.4947 | Accuracy: 30.585683 %\n",
            "Epoch 00021 | Loss 1.5481 | Time(s) 2.4954 | Accuracy: 31.035017 %\n",
            "Epoch 00022 | Loss 1.3377 | Time(s) 2.4941 | Accuracy: 30.864580 %\n",
            "Epoch 00023 | Loss 1.3892 | Time(s) 2.4914 | Accuracy: 31.027270 %\n",
            "Epoch 00024 | Loss 1.5006 | Time(s) 2.4908 | Accuracy: 31.282925 %\n",
            "Epoch 00025 | Loss 1.4680 | Time(s) 2.4889 | Accuracy: 31.399132 %\n",
            "Epoch 00026 | Loss 1.4471 | Time(s) 2.4880 | Accuracy: 31.399132 %\n",
            "Epoch 00027 | Loss 1.3386 | Time(s) 2.4878 | Accuracy: 31.515339 %\n",
            "Epoch 00028 | Loss 1.4524 | Time(s) 2.4870 | Accuracy: 31.492098 %\n",
            "Epoch 00029 | Loss 1.4338 | Time(s) 2.4867 | Accuracy: 31.453362 %\n",
            "Epoch 00030 | Loss 1.3007 | Time(s) 2.4870 | Accuracy: 31.523086 %\n",
            "Epoch 00031 | Loss 1.4705 | Time(s) 2.4868 | Accuracy: 31.414627 %\n",
            "Epoch 00032 | Loss 1.4046 | Time(s) 2.4856 | Accuracy: 31.244190 %\n",
            "Epoch 00033 | Loss 1.2612 | Time(s) 2.4851 | Accuracy: 31.422374 %\n",
            "Epoch 00034 | Loss 1.4562 | Time(s) 2.4842 | Accuracy: 31.701271 %\n",
            "Epoch 00035 | Loss 1.3931 | Time(s) 2.4823 | Accuracy: 31.600558 %\n",
            "Epoch 00036 | Loss 1.3863 | Time(s) 2.4834 | Accuracy: 31.662535 %\n",
            "Epoch 00037 | Loss 1.3805 | Time(s) 2.4821 | Accuracy: 31.732259 %\n",
            "Epoch 00038 | Loss 1.2784 | Time(s) 2.4812 | Accuracy: 31.755500 %\n",
            "Epoch 00039 | Loss 1.4262 | Time(s) 2.4801 | Accuracy: 31.778742 %\n",
            "Epoch 00040 | Loss 1.3474 | Time(s) 2.4809 | Accuracy: 31.863960 %\n",
            "Epoch 00041 | Loss 1.3118 | Time(s) 2.4791 | Accuracy: 31.755500 %\n",
            "Epoch 00042 | Loss 1.3598 | Time(s) 2.4795 | Accuracy: 31.980167 %\n",
            "Epoch 00043 | Loss 1.1352 | Time(s) 2.4783 | Accuracy: 31.887202 %\n",
            "Epoch 00044 | Loss 1.2575 | Time(s) 2.4786 | Accuracy: 32.042144 %\n",
            "Epoch 00045 | Loss 1.3468 | Time(s) 2.4785 | Accuracy: 32.336535 %\n",
            "Epoch 00046 | Loss 1.3423 | Time(s) 2.4773 | Accuracy: 32.080880 %\n",
            "Epoch 00047 | Loss 1.2017 | Time(s) 2.4756 | Accuracy: 32.003409 %\n",
            "Epoch 00048 | Loss 1.3957 | Time(s) 2.4752 | Accuracy: 31.972420 %\n",
            "Epoch 00049 | Loss 1.1703 | Time(s) 2.4749 | Accuracy: 31.949179 %\n",
            "Epoch 00050 | Loss 1.3838 | Time(s) 2.4747 | Accuracy: 32.042144 %\n",
            "Epoch 00051 | Loss 1.3218 | Time(s) 2.4733 | Accuracy: 32.042144 %\n",
            "Epoch 00052 | Loss 1.3354 | Time(s) 2.4728 | Accuracy: 32.057639 %\n",
            "Epoch 00053 | Loss 1.3155 | Time(s) 2.4734 | Accuracy: 31.894949 %\n",
            "Epoch 00054 | Loss 1.3094 | Time(s) 2.4733 | Accuracy: 31.856213 %\n",
            "Epoch 00055 | Loss 1.3033 | Time(s) 2.4731 | Accuracy: 32.104121 %\n",
            "Epoch 00056 | Loss 1.3224 | Time(s) 2.4745 | Accuracy: 32.204834 %\n",
            "Epoch 00057 | Loss 1.2904 | Time(s) 2.4743 | Accuracy: 32.119616 %\n",
            "Epoch 00058 | Loss 1.3220 | Time(s) 2.4730 | Accuracy: 31.871707 %\n",
            "Epoch 00059 | Loss 1.1282 | Time(s) 2.4722 | Accuracy: 31.871707 %\n",
            "Epoch 00060 | Loss 1.2800 | Time(s) 2.4712 | Accuracy: 31.980167 %\n",
            "Epoch 00061 | Loss 1.2043 | Time(s) 2.4710 | Accuracy: 31.848466 %\n",
            "Epoch 00062 | Loss 1.3386 | Time(s) 2.4705 | Accuracy: 32.173846 %\n",
            "Epoch 00063 | Loss 1.3157 | Time(s) 2.4698 | Accuracy: 32.096374 %\n",
            "Epoch 00064 | Loss 1.2819 | Time(s) 2.4694 | Accuracy: 31.863960 %\n",
            "Epoch 00065 | Loss 1.1741 | Time(s) 2.4696 | Accuracy: 31.887202 %\n",
            "Epoch 00066 | Loss 1.2609 | Time(s) 2.4699 | Accuracy: 32.026650 %\n",
            "Epoch 00067 | Loss 1.3231 | Time(s) 2.4706 | Accuracy: 31.871707 %\n",
            "Epoch 00068 | Loss 1.1650 | Time(s) 2.4709 | Accuracy: 31.894949 %\n",
            "Epoch 00069 | Loss 1.3295 | Time(s) 2.4704 | Accuracy: 32.127363 %\n",
            "Epoch 00070 | Loss 1.2878 | Time(s) 2.4707 | Accuracy: 32.282306 %\n",
            "Epoch 00071 | Loss 1.1184 | Time(s) 2.4703 | Accuracy: 32.049892 %\n",
            "Epoch 00072 | Loss 1.1150 | Time(s) 2.4698 | Accuracy: 31.871707 %\n",
            "Epoch 00073 | Loss 1.3169 | Time(s) 2.4697 | Accuracy: 31.747753 %\n",
            "Epoch 00074 | Loss 1.3140 | Time(s) 2.4701 | Accuracy: 31.887202 %\n",
            "Epoch 00075 | Loss 1.3208 | Time(s) 2.4697 | Accuracy: 32.018903 %\n",
            "Epoch 00076 | Loss 1.2704 | Time(s) 2.4698 | Accuracy: 31.879455 %\n",
            "Epoch 00077 | Loss 1.2931 | Time(s) 2.4702 | Accuracy: 31.964673 %\n",
            "Epoch 00078 | Loss 1.3126 | Time(s) 2.4696 | Accuracy: 32.096374 %\n",
            "Epoch 00079 | Loss 1.0561 | Time(s) 2.4700 | Accuracy: 31.987914 %\n",
            "Epoch 00080 | Loss 1.3079 | Time(s) 2.4699 | Accuracy: 32.119616 %\n",
            "Epoch 00081 | Loss 1.2781 | Time(s) 2.4699 | Accuracy: 31.879455 %\n",
            "Epoch 00082 | Loss 1.1457 | Time(s) 2.4703 | Accuracy: 31.918190 %\n",
            "Epoch 00083 | Loss 1.3046 | Time(s) 2.4709 | Accuracy: 32.049892 %\n",
            "Epoch 00084 | Loss 1.2314 | Time(s) 2.4705 | Accuracy: 32.034397 %\n",
            "Epoch 00085 | Loss 1.3101 | Time(s) 2.4705 | Accuracy: 32.065386 %\n",
            "Epoch 00086 | Loss 1.2239 | Time(s) 2.4705 | Accuracy: 32.111869 %\n",
            "Epoch 00087 | Loss 1.3076 | Time(s) 2.4700 | Accuracy: 32.042144 %\n",
            "Epoch 00088 | Loss 1.3056 | Time(s) 2.4699 | Accuracy: 32.197087 %\n",
            "Epoch 00089 | Loss 1.1640 | Time(s) 2.4700 | Accuracy: 32.080880 %\n",
            "Epoch 00090 | Loss 1.1623 | Time(s) 2.4696 | Accuracy: 32.065386 %\n",
            "Epoch 00091 | Loss 1.1605 | Time(s) 2.4702 | Accuracy: 32.018903 %\n",
            "Epoch 00092 | Loss 1.1047 | Time(s) 2.4699 | Accuracy: 32.065386 %\n",
            "Epoch 00093 | Loss 1.2657 | Time(s) 2.4700 | Accuracy: 32.189340 %\n",
            "Epoch 00094 | Loss 1.1474 | Time(s) 2.4702 | Accuracy: 31.980167 %\n",
            "Epoch 00095 | Loss 1.0523 | Time(s) 2.4702 | Accuracy: 32.158351 %\n",
            "Epoch 00096 | Loss 1.2603 | Time(s) 2.4695 | Accuracy: 32.166099 %\n",
            "Epoch 00097 | Loss 1.2588 | Time(s) 2.4693 | Accuracy: 32.243570 %\n",
            "Epoch 00098 | Loss 1.2977 | Time(s) 2.4697 | Accuracy: 32.321041 %\n",
            "Epoch 00099 | Loss 1.0504 | Time(s) 2.4692 | Accuracy: 32.204834 %\n",
            "Epoch 00100 | Loss 1.0487 | Time(s) 2.4692 | Accuracy: 32.104121 %\n",
            "Epoch 00101 | Loss 1.0981 | Time(s) 2.4693 | Accuracy: 31.980167 %\n",
            "Epoch 00102 | Loss 1.2615 | Time(s) 2.4688 | Accuracy: 32.003409 %\n",
            "Epoch 00103 | Loss 1.2201 | Time(s) 2.4693 | Accuracy: 32.111869 %\n",
            "Epoch 00104 | Loss 1.3091 | Time(s) 2.4690 | Accuracy: 32.282306 %\n",
            "Epoch 00105 | Loss 1.2526 | Time(s) 2.4696 | Accuracy: 32.142857 %\n",
            "Epoch 00106 | Loss 1.1473 | Time(s) 2.4694 | Accuracy: 32.011156 %\n",
            "Epoch 00107 | Loss 1.3059 | Time(s) 2.4691 | Accuracy: 31.980167 %\n",
            "Epoch 00108 | Loss 1.1629 | Time(s) 2.4692 | Accuracy: 31.863960 %\n",
            "Epoch 00109 | Loss 1.2750 | Time(s) 2.4692 | Accuracy: 31.259684 %\n",
            "Epoch 00110 | Loss 1.3105 | Time(s) 2.4688 | Accuracy: 31.701271 %\n",
            "Epoch 00111 | Loss 1.1792 | Time(s) 2.4683 | Accuracy: 31.585064 %\n",
            "Epoch 00112 | Loss 1.3047 | Time(s) 2.4682 | Accuracy: 31.980167 %\n",
            "Epoch 00113 | Loss 1.3055 | Time(s) 2.4680 | Accuracy: 32.065386 %\n",
            "Epoch 00114 | Loss 1.1406 | Time(s) 2.4681 | Accuracy: 32.158351 %\n",
            "Epoch 00115 | Loss 1.3069 | Time(s) 2.4679 | Accuracy: 32.135110 %\n",
            "Epoch 00116 | Loss 1.0430 | Time(s) 2.4676 | Accuracy: 31.724512 %\n",
            "Epoch 00117 | Loss 1.2416 | Time(s) 2.4679 | Accuracy: 31.941432 %\n",
            "Epoch 00118 | Loss 1.2949 | Time(s) 2.4681 | Accuracy: 32.042144 %\n",
            "Epoch 00119 | Loss 1.1640 | Time(s) 2.4677 | Accuracy: 32.080880 %\n",
            "Epoch 00120 | Loss 1.1537 | Time(s) 2.4680 | Accuracy: 31.817478 %\n",
            "Epoch 00121 | Loss 1.1383 | Time(s) 2.4690 | Accuracy: 31.856213 %\n",
            "Epoch 00122 | Loss 1.3036 | Time(s) 2.4693 | Accuracy: 31.616052 %\n",
            "Epoch 00123 | Loss 1.3005 | Time(s) 2.4688 | Accuracy: 32.111869 %\n",
            "Epoch 00124 | Loss 1.1679 | Time(s) 2.4687 | Accuracy: 32.018903 %\n",
            "Epoch 00125 | Loss 1.2589 | Time(s) 2.4692 | Accuracy: 32.111869 %\n",
            "Epoch 00126 | Loss 1.1362 | Time(s) 2.4689 | Accuracy: 32.166099 %\n",
            "Epoch 00127 | Loss 1.1343 | Time(s) 2.4693 | Accuracy: 32.259064 %\n",
            "Epoch 00128 | Loss 1.3006 | Time(s) 2.4699 | Accuracy: 32.228076 %\n",
            "Epoch 00129 | Loss 1.3061 | Time(s) 2.4707 | Accuracy: 32.181593 %\n",
            "Epoch 00130 | Loss 1.3000 | Time(s) 2.4705 | Accuracy: 32.189340 %\n",
            "Epoch 00131 | Loss 1.1324 | Time(s) 2.4705 | Accuracy: 32.111869 %\n",
            "Epoch 00132 | Loss 1.0953 | Time(s) 2.4702 | Accuracy: 32.135110 %\n",
            "Epoch 00133 | Loss 1.0922 | Time(s) 2.4700 | Accuracy: 32.057639 %\n",
            "Epoch 00134 | Loss 1.0895 | Time(s) 2.4701 | Accuracy: 31.995662 %\n",
            "Epoch 00135 | Loss 1.2672 | Time(s) 2.4698 | Accuracy: 32.173846 %\n",
            "Epoch 00136 | Loss 1.2984 | Time(s) 2.4696 | Accuracy: 32.034397 %\n",
            "Epoch 00137 | Loss 1.3134 | Time(s) 2.4697 | Accuracy: 32.150604 %\n",
            "Epoch 00138 | Loss 1.2521 | Time(s) 2.4694 | Accuracy: 32.111869 %\n",
            "Epoch 00139 | Loss 1.2164 | Time(s) 2.4694 | Accuracy: 32.243570 %\n",
            "Epoch 00140 | Loss 1.1698 | Time(s) 2.4697 | Accuracy: 32.127363 %\n",
            "Epoch 00141 | Loss 1.2517 | Time(s) 2.4694 | Accuracy: 32.212581 %\n",
            "Epoch 00142 | Loss 1.2474 | Time(s) 2.4696 | Accuracy: 32.243570 %\n",
            "Epoch 00143 | Loss 1.3122 | Time(s) 2.4697 | Accuracy: 32.173846 %\n",
            "Epoch 00144 | Loss 1.1664 | Time(s) 2.4694 | Accuracy: 32.228076 %\n",
            "Epoch 00145 | Loss 1.2540 | Time(s) 2.4692 | Accuracy: 32.127363 %\n",
            "Epoch 00146 | Loss 1.2041 | Time(s) 2.4689 | Accuracy: 32.259064 %\n",
            "Epoch 00147 | Loss 1.3108 | Time(s) 2.4686 | Accuracy: 32.197087 %\n",
            "Epoch 00148 | Loss 1.0369 | Time(s) 2.4687 | Accuracy: 32.189340 %\n",
            "Epoch 00149 | Loss 1.0362 | Time(s) 2.4684 | Accuracy: 32.166099 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7324 | Time(s) 2.5123 | Accuracy: 29.462349 %\n",
            "Epoch 00001 | Loss 1.6620 | Time(s) 2.4919 | Accuracy: 46.420824 %\n",
            "Epoch 00002 | Loss 1.5706 | Time(s) 2.4770 | Accuracy: 56.453362 %\n",
            "Epoch 00003 | Loss 1.4590 | Time(s) 2.4669 | Accuracy: 63.541989 %\n",
            "Epoch 00004 | Loss 1.4492 | Time(s) 2.4765 | Accuracy: 65.858382 %\n",
            "Epoch 00005 | Loss 1.3121 | Time(s) 2.4674 | Accuracy: 67.818407 %\n",
            "Epoch 00006 | Loss 1.3307 | Time(s) 2.4661 | Accuracy: 69.786179 %\n",
            "Epoch 00007 | Loss 1.4314 | Time(s) 2.4699 | Accuracy: 70.537651 %\n",
            "Epoch 00008 | Loss 1.1722 | Time(s) 2.4696 | Accuracy: 70.506663 %\n",
            "Epoch 00009 | Loss 1.3368 | Time(s) 2.4666 | Accuracy: 70.700341 %\n",
            "Epoch 00010 | Loss 1.1402 | Time(s) 2.4670 | Accuracy: 70.979238 %\n",
            "Epoch 00011 | Loss 1.1966 | Time(s) 2.4667 | Accuracy: 71.064456 %\n",
            "Epoch 00012 | Loss 1.0552 | Time(s) 2.4689 | Accuracy: 71.420824 %\n",
            "Epoch 00013 | Loss 1.0773 | Time(s) 2.4674 | Accuracy: 71.761698 %\n",
            "Epoch 00014 | Loss 0.8617 | Time(s) 2.4703 | Accuracy: 72.458940 %\n",
            "Epoch 00015 | Loss 0.9283 | Time(s) 2.4717 | Accuracy: 72.652619 %\n",
            "Epoch 00016 | Loss 0.9394 | Time(s) 2.4749 | Accuracy: 71.599008 %\n",
            "Epoch 00017 | Loss 0.8718 | Time(s) 2.4752 | Accuracy: 71.722963 %\n",
            "Epoch 00018 | Loss 0.9992 | Time(s) 2.4723 | Accuracy: 72.799814 %\n",
            "Epoch 00019 | Loss 0.8503 | Time(s) 2.4721 | Accuracy: 72.923768 %\n",
            "Epoch 00020 | Loss 0.8383 | Time(s) 2.4720 | Accuracy: 72.040595 %\n",
            "Epoch 00021 | Loss 0.9019 | Time(s) 2.4711 | Accuracy: 72.544159 %\n",
            "Epoch 00022 | Loss 0.8505 | Time(s) 2.4704 | Accuracy: 73.272389 %\n",
            "Epoch 00023 | Loss 0.8228 | Time(s) 2.4687 | Accuracy: 73.256895 %\n",
            "Epoch 00024 | Loss 0.6396 | Time(s) 2.4676 | Accuracy: 73.504803 %\n",
            "Epoch 00025 | Loss 0.8305 | Time(s) 2.4675 | Accuracy: 74.047103 %\n",
            "Epoch 00026 | Loss 0.6745 | Time(s) 2.4666 | Accuracy: 74.302758 %\n",
            "Epoch 00027 | Loss 0.8988 | Time(s) 2.4658 | Accuracy: 74.194298 %\n",
            "Epoch 00028 | Loss 0.7430 | Time(s) 2.4691 | Accuracy: 73.837930 %\n",
            "Epoch 00029 | Loss 0.7407 | Time(s) 2.4677 | Accuracy: 73.032228 %\n",
            "Epoch 00030 | Loss 0.6063 | Time(s) 2.4679 | Accuracy: 73.148435 %\n",
            "Epoch 00031 | Loss 0.7244 | Time(s) 2.4688 | Accuracy: 73.706229 %\n",
            "Epoch 00032 | Loss 0.6201 | Time(s) 2.4682 | Accuracy: 74.271769 %\n",
            "Epoch 00033 | Loss 0.7768 | Time(s) 2.4664 | Accuracy: 74.364735 %\n",
            "Epoch 00034 | Loss 0.6388 | Time(s) 2.4663 | Accuracy: 73.713976 %\n",
            "Epoch 00035 | Loss 0.5763 | Time(s) 2.4680 | Accuracy: 73.504803 %\n",
            "Epoch 00036 | Loss 0.6072 | Time(s) 2.4677 | Accuracy: 74.256275 %\n",
            "Epoch 00037 | Loss 0.7020 | Time(s) 2.4676 | Accuracy: 75.131701 %\n",
            "Epoch 00038 | Loss 0.5807 | Time(s) 2.4705 | Accuracy: 75.116207 %\n",
            "Epoch 00039 | Loss 0.4653 | Time(s) 2.4700 | Accuracy: 75.023241 %\n",
            "Epoch 00040 | Loss 0.5740 | Time(s) 2.4705 | Accuracy: 74.682368 %\n",
            "Epoch 00041 | Loss 0.5919 | Time(s) 2.4711 | Accuracy: 74.457701 %\n",
            "Epoch 00042 | Loss 0.6621 | Time(s) 2.4716 | Accuracy: 74.845057 %\n",
            "Epoch 00043 | Loss 0.5417 | Time(s) 2.4700 | Accuracy: 74.271769 %\n",
            "Epoch 00044 | Loss 0.4958 | Time(s) 2.4690 | Accuracy: 74.697862 %\n",
            "Epoch 00045 | Loss 0.6165 | Time(s) 2.4679 | Accuracy: 75.000000 %\n",
            "Epoch 00046 | Loss 0.4358 | Time(s) 2.4684 | Accuracy: 74.542919 %\n",
            "Epoch 00047 | Loss 0.4324 | Time(s) 2.4683 | Accuracy: 74.279517 %\n",
            "Epoch 00048 | Loss 0.4401 | Time(s) 2.4684 | Accuracy: 74.643632 %\n",
            "Epoch 00049 | Loss 0.3664 | Time(s) 2.4678 | Accuracy: 75.015494 %\n",
            "Epoch 00050 | Loss 0.4281 | Time(s) 2.4676 | Accuracy: 74.914782 %\n",
            "Epoch 00051 | Loss 0.4157 | Time(s) 2.4675 | Accuracy: 74.752092 %\n",
            "Epoch 00052 | Loss 0.4643 | Time(s) 2.4694 | Accuracy: 74.674620 %\n",
            "Epoch 00053 | Loss 0.4444 | Time(s) 2.4692 | Accuracy: 74.713356 %\n",
            "Epoch 00054 | Loss 0.3133 | Time(s) 2.4683 | Accuracy: 74.930276 %\n",
            "Epoch 00055 | Loss 0.4091 | Time(s) 2.4686 | Accuracy: 75.038736 %\n",
            "Epoch 00056 | Loss 0.4869 | Time(s) 2.4690 | Accuracy: 75.030989 %\n",
            "Epoch 00057 | Loss 0.4481 | Time(s) 2.4689 | Accuracy: 74.984506 %\n",
            "Epoch 00058 | Loss 0.3924 | Time(s) 2.4691 | Accuracy: 75.131701 %\n",
            "Epoch 00059 | Loss 0.3668 | Time(s) 2.4690 | Accuracy: 75.046483 %\n",
            "Epoch 00060 | Loss 0.4550 | Time(s) 2.4695 | Accuracy: 74.783080 %\n",
            "Epoch 00061 | Loss 0.3898 | Time(s) 2.4689 | Accuracy: 74.659126 %\n",
            "Epoch 00062 | Loss 0.3840 | Time(s) 2.4682 | Accuracy: 74.380229 %\n",
            "Epoch 00063 | Loss 0.3732 | Time(s) 2.4669 | Accuracy: 74.705609 %\n",
            "Epoch 00064 | Loss 0.3689 | Time(s) 2.4675 | Accuracy: 75.224667 %\n",
            "Epoch 00065 | Loss 0.3892 | Time(s) 2.4663 | Accuracy: 75.131701 %\n",
            "Epoch 00066 | Loss 0.2766 | Time(s) 2.4659 | Accuracy: 74.992253 %\n",
            "Epoch 00067 | Loss 0.4600 | Time(s) 2.4661 | Accuracy: 74.705609 %\n",
            "Epoch 00068 | Loss 0.3372 | Time(s) 2.4652 | Accuracy: 75.209173 %\n",
            "Epoch 00069 | Loss 0.3528 | Time(s) 2.4652 | Accuracy: 75.123954 %\n",
            "Epoch 00070 | Loss 0.2621 | Time(s) 2.4656 | Accuracy: 75.054230 %\n",
            "Epoch 00071 | Loss 0.4199 | Time(s) 2.4648 | Accuracy: 74.837310 %\n",
            "Epoch 00072 | Loss 0.3374 | Time(s) 2.4657 | Accuracy: 75.038736 %\n",
            "Epoch 00073 | Loss 0.3774 | Time(s) 2.4657 | Accuracy: 74.930276 %\n",
            "Epoch 00074 | Loss 0.2447 | Time(s) 2.4650 | Accuracy: 74.876046 %\n",
            "Epoch 00075 | Loss 0.3764 | Time(s) 2.4650 | Accuracy: 74.682368 %\n",
            "Epoch 00076 | Loss 0.3641 | Time(s) 2.4655 | Accuracy: 75.015494 %\n",
            "Epoch 00077 | Loss 0.4143 | Time(s) 2.4650 | Accuracy: 75.302138 %\n",
            "Epoch 00078 | Loss 0.3016 | Time(s) 2.4650 | Accuracy: 75.271150 %\n",
            "Epoch 00079 | Loss 0.3075 | Time(s) 2.4657 | Accuracy: 75.325380 %\n",
            "Epoch 00080 | Loss 0.3157 | Time(s) 2.4656 | Accuracy: 75.488069 %\n",
            "Epoch 00081 | Loss 0.2934 | Time(s) 2.4661 | Accuracy: 75.317632 %\n",
            "Epoch 00082 | Loss 0.3798 | Time(s) 2.4659 | Accuracy: 75.348621 %\n",
            "Epoch 00083 | Loss 0.3714 | Time(s) 2.4649 | Accuracy: 75.131701 %\n",
            "Epoch 00084 | Loss 0.2139 | Time(s) 2.4651 | Accuracy: 75.309885 %\n",
            "Epoch 00085 | Loss 0.3512 | Time(s) 2.4649 | Accuracy: 75.472575 %\n",
            "Epoch 00086 | Loss 0.2801 | Time(s) 2.4646 | Accuracy: 75.464828 %\n",
            "Epoch 00087 | Loss 0.2912 | Time(s) 2.4649 | Accuracy: 75.356368 %\n",
            "Epoch 00088 | Loss 0.3036 | Time(s) 2.4645 | Accuracy: 75.325380 %\n",
            "Epoch 00089 | Loss 0.3085 | Time(s) 2.4647 | Accuracy: 75.309885 %\n",
            "Epoch 00090 | Loss 0.2010 | Time(s) 2.4657 | Accuracy: 75.069724 %\n",
            "Epoch 00091 | Loss 0.1966 | Time(s) 2.4651 | Accuracy: 75.263403 %\n",
            "Epoch 00092 | Loss 0.1974 | Time(s) 2.4649 | Accuracy: 75.495817 %\n",
            "Epoch 00093 | Loss 0.2886 | Time(s) 2.4654 | Accuracy: 75.534552 %\n",
            "Epoch 00094 | Loss 0.2706 | Time(s) 2.4654 | Accuracy: 75.418345 %\n",
            "Epoch 00095 | Loss 0.3615 | Time(s) 2.4650 | Accuracy: 75.317632 %\n",
            "Epoch 00096 | Loss 0.3035 | Time(s) 2.4650 | Accuracy: 75.170437 %\n",
            "Epoch 00097 | Loss 0.3449 | Time(s) 2.4652 | Accuracy: 75.061977 %\n",
            "Epoch 00098 | Loss 0.2593 | Time(s) 2.4651 | Accuracy: 75.364115 %\n",
            "Epoch 00099 | Loss 0.2968 | Time(s) 2.4644 | Accuracy: 75.480322 %\n",
            "Epoch 00100 | Loss 0.3682 | Time(s) 2.4642 | Accuracy: 74.814069 %\n",
            "Epoch 00101 | Loss 0.2551 | Time(s) 2.4652 | Accuracy: 75.147196 %\n",
            "Epoch 00102 | Loss 0.2764 | Time(s) 2.4655 | Accuracy: 75.271150 %\n",
            "Epoch 00103 | Loss 0.3340 | Time(s) 2.4658 | Accuracy: 75.519058 %\n",
            "Epoch 00104 | Loss 0.2910 | Time(s) 2.4657 | Accuracy: 75.085218 %\n",
            "Epoch 00105 | Loss 0.3623 | Time(s) 2.4657 | Accuracy: 74.511931 %\n",
            "Epoch 00106 | Loss 0.2816 | Time(s) 2.4656 | Accuracy: 75.340874 %\n",
            "Epoch 00107 | Loss 0.1721 | Time(s) 2.4651 | Accuracy: 75.371862 %\n",
            "Epoch 00108 | Loss 0.4340 | Time(s) 2.4648 | Accuracy: 75.286644 %\n",
            "Epoch 00109 | Loss 0.2925 | Time(s) 2.4645 | Accuracy: 75.348621 %\n",
            "Epoch 00110 | Loss 0.3672 | Time(s) 2.4642 | Accuracy: 74.992253 %\n",
            "Epoch 00111 | Loss 0.2783 | Time(s) 2.4640 | Accuracy: 74.744345 %\n",
            "Epoch 00112 | Loss 0.2447 | Time(s) 2.4639 | Accuracy: 74.961264 %\n",
            "Epoch 00113 | Loss 0.2716 | Time(s) 2.4643 | Accuracy: 75.340874 %\n",
            "Epoch 00114 | Loss 0.2535 | Time(s) 2.4638 | Accuracy: 75.302138 %\n",
            "Epoch 00115 | Loss 0.3412 | Time(s) 2.4639 | Accuracy: 75.612024 %\n",
            "Epoch 00116 | Loss 0.2371 | Time(s) 2.4638 | Accuracy: 75.387357 %\n",
            "Epoch 00117 | Loss 0.1757 | Time(s) 2.4635 | Accuracy: 75.077471 %\n",
            "Epoch 00118 | Loss 0.2527 | Time(s) 2.4633 | Accuracy: 75.201425 %\n",
            "Epoch 00119 | Loss 0.1599 | Time(s) 2.4631 | Accuracy: 75.178184 %\n",
            "Epoch 00120 | Loss 0.3300 | Time(s) 2.4624 | Accuracy: 75.224667 %\n",
            "Epoch 00121 | Loss 0.2320 | Time(s) 2.4624 | Accuracy: 75.464828 %\n",
            "Epoch 00122 | Loss 0.1560 | Time(s) 2.4619 | Accuracy: 75.728231 %\n",
            "Epoch 00123 | Loss 0.2300 | Time(s) 2.4619 | Accuracy: 75.728231 %\n",
            "Epoch 00124 | Loss 0.1542 | Time(s) 2.4614 | Accuracy: 75.449334 %\n",
            "Epoch 00125 | Loss 0.1574 | Time(s) 2.4618 | Accuracy: 75.216920 %\n",
            "Epoch 00126 | Loss 0.3306 | Time(s) 2.4618 | Accuracy: 75.240161 %\n",
            "Epoch 00127 | Loss 0.1576 | Time(s) 2.4612 | Accuracy: 75.271150 %\n",
            "Epoch 00128 | Loss 0.3067 | Time(s) 2.4614 | Accuracy: 75.185931 %\n",
            "Epoch 00129 | Loss 0.3043 | Time(s) 2.4611 | Accuracy: 75.023241 %\n",
            "Epoch 00130 | Loss 0.2659 | Time(s) 2.4608 | Accuracy: 75.178184 %\n",
            "Epoch 00131 | Loss 0.1472 | Time(s) 2.4609 | Accuracy: 75.085218 %\n",
            "Epoch 00132 | Loss 0.1509 | Time(s) 2.4605 | Accuracy: 75.092966 %\n",
            "Epoch 00133 | Loss 0.1477 | Time(s) 2.4605 | Accuracy: 74.798575 %\n",
            "Epoch 00134 | Loss 0.2355 | Time(s) 2.4610 | Accuracy: 75.100713 %\n",
            "Epoch 00135 | Loss 0.3038 | Time(s) 2.4606 | Accuracy: 75.333127 %\n",
            "Epoch 00136 | Loss 0.2465 | Time(s) 2.4604 | Accuracy: 75.123954 %\n",
            "Epoch 00137 | Loss 0.2265 | Time(s) 2.4607 | Accuracy: 75.232414 %\n",
            "Epoch 00138 | Loss 0.2322 | Time(s) 2.4608 | Accuracy: 75.526805 %\n",
            "Epoch 00139 | Loss 0.1476 | Time(s) 2.4604 | Accuracy: 75.480322 %\n",
            "Epoch 00140 | Loss 0.2297 | Time(s) 2.4603 | Accuracy: 75.286644 %\n",
            "Epoch 00141 | Loss 0.2154 | Time(s) 2.4599 | Accuracy: 75.209173 %\n",
            "Epoch 00142 | Loss 0.2390 | Time(s) 2.4601 | Accuracy: 75.395104 %\n",
            "Epoch 00143 | Loss 0.3019 | Time(s) 2.4599 | Accuracy: 75.557794 %\n",
            "Epoch 00144 | Loss 0.2188 | Time(s) 2.4597 | Accuracy: 75.588782 %\n",
            "Epoch 00145 | Loss 0.1403 | Time(s) 2.4599 | Accuracy: 75.720483 %\n",
            "Epoch 00146 | Loss 0.2237 | Time(s) 2.4599 | Accuracy: 75.534552 %\n",
            "Epoch 00147 | Loss 0.1384 | Time(s) 2.4600 | Accuracy: 75.674001 %\n",
            "Epoch 00148 | Loss 0.2194 | Time(s) 2.4598 | Accuracy: 75.371862 %\n",
            "Epoch 00149 | Loss 0.2335 | Time(s) 2.4595 | Accuracy: 74.930276 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7599 | Time(s) 2.4706 | Accuracy: 29.260923 %\n",
            "Epoch 00001 | Loss 1.6841 | Time(s) 2.4442 | Accuracy: 43.012086 %\n",
            "Epoch 00002 | Loss 1.6614 | Time(s) 2.4204 | Accuracy: 46.513790 %\n",
            "Epoch 00003 | Loss 1.6382 | Time(s) 2.4314 | Accuracy: 47.350480 %\n",
            "Epoch 00004 | Loss 1.5035 | Time(s) 2.4252 | Accuracy: 47.149055 %\n",
            "Epoch 00005 | Loss 1.5473 | Time(s) 2.4323 | Accuracy: 47.110319 %\n",
            "Epoch 00006 | Loss 1.4702 | Time(s) 2.4301 | Accuracy: 47.373722 %\n",
            "Epoch 00007 | Loss 1.4143 | Time(s) 2.4359 | Accuracy: 49.271769 %\n",
            "Epoch 00008 | Loss 1.3818 | Time(s) 2.4363 | Accuracy: 54.640533 %\n",
            "Epoch 00009 | Loss 1.3207 | Time(s) 2.4366 | Accuracy: 57.034397 %\n",
            "Epoch 00010 | Loss 1.3484 | Time(s) 2.4431 | Accuracy: 57.925318 %\n",
            "Epoch 00011 | Loss 1.2035 | Time(s) 2.4453 | Accuracy: 58.304927 %\n",
            "Epoch 00012 | Loss 1.2886 | Time(s) 2.4532 | Accuracy: 58.909204 %\n",
            "Epoch 00013 | Loss 1.2555 | Time(s) 2.4521 | Accuracy: 59.513480 %\n",
            "Epoch 00014 | Loss 1.2525 | Time(s) 2.4496 | Accuracy: 60.156492 %\n",
            "Epoch 00015 | Loss 1.1408 | Time(s) 2.4464 | Accuracy: 60.412148 %\n",
            "Epoch 00016 | Loss 1.1602 | Time(s) 2.4469 | Accuracy: 60.869228 %\n",
            "Epoch 00017 | Loss 1.1795 | Time(s) 2.4478 | Accuracy: 61.086148 %\n",
            "Epoch 00018 | Loss 1.2008 | Time(s) 2.4458 | Accuracy: 60.481872 %\n",
            "Epoch 00019 | Loss 1.1583 | Time(s) 2.4454 | Accuracy: 60.450883 %\n",
            "Epoch 00020 | Loss 1.1344 | Time(s) 2.4505 | Accuracy: 60.931205 %\n",
            "Epoch 00021 | Loss 1.0422 | Time(s) 2.4498 | Accuracy: 61.396033 %\n",
            "Epoch 00022 | Loss 1.0095 | Time(s) 2.4499 | Accuracy: 61.667183 %\n",
            "Epoch 00023 | Loss 1.0552 | Time(s) 2.4473 | Accuracy: 62.077781 %\n",
            "Epoch 00024 | Loss 0.9759 | Time(s) 2.4542 | Accuracy: 61.992563 %\n",
            "Epoch 00025 | Loss 0.8832 | Time(s) 2.4546 | Accuracy: 62.132011 %\n",
            "Epoch 00026 | Loss 0.9717 | Time(s) 2.4590 | Accuracy: 62.255965 %\n",
            "Epoch 00027 | Loss 0.9429 | Time(s) 2.4606 | Accuracy: 62.333437 %\n",
            "Epoch 00028 | Loss 0.9339 | Time(s) 2.4633 | Accuracy: 61.334056 %\n",
            "Epoch 00029 | Loss 0.9670 | Time(s) 2.4664 | Accuracy: 61.605206 %\n",
            "Epoch 00030 | Loss 0.8879 | Time(s) 2.4713 | Accuracy: 62.627828 %\n",
            "Epoch 00031 | Loss 0.8710 | Time(s) 2.4728 | Accuracy: 62.929966 %\n",
            "Epoch 00032 | Loss 0.8875 | Time(s) 2.4751 | Accuracy: 63.131391 %\n",
            "Epoch 00033 | Loss 0.8520 | Time(s) 2.4755 | Accuracy: 62.968702 %\n",
            "Epoch 00034 | Loss 0.8317 | Time(s) 2.4759 | Accuracy: 62.627828 %\n",
            "Epoch 00035 | Loss 0.8218 | Time(s) 2.4753 | Accuracy: 63.193368 %\n",
            "Epoch 00036 | Loss 0.7902 | Time(s) 2.4756 | Accuracy: 63.278587 %\n",
            "Epoch 00037 | Loss 0.7990 | Time(s) 2.4784 | Accuracy: 63.146886 %\n",
            "Epoch 00038 | Loss 0.9291 | Time(s) 2.4788 | Accuracy: 62.341184 %\n",
            "Epoch 00039 | Loss 0.7714 | Time(s) 2.4798 | Accuracy: 62.449644 %\n",
            "Epoch 00040 | Loss 0.8394 | Time(s) 2.4810 | Accuracy: 62.627828 %\n",
            "Epoch 00041 | Loss 0.8021 | Time(s) 2.4835 | Accuracy: 63.061667 %\n",
            "Epoch 00042 | Loss 0.8365 | Time(s) 2.4848 | Accuracy: 63.139139 %\n",
            "Epoch 00043 | Loss 0.8680 | Time(s) 2.4866 | Accuracy: 62.937713 %\n",
            "Epoch 00044 | Loss 0.8150 | Time(s) 2.4876 | Accuracy: 62.906725 %\n",
            "Epoch 00045 | Loss 0.7475 | Time(s) 2.4890 | Accuracy: 63.077161 %\n",
            "Epoch 00046 | Loss 0.7315 | Time(s) 2.4907 | Accuracy: 62.798265 %\n",
            "Epoch 00047 | Loss 0.8347 | Time(s) 2.4918 | Accuracy: 62.891230 %\n",
            "Epoch 00048 | Loss 0.7187 | Time(s) 2.4938 | Accuracy: 63.418035 %\n",
            "Epoch 00049 | Loss 0.8248 | Time(s) 2.4954 | Accuracy: 63.642702 %\n",
            "Epoch 00050 | Loss 0.7608 | Time(s) 2.4968 | Accuracy: 63.418035 %\n",
            "Epoch 00051 | Loss 0.7682 | Time(s) 2.4978 | Accuracy: 63.154633 %\n",
            "Epoch 00052 | Loss 0.7779 | Time(s) 2.4989 | Accuracy: 63.464518 %\n",
            "Epoch 00053 | Loss 0.7595 | Time(s) 2.5008 | Accuracy: 63.495507 %\n",
            "Epoch 00054 | Loss 0.6304 | Time(s) 2.5024 | Accuracy: 63.619461 %\n",
            "Epoch 00055 | Loss 0.6444 | Time(s) 2.5040 | Accuracy: 63.937093 %\n",
            "Epoch 00056 | Loss 0.6814 | Time(s) 2.5051 | Accuracy: 63.844128 %\n",
            "Epoch 00057 | Loss 0.7100 | Time(s) 2.5071 | Accuracy: 63.263093 %\n",
            "Epoch 00058 | Loss 0.7529 | Time(s) 2.5087 | Accuracy: 62.604586 %\n",
            "Epoch 00059 | Loss 0.6130 | Time(s) 2.5110 | Accuracy: 62.534862 %\n",
            "Epoch 00060 | Loss 0.7380 | Time(s) 2.5110 | Accuracy: 63.433530 %\n",
            "Epoch 00061 | Loss 0.7142 | Time(s) 2.5114 | Accuracy: 63.851875 %\n",
            "Epoch 00062 | Loss 0.6904 | Time(s) 2.5119 | Accuracy: 63.890610 %\n",
            "Epoch 00063 | Loss 0.6550 | Time(s) 2.5119 | Accuracy: 64.053300 %\n",
            "Epoch 00064 | Loss 0.6760 | Time(s) 2.5120 | Accuracy: 63.735668 %\n",
            "Epoch 00065 | Loss 0.7186 | Time(s) 2.5118 | Accuracy: 63.348311 %\n",
            "Epoch 00066 | Loss 0.5750 | Time(s) 2.5117 | Accuracy: 63.418035 %\n",
            "Epoch 00067 | Loss 0.6552 | Time(s) 2.5120 | Accuracy: 63.704679 %\n",
            "Epoch 00068 | Loss 0.7151 | Time(s) 2.5131 | Accuracy: 64.022312 %\n",
            "Epoch 00069 | Loss 0.5547 | Time(s) 2.5144 | Accuracy: 63.820886 %\n",
            "Epoch 00070 | Loss 0.5660 | Time(s) 2.5141 | Accuracy: 63.875116 %\n",
            "Epoch 00071 | Loss 0.6760 | Time(s) 2.5144 | Accuracy: 64.030059 %\n",
            "Epoch 00072 | Loss 0.6831 | Time(s) 2.5145 | Accuracy: 63.782151 %\n",
            "Epoch 00073 | Loss 0.5408 | Time(s) 2.5150 | Accuracy: 63.696932 %\n",
            "Epoch 00074 | Loss 0.6991 | Time(s) 2.5147 | Accuracy: 63.774403 %\n",
            "Epoch 00075 | Loss 0.7322 | Time(s) 2.5146 | Accuracy: 63.735668 %\n",
            "Epoch 00076 | Loss 0.6623 | Time(s) 2.5154 | Accuracy: 63.286334 %\n",
            "Epoch 00077 | Loss 0.6373 | Time(s) 2.5169 | Accuracy: 63.704679 %\n",
            "Epoch 00078 | Loss 0.5367 | Time(s) 2.5168 | Accuracy: 63.944840 %\n",
            "Epoch 00079 | Loss 0.6531 | Time(s) 2.5183 | Accuracy: 64.161760 %\n",
            "Epoch 00080 | Loss 0.5182 | Time(s) 2.5186 | Accuracy: 64.161760 %\n",
            "Epoch 00081 | Loss 0.6645 | Time(s) 2.5193 | Accuracy: 64.192749 %\n",
            "Epoch 00082 | Loss 0.6614 | Time(s) 2.5192 | Accuracy: 64.014565 %\n",
            "Epoch 00083 | Loss 0.6480 | Time(s) 2.5194 | Accuracy: 63.797645 %\n",
            "Epoch 00084 | Loss 0.6554 | Time(s) 2.5201 | Accuracy: 63.580725 %\n",
            "Epoch 00085 | Loss 0.6372 | Time(s) 2.5205 | Accuracy: 63.433530 %\n",
            "Epoch 00086 | Loss 0.6492 | Time(s) 2.5203 | Accuracy: 63.611714 %\n",
            "Epoch 00087 | Loss 0.5127 | Time(s) 2.5204 | Accuracy: 64.061047 %\n",
            "Epoch 00088 | Loss 0.6163 | Time(s) 2.5204 | Accuracy: 64.006817 %\n",
            "Epoch 00089 | Loss 0.6445 | Time(s) 2.5203 | Accuracy: 64.045553 %\n",
            "Epoch 00090 | Loss 0.6384 | Time(s) 2.5206 | Accuracy: 63.999070 %\n",
            "Epoch 00091 | Loss 0.5061 | Time(s) 2.5208 | Accuracy: 63.991323 %\n",
            "Epoch 00092 | Loss 0.6221 | Time(s) 2.5205 | Accuracy: 64.053300 %\n",
            "Epoch 00093 | Loss 0.6149 | Time(s) 2.5205 | Accuracy: 64.301209 %\n",
            "Epoch 00094 | Loss 0.6261 | Time(s) 2.5203 | Accuracy: 64.068795 %\n",
            "Epoch 00095 | Loss 0.6361 | Time(s) 2.5200 | Accuracy: 63.789898 %\n",
            "Epoch 00096 | Loss 0.6093 | Time(s) 2.5200 | Accuracy: 64.037806 %\n",
            "Epoch 00097 | Loss 0.6205 | Time(s) 2.5200 | Accuracy: 64.277967 %\n",
            "Epoch 00098 | Loss 0.4992 | Time(s) 2.5204 | Accuracy: 64.130772 %\n",
            "Epoch 00099 | Loss 0.5662 | Time(s) 2.5206 | Accuracy: 63.968082 %\n",
            "Epoch 00100 | Loss 0.6119 | Time(s) 2.5203 | Accuracy: 64.014565 %\n",
            "Epoch 00101 | Loss 0.5997 | Time(s) 2.5201 | Accuracy: 63.255346 %\n",
            "Epoch 00102 | Loss 0.5558 | Time(s) 2.5201 | Accuracy: 63.619461 %\n",
            "Epoch 00103 | Loss 0.6114 | Time(s) 2.5201 | Accuracy: 63.890610 %\n",
            "Epoch 00104 | Loss 0.4918 | Time(s) 2.5200 | Accuracy: 64.045553 %\n",
            "Epoch 00105 | Loss 0.5522 | Time(s) 2.5209 | Accuracy: 64.347691 %\n",
            "Epoch 00106 | Loss 0.4811 | Time(s) 2.5209 | Accuracy: 64.146266 %\n",
            "Epoch 00107 | Loss 0.5435 | Time(s) 2.5211 | Accuracy: 63.991323 %\n",
            "Epoch 00108 | Loss 0.4800 | Time(s) 2.5214 | Accuracy: 64.208243 %\n",
            "Epoch 00109 | Loss 0.4636 | Time(s) 2.5215 | Accuracy: 63.844128 %\n",
            "Epoch 00110 | Loss 0.5414 | Time(s) 2.5214 | Accuracy: 63.650449 %\n",
            "Epoch 00111 | Loss 0.4755 | Time(s) 2.5220 | Accuracy: 63.921599 %\n",
            "Epoch 00112 | Loss 0.5834 | Time(s) 2.5223 | Accuracy: 64.130772 %\n",
            "Epoch 00113 | Loss 0.6034 | Time(s) 2.5220 | Accuracy: 64.138519 %\n",
            "Epoch 00114 | Loss 0.6027 | Time(s) 2.5222 | Accuracy: 64.246979 %\n",
            "Epoch 00115 | Loss 0.6015 | Time(s) 2.5228 | Accuracy: 64.215990 %\n",
            "Epoch 00116 | Loss 0.6276 | Time(s) 2.5230 | Accuracy: 64.037806 %\n",
            "Epoch 00117 | Loss 0.6192 | Time(s) 2.5229 | Accuracy: 63.727921 %\n",
            "Epoch 00118 | Loss 0.4407 | Time(s) 2.5230 | Accuracy: 63.999070 %\n",
            "Epoch 00119 | Loss 0.5940 | Time(s) 2.5236 | Accuracy: 63.828633 %\n",
            "Epoch 00120 | Loss 0.4821 | Time(s) 2.5235 | Accuracy: 63.906105 %\n",
            "Epoch 00121 | Loss 0.4374 | Time(s) 2.5235 | Accuracy: 64.370933 %\n",
            "Epoch 00122 | Loss 0.5995 | Time(s) 2.5240 | Accuracy: 64.510381 %\n",
            "Epoch 00123 | Loss 0.5960 | Time(s) 2.5241 | Accuracy: 64.580105 %\n",
            "Epoch 00124 | Loss 0.5106 | Time(s) 2.5244 | Accuracy: 64.270220 %\n",
            "Epoch 00125 | Loss 0.5966 | Time(s) 2.5243 | Accuracy: 64.084289 %\n",
            "Epoch 00126 | Loss 0.6117 | Time(s) 2.5248 | Accuracy: 64.254726 %\n",
            "Epoch 00127 | Loss 0.4720 | Time(s) 2.5250 | Accuracy: 64.378680 %\n",
            "Epoch 00128 | Loss 0.6032 | Time(s) 2.5255 | Accuracy: 64.572358 %\n",
            "Epoch 00129 | Loss 0.5924 | Time(s) 2.5255 | Accuracy: 64.471645 %\n",
            "Epoch 00130 | Loss 0.5975 | Time(s) 2.5257 | Accuracy: 64.215990 %\n",
            "Epoch 00131 | Loss 0.6064 | Time(s) 2.5264 | Accuracy: 64.316703 %\n",
            "Epoch 00132 | Loss 0.6709 | Time(s) 2.5265 | Accuracy: 64.494887 %\n",
            "Epoch 00133 | Loss 0.5893 | Time(s) 2.5266 | Accuracy: 64.316703 %\n",
            "Epoch 00134 | Loss 0.5027 | Time(s) 2.5269 | Accuracy: 64.014565 %\n",
            "Epoch 00135 | Loss 0.4640 | Time(s) 2.5271 | Accuracy: 63.751162 %\n",
            "Epoch 00136 | Loss 0.5847 | Time(s) 2.5273 | Accuracy: 64.324450 %\n",
            "Epoch 00137 | Loss 0.5002 | Time(s) 2.5275 | Accuracy: 64.246979 %\n",
            "Epoch 00138 | Loss 0.4608 | Time(s) 2.5280 | Accuracy: 64.130772 %\n",
            "Epoch 00139 | Loss 0.4935 | Time(s) 2.5283 | Accuracy: 63.968082 %\n",
            "Epoch 00140 | Loss 0.6557 | Time(s) 2.5286 | Accuracy: 64.076542 %\n",
            "Epoch 00141 | Loss 0.5648 | Time(s) 2.5288 | Accuracy: 64.185002 %\n",
            "Epoch 00142 | Loss 0.5794 | Time(s) 2.5293 | Accuracy: 63.797645 %\n",
            "Epoch 00143 | Loss 0.6507 | Time(s) 2.5297 | Accuracy: 63.294081 %\n",
            "Epoch 00144 | Loss 0.5914 | Time(s) 2.5299 | Accuracy: 64.301209 %\n",
            "Epoch 00145 | Loss 0.4600 | Time(s) 2.5299 | Accuracy: 63.681438 %\n",
            "Epoch 00146 | Loss 0.5785 | Time(s) 2.5305 | Accuracy: 64.014565 %\n",
            "Epoch 00147 | Loss 0.5785 | Time(s) 2.5306 | Accuracy: 64.254726 %\n",
            "Epoch 00148 | Loss 0.4573 | Time(s) 2.5307 | Accuracy: 64.370933 %\n",
            "Epoch 00149 | Loss 0.4972 | Time(s) 2.5308 | Accuracy: 64.006817 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7318 | Time(s) 2.6019 | Accuracy: 27.052990 %\n",
            "Epoch 00001 | Loss 1.6641 | Time(s) 2.6092 | Accuracy: 35.032538 %\n",
            "Epoch 00002 | Loss 1.6169 | Time(s) 2.5918 | Accuracy: 37.279207 %\n",
            "Epoch 00003 | Loss 1.5740 | Time(s) 2.5872 | Accuracy: 39.944221 %\n",
            "Epoch 00004 | Loss 1.5374 | Time(s) 2.5945 | Accuracy: 45.034087 %\n",
            "Epoch 00005 | Loss 1.3587 | Time(s) 2.5918 | Accuracy: 55.206074 %\n",
            "Epoch 00006 | Loss 1.3639 | Time(s) 2.5857 | Accuracy: 62.674311 %\n",
            "Epoch 00007 | Loss 1.2634 | Time(s) 2.5870 | Accuracy: 66.648590 %\n",
            "Epoch 00008 | Loss 1.2756 | Time(s) 2.5833 | Accuracy: 69.476294 %\n",
            "Epoch 00009 | Loss 1.2436 | Time(s) 2.5839 | Accuracy: 71.320112 %\n",
            "Epoch 00010 | Loss 1.2922 | Time(s) 2.5841 | Accuracy: 72.040595 %\n",
            "Epoch 00011 | Loss 1.1404 | Time(s) 2.5849 | Accuracy: 72.032848 %\n",
            "Epoch 00012 | Loss 1.1087 | Time(s) 2.5831 | Accuracy: 72.110319 %\n",
            "Epoch 00013 | Loss 0.9352 | Time(s) 2.5808 | Accuracy: 72.985745 %\n",
            "Epoch 00014 | Loss 1.1731 | Time(s) 2.5796 | Accuracy: 74.101333 %\n",
            "Epoch 00015 | Loss 0.8740 | Time(s) 2.5790 | Accuracy: 73.791447 %\n",
            "Epoch 00016 | Loss 0.8360 | Time(s) 2.5829 | Accuracy: 74.124574 %\n",
            "Epoch 00017 | Loss 0.7699 | Time(s) 2.5874 | Accuracy: 74.264022 %\n",
            "Epoch 00018 | Loss 0.8579 | Time(s) 2.5859 | Accuracy: 74.295011 %\n",
            "Epoch 00019 | Loss 0.9444 | Time(s) 2.5842 | Accuracy: 74.488689 %\n",
            "Epoch 00020 | Loss 0.7846 | Time(s) 2.5838 | Accuracy: 74.070344 %\n",
            "Epoch 00021 | Loss 0.9528 | Time(s) 2.5826 | Accuracy: 73.985126 %\n",
            "Epoch 00022 | Loss 0.8335 | Time(s) 2.5837 | Accuracy: 74.225287 %\n",
            "Epoch 00023 | Loss 0.6459 | Time(s) 2.5831 | Accuracy: 74.364735 %\n",
            "Epoch 00024 | Loss 0.6828 | Time(s) 2.5825 | Accuracy: 73.985126 %\n",
            "Epoch 00025 | Loss 0.8502 | Time(s) 2.5845 | Accuracy: 74.790827 %\n",
            "Epoch 00026 | Loss 0.7976 | Time(s) 2.5852 | Accuracy: 75.069724 %\n",
            "Epoch 00027 | Loss 0.5492 | Time(s) 2.5842 | Accuracy: 74.395724 %\n",
            "Epoch 00028 | Loss 0.6204 | Time(s) 2.5843 | Accuracy: 73.930896 %\n",
            "Epoch 00029 | Loss 0.6359 | Time(s) 2.5846 | Accuracy: 74.155562 %\n",
            "Epoch 00030 | Loss 0.7298 | Time(s) 2.5861 | Accuracy: 74.837310 %\n",
            "Epoch 00031 | Loss 0.5965 | Time(s) 2.5860 | Accuracy: 74.736597 %\n",
            "Epoch 00032 | Loss 0.6419 | Time(s) 2.5854 | Accuracy: 74.372482 %\n",
            "Epoch 00033 | Loss 0.6977 | Time(s) 2.5860 | Accuracy: 73.706229 %\n",
            "Epoch 00034 | Loss 0.5082 | Time(s) 2.5864 | Accuracy: 74.047103 %\n",
            "Epoch 00035 | Loss 0.4815 | Time(s) 2.5854 | Accuracy: 74.775333 %\n",
            "Epoch 00036 | Loss 0.5395 | Time(s) 2.5861 | Accuracy: 75.519058 %\n",
            "Epoch 00037 | Loss 0.6398 | Time(s) 2.5852 | Accuracy: 75.379610 %\n",
            "Epoch 00038 | Loss 0.5005 | Time(s) 2.5862 | Accuracy: 75.433839 %\n",
            "Epoch 00039 | Loss 0.4391 | Time(s) 2.5855 | Accuracy: 75.418345 %\n",
            "Epoch 00040 | Loss 0.4097 | Time(s) 2.5865 | Accuracy: 75.774713 %\n",
            "Epoch 00041 | Loss 0.4784 | Time(s) 2.5859 | Accuracy: 75.790208 %\n",
            "Epoch 00042 | Loss 0.5249 | Time(s) 2.5855 | Accuracy: 75.612024 %\n",
            "Epoch 00043 | Loss 0.4603 | Time(s) 2.5853 | Accuracy: 75.728231 %\n",
            "Epoch 00044 | Loss 0.3707 | Time(s) 2.5844 | Accuracy: 75.712736 %\n",
            "Epoch 00045 | Loss 0.4849 | Time(s) 2.5847 | Accuracy: 75.813449 %\n",
            "Epoch 00046 | Loss 0.4352 | Time(s) 2.5847 | Accuracy: 76.262783 %\n",
            "Epoch 00047 | Loss 0.3264 | Time(s) 2.5847 | Accuracy: 76.038116 %\n",
            "Epoch 00048 | Loss 0.3533 | Time(s) 2.5847 | Accuracy: 75.790208 %\n",
            "Epoch 00049 | Loss 0.4727 | Time(s) 2.5851 | Accuracy: 75.844438 %\n",
            "Epoch 00050 | Loss 0.3896 | Time(s) 2.5856 | Accuracy: 75.976139 %\n",
            "Epoch 00051 | Loss 0.4382 | Time(s) 2.5857 | Accuracy: 76.115587 %\n",
            "Epoch 00052 | Loss 0.2581 | Time(s) 2.5852 | Accuracy: 76.386737 %\n",
            "Epoch 00053 | Loss 0.2951 | Time(s) 2.5850 | Accuracy: 76.069104 %\n",
            "Epoch 00054 | Loss 0.2392 | Time(s) 2.5848 | Accuracy: 75.983886 %\n",
            "Epoch 00055 | Loss 0.2752 | Time(s) 2.5848 | Accuracy: 76.193059 %\n",
            "Epoch 00056 | Loss 0.3406 | Time(s) 2.5851 | Accuracy: 76.425473 %\n",
            "Epoch 00057 | Loss 0.2449 | Time(s) 2.5848 | Accuracy: 76.580415 %\n",
            "Epoch 00058 | Loss 0.4530 | Time(s) 2.5844 | Accuracy: 76.433220 %\n",
            "Epoch 00059 | Loss 0.2584 | Time(s) 2.5842 | Accuracy: 75.937403 %\n",
            "Epoch 00060 | Loss 0.3143 | Time(s) 2.5837 | Accuracy: 76.270530 %\n",
            "Epoch 00061 | Loss 0.4372 | Time(s) 2.5842 | Accuracy: 77.045243 %\n",
            "Epoch 00062 | Loss 0.3252 | Time(s) 2.5843 | Accuracy: 76.735358 %\n",
            "Epoch 00063 | Loss 0.3153 | Time(s) 2.5842 | Accuracy: 75.945150 %\n",
            "Epoch 00064 | Loss 0.3801 | Time(s) 2.5842 | Accuracy: 75.604276 %\n",
            "Epoch 00065 | Loss 0.3715 | Time(s) 2.5837 | Accuracy: 76.262783 %\n",
            "Epoch 00066 | Loss 0.3209 | Time(s) 2.5840 | Accuracy: 76.348001 %\n",
            "Epoch 00067 | Loss 0.3126 | Time(s) 2.5842 | Accuracy: 76.549427 %\n",
            "Epoch 00068 | Loss 0.2522 | Time(s) 2.5842 | Accuracy: 76.030369 %\n",
            "Epoch 00069 | Loss 0.1742 | Time(s) 2.5847 | Accuracy: 76.107840 %\n",
            "Epoch 00070 | Loss 0.2759 | Time(s) 2.5846 | Accuracy: 76.696622 %\n",
            "Epoch 00071 | Loss 0.2721 | Time(s) 2.5844 | Accuracy: 76.991013 %\n",
            "Epoch 00072 | Loss 0.1618 | Time(s) 2.5844 | Accuracy: 77.045243 %\n",
            "Epoch 00073 | Loss 0.2277 | Time(s) 2.5840 | Accuracy: 76.797335 %\n",
            "Epoch 00074 | Loss 0.2184 | Time(s) 2.5846 | Accuracy: 76.743105 %\n",
            "Epoch 00075 | Loss 0.3180 | Time(s) 2.5842 | Accuracy: 76.828324 %\n",
            "Epoch 00076 | Loss 0.2479 | Time(s) 2.5845 | Accuracy: 76.797335 %\n",
            "Epoch 00077 | Loss 0.2489 | Time(s) 2.5843 | Accuracy: 76.696622 %\n",
            "Epoch 00078 | Loss 0.1309 | Time(s) 2.5843 | Accuracy: 76.332507 %\n",
            "Epoch 00079 | Loss 0.2915 | Time(s) 2.5843 | Accuracy: 76.324760 %\n",
            "Epoch 00080 | Loss 0.1210 | Time(s) 2.5841 | Accuracy: 76.735358 %\n",
            "Epoch 00081 | Loss 0.1173 | Time(s) 2.5841 | Accuracy: 76.828324 %\n",
            "Epoch 00082 | Loss 0.1935 | Time(s) 2.5837 | Accuracy: 76.719864 %\n",
            "Epoch 00083 | Loss 0.2165 | Time(s) 2.5841 | Accuracy: 76.820576 %\n",
            "Epoch 00084 | Loss 0.1330 | Time(s) 2.5843 | Accuracy: 76.665634 %\n",
            "Epoch 00085 | Loss 0.1853 | Time(s) 2.5840 | Accuracy: 76.595910 %\n",
            "Epoch 00086 | Loss 0.1797 | Time(s) 2.5839 | Accuracy: 76.696622 %\n",
            "Epoch 00087 | Loss 0.2101 | Time(s) 2.5839 | Accuracy: 76.611404 %\n",
            "Epoch 00088 | Loss 0.1969 | Time(s) 2.5836 | Accuracy: 76.665634 %\n",
            "Epoch 00089 | Loss 0.0992 | Time(s) 2.5834 | Accuracy: 76.688875 %\n",
            "Epoch 00090 | Loss 0.1148 | Time(s) 2.5830 | Accuracy: 76.758599 %\n",
            "Epoch 00091 | Loss 0.0904 | Time(s) 2.5831 | Accuracy: 76.820576 %\n",
            "Epoch 00092 | Loss 0.1112 | Time(s) 2.5835 | Accuracy: 76.812829 %\n",
            "Epoch 00093 | Loss 0.1534 | Time(s) 2.5835 | Accuracy: 76.673381 %\n",
            "Epoch 00094 | Loss 0.1063 | Time(s) 2.5837 | Accuracy: 76.634645 %\n",
            "Epoch 00095 | Loss 0.1024 | Time(s) 2.5840 | Accuracy: 76.812829 %\n",
            "Epoch 00096 | Loss 0.0826 | Time(s) 2.5840 | Accuracy: 76.626898 %\n",
            "Epoch 00097 | Loss 0.0806 | Time(s) 2.5839 | Accuracy: 76.557174 %\n",
            "Epoch 00098 | Loss 0.1495 | Time(s) 2.5841 | Accuracy: 76.479703 %\n",
            "Epoch 00099 | Loss 0.1643 | Time(s) 2.5840 | Accuracy: 76.750852 %\n",
            "Epoch 00100 | Loss 0.1672 | Time(s) 2.5840 | Accuracy: 76.820576 %\n",
            "Epoch 00101 | Loss 0.1669 | Time(s) 2.5839 | Accuracy: 76.696622 %\n",
            "Epoch 00102 | Loss 0.1616 | Time(s) 2.5838 | Accuracy: 76.378990 %\n",
            "Epoch 00103 | Loss 0.1393 | Time(s) 2.5835 | Accuracy: 76.317013 %\n",
            "Epoch 00104 | Loss 0.0916 | Time(s) 2.5840 | Accuracy: 76.495197 %\n",
            "Epoch 00105 | Loss 0.0759 | Time(s) 2.5837 | Accuracy: 76.735358 %\n",
            "Epoch 00106 | Loss 0.1341 | Time(s) 2.5839 | Accuracy: 76.921289 %\n",
            "Epoch 00107 | Loss 0.0896 | Time(s) 2.5838 | Accuracy: 76.704369 %\n",
            "Epoch 00108 | Loss 0.1219 | Time(s) 2.5838 | Accuracy: 76.626898 %\n",
            "Epoch 00109 | Loss 0.1867 | Time(s) 2.5837 | Accuracy: 76.766346 %\n",
            "Epoch 00110 | Loss 0.1154 | Time(s) 2.5838 | Accuracy: 76.588162 %\n",
            "Epoch 00111 | Loss 0.0679 | Time(s) 2.5836 | Accuracy: 76.471955 %\n",
            "Epoch 00112 | Loss 0.1207 | Time(s) 2.5836 | Accuracy: 76.634645 %\n",
            "Epoch 00113 | Loss 0.1537 | Time(s) 2.5837 | Accuracy: 76.743105 %\n",
            "Epoch 00114 | Loss 0.1178 | Time(s) 2.5837 | Accuracy: 76.898048 %\n",
            "Epoch 00115 | Loss 0.1378 | Time(s) 2.5839 | Accuracy: 76.743105 %\n",
            "Epoch 00116 | Loss 0.1073 | Time(s) 2.5840 | Accuracy: 76.781841 %\n",
            "Epoch 00117 | Loss 0.0724 | Time(s) 2.5840 | Accuracy: 76.766346 %\n",
            "Epoch 00118 | Loss 0.0698 | Time(s) 2.5845 | Accuracy: 76.921289 %\n",
            "Epoch 00119 | Loss 0.1098 | Time(s) 2.5850 | Accuracy: 76.998760 %\n",
            "Epoch 00120 | Loss 0.0940 | Time(s) 2.5851 | Accuracy: 77.060738 %\n",
            "Epoch 00121 | Loss 0.1457 | Time(s) 2.5850 | Accuracy: 76.983266 %\n",
            "Epoch 00122 | Loss 0.1356 | Time(s) 2.5848 | Accuracy: 77.052990 %\n",
            "Epoch 00123 | Loss 0.0898 | Time(s) 2.5845 | Accuracy: 76.836071 %\n",
            "Epoch 00124 | Loss 0.1100 | Time(s) 2.5851 | Accuracy: 76.789588 %\n",
            "Epoch 00125 | Loss 0.1010 | Time(s) 2.5852 | Accuracy: 76.828324 %\n",
            "Epoch 00126 | Loss 0.0618 | Time(s) 2.5857 | Accuracy: 76.890301 %\n",
            "Epoch 00127 | Loss 0.1228 | Time(s) 2.5857 | Accuracy: 76.882553 %\n",
            "Epoch 00128 | Loss 0.0978 | Time(s) 2.5860 | Accuracy: 76.603657 %\n",
            "Epoch 00129 | Loss 0.0883 | Time(s) 2.5857 | Accuracy: 76.378990 %\n",
            "Epoch 00130 | Loss 0.0934 | Time(s) 2.5855 | Accuracy: 76.642392 %\n",
            "Epoch 00131 | Loss 0.0963 | Time(s) 2.5859 | Accuracy: 76.688875 %\n",
            "Epoch 00132 | Loss 0.0953 | Time(s) 2.5859 | Accuracy: 76.603657 %\n",
            "Epoch 00133 | Loss 0.0935 | Time(s) 2.5859 | Accuracy: 76.634645 %\n",
            "Epoch 00134 | Loss 0.0910 | Time(s) 2.5859 | Accuracy: 76.626898 %\n",
            "Epoch 00135 | Loss 0.1048 | Time(s) 2.5858 | Accuracy: 76.650139 %\n",
            "Epoch 00136 | Loss 0.0964 | Time(s) 2.5857 | Accuracy: 76.603657 %\n",
            "Epoch 00137 | Loss 0.0852 | Time(s) 2.5857 | Accuracy: 76.603657 %\n",
            "Epoch 00138 | Loss 0.0684 | Time(s) 2.5855 | Accuracy: 76.719864 %\n",
            "Epoch 00139 | Loss 0.0693 | Time(s) 2.5853 | Accuracy: 76.758599 %\n",
            "Epoch 00140 | Loss 0.0739 | Time(s) 2.5854 | Accuracy: 76.634645 %\n",
            "Epoch 00141 | Loss 0.0860 | Time(s) 2.5853 | Accuracy: 76.409978 %\n",
            "Epoch 00142 | Loss 0.0901 | Time(s) 2.5854 | Accuracy: 76.301518 %\n",
            "Epoch 00143 | Loss 0.1106 | Time(s) 2.5857 | Accuracy: 76.425473 %\n",
            "Epoch 00144 | Loss 0.0874 | Time(s) 2.5856 | Accuracy: 76.526185 %\n",
            "Epoch 00145 | Loss 0.0760 | Time(s) 2.5857 | Accuracy: 76.409978 %\n",
            "Epoch 00146 | Loss 0.0803 | Time(s) 2.5856 | Accuracy: 76.719864 %\n",
            "Epoch 00147 | Loss 0.0457 | Time(s) 2.5856 | Accuracy: 76.471955 %\n",
            "Epoch 00148 | Loss 0.0752 | Time(s) 2.5856 | Accuracy: 76.255036 %\n",
            "Epoch 00149 | Loss 0.0907 | Time(s) 2.5854 | Accuracy: 76.417725 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7664 | Time(s) 2.5712 | Accuracy: 24.202045 %\n",
            "Epoch 00001 | Loss 1.7429 | Time(s) 2.5753 | Accuracy: 36.186861 %\n",
            "Epoch 00002 | Loss 1.6704 | Time(s) 2.5761 | Accuracy: 42.988844 %\n",
            "Epoch 00003 | Loss 1.6195 | Time(s) 2.5705 | Accuracy: 45.731329 %\n",
            "Epoch 00004 | Loss 1.5709 | Time(s) 2.5784 | Accuracy: 47.916021 %\n",
            "Epoch 00005 | Loss 1.5168 | Time(s) 2.5846 | Accuracy: 50.914162 %\n",
            "Epoch 00006 | Loss 1.5247 | Time(s) 2.5925 | Accuracy: 56.073753 %\n",
            "Epoch 00007 | Loss 1.4070 | Time(s) 2.5905 | Accuracy: 57.383018 %\n",
            "Epoch 00008 | Loss 1.4176 | Time(s) 2.5872 | Accuracy: 60.288193 %\n",
            "Epoch 00009 | Loss 1.3785 | Time(s) 2.5853 | Accuracy: 64.657577 %\n",
            "Epoch 00010 | Loss 1.2426 | Time(s) 2.5839 | Accuracy: 68.019833 %\n",
            "Epoch 00011 | Loss 1.2501 | Time(s) 2.5825 | Accuracy: 69.460800 %\n",
            "Epoch 00012 | Loss 1.2533 | Time(s) 2.5812 | Accuracy: 68.988224 %\n",
            "Epoch 00013 | Loss 1.1788 | Time(s) 2.5781 | Accuracy: 68.399442 %\n",
            "Epoch 00014 | Loss 1.1643 | Time(s) 2.5801 | Accuracy: 68.949489 %\n",
            "Epoch 00015 | Loss 1.0929 | Time(s) 2.5805 | Accuracy: 69.979857 %\n",
            "Epoch 00016 | Loss 1.0798 | Time(s) 2.5783 | Accuracy: 70.568640 %\n",
            "Epoch 00017 | Loss 1.0593 | Time(s) 2.5768 | Accuracy: 71.064456 %\n",
            "Epoch 00018 | Loss 0.8989 | Time(s) 2.5770 | Accuracy: 71.428571 %\n",
            "Epoch 00019 | Loss 1.0324 | Time(s) 2.5762 | Accuracy: 72.273009 %\n",
            "Epoch 00020 | Loss 0.8445 | Time(s) 2.5760 | Accuracy: 71.978618 %\n",
            "Epoch 00021 | Loss 0.8666 | Time(s) 2.5754 | Accuracy: 71.645491 %\n",
            "Epoch 00022 | Loss 0.7335 | Time(s) 2.5742 | Accuracy: 72.559653 %\n",
            "Epoch 00023 | Loss 0.8173 | Time(s) 2.5737 | Accuracy: 72.730090 %\n",
            "Epoch 00024 | Loss 0.7261 | Time(s) 2.5708 | Accuracy: 73.574527 %\n",
            "Epoch 00025 | Loss 0.7463 | Time(s) 2.5717 | Accuracy: 74.310505 %\n",
            "Epoch 00026 | Loss 0.6973 | Time(s) 2.5711 | Accuracy: 74.062597 %\n",
            "Epoch 00027 | Loss 0.6345 | Time(s) 2.5691 | Accuracy: 73.713976 %\n",
            "Epoch 00028 | Loss 0.6492 | Time(s) 2.5684 | Accuracy: 73.489309 %\n",
            "Epoch 00029 | Loss 0.5476 | Time(s) 2.5665 | Accuracy: 73.512550 %\n",
            "Epoch 00030 | Loss 0.7450 | Time(s) 2.5663 | Accuracy: 73.830183 %\n",
            "Epoch 00031 | Loss 0.8471 | Time(s) 2.5650 | Accuracy: 74.171057 %\n",
            "Epoch 00032 | Loss 0.6557 | Time(s) 2.5624 | Accuracy: 74.612643 %\n",
            "Epoch 00033 | Loss 0.7011 | Time(s) 2.5629 | Accuracy: 74.542919 %\n",
            "Epoch 00034 | Loss 0.7712 | Time(s) 2.5609 | Accuracy: 74.434459 %\n",
            "Epoch 00035 | Loss 0.6399 | Time(s) 2.5608 | Accuracy: 74.271769 %\n",
            "Epoch 00036 | Loss 0.7394 | Time(s) 2.5588 | Accuracy: 74.426712 %\n",
            "Epoch 00037 | Loss 0.5825 | Time(s) 2.5569 | Accuracy: 74.690115 %\n",
            "Epoch 00038 | Loss 0.5539 | Time(s) 2.5552 | Accuracy: 74.798575 %\n",
            "Epoch 00039 | Loss 0.6503 | Time(s) 2.5550 | Accuracy: 74.829563 %\n",
            "Epoch 00040 | Loss 0.4598 | Time(s) 2.5541 | Accuracy: 74.752092 %\n",
            "Epoch 00041 | Loss 0.6696 | Time(s) 2.5533 | Accuracy: 74.907034 %\n",
            "Epoch 00042 | Loss 0.4295 | Time(s) 2.5519 | Accuracy: 74.721103 %\n",
            "Epoch 00043 | Loss 0.5715 | Time(s) 2.5511 | Accuracy: 75.178184 %\n",
            "Epoch 00044 | Loss 0.6149 | Time(s) 2.5494 | Accuracy: 75.263403 %\n",
            "Epoch 00045 | Loss 0.4649 | Time(s) 2.5477 | Accuracy: 75.410598 %\n",
            "Epoch 00046 | Loss 0.3929 | Time(s) 2.5470 | Accuracy: 75.286644 %\n",
            "Epoch 00047 | Loss 0.4782 | Time(s) 2.5460 | Accuracy: 75.797955 %\n",
            "Epoch 00048 | Loss 0.5386 | Time(s) 2.5451 | Accuracy: 75.782460 %\n",
            "Epoch 00049 | Loss 0.3648 | Time(s) 2.5430 | Accuracy: 75.612024 %\n",
            "Epoch 00050 | Loss 0.4189 | Time(s) 2.5417 | Accuracy: 75.697242 %\n",
            "Epoch 00051 | Loss 0.3100 | Time(s) 2.5407 | Accuracy: 76.200806 %\n",
            "Epoch 00052 | Loss 0.3850 | Time(s) 2.5398 | Accuracy: 76.433220 %\n",
            "Epoch 00053 | Loss 0.3236 | Time(s) 2.5387 | Accuracy: 76.580415 %\n",
            "Epoch 00054 | Loss 0.3852 | Time(s) 2.5377 | Accuracy: 76.471955 %\n",
            "Epoch 00055 | Loss 0.3767 | Time(s) 2.5365 | Accuracy: 76.293771 %\n",
            "Epoch 00056 | Loss 0.2987 | Time(s) 2.5349 | Accuracy: 76.138829 %\n",
            "Epoch 00057 | Loss 0.2815 | Time(s) 2.5336 | Accuracy: 76.619151 %\n",
            "Epoch 00058 | Loss 0.3406 | Time(s) 2.5322 | Accuracy: 76.634645 %\n",
            "Epoch 00059 | Loss 0.3633 | Time(s) 2.5322 | Accuracy: 76.386737 %\n",
            "Epoch 00060 | Loss 0.2509 | Time(s) 2.5326 | Accuracy: 76.386737 %\n",
            "Epoch 00061 | Loss 0.3213 | Time(s) 2.5311 | Accuracy: 76.317013 %\n",
            "Epoch 00062 | Loss 0.2357 | Time(s) 2.5295 | Accuracy: 76.409978 %\n",
            "Epoch 00063 | Loss 0.4605 | Time(s) 2.5280 | Accuracy: 76.448714 %\n",
            "Epoch 00064 | Loss 0.2101 | Time(s) 2.5266 | Accuracy: 76.402231 %\n",
            "Epoch 00065 | Loss 0.2851 | Time(s) 2.5248 | Accuracy: 76.603657 %\n",
            "Epoch 00066 | Loss 0.2939 | Time(s) 2.5233 | Accuracy: 76.851565 %\n",
            "Epoch 00067 | Loss 0.2593 | Time(s) 2.5219 | Accuracy: 76.913542 %\n",
            "Epoch 00068 | Loss 0.1859 | Time(s) 2.5207 | Accuracy: 76.859312 %\n",
            "Epoch 00069 | Loss 0.2453 | Time(s) 2.5194 | Accuracy: 76.983266 %\n",
            "Epoch 00070 | Loss 0.2605 | Time(s) 2.5190 | Accuracy: 76.766346 %\n",
            "Epoch 00071 | Loss 0.2033 | Time(s) 2.5178 | Accuracy: 76.580415 %\n",
            "Epoch 00072 | Loss 0.2395 | Time(s) 2.5163 | Accuracy: 76.588162 %\n",
            "Epoch 00073 | Loss 0.2392 | Time(s) 2.5149 | Accuracy: 76.541680 %\n",
            "Epoch 00074 | Loss 0.3546 | Time(s) 2.5136 | Accuracy: 76.549427 %\n",
            "Epoch 00075 | Loss 0.2837 | Time(s) 2.5132 | Accuracy: 76.712117 %\n",
            "Epoch 00076 | Loss 0.1944 | Time(s) 2.5124 | Accuracy: 76.278277 %\n",
            "Epoch 00077 | Loss 0.1581 | Time(s) 2.5116 | Accuracy: 76.262783 %\n",
            "Epoch 00078 | Loss 0.1526 | Time(s) 2.5115 | Accuracy: 76.611404 %\n",
            "Epoch 00079 | Loss 0.2205 | Time(s) 2.5106 | Accuracy: 76.913542 %\n",
            "Epoch 00080 | Loss 0.1242 | Time(s) 2.5092 | Accuracy: 77.076232 %\n",
            "Epoch 00081 | Loss 0.1225 | Time(s) 2.5080 | Accuracy: 76.828324 %\n",
            "Epoch 00082 | Loss 0.3042 | Time(s) 2.5071 | Accuracy: 76.719864 %\n",
            "Epoch 00083 | Loss 0.1835 | Time(s) 2.5069 | Accuracy: 76.944531 %\n",
            "Epoch 00084 | Loss 0.2868 | Time(s) 2.5068 | Accuracy: 76.836071 %\n",
            "Epoch 00085 | Loss 0.2053 | Time(s) 2.5057 | Accuracy: 76.712117 %\n",
            "Epoch 00086 | Loss 0.2172 | Time(s) 2.5051 | Accuracy: 76.642392 %\n",
            "Epoch 00087 | Loss 0.1420 | Time(s) 2.5044 | Accuracy: 76.828324 %\n",
            "Epoch 00088 | Loss 0.1116 | Time(s) 2.5047 | Accuracy: 76.936783 %\n",
            "Epoch 00089 | Loss 0.1768 | Time(s) 2.5038 | Accuracy: 76.890301 %\n",
            "Epoch 00090 | Loss 0.1701 | Time(s) 2.5031 | Accuracy: 76.634645 %\n",
            "Epoch 00091 | Loss 0.1687 | Time(s) 2.5025 | Accuracy: 76.944531 %\n",
            "Epoch 00092 | Loss 0.1640 | Time(s) 2.5020 | Accuracy: 77.076232 %\n",
            "Epoch 00093 | Loss 0.1419 | Time(s) 2.5012 | Accuracy: 76.998760 %\n",
            "Epoch 00094 | Loss 0.1661 | Time(s) 2.4999 | Accuracy: 76.836071 %\n",
            "Epoch 00095 | Loss 0.1231 | Time(s) 2.4996 | Accuracy: 76.905795 %\n",
            "Epoch 00096 | Loss 0.1217 | Time(s) 2.4988 | Accuracy: 76.874806 %\n",
            "Epoch 00097 | Loss 0.2219 | Time(s) 2.4983 | Accuracy: 76.719864 %\n",
            "Epoch 00098 | Loss 0.1662 | Time(s) 2.4973 | Accuracy: 76.704369 %\n",
            "Epoch 00099 | Loss 0.1595 | Time(s) 2.4965 | Accuracy: 76.867059 %\n",
            "Epoch 00100 | Loss 0.0778 | Time(s) 2.4962 | Accuracy: 76.921289 %\n",
            "Epoch 00101 | Loss 0.1508 | Time(s) 2.4958 | Accuracy: 76.781841 %\n",
            "Epoch 00102 | Loss 0.1778 | Time(s) 2.4954 | Accuracy: 76.944531 %\n",
            "Epoch 00103 | Loss 0.1817 | Time(s) 2.4947 | Accuracy: 76.766346 %\n",
            "Epoch 00104 | Loss 0.1165 | Time(s) 2.4936 | Accuracy: 76.805082 %\n",
            "Epoch 00105 | Loss 0.1699 | Time(s) 2.4927 | Accuracy: 76.991013 %\n",
            "Epoch 00106 | Loss 0.1378 | Time(s) 2.4917 | Accuracy: 77.045243 %\n",
            "Epoch 00107 | Loss 0.1345 | Time(s) 2.4911 | Accuracy: 77.122715 %\n",
            "Epoch 00108 | Loss 0.1314 | Time(s) 2.4903 | Accuracy: 76.929036 %\n",
            "Epoch 00109 | Loss 0.1642 | Time(s) 2.4897 | Accuracy: 76.735358 %\n",
            "Epoch 00110 | Loss 0.0659 | Time(s) 2.4886 | Accuracy: 76.448714 %\n",
            "Epoch 00111 | Loss 0.1180 | Time(s) 2.4878 | Accuracy: 76.239541 %\n",
            "Epoch 00112 | Loss 0.0946 | Time(s) 2.4873 | Accuracy: 76.394484 %\n",
            "Epoch 00113 | Loss 0.1048 | Time(s) 2.4868 | Accuracy: 76.696622 %\n",
            "Epoch 00114 | Loss 0.0585 | Time(s) 2.4861 | Accuracy: 76.882553 %\n",
            "Epoch 00115 | Loss 0.1682 | Time(s) 2.4850 | Accuracy: 77.161450 %\n",
            "Epoch 00116 | Loss 0.0585 | Time(s) 2.4843 | Accuracy: 77.099473 %\n",
            "Epoch 00117 | Loss 0.1102 | Time(s) 2.4838 | Accuracy: 76.828324 %\n",
            "Epoch 00118 | Loss 0.1647 | Time(s) 2.4832 | Accuracy: 76.975519 %\n",
            "Epoch 00119 | Loss 0.1409 | Time(s) 2.4824 | Accuracy: 77.014255 %\n",
            "Epoch 00120 | Loss 0.0575 | Time(s) 2.4823 | Accuracy: 77.029749 %\n",
            "Epoch 00121 | Loss 0.0979 | Time(s) 2.4819 | Accuracy: 77.029749 %\n",
            "Epoch 00122 | Loss 0.0918 | Time(s) 2.4814 | Accuracy: 76.851565 %\n",
            "Epoch 00123 | Loss 0.0554 | Time(s) 2.4809 | Accuracy: 76.998760 %\n",
            "Epoch 00124 | Loss 0.1146 | Time(s) 2.4802 | Accuracy: 76.929036 %\n",
            "Epoch 00125 | Loss 0.1227 | Time(s) 2.4802 | Accuracy: 76.836071 %\n",
            "Epoch 00126 | Loss 0.1185 | Time(s) 2.4795 | Accuracy: 76.967772 %\n",
            "Epoch 00127 | Loss 0.0819 | Time(s) 2.4794 | Accuracy: 77.107220 %\n",
            "Epoch 00128 | Loss 0.0893 | Time(s) 2.4791 | Accuracy: 77.037496 %\n",
            "Epoch 00129 | Loss 0.1096 | Time(s) 2.4787 | Accuracy: 76.890301 %\n",
            "Epoch 00130 | Loss 0.0560 | Time(s) 2.4782 | Accuracy: 76.727611 %\n",
            "Epoch 00131 | Loss 0.0807 | Time(s) 2.4780 | Accuracy: 76.619151 %\n",
            "Epoch 00132 | Loss 0.0836 | Time(s) 2.4774 | Accuracy: 76.479703 %\n",
            "Epoch 00133 | Loss 0.0973 | Time(s) 2.4768 | Accuracy: 76.456461 %\n",
            "Epoch 00134 | Loss 0.0708 | Time(s) 2.4761 | Accuracy: 76.781841 %\n",
            "Epoch 00135 | Loss 0.0754 | Time(s) 2.4756 | Accuracy: 76.874806 %\n",
            "Epoch 00136 | Loss 0.0853 | Time(s) 2.4752 | Accuracy: 76.836071 %\n",
            "Epoch 00137 | Loss 0.0976 | Time(s) 2.4752 | Accuracy: 76.580415 %\n",
            "Epoch 00138 | Loss 0.0761 | Time(s) 2.4752 | Accuracy: 76.495197 %\n",
            "Epoch 00139 | Loss 0.0810 | Time(s) 2.4743 | Accuracy: 76.750852 %\n",
            "Epoch 00140 | Loss 0.0870 | Time(s) 2.4736 | Accuracy: 76.898048 %\n",
            "Epoch 00141 | Loss 0.0830 | Time(s) 2.4730 | Accuracy: 76.960025 %\n",
            "Epoch 00142 | Loss 0.0816 | Time(s) 2.4726 | Accuracy: 76.991013 %\n",
            "Epoch 00143 | Loss 0.0775 | Time(s) 2.4724 | Accuracy: 76.874806 %\n",
            "Epoch 00144 | Loss 0.0766 | Time(s) 2.4723 | Accuracy: 76.642392 %\n",
            "Epoch 00145 | Loss 0.0675 | Time(s) 2.4717 | Accuracy: 76.750852 %\n",
            "Epoch 00146 | Loss 0.0697 | Time(s) 2.4716 | Accuracy: 76.789588 %\n",
            "Epoch 00147 | Loss 0.0645 | Time(s) 2.4713 | Accuracy: 76.882553 %\n",
            "Epoch 00148 | Loss 0.0708 | Time(s) 2.4705 | Accuracy: 76.874806 %\n",
            "Epoch 00149 | Loss 0.0527 | Time(s) 2.4700 | Accuracy: 76.812829 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7853 | Time(s) 2.3883 | Accuracy: 17.407809 %\n",
            "Epoch 00001 | Loss 1.7676 | Time(s) 2.4073 | Accuracy: 17.717694 %\n",
            "Epoch 00002 | Loss 1.7615 | Time(s) 2.3920 | Accuracy: 18.949489 %\n",
            "Epoch 00003 | Loss 1.6999 | Time(s) 2.4012 | Accuracy: 25.797955 %\n",
            "Epoch 00004 | Loss 1.7052 | Time(s) 2.3949 | Accuracy: 30.213821 %\n",
            "Epoch 00005 | Loss 1.6851 | Time(s) 2.3943 | Accuracy: 31.933685 %\n",
            "Epoch 00006 | Loss 1.5676 | Time(s) 2.3929 | Accuracy: 32.437248 %\n",
            "Epoch 00007 | Loss 1.6155 | Time(s) 2.3908 | Accuracy: 32.731639 %\n",
            "Epoch 00008 | Loss 1.6032 | Time(s) 2.3914 | Accuracy: 32.878835 %\n",
            "Epoch 00009 | Loss 1.4974 | Time(s) 2.3933 | Accuracy: 32.933065 %\n",
            "Epoch 00010 | Loss 1.5579 | Time(s) 2.3989 | Accuracy: 32.824605 %\n",
            "Epoch 00011 | Loss 1.5225 | Time(s) 2.3960 | Accuracy: 32.778122 %\n",
            "Epoch 00012 | Loss 1.4255 | Time(s) 2.3977 | Accuracy: 32.778122 %\n",
            "Epoch 00013 | Loss 1.5181 | Time(s) 2.3950 | Accuracy: 32.832352 %\n",
            "Epoch 00014 | Loss 1.4859 | Time(s) 2.3940 | Accuracy: 32.793616 %\n",
            "Epoch 00015 | Loss 1.4803 | Time(s) 2.3951 | Accuracy: 32.878835 %\n",
            "Epoch 00016 | Loss 1.4484 | Time(s) 2.3942 | Accuracy: 33.142237 %\n",
            "Epoch 00017 | Loss 1.3673 | Time(s) 2.3947 | Accuracy: 33.258444 %\n",
            "Epoch 00018 | Loss 1.4228 | Time(s) 2.3947 | Accuracy: 33.382399 %\n",
            "Epoch 00019 | Loss 1.4389 | Time(s) 2.3948 | Accuracy: 33.413387 %\n",
            "Epoch 00020 | Loss 1.5042 | Time(s) 2.3944 | Accuracy: 33.328169 %\n",
            "Epoch 00021 | Loss 1.4924 | Time(s) 2.3949 | Accuracy: 33.312674 %\n",
            "Epoch 00022 | Loss 1.4293 | Time(s) 2.3935 | Accuracy: 33.165479 %\n",
            "Epoch 00023 | Loss 1.2921 | Time(s) 2.3930 | Accuracy: 33.219709 %\n",
            "Epoch 00024 | Loss 1.3737 | Time(s) 2.3941 | Accuracy: 33.374651 %\n",
            "Epoch 00025 | Loss 1.3614 | Time(s) 2.3928 | Accuracy: 33.273939 %\n",
            "Epoch 00026 | Loss 1.3732 | Time(s) 2.3941 | Accuracy: 33.382399 %\n",
            "Epoch 00027 | Loss 1.3615 | Time(s) 2.3945 | Accuracy: 33.560583 %\n",
            "Epoch 00028 | Loss 1.3494 | Time(s) 2.3935 | Accuracy: 33.459870 %\n",
            "Epoch 00029 | Loss 1.2960 | Time(s) 2.3922 | Accuracy: 33.444376 %\n",
            "Epoch 00030 | Loss 1.3276 | Time(s) 2.3922 | Accuracy: 33.405640 %\n",
            "Epoch 00031 | Loss 1.2674 | Time(s) 2.3916 | Accuracy: 33.459870 %\n",
            "Epoch 00032 | Loss 1.2649 | Time(s) 2.3915 | Accuracy: 33.374651 %\n",
            "Epoch 00033 | Loss 1.2562 | Time(s) 2.3922 | Accuracy: 33.529594 %\n",
            "Epoch 00034 | Loss 1.3566 | Time(s) 2.3918 | Accuracy: 33.405640 %\n",
            "Epoch 00035 | Loss 1.2981 | Time(s) 2.3912 | Accuracy: 33.684537 %\n",
            "Epoch 00036 | Loss 1.2154 | Time(s) 2.3896 | Accuracy: 33.537341 %\n",
            "Epoch 00037 | Loss 1.2865 | Time(s) 2.3903 | Accuracy: 33.692284 %\n",
            "Epoch 00038 | Loss 1.2751 | Time(s) 2.3902 | Accuracy: 33.870468 %\n",
            "Epoch 00039 | Loss 1.2659 | Time(s) 2.3909 | Accuracy: 33.947939 %\n",
            "Epoch 00040 | Loss 1.2656 | Time(s) 2.3897 | Accuracy: 33.769755 %\n",
            "Epoch 00041 | Loss 1.2576 | Time(s) 2.3904 | Accuracy: 33.924698 %\n",
            "Epoch 00042 | Loss 1.2105 | Time(s) 2.3903 | Accuracy: 34.110629 %\n",
            "Epoch 00043 | Loss 1.1820 | Time(s) 2.3902 | Accuracy: 34.009916 %\n",
            "Epoch 00044 | Loss 1.3123 | Time(s) 2.3894 | Accuracy: 34.033158 %\n",
            "Epoch 00045 | Loss 1.3028 | Time(s) 2.3899 | Accuracy: 33.986675 %\n",
            "Epoch 00046 | Loss 1.2572 | Time(s) 2.3899 | Accuracy: 33.916951 %\n",
            "Epoch 00047 | Loss 1.3352 | Time(s) 2.3901 | Accuracy: 33.940192 %\n",
            "Epoch 00048 | Loss 1.2390 | Time(s) 2.3900 | Accuracy: 33.924698 %\n",
            "Epoch 00049 | Loss 1.1901 | Time(s) 2.3897 | Accuracy: 33.994422 %\n",
            "Epoch 00050 | Loss 1.1830 | Time(s) 2.3899 | Accuracy: 33.870468 %\n",
            "Epoch 00051 | Loss 1.1854 | Time(s) 2.3895 | Accuracy: 33.661295 %\n",
            "Epoch 00052 | Loss 1.1511 | Time(s) 2.3884 | Accuracy: 33.707778 %\n",
            "Epoch 00053 | Loss 1.1070 | Time(s) 2.3887 | Accuracy: 33.583824 %\n",
            "Epoch 00054 | Loss 1.2428 | Time(s) 2.3888 | Accuracy: 33.599318 %\n",
            "Epoch 00055 | Loss 1.2893 | Time(s) 2.3885 | Accuracy: 33.885962 %\n",
            "Epoch 00056 | Loss 1.3199 | Time(s) 2.3880 | Accuracy: 33.723272 %\n",
            "Epoch 00057 | Loss 1.1218 | Time(s) 2.3876 | Accuracy: 33.723272 %\n",
            "Epoch 00058 | Loss 1.1159 | Time(s) 2.3882 | Accuracy: 33.792997 %\n",
            "Epoch 00059 | Loss 1.2273 | Time(s) 2.3879 | Accuracy: 33.816238 %\n",
            "Epoch 00060 | Loss 1.0755 | Time(s) 2.3879 | Accuracy: 33.738767 %\n",
            "Epoch 00061 | Loss 1.2131 | Time(s) 2.3874 | Accuracy: 33.792997 %\n",
            "Epoch 00062 | Loss 1.2614 | Time(s) 2.3879 | Accuracy: 33.583824 %\n",
            "Epoch 00063 | Loss 1.1720 | Time(s) 2.3886 | Accuracy: 33.847227 %\n",
            "Epoch 00064 | Loss 1.0790 | Time(s) 2.3884 | Accuracy: 33.808491 %\n",
            "Epoch 00065 | Loss 1.0703 | Time(s) 2.3884 | Accuracy: 33.738767 %\n",
            "Epoch 00066 | Loss 1.2242 | Time(s) 2.3888 | Accuracy: 33.475364 %\n",
            "Epoch 00067 | Loss 1.1569 | Time(s) 2.3889 | Accuracy: 33.545088 %\n",
            "Epoch 00068 | Loss 1.2239 | Time(s) 2.3891 | Accuracy: 33.630307 %\n",
            "Epoch 00069 | Loss 1.1980 | Time(s) 2.3888 | Accuracy: 33.498606 %\n",
            "Epoch 00070 | Loss 1.2201 | Time(s) 2.3885 | Accuracy: 33.537341 %\n",
            "Epoch 00071 | Loss 1.1442 | Time(s) 2.3882 | Accuracy: 33.390146 %\n",
            "Epoch 00072 | Loss 1.1160 | Time(s) 2.3885 | Accuracy: 33.142237 %\n",
            "Epoch 00073 | Loss 1.1395 | Time(s) 2.3880 | Accuracy: 33.475364 %\n",
            "Epoch 00074 | Loss 1.1174 | Time(s) 2.3876 | Accuracy: 33.374651 %\n",
            "Epoch 00075 | Loss 1.1013 | Time(s) 2.3884 | Accuracy: 33.444376 %\n",
            "Epoch 00076 | Loss 1.0917 | Time(s) 2.3892 | Accuracy: 33.622560 %\n",
            "Epoch 00077 | Loss 1.1333 | Time(s) 2.3890 | Accuracy: 33.576077 %\n",
            "Epoch 00078 | Loss 1.2576 | Time(s) 2.3891 | Accuracy: 33.870468 %\n",
            "Epoch 00079 | Loss 1.1834 | Time(s) 2.3885 | Accuracy: 33.785249 %\n",
            "Epoch 00080 | Loss 1.1322 | Time(s) 2.3887 | Accuracy: 33.769755 %\n",
            "Epoch 00081 | Loss 1.2040 | Time(s) 2.3888 | Accuracy: 33.684537 %\n",
            "Epoch 00082 | Loss 1.2105 | Time(s) 2.3886 | Accuracy: 33.607065 %\n",
            "Epoch 00083 | Loss 1.3206 | Time(s) 2.3886 | Accuracy: 33.382399 %\n",
            "Epoch 00084 | Loss 1.1911 | Time(s) 2.3883 | Accuracy: 33.506353 %\n",
            "Epoch 00085 | Loss 1.1568 | Time(s) 2.3882 | Accuracy: 33.676790 %\n",
            "Epoch 00086 | Loss 1.0444 | Time(s) 2.3881 | Accuracy: 33.800744 %\n",
            "Epoch 00087 | Loss 1.2498 | Time(s) 2.3876 | Accuracy: 33.715525 %\n",
            "Epoch 00088 | Loss 1.1904 | Time(s) 2.3883 | Accuracy: 33.746514 %\n",
            "Epoch 00089 | Loss 1.1893 | Time(s) 2.3879 | Accuracy: 33.947939 %\n",
            "Epoch 00090 | Loss 1.1695 | Time(s) 2.3877 | Accuracy: 33.854974 %\n",
            "Epoch 00091 | Loss 1.2990 | Time(s) 2.3874 | Accuracy: 33.583824 %\n",
            "Epoch 00092 | Loss 1.0940 | Time(s) 2.3873 | Accuracy: 33.552835 %\n",
            "Epoch 00093 | Loss 1.2981 | Time(s) 2.3867 | Accuracy: 33.878215 %\n",
            "Epoch 00094 | Loss 1.2923 | Time(s) 2.3867 | Accuracy: 34.133870 %\n",
            "Epoch 00095 | Loss 1.1378 | Time(s) 2.3862 | Accuracy: 33.738767 %\n",
            "Epoch 00096 | Loss 1.2885 | Time(s) 2.3863 | Accuracy: 33.661295 %\n",
            "Epoch 00097 | Loss 1.0963 | Time(s) 2.3861 | Accuracy: 33.669042 %\n",
            "Epoch 00098 | Loss 1.2193 | Time(s) 2.3860 | Accuracy: 33.707778 %\n",
            "Epoch 00099 | Loss 1.1758 | Time(s) 2.3856 | Accuracy: 33.762008 %\n",
            "Epoch 00100 | Loss 1.1609 | Time(s) 2.3860 | Accuracy: 33.762008 %\n",
            "Epoch 00101 | Loss 1.0438 | Time(s) 2.3855 | Accuracy: 33.614813 %\n",
            "Epoch 00102 | Loss 1.2106 | Time(s) 2.3855 | Accuracy: 33.552835 %\n",
            "Epoch 00103 | Loss 1.1119 | Time(s) 2.3857 | Accuracy: 33.560583 %\n",
            "Epoch 00104 | Loss 1.2057 | Time(s) 2.3855 | Accuracy: 33.397893 %\n",
            "Epoch 00105 | Loss 1.1916 | Time(s) 2.3854 | Accuracy: 33.343663 %\n",
            "Epoch 00106 | Loss 1.2344 | Time(s) 2.3855 | Accuracy: 33.653548 %\n",
            "Epoch 00107 | Loss 1.2279 | Time(s) 2.3853 | Accuracy: 33.769755 %\n",
            "Epoch 00108 | Loss 1.1379 | Time(s) 2.3859 | Accuracy: 33.599318 %\n",
            "Epoch 00109 | Loss 1.2021 | Time(s) 2.3858 | Accuracy: 33.676790 %\n",
            "Epoch 00110 | Loss 1.2325 | Time(s) 2.3855 | Accuracy: 33.630307 %\n",
            "Epoch 00111 | Loss 1.2005 | Time(s) 2.3856 | Accuracy: 33.576077 %\n",
            "Epoch 00112 | Loss 1.1644 | Time(s) 2.3856 | Accuracy: 33.591571 %\n",
            "Epoch 00113 | Loss 1.1105 | Time(s) 2.3856 | Accuracy: 33.762008 %\n",
            "Epoch 00114 | Loss 1.0632 | Time(s) 2.3859 | Accuracy: 33.622560 %\n",
            "Epoch 00115 | Loss 1.1611 | Time(s) 2.3854 | Accuracy: 33.614813 %\n",
            "Epoch 00116 | Loss 1.1596 | Time(s) 2.3855 | Accuracy: 33.382399 %\n",
            "Epoch 00117 | Loss 1.1095 | Time(s) 2.3854 | Accuracy: 33.599318 %\n",
            "Epoch 00118 | Loss 1.0574 | Time(s) 2.3854 | Accuracy: 33.731020 %\n",
            "Epoch 00119 | Loss 1.1699 | Time(s) 2.3852 | Accuracy: 33.754261 %\n",
            "Epoch 00120 | Loss 1.1918 | Time(s) 2.3852 | Accuracy: 33.731020 %\n",
            "Epoch 00121 | Loss 1.1092 | Time(s) 2.3853 | Accuracy: 33.700031 %\n",
            "Epoch 00122 | Loss 1.0265 | Time(s) 2.3854 | Accuracy: 33.715525 %\n",
            "Epoch 00123 | Loss 1.1844 | Time(s) 2.3857 | Accuracy: 33.800744 %\n",
            "Epoch 00124 | Loss 1.2860 | Time(s) 2.3856 | Accuracy: 33.862721 %\n",
            "Epoch 00125 | Loss 1.2816 | Time(s) 2.3862 | Accuracy: 33.986675 %\n",
            "Epoch 00126 | Loss 1.1578 | Time(s) 2.3861 | Accuracy: 33.901456 %\n",
            "Epoch 00127 | Loss 1.1851 | Time(s) 2.3863 | Accuracy: 33.800744 %\n",
            "Epoch 00128 | Loss 1.2730 | Time(s) 2.3863 | Accuracy: 33.560583 %\n",
            "Epoch 00129 | Loss 1.1807 | Time(s) 2.3861 | Accuracy: 33.475364 %\n",
            "Epoch 00130 | Loss 1.0531 | Time(s) 2.3861 | Accuracy: 33.521847 %\n",
            "Epoch 00131 | Loss 1.1499 | Time(s) 2.3861 | Accuracy: 33.529594 %\n",
            "Epoch 00132 | Loss 1.0789 | Time(s) 2.3860 | Accuracy: 33.475364 %\n",
            "Epoch 00133 | Loss 1.1491 | Time(s) 2.3863 | Accuracy: 33.762008 %\n",
            "Epoch 00134 | Loss 1.2088 | Time(s) 2.3865 | Accuracy: 33.800744 %\n",
            "Epoch 00135 | Loss 1.0635 | Time(s) 2.3862 | Accuracy: 33.862721 %\n",
            "Epoch 00136 | Loss 1.2684 | Time(s) 2.3859 | Accuracy: 33.978928 %\n",
            "Epoch 00137 | Loss 1.2081 | Time(s) 2.3856 | Accuracy: 33.777502 %\n",
            "Epoch 00138 | Loss 1.1814 | Time(s) 2.3856 | Accuracy: 33.622560 %\n",
            "Epoch 00139 | Loss 1.2040 | Time(s) 2.3856 | Accuracy: 33.854974 %\n",
            "Epoch 00140 | Loss 1.1584 | Time(s) 2.3861 | Accuracy: 33.723272 %\n",
            "Epoch 00141 | Loss 1.1594 | Time(s) 2.3859 | Accuracy: 33.777502 %\n",
            "Epoch 00142 | Loss 1.2037 | Time(s) 2.3859 | Accuracy: 33.630307 %\n",
            "Epoch 00143 | Loss 1.1500 | Time(s) 2.3860 | Accuracy: 33.583824 %\n",
            "Epoch 00144 | Loss 1.1488 | Time(s) 2.3858 | Accuracy: 33.785249 %\n",
            "Epoch 00145 | Loss 1.1777 | Time(s) 2.3860 | Accuracy: 33.839479 %\n",
            "Epoch 00146 | Loss 1.1519 | Time(s) 2.3859 | Accuracy: 33.862721 %\n",
            "Epoch 00147 | Loss 1.1501 | Time(s) 2.3863 | Accuracy: 33.777502 %\n",
            "Epoch 00148 | Loss 1.1747 | Time(s) 2.3862 | Accuracy: 33.692284 %\n",
            "Epoch 00149 | Loss 1.0430 | Time(s) 2.3862 | Accuracy: 33.661295 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7392 | Time(s) 2.4971 | Accuracy: 25.147196 %\n",
            "Epoch 00001 | Loss 1.6090 | Time(s) 2.4460 | Accuracy: 31.259684 %\n",
            "Epoch 00002 | Loss 1.6153 | Time(s) 2.4265 | Accuracy: 37.062287 %\n",
            "Epoch 00003 | Loss 1.5546 | Time(s) 2.4178 | Accuracy: 44.801673 %\n",
            "Epoch 00004 | Loss 1.5052 | Time(s) 2.4095 | Accuracy: 49.387976 %\n",
            "Epoch 00005 | Loss 1.5224 | Time(s) 2.4127 | Accuracy: 53.842578 %\n",
            "Epoch 00006 | Loss 1.4594 | Time(s) 2.4127 | Accuracy: 60.737527 %\n",
            "Epoch 00007 | Loss 1.4332 | Time(s) 2.4159 | Accuracy: 63.921599 %\n",
            "Epoch 00008 | Loss 1.2382 | Time(s) 2.4114 | Accuracy: 65.749923 %\n",
            "Epoch 00009 | Loss 1.2193 | Time(s) 2.4074 | Accuracy: 67.400062 %\n",
            "Epoch 00010 | Loss 1.1573 | Time(s) 2.4105 | Accuracy: 69.081190 %\n",
            "Epoch 00011 | Loss 1.1962 | Time(s) 2.4118 | Accuracy: 69.747443 %\n",
            "Epoch 00012 | Loss 1.1737 | Time(s) 2.4095 | Accuracy: 69.902386 %\n",
            "Epoch 00013 | Loss 0.9971 | Time(s) 2.4061 | Accuracy: 70.119306 %\n",
            "Epoch 00014 | Loss 1.0471 | Time(s) 2.4055 | Accuracy: 70.584134 %\n",
            "Epoch 00015 | Loss 0.9971 | Time(s) 2.4067 | Accuracy: 71.839170 %\n",
            "Epoch 00016 | Loss 0.9615 | Time(s) 2.4038 | Accuracy: 72.466687 %\n",
            "Epoch 00017 | Loss 0.8077 | Time(s) 2.4028 | Accuracy: 73.644252 %\n",
            "Epoch 00018 | Loss 0.9663 | Time(s) 2.4056 | Accuracy: 74.349241 %\n",
            "Epoch 00019 | Loss 0.8194 | Time(s) 2.4067 | Accuracy: 73.590022 %\n",
            "Epoch 00020 | Loss 0.7088 | Time(s) 2.4066 | Accuracy: 73.125194 %\n",
            "Epoch 00021 | Loss 0.7578 | Time(s) 2.4064 | Accuracy: 74.116827 %\n",
            "Epoch 00022 | Loss 0.6541 | Time(s) 2.4049 | Accuracy: 74.519678 %\n",
            "Epoch 00023 | Loss 0.7276 | Time(s) 2.4033 | Accuracy: 73.845677 %\n",
            "Epoch 00024 | Loss 0.9902 | Time(s) 2.4016 | Accuracy: 73.752711 %\n",
            "Epoch 00025 | Loss 0.7832 | Time(s) 2.4022 | Accuracy: 73.938643 %\n",
            "Epoch 00026 | Loss 0.6396 | Time(s) 2.4001 | Accuracy: 74.612643 %\n",
            "Epoch 00027 | Loss 0.7269 | Time(s) 2.3986 | Accuracy: 75.131701 %\n",
            "Epoch 00028 | Loss 0.6834 | Time(s) 2.3973 | Accuracy: 74.752092 %\n",
            "Epoch 00029 | Loss 0.6262 | Time(s) 2.3970 | Accuracy: 74.186551 %\n",
            "Epoch 00030 | Loss 0.5377 | Time(s) 2.3962 | Accuracy: 74.651379 %\n",
            "Epoch 00031 | Loss 0.5298 | Time(s) 2.3956 | Accuracy: 75.495817 %\n",
            "Epoch 00032 | Loss 0.5010 | Time(s) 2.3950 | Accuracy: 75.309885 %\n",
            "Epoch 00033 | Loss 0.5892 | Time(s) 2.3953 | Accuracy: 75.209173 %\n",
            "Epoch 00034 | Loss 0.4466 | Time(s) 2.3959 | Accuracy: 74.938023 %\n",
            "Epoch 00035 | Loss 0.7663 | Time(s) 2.3951 | Accuracy: 75.271150 %\n",
            "Epoch 00036 | Loss 0.4613 | Time(s) 2.3961 | Accuracy: 75.883173 %\n",
            "Epoch 00037 | Loss 0.6652 | Time(s) 2.3960 | Accuracy: 75.635265 %\n",
            "Epoch 00038 | Loss 0.4339 | Time(s) 2.3973 | Accuracy: 74.666873 %\n",
            "Epoch 00039 | Loss 0.4399 | Time(s) 2.3980 | Accuracy: 75.015494 %\n",
            "Epoch 00040 | Loss 0.6582 | Time(s) 2.3975 | Accuracy: 75.805702 %\n",
            "Epoch 00041 | Loss 0.4900 | Time(s) 2.3964 | Accuracy: 76.076852 %\n",
            "Epoch 00042 | Loss 0.4054 | Time(s) 2.3965 | Accuracy: 75.890920 %\n",
            "Epoch 00043 | Loss 0.3959 | Time(s) 2.3987 | Accuracy: 75.650759 %\n",
            "Epoch 00044 | Loss 0.6294 | Time(s) 2.3989 | Accuracy: 75.813449 %\n",
            "Epoch 00045 | Loss 0.4387 | Time(s) 2.3996 | Accuracy: 75.805702 %\n",
            "Epoch 00046 | Loss 0.3350 | Time(s) 2.3996 | Accuracy: 75.085218 %\n",
            "Epoch 00047 | Loss 0.3106 | Time(s) 2.3993 | Accuracy: 75.263403 %\n",
            "Epoch 00048 | Loss 0.3894 | Time(s) 2.3985 | Accuracy: 75.999380 %\n",
            "Epoch 00049 | Loss 0.2871 | Time(s) 2.3993 | Accuracy: 75.952897 %\n",
            "Epoch 00050 | Loss 0.4688 | Time(s) 2.4016 | Accuracy: 75.999380 %\n",
            "Epoch 00051 | Loss 0.3983 | Time(s) 2.4019 | Accuracy: 75.898667 %\n",
            "Epoch 00052 | Loss 0.2994 | Time(s) 2.4020 | Accuracy: 75.828943 %\n",
            "Epoch 00053 | Loss 0.3795 | Time(s) 2.4024 | Accuracy: 75.921909 %\n",
            "Epoch 00054 | Loss 0.3731 | Time(s) 2.4028 | Accuracy: 76.045863 %\n",
            "Epoch 00055 | Loss 0.4219 | Time(s) 2.4019 | Accuracy: 76.216300 %\n",
            "Epoch 00056 | Loss 0.3531 | Time(s) 2.4021 | Accuracy: 76.231794 %\n",
            "Epoch 00057 | Loss 0.4508 | Time(s) 2.4018 | Accuracy: 76.417725 %\n",
            "Epoch 00058 | Loss 0.3777 | Time(s) 2.4025 | Accuracy: 76.239541 %\n",
            "Epoch 00059 | Loss 0.3102 | Time(s) 2.4026 | Accuracy: 76.146576 %\n",
            "Epoch 00060 | Loss 0.2718 | Time(s) 2.4027 | Accuracy: 76.471955 %\n",
            "Epoch 00061 | Loss 0.3619 | Time(s) 2.4028 | Accuracy: 76.774094 %\n",
            "Epoch 00062 | Loss 0.3485 | Time(s) 2.4034 | Accuracy: 76.634645 %\n",
            "Epoch 00063 | Loss 0.2009 | Time(s) 2.4033 | Accuracy: 76.317013 %\n",
            "Epoch 00064 | Loss 0.2753 | Time(s) 2.4029 | Accuracy: 76.231794 %\n",
            "Epoch 00065 | Loss 0.2238 | Time(s) 2.4026 | Accuracy: 76.526185 %\n",
            "Epoch 00066 | Loss 0.2142 | Time(s) 2.4029 | Accuracy: 76.549427 %\n",
            "Epoch 00067 | Loss 0.3743 | Time(s) 2.4030 | Accuracy: 76.301518 %\n",
            "Epoch 00068 | Loss 0.2473 | Time(s) 2.4038 | Accuracy: 76.533932 %\n",
            "Epoch 00069 | Loss 0.2389 | Time(s) 2.4040 | Accuracy: 76.820576 %\n",
            "Epoch 00070 | Loss 0.2523 | Time(s) 2.4038 | Accuracy: 76.836071 %\n",
            "Epoch 00071 | Loss 0.3763 | Time(s) 2.4042 | Accuracy: 76.898048 %\n",
            "Epoch 00072 | Loss 0.3134 | Time(s) 2.4044 | Accuracy: 76.673381 %\n",
            "Epoch 00073 | Loss 0.2163 | Time(s) 2.4046 | Accuracy: 76.262783 %\n",
            "Epoch 00074 | Loss 0.1950 | Time(s) 2.4041 | Accuracy: 77.114967 %\n",
            "Epoch 00075 | Loss 0.2114 | Time(s) 2.4047 | Accuracy: 77.014255 %\n",
            "Epoch 00076 | Loss 0.1881 | Time(s) 2.4048 | Accuracy: 76.735358 %\n",
            "Epoch 00077 | Loss 0.2021 | Time(s) 2.4051 | Accuracy: 76.417725 %\n",
            "Epoch 00078 | Loss 0.1888 | Time(s) 2.4050 | Accuracy: 76.665634 %\n",
            "Epoch 00079 | Loss 0.1446 | Time(s) 2.4053 | Accuracy: 76.712117 %\n",
            "Epoch 00080 | Loss 0.1432 | Time(s) 2.4056 | Accuracy: 76.533932 %\n",
            "Epoch 00081 | Loss 0.1821 | Time(s) 2.4064 | Accuracy: 76.828324 %\n",
            "Epoch 00082 | Loss 0.3012 | Time(s) 2.4070 | Accuracy: 76.998760 %\n",
            "Epoch 00083 | Loss 0.1732 | Time(s) 2.4080 | Accuracy: 77.045243 %\n",
            "Epoch 00084 | Loss 0.1947 | Time(s) 2.4078 | Accuracy: 77.107220 %\n",
            "Epoch 00085 | Loss 0.1612 | Time(s) 2.4088 | Accuracy: 77.099473 %\n",
            "Epoch 00086 | Loss 0.1862 | Time(s) 2.4092 | Accuracy: 76.673381 %\n",
            "Epoch 00087 | Loss 0.1719 | Time(s) 2.4095 | Accuracy: 76.758599 %\n",
            "Epoch 00088 | Loss 0.1535 | Time(s) 2.4099 | Accuracy: 77.060738 %\n",
            "Epoch 00089 | Loss 0.1272 | Time(s) 2.4101 | Accuracy: 77.068485 %\n",
            "Epoch 00090 | Loss 0.1959 | Time(s) 2.4106 | Accuracy: 76.898048 %\n",
            "Epoch 00091 | Loss 0.1487 | Time(s) 2.4112 | Accuracy: 76.843818 %\n",
            "Epoch 00092 | Loss 0.1621 | Time(s) 2.4109 | Accuracy: 76.820576 %\n",
            "Epoch 00093 | Loss 0.1112 | Time(s) 2.4113 | Accuracy: 76.743105 %\n",
            "Epoch 00094 | Loss 0.1399 | Time(s) 2.4116 | Accuracy: 76.712117 %\n",
            "Epoch 00095 | Loss 0.0982 | Time(s) 2.4115 | Accuracy: 76.572668 %\n",
            "Epoch 00096 | Loss 0.1317 | Time(s) 2.4122 | Accuracy: 76.874806 %\n",
            "Epoch 00097 | Loss 0.1412 | Time(s) 2.4122 | Accuracy: 76.805082 %\n",
            "Epoch 00098 | Loss 0.2332 | Time(s) 2.4130 | Accuracy: 77.014255 %\n",
            "Epoch 00099 | Loss 0.1157 | Time(s) 2.4134 | Accuracy: 76.882553 %\n",
            "Epoch 00100 | Loss 0.2206 | Time(s) 2.4133 | Accuracy: 76.936783 %\n",
            "Epoch 00101 | Loss 0.1365 | Time(s) 2.4134 | Accuracy: 76.526185 %\n",
            "Epoch 00102 | Loss 0.1518 | Time(s) 2.4140 | Accuracy: 76.231794 %\n",
            "Epoch 00103 | Loss 0.1214 | Time(s) 2.4140 | Accuracy: 77.091726 %\n",
            "Epoch 00104 | Loss 0.1214 | Time(s) 2.4145 | Accuracy: 77.099473 %\n",
            "Epoch 00105 | Loss 0.1170 | Time(s) 2.4147 | Accuracy: 76.960025 %\n",
            "Epoch 00106 | Loss 0.1300 | Time(s) 2.4151 | Accuracy: 76.255036 %\n",
            "Epoch 00107 | Loss 0.1267 | Time(s) 2.4153 | Accuracy: 76.038116 %\n",
            "Epoch 00108 | Loss 0.1476 | Time(s) 2.4154 | Accuracy: 76.727611 %\n",
            "Epoch 00109 | Loss 0.1475 | Time(s) 2.4154 | Accuracy: 76.766346 %\n",
            "Epoch 00110 | Loss 0.1874 | Time(s) 2.4153 | Accuracy: 76.805082 %\n",
            "Epoch 00111 | Loss 0.0704 | Time(s) 2.4155 | Accuracy: 76.603657 %\n",
            "Epoch 00112 | Loss 0.1122 | Time(s) 2.4168 | Accuracy: 76.177564 %\n",
            "Epoch 00113 | Loss 0.1299 | Time(s) 2.4168 | Accuracy: 76.967772 %\n",
            "Epoch 00114 | Loss 0.2190 | Time(s) 2.4168 | Accuracy: 77.060738 %\n",
            "Epoch 00115 | Loss 0.1084 | Time(s) 2.4168 | Accuracy: 76.781841 %\n",
            "Epoch 00116 | Loss 0.1192 | Time(s) 2.4169 | Accuracy: 76.471955 %\n",
            "Epoch 00117 | Loss 0.1155 | Time(s) 2.4165 | Accuracy: 76.479703 %\n",
            "Epoch 00118 | Loss 0.1342 | Time(s) 2.4164 | Accuracy: 76.417725 %\n",
            "Epoch 00119 | Loss 0.1162 | Time(s) 2.4164 | Accuracy: 76.750852 %\n",
            "Epoch 00120 | Loss 0.0889 | Time(s) 2.4169 | Accuracy: 76.603657 %\n",
            "Epoch 00121 | Loss 0.1149 | Time(s) 2.4168 | Accuracy: 76.425473 %\n",
            "Epoch 00122 | Loss 0.0921 | Time(s) 2.4165 | Accuracy: 76.394484 %\n",
            "Epoch 00123 | Loss 0.1239 | Time(s) 2.4165 | Accuracy: 76.402231 %\n",
            "Epoch 00124 | Loss 0.1016 | Time(s) 2.4168 | Accuracy: 76.634645 %\n",
            "Epoch 00125 | Loss 0.1451 | Time(s) 2.4175 | Accuracy: 76.735358 %\n",
            "Epoch 00126 | Loss 0.0910 | Time(s) 2.4175 | Accuracy: 76.719864 %\n",
            "Epoch 00127 | Loss 0.1047 | Time(s) 2.4186 | Accuracy: 76.673381 %\n",
            "Epoch 00128 | Loss 0.1246 | Time(s) 2.4185 | Accuracy: 76.843818 %\n",
            "Epoch 00129 | Loss 0.0773 | Time(s) 2.4188 | Accuracy: 76.688875 %\n",
            "Epoch 00130 | Loss 0.1038 | Time(s) 2.4187 | Accuracy: 76.696622 %\n",
            "Epoch 00131 | Loss 0.1017 | Time(s) 2.4188 | Accuracy: 76.495197 %\n",
            "Epoch 00132 | Loss 0.0729 | Time(s) 2.4188 | Accuracy: 76.433220 %\n",
            "Epoch 00133 | Loss 0.1047 | Time(s) 2.4192 | Accuracy: 76.440967 %\n",
            "Epoch 00134 | Loss 0.0964 | Time(s) 2.4196 | Accuracy: 76.471955 %\n",
            "Epoch 00135 | Loss 0.0861 | Time(s) 2.4201 | Accuracy: 76.541680 %\n",
            "Epoch 00136 | Loss 0.0737 | Time(s) 2.4207 | Accuracy: 76.665634 %\n",
            "Epoch 00137 | Loss 0.0920 | Time(s) 2.4217 | Accuracy: 76.650139 %\n",
            "Epoch 00138 | Loss 0.0985 | Time(s) 2.4220 | Accuracy: 76.619151 %\n",
            "Epoch 00139 | Loss 0.0908 | Time(s) 2.4219 | Accuracy: 76.650139 %\n",
            "Epoch 00140 | Loss 0.0571 | Time(s) 2.4221 | Accuracy: 76.619151 %\n",
            "Epoch 00141 | Loss 0.0810 | Time(s) 2.4224 | Accuracy: 76.735358 %\n",
            "Epoch 00142 | Loss 0.1101 | Time(s) 2.4226 | Accuracy: 76.874806 %\n",
            "Epoch 00143 | Loss 0.1078 | Time(s) 2.4232 | Accuracy: 76.774094 %\n",
            "Epoch 00144 | Loss 0.0891 | Time(s) 2.4236 | Accuracy: 76.766346 %\n",
            "Epoch 00145 | Loss 0.0723 | Time(s) 2.4240 | Accuracy: 76.735358 %\n",
            "Epoch 00146 | Loss 0.1011 | Time(s) 2.4243 | Accuracy: 76.719864 %\n",
            "Epoch 00147 | Loss 0.0718 | Time(s) 2.4243 | Accuracy: 76.843818 %\n",
            "Epoch 00148 | Loss 0.0496 | Time(s) 2.4248 | Accuracy: 76.712117 %\n",
            "Epoch 00149 | Loss 0.0977 | Time(s) 2.4251 | Accuracy: 76.735358 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7548 | Time(s) 2.4503 | Accuracy: 18.678339 %\n",
            "Epoch 00001 | Loss 1.6933 | Time(s) 2.4523 | Accuracy: 37.139758 %\n",
            "Epoch 00002 | Loss 1.6579 | Time(s) 2.4434 | Accuracy: 44.329098 %\n",
            "Epoch 00003 | Loss 1.6054 | Time(s) 2.4502 | Accuracy: 46.165169 %\n",
            "Epoch 00004 | Loss 1.6073 | Time(s) 2.4449 | Accuracy: 47.606136 %\n",
            "Epoch 00005 | Loss 1.5711 | Time(s) 2.4422 | Accuracy: 49.659126 %\n",
            "Epoch 00006 | Loss 1.5724 | Time(s) 2.4472 | Accuracy: 51.588162 %\n",
            "Epoch 00007 | Loss 1.5353 | Time(s) 2.4550 | Accuracy: 51.123334 %\n",
            "Epoch 00008 | Loss 1.3522 | Time(s) 2.4534 | Accuracy: 52.572048 %\n",
            "Epoch 00009 | Loss 1.4200 | Time(s) 2.4518 | Accuracy: 54.144716 %\n",
            "Epoch 00010 | Loss 1.3834 | Time(s) 2.4582 | Accuracy: 54.377130 %\n",
            "Epoch 00011 | Loss 1.3449 | Time(s) 2.4549 | Accuracy: 55.066625 %\n",
            "Epoch 00012 | Loss 1.2863 | Time(s) 2.4544 | Accuracy: 56.352650 %\n",
            "Epoch 00013 | Loss 1.2447 | Time(s) 2.4539 | Accuracy: 56.685776 %\n",
            "Epoch 00014 | Loss 1.2160 | Time(s) 2.4502 | Accuracy: 58.111249 %\n",
            "Epoch 00015 | Loss 1.1534 | Time(s) 2.4484 | Accuracy: 59.807871 %\n",
            "Epoch 00016 | Loss 1.2885 | Time(s) 2.4509 | Accuracy: 59.606446 %\n",
            "Epoch 00017 | Loss 1.1739 | Time(s) 2.4570 | Accuracy: 60.536102 %\n",
            "Epoch 00018 | Loss 1.2080 | Time(s) 2.4614 | Accuracy: 61.062907 %\n",
            "Epoch 00019 | Loss 1.1020 | Time(s) 2.4674 | Accuracy: 61.062907 %\n",
            "Epoch 00020 | Loss 1.1102 | Time(s) 2.4657 | Accuracy: 60.791757 %\n",
            "Epoch 00021 | Loss 1.0312 | Time(s) 2.4649 | Accuracy: 60.233963 %\n",
            "Epoch 00022 | Loss 0.9955 | Time(s) 2.4681 | Accuracy: 60.644562 %\n",
            "Epoch 00023 | Loss 1.0432 | Time(s) 2.4683 | Accuracy: 61.365045 %\n",
            "Epoch 00024 | Loss 1.0768 | Time(s) 2.4682 | Accuracy: 61.504493 %\n",
            "Epoch 00025 | Loss 0.9894 | Time(s) 2.4682 | Accuracy: 61.736907 %\n",
            "Epoch 00026 | Loss 0.9095 | Time(s) 2.4691 | Accuracy: 61.519988 %\n",
            "Epoch 00027 | Loss 0.8892 | Time(s) 2.4678 | Accuracy: 61.488999 %\n",
            "Epoch 00028 | Loss 0.8518 | Time(s) 2.4693 | Accuracy: 61.427022 %\n",
            "Epoch 00029 | Loss 0.9210 | Time(s) 2.4697 | Accuracy: 61.961574 %\n",
            "Epoch 00030 | Loss 0.9245 | Time(s) 2.4717 | Accuracy: 61.860861 %\n",
            "Epoch 00031 | Loss 0.7957 | Time(s) 2.4704 | Accuracy: 61.977068 %\n",
            "Epoch 00032 | Loss 0.9407 | Time(s) 2.4685 | Accuracy: 61.891850 %\n",
            "Epoch 00033 | Loss 0.8328 | Time(s) 2.4675 | Accuracy: 61.953827 %\n",
            "Epoch 00034 | Loss 0.8798 | Time(s) 2.4667 | Accuracy: 61.798884 %\n",
            "Epoch 00035 | Loss 0.7788 | Time(s) 2.4669 | Accuracy: 61.791137 %\n",
            "Epoch 00036 | Loss 0.7547 | Time(s) 2.4662 | Accuracy: 62.441896 %\n",
            "Epoch 00037 | Loss 0.7201 | Time(s) 2.4654 | Accuracy: 62.302448 %\n",
            "Epoch 00038 | Loss 0.8261 | Time(s) 2.4651 | Accuracy: 62.224977 %\n",
            "Epoch 00039 | Loss 0.6892 | Time(s) 2.4652 | Accuracy: 62.240471 %\n",
            "Epoch 00040 | Loss 0.7587 | Time(s) 2.4651 | Accuracy: 62.581345 %\n",
            "Epoch 00041 | Loss 0.7486 | Time(s) 2.4647 | Accuracy: 62.806012 %\n",
            "Epoch 00042 | Loss 0.8289 | Time(s) 2.4642 | Accuracy: 62.852495 %\n",
            "Epoch 00043 | Loss 0.7679 | Time(s) 2.4643 | Accuracy: 62.720793 %\n",
            "Epoch 00044 | Loss 0.7132 | Time(s) 2.4635 | Accuracy: 62.798265 %\n",
            "Epoch 00045 | Loss 0.7923 | Time(s) 2.4629 | Accuracy: 62.852495 %\n",
            "Epoch 00046 | Loss 0.7807 | Time(s) 2.4630 | Accuracy: 62.852495 %\n",
            "Epoch 00047 | Loss 0.7378 | Time(s) 2.4632 | Accuracy: 62.945460 %\n",
            "Epoch 00048 | Loss 0.6215 | Time(s) 2.4636 | Accuracy: 62.837000 %\n",
            "Epoch 00049 | Loss 0.8026 | Time(s) 2.4641 | Accuracy: 62.929966 %\n",
            "Epoch 00050 | Loss 0.5901 | Time(s) 2.4644 | Accuracy: 63.046173 %\n",
            "Epoch 00051 | Loss 0.7737 | Time(s) 2.4661 | Accuracy: 63.038426 %\n",
            "Epoch 00052 | Loss 0.6532 | Time(s) 2.4664 | Accuracy: 63.208863 %\n",
            "Epoch 00053 | Loss 0.6400 | Time(s) 2.4665 | Accuracy: 63.456771 %\n",
            "Epoch 00054 | Loss 0.7128 | Time(s) 2.4664 | Accuracy: 63.425782 %\n",
            "Epoch 00055 | Loss 0.7030 | Time(s) 2.4680 | Accuracy: 63.425782 %\n",
            "Epoch 00056 | Loss 0.5450 | Time(s) 2.4689 | Accuracy: 63.123644 %\n",
            "Epoch 00057 | Loss 0.5451 | Time(s) 2.4693 | Accuracy: 62.829253 %\n",
            "Epoch 00058 | Loss 0.5321 | Time(s) 2.4689 | Accuracy: 63.100403 %\n",
            "Epoch 00059 | Loss 0.5989 | Time(s) 2.4692 | Accuracy: 63.053920 %\n",
            "Epoch 00060 | Loss 0.6662 | Time(s) 2.4708 | Accuracy: 63.108150 %\n",
            "Epoch 00061 | Loss 0.5289 | Time(s) 2.4708 | Accuracy: 63.294081 %\n",
            "Epoch 00062 | Loss 0.6213 | Time(s) 2.4705 | Accuracy: 63.464518 %\n",
            "Epoch 00063 | Loss 0.6272 | Time(s) 2.4699 | Accuracy: 63.588472 %\n",
            "Epoch 00064 | Loss 0.5116 | Time(s) 2.4704 | Accuracy: 63.487760 %\n",
            "Epoch 00065 | Loss 0.6392 | Time(s) 2.4706 | Accuracy: 63.348311 %\n",
            "Epoch 00066 | Loss 0.6043 | Time(s) 2.4707 | Accuracy: 63.456771 %\n",
            "Epoch 00067 | Loss 0.6656 | Time(s) 2.4712 | Accuracy: 63.526495 %\n",
            "Epoch 00068 | Loss 0.6200 | Time(s) 2.4718 | Accuracy: 63.294081 %\n",
            "Epoch 00069 | Loss 0.4444 | Time(s) 2.4716 | Accuracy: 62.991943 %\n",
            "Epoch 00070 | Loss 0.5902 | Time(s) 2.4716 | Accuracy: 63.185621 %\n",
            "Epoch 00071 | Loss 0.5377 | Time(s) 2.4731 | Accuracy: 63.340564 %\n",
            "Epoch 00072 | Loss 0.5963 | Time(s) 2.4730 | Accuracy: 63.340564 %\n",
            "Epoch 00073 | Loss 0.5755 | Time(s) 2.4730 | Accuracy: 63.208863 %\n",
            "Epoch 00074 | Loss 0.5941 | Time(s) 2.4731 | Accuracy: 63.162380 %\n",
            "Epoch 00075 | Loss 0.4731 | Time(s) 2.4731 | Accuracy: 63.046173 %\n",
            "Epoch 00076 | Loss 0.6757 | Time(s) 2.4734 | Accuracy: 63.278587 %\n",
            "Epoch 00077 | Loss 0.4498 | Time(s) 2.4743 | Accuracy: 63.309575 %\n",
            "Epoch 00078 | Loss 0.5567 | Time(s) 2.4750 | Accuracy: 63.263093 %\n",
            "Epoch 00079 | Loss 0.4119 | Time(s) 2.4770 | Accuracy: 63.123644 %\n",
            "Epoch 00080 | Loss 0.6093 | Time(s) 2.4776 | Accuracy: 63.387047 %\n",
            "Epoch 00081 | Loss 0.5455 | Time(s) 2.4787 | Accuracy: 63.464518 %\n",
            "Epoch 00082 | Loss 0.5289 | Time(s) 2.4786 | Accuracy: 63.387047 %\n",
            "Epoch 00083 | Loss 0.4569 | Time(s) 2.4790 | Accuracy: 63.255346 %\n",
            "Epoch 00084 | Loss 0.5668 | Time(s) 2.4801 | Accuracy: 63.410288 %\n",
            "Epoch 00085 | Loss 0.5448 | Time(s) 2.4802 | Accuracy: 63.379300 %\n",
            "Epoch 00086 | Loss 0.5324 | Time(s) 2.4806 | Accuracy: 63.069414 %\n",
            "Epoch 00087 | Loss 0.5748 | Time(s) 2.4805 | Accuracy: 62.581345 %\n",
            "Epoch 00088 | Loss 0.5332 | Time(s) 2.4810 | Accuracy: 62.782770 %\n",
            "Epoch 00089 | Loss 0.5270 | Time(s) 2.4821 | Accuracy: 62.821506 %\n",
            "Epoch 00090 | Loss 0.5120 | Time(s) 2.4824 | Accuracy: 63.046173 %\n",
            "Epoch 00091 | Loss 0.4218 | Time(s) 2.4829 | Accuracy: 63.371553 %\n",
            "Epoch 00092 | Loss 0.5063 | Time(s) 2.4835 | Accuracy: 63.456771 %\n",
            "Epoch 00093 | Loss 0.4420 | Time(s) 2.4832 | Accuracy: 63.394794 %\n",
            "Epoch 00094 | Loss 0.5629 | Time(s) 2.4836 | Accuracy: 62.953207 %\n",
            "Epoch 00095 | Loss 0.4970 | Time(s) 2.4842 | Accuracy: 63.015184 %\n",
            "Epoch 00096 | Loss 0.4999 | Time(s) 2.4845 | Accuracy: 63.340564 %\n",
            "Epoch 00097 | Loss 0.4830 | Time(s) 2.4851 | Accuracy: 63.356058 %\n",
            "Epoch 00098 | Loss 0.4448 | Time(s) 2.4853 | Accuracy: 63.325070 %\n",
            "Epoch 00099 | Loss 0.3761 | Time(s) 2.4858 | Accuracy: 63.123644 %\n",
            "Epoch 00100 | Loss 0.5008 | Time(s) 2.4866 | Accuracy: 63.309575 %\n",
            "Epoch 00101 | Loss 0.4920 | Time(s) 2.4867 | Accuracy: 63.208863 %\n",
            "Epoch 00102 | Loss 0.4168 | Time(s) 2.4866 | Accuracy: 63.053920 %\n",
            "Epoch 00103 | Loss 0.3690 | Time(s) 2.4875 | Accuracy: 63.193368 %\n",
            "Epoch 00104 | Loss 0.5036 | Time(s) 2.4876 | Accuracy: 63.061667 %\n",
            "Epoch 00105 | Loss 0.3677 | Time(s) 2.4883 | Accuracy: 63.069414 %\n",
            "Epoch 00106 | Loss 0.4906 | Time(s) 2.4880 | Accuracy: 63.418035 %\n",
            "Epoch 00107 | Loss 0.4864 | Time(s) 2.4884 | Accuracy: 63.495507 %\n",
            "Epoch 00108 | Loss 0.4887 | Time(s) 2.4885 | Accuracy: 63.603967 %\n",
            "Epoch 00109 | Loss 0.4115 | Time(s) 2.4885 | Accuracy: 63.332817 %\n",
            "Epoch 00110 | Loss 0.3919 | Time(s) 2.4890 | Accuracy: 63.255346 %\n",
            "Epoch 00111 | Loss 0.4631 | Time(s) 2.4889 | Accuracy: 63.487760 %\n",
            "Epoch 00112 | Loss 0.4036 | Time(s) 2.4891 | Accuracy: 63.402541 %\n",
            "Epoch 00113 | Loss 0.3567 | Time(s) 2.4901 | Accuracy: 62.914472 %\n",
            "Epoch 00114 | Loss 0.5423 | Time(s) 2.4901 | Accuracy: 62.806012 %\n",
            "Epoch 00115 | Loss 0.4711 | Time(s) 2.4905 | Accuracy: 63.193368 %\n",
            "Epoch 00116 | Loss 0.5324 | Time(s) 2.4906 | Accuracy: 63.356058 %\n",
            "Epoch 00117 | Loss 0.5280 | Time(s) 2.4909 | Accuracy: 63.433530 %\n",
            "Epoch 00118 | Loss 0.4621 | Time(s) 2.4911 | Accuracy: 63.410288 %\n",
            "Epoch 00119 | Loss 0.4010 | Time(s) 2.4915 | Accuracy: 63.495507 %\n",
            "Epoch 00120 | Loss 0.4764 | Time(s) 2.4919 | Accuracy: 63.363805 %\n",
            "Epoch 00121 | Loss 0.4754 | Time(s) 2.4922 | Accuracy: 63.193368 %\n",
            "Epoch 00122 | Loss 0.3934 | Time(s) 2.4924 | Accuracy: 63.193368 %\n",
            "Epoch 00123 | Loss 0.5141 | Time(s) 2.4922 | Accuracy: 63.131391 %\n",
            "Epoch 00124 | Loss 0.4971 | Time(s) 2.4919 | Accuracy: 63.115897 %\n",
            "Epoch 00125 | Loss 0.4673 | Time(s) 2.4919 | Accuracy: 63.084909 %\n",
            "Epoch 00126 | Loss 0.4890 | Time(s) 2.4925 | Accuracy: 63.030679 %\n",
            "Epoch 00127 | Loss 0.5097 | Time(s) 2.4929 | Accuracy: 63.123644 %\n",
            "Epoch 00128 | Loss 0.4576 | Time(s) 2.4931 | Accuracy: 63.224357 %\n",
            "Epoch 00129 | Loss 0.4544 | Time(s) 2.4933 | Accuracy: 63.441277 %\n",
            "Epoch 00130 | Loss 0.4608 | Time(s) 2.4942 | Accuracy: 63.348311 %\n",
            "Epoch 00131 | Loss 0.4610 | Time(s) 2.4944 | Accuracy: 63.263093 %\n",
            "Epoch 00132 | Loss 0.4591 | Time(s) 2.4944 | Accuracy: 63.294081 %\n",
            "Epoch 00133 | Loss 0.4447 | Time(s) 2.4945 | Accuracy: 63.309575 %\n",
            "Epoch 00134 | Loss 0.4417 | Time(s) 2.4947 | Accuracy: 63.526495 %\n",
            "Epoch 00135 | Loss 0.4935 | Time(s) 2.4946 | Accuracy: 63.557484 %\n",
            "Epoch 00136 | Loss 0.4956 | Time(s) 2.4947 | Accuracy: 63.511001 %\n",
            "Epoch 00137 | Loss 0.3847 | Time(s) 2.4947 | Accuracy: 63.278587 %\n",
            "Epoch 00138 | Loss 0.4902 | Time(s) 2.4945 | Accuracy: 63.208863 %\n",
            "Epoch 00139 | Loss 0.3700 | Time(s) 2.4950 | Accuracy: 63.418035 %\n",
            "Epoch 00140 | Loss 0.3684 | Time(s) 2.4951 | Accuracy: 63.511001 %\n",
            "Epoch 00141 | Loss 0.3756 | Time(s) 2.4953 | Accuracy: 63.464518 %\n",
            "Epoch 00142 | Loss 0.4904 | Time(s) 2.4952 | Accuracy: 63.503254 %\n",
            "Epoch 00143 | Loss 0.4905 | Time(s) 2.4954 | Accuracy: 63.518748 %\n",
            "Epoch 00144 | Loss 0.3644 | Time(s) 2.4962 | Accuracy: 63.472265 %\n",
            "Epoch 00145 | Loss 0.3479 | Time(s) 2.4961 | Accuracy: 63.503254 %\n",
            "Epoch 00146 | Loss 0.3617 | Time(s) 2.4961 | Accuracy: 63.363805 %\n",
            "Epoch 00147 | Loss 0.4891 | Time(s) 2.4963 | Accuracy: 63.247598 %\n",
            "Epoch 00148 | Loss 0.4480 | Time(s) 2.4960 | Accuracy: 63.108150 %\n",
            "Epoch 00149 | Loss 0.4637 | Time(s) 2.4960 | Accuracy: 63.247598 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7121 | Time(s) 2.5661 | Accuracy: 28.912302 %\n",
            "Epoch 00001 | Loss 1.6961 | Time(s) 2.5559 | Accuracy: 36.891850 %\n",
            "Epoch 00002 | Loss 1.6460 | Time(s) 2.5495 | Accuracy: 44.964363 %\n",
            "Epoch 00003 | Loss 1.4739 | Time(s) 2.5431 | Accuracy: 49.031608 %\n",
            "Epoch 00004 | Loss 1.5754 | Time(s) 2.5387 | Accuracy: 54.082739 %\n",
            "Epoch 00005 | Loss 1.4763 | Time(s) 2.5386 | Accuracy: 57.692904 %\n",
            "Epoch 00006 | Loss 1.4508 | Time(s) 2.5401 | Accuracy: 59.637434 %\n",
            "Epoch 00007 | Loss 1.4217 | Time(s) 2.5346 | Accuracy: 58.599318 %\n",
            "Epoch 00008 | Loss 1.4266 | Time(s) 2.5296 | Accuracy: 58.916951 %\n",
            "Epoch 00009 | Loss 1.2034 | Time(s) 2.5244 | Accuracy: 61.891850 %\n",
            "Epoch 00010 | Loss 1.2961 | Time(s) 2.5246 | Accuracy: 62.070034 %\n",
            "Epoch 00011 | Loss 1.2311 | Time(s) 2.5279 | Accuracy: 61.907344 %\n",
            "Epoch 00012 | Loss 1.0599 | Time(s) 2.5243 | Accuracy: 61.303068 %\n",
            "Epoch 00013 | Loss 1.2023 | Time(s) 2.5211 | Accuracy: 61.241091 %\n",
            "Epoch 00014 | Loss 1.1758 | Time(s) 2.5231 | Accuracy: 62.132011 %\n",
            "Epoch 00015 | Loss 1.1582 | Time(s) 2.5207 | Accuracy: 62.271460 %\n",
            "Epoch 00016 | Loss 1.0617 | Time(s) 2.5271 | Accuracy: 62.457391 %\n",
            "Epoch 00017 | Loss 1.0828 | Time(s) 2.5249 | Accuracy: 62.077781 %\n",
            "Epoch 00018 | Loss 1.1089 | Time(s) 2.5237 | Accuracy: 62.356678 %\n",
            "Epoch 00019 | Loss 1.0365 | Time(s) 2.5227 | Accuracy: 62.767276 %\n",
            "Epoch 00020 | Loss 1.0494 | Time(s) 2.5223 | Accuracy: 62.945460 %\n",
            "Epoch 00021 | Loss 0.8422 | Time(s) 2.5215 | Accuracy: 62.317942 %\n",
            "Epoch 00022 | Loss 0.9910 | Time(s) 2.5231 | Accuracy: 62.534862 %\n",
            "Epoch 00023 | Loss 1.0533 | Time(s) 2.5214 | Accuracy: 63.503254 %\n",
            "Epoch 00024 | Loss 0.9588 | Time(s) 2.5224 | Accuracy: 63.402541 %\n",
            "Epoch 00025 | Loss 0.8105 | Time(s) 2.5198 | Accuracy: 63.480012 %\n",
            "Epoch 00026 | Loss 0.9597 | Time(s) 2.5205 | Accuracy: 63.387047 %\n",
            "Epoch 00027 | Loss 0.7278 | Time(s) 2.5213 | Accuracy: 63.061667 %\n",
            "Epoch 00028 | Loss 0.9138 | Time(s) 2.5217 | Accuracy: 63.472265 %\n",
            "Epoch 00029 | Loss 0.9440 | Time(s) 2.5207 | Accuracy: 63.681438 %\n",
            "Epoch 00030 | Loss 0.8124 | Time(s) 2.5203 | Accuracy: 63.875116 %\n",
            "Epoch 00031 | Loss 0.8610 | Time(s) 2.5193 | Accuracy: 63.580725 %\n",
            "Epoch 00032 | Loss 0.9755 | Time(s) 2.5181 | Accuracy: 63.580725 %\n",
            "Epoch 00033 | Loss 0.8401 | Time(s) 2.5160 | Accuracy: 64.115277 %\n",
            "Epoch 00034 | Loss 0.9423 | Time(s) 2.5163 | Accuracy: 64.130772 %\n",
            "Epoch 00035 | Loss 0.7951 | Time(s) 2.5169 | Accuracy: 63.875116 %\n",
            "Epoch 00036 | Loss 0.7162 | Time(s) 2.5170 | Accuracy: 64.394174 %\n",
            "Epoch 00037 | Loss 0.7833 | Time(s) 2.5164 | Accuracy: 64.347691 %\n",
            "Epoch 00038 | Loss 0.6992 | Time(s) 2.5158 | Accuracy: 63.503254 %\n",
            "Epoch 00039 | Loss 0.7228 | Time(s) 2.5163 | Accuracy: 63.696932 %\n",
            "Epoch 00040 | Loss 0.6080 | Time(s) 2.5157 | Accuracy: 64.432910 %\n",
            "Epoch 00041 | Loss 0.8443 | Time(s) 2.5151 | Accuracy: 64.308956 %\n",
            "Epoch 00042 | Loss 0.9075 | Time(s) 2.5146 | Accuracy: 64.231484 %\n",
            "Epoch 00043 | Loss 0.8381 | Time(s) 2.5149 | Accuracy: 64.084289 %\n",
            "Epoch 00044 | Loss 0.7928 | Time(s) 2.5138 | Accuracy: 64.006817 %\n",
            "Epoch 00045 | Loss 0.7070 | Time(s) 2.5129 | Accuracy: 64.254726 %\n",
            "Epoch 00046 | Loss 0.8434 | Time(s) 2.5124 | Accuracy: 64.394174 %\n",
            "Epoch 00047 | Loss 0.6983 | Time(s) 2.5124 | Accuracy: 64.239231 %\n",
            "Epoch 00048 | Loss 0.8661 | Time(s) 2.5130 | Accuracy: 64.130772 %\n",
            "Epoch 00049 | Loss 0.7243 | Time(s) 2.5120 | Accuracy: 64.123024 %\n",
            "Epoch 00050 | Loss 0.6548 | Time(s) 2.5134 | Accuracy: 64.154013 %\n",
            "Epoch 00051 | Loss 0.6949 | Time(s) 2.5146 | Accuracy: 64.154013 %\n",
            "Epoch 00052 | Loss 0.7452 | Time(s) 2.5169 | Accuracy: 64.231484 %\n",
            "Epoch 00053 | Loss 0.5192 | Time(s) 2.5172 | Accuracy: 64.223737 %\n",
            "Epoch 00054 | Loss 0.8320 | Time(s) 2.5168 | Accuracy: 64.092036 %\n",
            "Epoch 00055 | Loss 0.8115 | Time(s) 2.5162 | Accuracy: 64.130772 %\n",
            "Epoch 00056 | Loss 0.6558 | Time(s) 2.5170 | Accuracy: 63.844128 %\n",
            "Epoch 00057 | Loss 0.5949 | Time(s) 2.5163 | Accuracy: 64.285714 %\n",
            "Epoch 00058 | Loss 0.5875 | Time(s) 2.5172 | Accuracy: 64.394174 %\n",
            "Epoch 00059 | Loss 0.8310 | Time(s) 2.5166 | Accuracy: 63.952588 %\n",
            "Epoch 00060 | Loss 0.7101 | Time(s) 2.5165 | Accuracy: 64.200496 %\n",
            "Epoch 00061 | Loss 0.5693 | Time(s) 2.5166 | Accuracy: 64.789278 %\n",
            "Epoch 00062 | Loss 0.5607 | Time(s) 2.5156 | Accuracy: 64.773784 %\n",
            "Epoch 00063 | Loss 0.6902 | Time(s) 2.5149 | Accuracy: 64.665324 %\n",
            "Epoch 00064 | Loss 0.5916 | Time(s) 2.5167 | Accuracy: 64.363186 %\n",
            "Epoch 00065 | Loss 0.8393 | Time(s) 2.5163 | Accuracy: 64.030059 %\n",
            "Epoch 00066 | Loss 0.5876 | Time(s) 2.5161 | Accuracy: 64.564611 %\n",
            "Epoch 00067 | Loss 0.5540 | Time(s) 2.5152 | Accuracy: 64.564611 %\n",
            "Epoch 00068 | Loss 0.6129 | Time(s) 2.5146 | Accuracy: 64.456151 %\n",
            "Epoch 00069 | Loss 0.5918 | Time(s) 2.5147 | Accuracy: 64.673071 %\n",
            "Epoch 00070 | Loss 0.6526 | Time(s) 2.5138 | Accuracy: 64.533623 %\n",
            "Epoch 00071 | Loss 0.5648 | Time(s) 2.5143 | Accuracy: 64.386427 %\n",
            "Epoch 00072 | Loss 0.4477 | Time(s) 2.5147 | Accuracy: 64.564611 %\n",
            "Epoch 00073 | Loss 0.6257 | Time(s) 2.5143 | Accuracy: 64.355438 %\n",
            "Epoch 00074 | Loss 0.6423 | Time(s) 2.5150 | Accuracy: 64.409668 %\n",
            "Epoch 00075 | Loss 0.6171 | Time(s) 2.5144 | Accuracy: 64.549117 %\n",
            "Epoch 00076 | Loss 0.5511 | Time(s) 2.5145 | Accuracy: 64.649830 %\n",
            "Epoch 00077 | Loss 0.5169 | Time(s) 2.5142 | Accuracy: 64.549117 %\n",
            "Epoch 00078 | Loss 0.4180 | Time(s) 2.5140 | Accuracy: 64.277967 %\n",
            "Epoch 00079 | Loss 0.5057 | Time(s) 2.5134 | Accuracy: 64.355438 %\n",
            "Epoch 00080 | Loss 0.7837 | Time(s) 2.5128 | Accuracy: 64.316703 %\n",
            "Epoch 00081 | Loss 0.7656 | Time(s) 2.5123 | Accuracy: 64.246979 %\n",
            "Epoch 00082 | Loss 0.5478 | Time(s) 2.5123 | Accuracy: 64.355438 %\n",
            "Epoch 00083 | Loss 0.6114 | Time(s) 2.5123 | Accuracy: 64.471645 %\n",
            "Epoch 00084 | Loss 0.7675 | Time(s) 2.5121 | Accuracy: 63.983576 %\n",
            "Epoch 00085 | Loss 0.7615 | Time(s) 2.5119 | Accuracy: 63.875116 %\n",
            "Epoch 00086 | Loss 0.4847 | Time(s) 2.5113 | Accuracy: 64.285714 %\n",
            "Epoch 00087 | Loss 0.5614 | Time(s) 2.5109 | Accuracy: 64.277967 %\n",
            "Epoch 00088 | Loss 0.5407 | Time(s) 2.5109 | Accuracy: 64.277967 %\n",
            "Epoch 00089 | Loss 0.4016 | Time(s) 2.5107 | Accuracy: 64.185002 %\n",
            "Epoch 00090 | Loss 0.4923 | Time(s) 2.5108 | Accuracy: 64.169507 %\n",
            "Epoch 00091 | Loss 0.4749 | Time(s) 2.5107 | Accuracy: 64.463898 %\n",
            "Epoch 00092 | Loss 0.5917 | Time(s) 2.5099 | Accuracy: 64.549117 %\n",
            "Epoch 00093 | Loss 0.5056 | Time(s) 2.5103 | Accuracy: 64.471645 %\n",
            "Epoch 00094 | Loss 0.5385 | Time(s) 2.5103 | Accuracy: 64.580105 %\n",
            "Epoch 00095 | Loss 0.6717 | Time(s) 2.5101 | Accuracy: 64.463898 %\n",
            "Epoch 00096 | Loss 0.6668 | Time(s) 2.5109 | Accuracy: 64.549117 %\n",
            "Epoch 00097 | Loss 0.4064 | Time(s) 2.5106 | Accuracy: 63.627208 %\n",
            "Epoch 00098 | Loss 0.7230 | Time(s) 2.5108 | Accuracy: 64.463898 %\n",
            "Epoch 00099 | Loss 0.5114 | Time(s) 2.5104 | Accuracy: 64.386427 %\n",
            "Epoch 00100 | Loss 0.6700 | Time(s) 2.5099 | Accuracy: 63.681438 %\n",
            "Epoch 00101 | Loss 0.4007 | Time(s) 2.5097 | Accuracy: 64.332197 %\n",
            "Epoch 00102 | Loss 0.4847 | Time(s) 2.5099 | Accuracy: 64.254726 %\n",
            "Epoch 00103 | Loss 0.5245 | Time(s) 2.5090 | Accuracy: 64.154013 %\n",
            "Epoch 00104 | Loss 0.5244 | Time(s) 2.5086 | Accuracy: 64.107530 %\n",
            "Epoch 00105 | Loss 0.4656 | Time(s) 2.5082 | Accuracy: 64.239231 %\n",
            "Epoch 00106 | Loss 0.4792 | Time(s) 2.5076 | Accuracy: 64.293461 %\n",
            "Epoch 00107 | Loss 0.5832 | Time(s) 2.5076 | Accuracy: 64.316703 %\n",
            "Epoch 00108 | Loss 0.3961 | Time(s) 2.5074 | Accuracy: 63.735668 %\n",
            "Epoch 00109 | Loss 0.4615 | Time(s) 2.5070 | Accuracy: 63.944840 %\n",
            "Epoch 00110 | Loss 0.5784 | Time(s) 2.5071 | Accuracy: 64.440657 %\n",
            "Epoch 00111 | Loss 0.4699 | Time(s) 2.5069 | Accuracy: 64.417416 %\n",
            "Epoch 00112 | Loss 0.4935 | Time(s) 2.5075 | Accuracy: 64.208243 %\n",
            "Epoch 00113 | Loss 0.5742 | Time(s) 2.5076 | Accuracy: 64.432910 %\n",
            "Epoch 00114 | Loss 0.6716 | Time(s) 2.5077 | Accuracy: 64.649830 %\n",
            "Epoch 00115 | Loss 0.6386 | Time(s) 2.5077 | Accuracy: 64.448404 %\n",
            "Epoch 00116 | Loss 0.4552 | Time(s) 2.5076 | Accuracy: 64.270220 %\n",
            "Epoch 00117 | Loss 0.5774 | Time(s) 2.5072 | Accuracy: 64.448404 %\n",
            "Epoch 00118 | Loss 0.4569 | Time(s) 2.5071 | Accuracy: 64.425163 %\n",
            "Epoch 00119 | Loss 0.6455 | Time(s) 2.5073 | Accuracy: 64.339944 %\n",
            "Epoch 00120 | Loss 0.5450 | Time(s) 2.5073 | Accuracy: 64.339944 %\n",
            "Epoch 00121 | Loss 0.4818 | Time(s) 2.5071 | Accuracy: 64.510381 %\n",
            "Epoch 00122 | Loss 0.4813 | Time(s) 2.5070 | Accuracy: 64.479393 %\n",
            "Epoch 00123 | Loss 0.5467 | Time(s) 2.5068 | Accuracy: 64.270220 %\n",
            "Epoch 00124 | Loss 0.4739 | Time(s) 2.5076 | Accuracy: 64.494887 %\n",
            "Epoch 00125 | Loss 0.4977 | Time(s) 2.5073 | Accuracy: 64.487140 %\n",
            "Epoch 00126 | Loss 0.4747 | Time(s) 2.5072 | Accuracy: 64.123024 %\n",
            "Epoch 00127 | Loss 0.6855 | Time(s) 2.5076 | Accuracy: 64.502634 %\n",
            "Epoch 00128 | Loss 0.6462 | Time(s) 2.5073 | Accuracy: 64.347691 %\n",
            "Epoch 00129 | Loss 0.5423 | Time(s) 2.5069 | Accuracy: 63.549737 %\n",
            "Epoch 00130 | Loss 0.4611 | Time(s) 2.5067 | Accuracy: 64.494887 %\n",
            "Epoch 00131 | Loss 0.5108 | Time(s) 2.5072 | Accuracy: 64.270220 %\n",
            "Epoch 00132 | Loss 0.5320 | Time(s) 2.5072 | Accuracy: 64.293461 %\n",
            "Epoch 00133 | Loss 0.4784 | Time(s) 2.5070 | Accuracy: 64.068795 %\n",
            "Epoch 00134 | Loss 0.3981 | Time(s) 2.5071 | Accuracy: 64.502634 %\n",
            "Epoch 00135 | Loss 0.4608 | Time(s) 2.5073 | Accuracy: 64.169507 %\n",
            "Epoch 00136 | Loss 0.6313 | Time(s) 2.5077 | Accuracy: 64.471645 %\n",
            "Epoch 00137 | Loss 0.5638 | Time(s) 2.5081 | Accuracy: 64.339944 %\n",
            "Epoch 00138 | Loss 0.4604 | Time(s) 2.5078 | Accuracy: 63.882863 %\n",
            "Epoch 00139 | Loss 0.5271 | Time(s) 2.5079 | Accuracy: 64.045553 %\n",
            "Epoch 00140 | Loss 0.4520 | Time(s) 2.5079 | Accuracy: 64.308956 %\n",
            "Epoch 00141 | Loss 0.4482 | Time(s) 2.5076 | Accuracy: 64.564611 %\n",
            "Epoch 00142 | Loss 0.5617 | Time(s) 2.5072 | Accuracy: 64.378680 %\n",
            "Epoch 00143 | Loss 0.4401 | Time(s) 2.5075 | Accuracy: 64.277967 %\n",
            "Epoch 00144 | Loss 0.4529 | Time(s) 2.5079 | Accuracy: 64.277967 %\n",
            "Epoch 00145 | Loss 0.4452 | Time(s) 2.5080 | Accuracy: 64.262473 %\n",
            "Epoch 00146 | Loss 0.4531 | Time(s) 2.5084 | Accuracy: 64.339944 %\n",
            "Epoch 00147 | Loss 0.4953 | Time(s) 2.5085 | Accuracy: 64.425163 %\n",
            "Epoch 00148 | Loss 0.6256 | Time(s) 2.5084 | Accuracy: 64.301209 %\n",
            "Epoch 00149 | Loss 0.5284 | Time(s) 2.5086 | Accuracy: 64.185002 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7437 | Time(s) 2.5092 | Accuracy: 22.025101 %\n",
            "Epoch 00001 | Loss 1.6880 | Time(s) 2.5027 | Accuracy: 30.035637 %\n",
            "Epoch 00002 | Loss 1.6289 | Time(s) 2.4972 | Accuracy: 40.323830 %\n",
            "Epoch 00003 | Loss 1.5238 | Time(s) 2.5028 | Accuracy: 49.240781 %\n",
            "Epoch 00004 | Loss 1.5633 | Time(s) 2.5054 | Accuracy: 52.083979 %\n",
            "Epoch 00005 | Loss 1.3887 | Time(s) 2.4996 | Accuracy: 52.107220 %\n",
            "Epoch 00006 | Loss 1.4785 | Time(s) 2.5012 | Accuracy: 55.074372 %\n",
            "Epoch 00007 | Loss 1.2878 | Time(s) 2.5030 | Accuracy: 57.104121 %\n",
            "Epoch 00008 | Loss 1.3018 | Time(s) 2.5001 | Accuracy: 57.065386 %\n",
            "Epoch 00009 | Loss 1.3233 | Time(s) 2.5025 | Accuracy: 57.506972 %\n",
            "Epoch 00010 | Loss 1.2944 | Time(s) 2.5046 | Accuracy: 57.003409 %\n",
            "Epoch 00011 | Loss 1.1759 | Time(s) 2.5043 | Accuracy: 56.089247 %\n",
            "Epoch 00012 | Loss 1.2300 | Time(s) 2.5027 | Accuracy: 55.593430 %\n",
            "Epoch 00013 | Loss 1.2719 | Time(s) 2.5016 | Accuracy: 55.663155 %\n",
            "Epoch 00014 | Loss 1.1850 | Time(s) 2.5032 | Accuracy: 56.414627 %\n",
            "Epoch 00015 | Loss 1.1551 | Time(s) 2.5028 | Accuracy: 58.196467 %\n",
            "Epoch 00016 | Loss 1.0998 | Time(s) 2.5000 | Accuracy: 58.607065 %\n",
            "Epoch 00017 | Loss 1.1158 | Time(s) 2.5021 | Accuracy: 57.638674 %\n",
            "Epoch 00018 | Loss 1.0134 | Time(s) 2.5040 | Accuracy: 56.972420 %\n",
            "Epoch 00019 | Loss 1.1209 | Time(s) 2.5053 | Accuracy: 58.258444 %\n",
            "Epoch 00020 | Loss 1.1048 | Time(s) 2.5071 | Accuracy: 59.614193 %\n",
            "Epoch 00021 | Loss 1.0625 | Time(s) 2.5103 | Accuracy: 59.343043 %\n",
            "Epoch 00022 | Loss 0.9618 | Time(s) 2.5092 | Accuracy: 57.824605 %\n",
            "Epoch 00023 | Loss 1.0401 | Time(s) 2.5115 | Accuracy: 56.701271 %\n",
            "Epoch 00024 | Loss 0.7989 | Time(s) 2.5129 | Accuracy: 56.933685 %\n",
            "Epoch 00025 | Loss 0.7781 | Time(s) 2.5142 | Accuracy: 58.103502 %\n",
            "Epoch 00026 | Loss 0.9370 | Time(s) 2.5142 | Accuracy: 58.118996 %\n",
            "Epoch 00027 | Loss 0.9098 | Time(s) 2.5152 | Accuracy: 58.413387 %\n",
            "Epoch 00028 | Loss 0.8103 | Time(s) 2.5156 | Accuracy: 58.630307 %\n",
            "Epoch 00029 | Loss 0.7910 | Time(s) 2.5147 | Accuracy: 59.358537 %\n",
            "Epoch 00030 | Loss 0.8297 | Time(s) 2.5124 | Accuracy: 59.327549 %\n",
            "Epoch 00031 | Loss 0.8465 | Time(s) 2.5105 | Accuracy: 59.598698 %\n",
            "Epoch 00032 | Loss 0.8334 | Time(s) 2.5093 | Accuracy: 59.552216 %\n",
            "Epoch 00033 | Loss 0.8341 | Time(s) 2.5087 | Accuracy: 59.436009 %\n",
            "Epoch 00034 | Loss 0.8124 | Time(s) 2.5087 | Accuracy: 58.568330 %\n",
            "Epoch 00035 | Loss 0.7969 | Time(s) 2.5068 | Accuracy: 58.893709 %\n",
            "Epoch 00036 | Loss 0.6480 | Time(s) 2.5072 | Accuracy: 59.358537 %\n",
            "Epoch 00037 | Loss 0.6948 | Time(s) 2.5058 | Accuracy: 59.312055 %\n",
            "Epoch 00038 | Loss 0.7781 | Time(s) 2.5041 | Accuracy: 59.668423 %\n",
            "Epoch 00039 | Loss 1.0176 | Time(s) 2.5032 | Accuracy: 60.388906 %\n",
            "Epoch 00040 | Loss 0.6833 | Time(s) 2.5036 | Accuracy: 60.110009 %\n",
            "Epoch 00041 | Loss 0.7715 | Time(s) 2.5035 | Accuracy: 59.707158 %\n",
            "Epoch 00042 | Loss 0.7404 | Time(s) 2.5032 | Accuracy: 59.590951 %\n",
            "Epoch 00043 | Loss 0.7379 | Time(s) 2.5028 | Accuracy: 59.831112 %\n",
            "Epoch 00044 | Loss 0.7246 | Time(s) 2.5037 | Accuracy: 60.443136 %\n",
            "Epoch 00045 | Loss 0.6295 | Time(s) 2.5054 | Accuracy: 60.551596 %\n",
            "Epoch 00046 | Loss 0.6733 | Time(s) 2.5051 | Accuracy: 60.342423 %\n",
            "Epoch 00047 | Loss 0.6254 | Time(s) 2.5047 | Accuracy: 60.210722 %\n",
            "Epoch 00048 | Loss 0.6099 | Time(s) 2.5052 | Accuracy: 60.427642 %\n",
            "Epoch 00049 | Loss 0.6641 | Time(s) 2.5052 | Accuracy: 60.845987 %\n",
            "Epoch 00050 | Loss 0.6468 | Time(s) 2.5051 | Accuracy: 60.481872 %\n",
            "Epoch 00051 | Loss 0.6083 | Time(s) 2.5041 | Accuracy: 60.009297 %\n",
            "Epoch 00052 | Loss 0.5999 | Time(s) 2.5027 | Accuracy: 60.326929 %\n",
            "Epoch 00053 | Loss 0.9469 | Time(s) 2.5026 | Accuracy: 60.760769 %\n",
            "Epoch 00054 | Loss 0.5654 | Time(s) 2.5014 | Accuracy: 60.567090 %\n",
            "Epoch 00055 | Loss 0.5442 | Time(s) 2.5009 | Accuracy: 60.427642 %\n",
            "Epoch 00056 | Loss 0.6355 | Time(s) 2.5003 | Accuracy: 60.319182 %\n",
            "Epoch 00057 | Loss 0.6160 | Time(s) 2.5006 | Accuracy: 60.396653 %\n",
            "Epoch 00058 | Loss 0.5428 | Time(s) 2.5006 | Accuracy: 60.605826 %\n",
            "Epoch 00059 | Loss 0.5542 | Time(s) 2.5001 | Accuracy: 60.605826 %\n",
            "Epoch 00060 | Loss 0.5516 | Time(s) 2.4988 | Accuracy: 60.404400 %\n",
            "Epoch 00061 | Loss 0.5351 | Time(s) 2.4979 | Accuracy: 60.288193 %\n",
            "Epoch 00062 | Loss 0.5211 | Time(s) 2.4979 | Accuracy: 60.489619 %\n",
            "Epoch 00063 | Loss 0.4948 | Time(s) 2.4970 | Accuracy: 60.652309 %\n",
            "Epoch 00064 | Loss 0.5127 | Time(s) 2.4968 | Accuracy: 60.528355 %\n",
            "Epoch 00065 | Loss 0.6194 | Time(s) 2.4973 | Accuracy: 60.264952 %\n",
            "Epoch 00066 | Loss 0.4958 | Time(s) 2.4970 | Accuracy: 60.280446 %\n",
            "Epoch 00067 | Loss 0.4727 | Time(s) 2.4972 | Accuracy: 60.505113 %\n",
            "Epoch 00068 | Loss 0.8342 | Time(s) 2.4970 | Accuracy: 60.543849 %\n",
            "Epoch 00069 | Loss 0.5712 | Time(s) 2.4976 | Accuracy: 60.272699 %\n",
            "Epoch 00070 | Loss 0.5667 | Time(s) 2.4974 | Accuracy: 59.862101 %\n",
            "Epoch 00071 | Loss 0.4958 | Time(s) 2.4977 | Accuracy: 60.636814 %\n",
            "Epoch 00072 | Loss 0.4545 | Time(s) 2.4976 | Accuracy: 61.016424 %\n",
            "Epoch 00073 | Loss 0.4480 | Time(s) 2.4980 | Accuracy: 60.753021 %\n",
            "Epoch 00074 | Loss 0.5393 | Time(s) 2.4979 | Accuracy: 60.706539 %\n",
            "Epoch 00075 | Loss 0.5364 | Time(s) 2.4973 | Accuracy: 60.652309 %\n",
            "Epoch 00076 | Loss 0.4630 | Time(s) 2.4971 | Accuracy: 60.683297 %\n",
            "Epoch 00077 | Loss 0.4774 | Time(s) 2.4961 | Accuracy: 60.791757 %\n",
            "Epoch 00078 | Loss 0.5207 | Time(s) 2.4971 | Accuracy: 60.776263 %\n",
            "Epoch 00079 | Loss 0.4619 | Time(s) 2.4968 | Accuracy: 60.807251 %\n",
            "Epoch 00080 | Loss 0.4529 | Time(s) 2.4958 | Accuracy: 60.799504 %\n",
            "Epoch 00081 | Loss 0.5170 | Time(s) 2.4960 | Accuracy: 60.605826 %\n",
            "Epoch 00082 | Loss 0.6122 | Time(s) 2.4959 | Accuracy: 60.195228 %\n",
            "Epoch 00083 | Loss 0.5155 | Time(s) 2.4958 | Accuracy: 60.520607 %\n",
            "Epoch 00084 | Loss 0.5765 | Time(s) 2.4955 | Accuracy: 60.590332 %\n",
            "Epoch 00085 | Loss 0.4465 | Time(s) 2.4956 | Accuracy: 60.745274 %\n",
            "Epoch 00086 | Loss 0.4769 | Time(s) 2.4946 | Accuracy: 60.892470 %\n",
            "Epoch 00087 | Loss 0.4325 | Time(s) 2.4943 | Accuracy: 60.241711 %\n",
            "Epoch 00088 | Loss 0.5629 | Time(s) 2.4938 | Accuracy: 60.505113 %\n",
            "Epoch 00089 | Loss 0.4487 | Time(s) 2.4930 | Accuracy: 60.791757 %\n",
            "Epoch 00090 | Loss 0.5466 | Time(s) 2.4926 | Accuracy: 60.814998 %\n",
            "Epoch 00091 | Loss 0.4368 | Time(s) 2.4919 | Accuracy: 60.427642 %\n",
            "Epoch 00092 | Loss 0.4598 | Time(s) 2.4917 | Accuracy: 60.528355 %\n",
            "Epoch 00093 | Loss 0.4233 | Time(s) 2.4916 | Accuracy: 60.536102 %\n",
            "Epoch 00094 | Loss 0.4125 | Time(s) 2.4915 | Accuracy: 60.497366 %\n",
            "Epoch 00095 | Loss 0.4015 | Time(s) 2.4916 | Accuracy: 60.590332 %\n",
            "Epoch 00096 | Loss 0.4427 | Time(s) 2.4914 | Accuracy: 60.869228 %\n",
            "Epoch 00097 | Loss 0.4314 | Time(s) 2.4913 | Accuracy: 60.814998 %\n",
            "Epoch 00098 | Loss 0.5523 | Time(s) 2.4909 | Accuracy: 60.814998 %\n",
            "Epoch 00099 | Loss 0.4450 | Time(s) 2.4911 | Accuracy: 60.574837 %\n",
            "Epoch 00100 | Loss 0.4365 | Time(s) 2.4913 | Accuracy: 60.357918 %\n",
            "Epoch 00101 | Loss 0.3917 | Time(s) 2.4911 | Accuracy: 60.691044 %\n",
            "Epoch 00102 | Loss 0.4226 | Time(s) 2.4916 | Accuracy: 61.117137 %\n",
            "Epoch 00103 | Loss 0.4110 | Time(s) 2.4912 | Accuracy: 61.016424 %\n",
            "Epoch 00104 | Loss 0.4408 | Time(s) 2.4909 | Accuracy: 60.458630 %\n",
            "Epoch 00105 | Loss 0.4388 | Time(s) 2.4902 | Accuracy: 60.226216 %\n",
            "Epoch 00106 | Loss 0.4119 | Time(s) 2.4906 | Accuracy: 60.737527 %\n",
            "Epoch 00107 | Loss 0.4021 | Time(s) 2.4900 | Accuracy: 61.279826 %\n",
            "Epoch 00108 | Loss 0.3904 | Time(s) 2.4904 | Accuracy: 60.799504 %\n",
            "Epoch 00109 | Loss 0.4453 | Time(s) 2.4898 | Accuracy: 60.381159 %\n",
            "Epoch 00110 | Loss 0.3826 | Time(s) 2.4893 | Accuracy: 60.350170 %\n",
            "Epoch 00111 | Loss 0.3920 | Time(s) 2.4888 | Accuracy: 60.427642 %\n",
            "Epoch 00112 | Loss 0.3897 | Time(s) 2.4887 | Accuracy: 60.644562 %\n",
            "Epoch 00113 | Loss 0.3843 | Time(s) 2.4880 | Accuracy: 60.853734 %\n",
            "Epoch 00114 | Loss 0.6818 | Time(s) 2.4879 | Accuracy: 60.985435 %\n",
            "Epoch 00115 | Loss 0.3875 | Time(s) 2.4879 | Accuracy: 60.760769 %\n",
            "Epoch 00116 | Loss 0.3895 | Time(s) 2.4875 | Accuracy: 60.357918 %\n",
            "Epoch 00117 | Loss 0.6044 | Time(s) 2.4877 | Accuracy: 60.660056 %\n",
            "Epoch 00118 | Loss 0.3796 | Time(s) 2.4875 | Accuracy: 60.845987 %\n",
            "Epoch 00119 | Loss 0.6027 | Time(s) 2.4868 | Accuracy: 60.931205 %\n",
            "Epoch 00120 | Loss 0.5890 | Time(s) 2.4863 | Accuracy: 60.760769 %\n",
            "Epoch 00121 | Loss 0.5813 | Time(s) 2.4859 | Accuracy: 60.760769 %\n",
            "Epoch 00122 | Loss 0.3726 | Time(s) 2.4855 | Accuracy: 60.567090 %\n",
            "Epoch 00123 | Loss 0.5006 | Time(s) 2.4856 | Accuracy: 60.605826 %\n",
            "Epoch 00124 | Loss 0.4275 | Time(s) 2.4858 | Accuracy: 60.660056 %\n",
            "Epoch 00125 | Loss 0.4982 | Time(s) 2.4853 | Accuracy: 60.714286 %\n",
            "Epoch 00126 | Loss 0.4982 | Time(s) 2.4851 | Accuracy: 60.543849 %\n",
            "Epoch 00127 | Loss 0.3947 | Time(s) 2.4848 | Accuracy: 60.791757 %\n",
            "Epoch 00128 | Loss 0.4862 | Time(s) 2.4841 | Accuracy: 60.946700 %\n",
            "Epoch 00129 | Loss 0.4835 | Time(s) 2.4841 | Accuracy: 60.776263 %\n",
            "Epoch 00130 | Loss 0.3840 | Time(s) 2.4836 | Accuracy: 60.667803 %\n",
            "Epoch 00131 | Loss 0.3645 | Time(s) 2.4832 | Accuracy: 60.698791 %\n",
            "Epoch 00132 | Loss 0.4922 | Time(s) 2.4828 | Accuracy: 60.907964 %\n",
            "Epoch 00133 | Loss 0.3734 | Time(s) 2.4824 | Accuracy: 61.008677 %\n",
            "Epoch 00134 | Loss 0.3606 | Time(s) 2.4823 | Accuracy: 60.915711 %\n",
            "Epoch 00135 | Loss 0.4921 | Time(s) 2.4819 | Accuracy: 60.861481 %\n",
            "Epoch 00136 | Loss 0.4208 | Time(s) 2.4820 | Accuracy: 60.861481 %\n",
            "Epoch 00137 | Loss 0.4007 | Time(s) 2.4819 | Accuracy: 60.729780 %\n",
            "Epoch 00138 | Loss 0.3959 | Time(s) 2.4818 | Accuracy: 60.520607 %\n",
            "Epoch 00139 | Loss 0.4246 | Time(s) 2.4816 | Accuracy: 60.605826 %\n",
            "Epoch 00140 | Loss 0.3835 | Time(s) 2.4818 | Accuracy: 60.962194 %\n",
            "Epoch 00141 | Loss 0.5656 | Time(s) 2.4816 | Accuracy: 61.024171 %\n",
            "Epoch 00142 | Loss 0.3468 | Time(s) 2.4818 | Accuracy: 60.946700 %\n",
            "Epoch 00143 | Loss 0.4916 | Time(s) 2.4820 | Accuracy: 60.760769 %\n",
            "Epoch 00144 | Loss 0.4761 | Time(s) 2.4817 | Accuracy: 60.876976 %\n",
            "Epoch 00145 | Loss 0.3796 | Time(s) 2.4814 | Accuracy: 60.683297 %\n",
            "Epoch 00146 | Loss 0.4820 | Time(s) 2.4816 | Accuracy: 60.985435 %\n",
            "Epoch 00147 | Loss 0.4773 | Time(s) 2.4817 | Accuracy: 60.807251 %\n",
            "Epoch 00148 | Loss 0.3711 | Time(s) 2.4815 | Accuracy: 60.729780 %\n",
            "Epoch 00149 | Loss 0.3442 | Time(s) 2.4813 | Accuracy: 60.698791 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7220 | Time(s) 2.5391 | Accuracy: 23.086458 %\n",
            "Epoch 00001 | Loss 1.6514 | Time(s) 2.5408 | Accuracy: 27.052990 %\n",
            "Epoch 00002 | Loss 1.6869 | Time(s) 2.5220 | Accuracy: 34.343043 %\n",
            "Epoch 00003 | Loss 1.6752 | Time(s) 2.5138 | Accuracy: 41.439417 %\n",
            "Epoch 00004 | Loss 1.5820 | Time(s) 2.5074 | Accuracy: 43.647350 %\n",
            "Epoch 00005 | Loss 1.5321 | Time(s) 2.4957 | Accuracy: 44.801673 %\n",
            "Epoch 00006 | Loss 1.4934 | Time(s) 2.4863 | Accuracy: 45.158042 %\n",
            "Epoch 00007 | Loss 1.5389 | Time(s) 2.4824 | Accuracy: 46.684227 %\n",
            "Epoch 00008 | Loss 1.5397 | Time(s) 2.4769 | Accuracy: 47.916021 %\n",
            "Epoch 00009 | Loss 1.3881 | Time(s) 2.4741 | Accuracy: 50.302138 %\n",
            "Epoch 00010 | Loss 1.4059 | Time(s) 2.4669 | Accuracy: 53.943291 %\n",
            "Epoch 00011 | Loss 1.2534 | Time(s) 2.4627 | Accuracy: 57.700651 %\n",
            "Epoch 00012 | Loss 1.3205 | Time(s) 2.4632 | Accuracy: 60.760769 %\n",
            "Epoch 00013 | Loss 1.2479 | Time(s) 2.4620 | Accuracy: 61.767896 %\n",
            "Epoch 00014 | Loss 1.2706 | Time(s) 2.4662 | Accuracy: 62.155253 %\n",
            "Epoch 00015 | Loss 1.0665 | Time(s) 2.4674 | Accuracy: 61.272079 %\n",
            "Epoch 00016 | Loss 1.1808 | Time(s) 2.4652 | Accuracy: 61.093895 %\n",
            "Epoch 00017 | Loss 1.1902 | Time(s) 2.4661 | Accuracy: 62.077781 %\n",
            "Epoch 00018 | Loss 1.1721 | Time(s) 2.4670 | Accuracy: 63.092656 %\n",
            "Epoch 00019 | Loss 1.2577 | Time(s) 2.4649 | Accuracy: 63.449024 %\n",
            "Epoch 00020 | Loss 1.0640 | Time(s) 2.4635 | Accuracy: 63.216610 %\n",
            "Epoch 00021 | Loss 1.1096 | Time(s) 2.4638 | Accuracy: 62.658816 %\n",
            "Epoch 00022 | Loss 1.0159 | Time(s) 2.4631 | Accuracy: 62.829253 %\n",
            "Epoch 00023 | Loss 0.9739 | Time(s) 2.4636 | Accuracy: 63.464518 %\n",
            "Epoch 00024 | Loss 0.9602 | Time(s) 2.4634 | Accuracy: 63.875116 %\n",
            "Epoch 00025 | Loss 1.0310 | Time(s) 2.4618 | Accuracy: 63.619461 %\n",
            "Epoch 00026 | Loss 0.9682 | Time(s) 2.4631 | Accuracy: 63.673691 %\n",
            "Epoch 00027 | Loss 0.9881 | Time(s) 2.4618 | Accuracy: 63.820886 %\n",
            "Epoch 00028 | Loss 0.9574 | Time(s) 2.4606 | Accuracy: 64.154013 %\n",
            "Epoch 00029 | Loss 0.8920 | Time(s) 2.4614 | Accuracy: 64.494887 %\n",
            "Epoch 00030 | Loss 0.6890 | Time(s) 2.4607 | Accuracy: 64.572358 %\n",
            "Epoch 00031 | Loss 0.7177 | Time(s) 2.4594 | Accuracy: 64.889991 %\n",
            "Epoch 00032 | Loss 0.7992 | Time(s) 2.4583 | Accuracy: 64.882244 %\n",
            "Epoch 00033 | Loss 0.8572 | Time(s) 2.4576 | Accuracy: 64.828014 %\n",
            "Epoch 00034 | Loss 0.6717 | Time(s) 2.4579 | Accuracy: 64.905485 %\n",
            "Epoch 00035 | Loss 0.7112 | Time(s) 2.4570 | Accuracy: 65.029439 %\n",
            "Epoch 00036 | Loss 0.6938 | Time(s) 2.4566 | Accuracy: 64.673071 %\n",
            "Epoch 00037 | Loss 0.6274 | Time(s) 2.4584 | Accuracy: 64.618841 %\n",
            "Epoch 00038 | Loss 0.6097 | Time(s) 2.4579 | Accuracy: 65.060428 %\n",
            "Epoch 00039 | Loss 0.7648 | Time(s) 2.4602 | Accuracy: 65.006198 %\n",
            "Epoch 00040 | Loss 0.7788 | Time(s) 2.4626 | Accuracy: 64.889991 %\n",
            "Epoch 00041 | Loss 0.8380 | Time(s) 2.4645 | Accuracy: 64.463898 %\n",
            "Epoch 00042 | Loss 0.7512 | Time(s) 2.4654 | Accuracy: 64.572358 %\n",
            "Epoch 00043 | Loss 0.7811 | Time(s) 2.4643 | Accuracy: 64.851255 %\n",
            "Epoch 00044 | Loss 0.6309 | Time(s) 2.4632 | Accuracy: 64.835761 %\n",
            "Epoch 00045 | Loss 0.6606 | Time(s) 2.4620 | Accuracy: 64.409668 %\n",
            "Epoch 00046 | Loss 0.6066 | Time(s) 2.4621 | Accuracy: 65.029439 %\n",
            "Epoch 00047 | Loss 0.7677 | Time(s) 2.4617 | Accuracy: 64.959715 %\n",
            "Epoch 00048 | Loss 0.7597 | Time(s) 2.4611 | Accuracy: 64.812519 %\n",
            "Epoch 00049 | Loss 0.7418 | Time(s) 2.4621 | Accuracy: 64.285714 %\n",
            "Epoch 00050 | Loss 0.6131 | Time(s) 2.4614 | Accuracy: 64.277967 %\n",
            "Epoch 00051 | Loss 0.6872 | Time(s) 2.4611 | Accuracy: 64.835761 %\n",
            "Epoch 00052 | Loss 0.6755 | Time(s) 2.4615 | Accuracy: 65.378060 %\n",
            "Epoch 00053 | Loss 0.5691 | Time(s) 2.4641 | Accuracy: 65.385807 %\n",
            "Epoch 00054 | Loss 0.6103 | Time(s) 2.4634 | Accuracy: 65.401302 %\n",
            "Epoch 00055 | Loss 0.5989 | Time(s) 2.4640 | Accuracy: 65.672451 %\n",
            "Epoch 00056 | Loss 0.5324 | Time(s) 2.4649 | Accuracy: 65.649210 %\n",
            "Epoch 00057 | Loss 0.4685 | Time(s) 2.4656 | Accuracy: 65.610474 %\n",
            "Epoch 00058 | Loss 0.5559 | Time(s) 2.4651 | Accuracy: 65.618221 %\n",
            "Epoch 00059 | Loss 0.5064 | Time(s) 2.4655 | Accuracy: 65.339324 %\n",
            "Epoch 00060 | Loss 0.5586 | Time(s) 2.4660 | Accuracy: 65.300589 %\n",
            "Epoch 00061 | Loss 0.6834 | Time(s) 2.4660 | Accuracy: 65.742175 %\n",
            "Epoch 00062 | Loss 0.4559 | Time(s) 2.4659 | Accuracy: 65.463279 %\n",
            "Epoch 00063 | Loss 0.6264 | Time(s) 2.4664 | Accuracy: 65.300589 %\n",
            "Epoch 00064 | Loss 0.4661 | Time(s) 2.4664 | Accuracy: 65.672451 %\n",
            "Epoch 00065 | Loss 0.6310 | Time(s) 2.4671 | Accuracy: 65.804152 %\n",
            "Epoch 00066 | Loss 0.5876 | Time(s) 2.4673 | Accuracy: 65.393554 %\n",
            "Epoch 00067 | Loss 0.5771 | Time(s) 2.4668 | Accuracy: 65.393554 %\n",
            "Epoch 00068 | Loss 0.5027 | Time(s) 2.4665 | Accuracy: 65.749923 %\n",
            "Epoch 00069 | Loss 0.5599 | Time(s) 2.4665 | Accuracy: 66.090796 %\n",
            "Epoch 00070 | Loss 0.4917 | Time(s) 2.4663 | Accuracy: 65.571738 %\n",
            "Epoch 00071 | Loss 0.5867 | Time(s) 2.4660 | Accuracy: 65.308336 %\n",
            "Epoch 00072 | Loss 0.4123 | Time(s) 2.4656 | Accuracy: 65.664704 %\n",
            "Epoch 00073 | Loss 0.4526 | Time(s) 2.4656 | Accuracy: 65.788658 %\n",
            "Epoch 00074 | Loss 0.4581 | Time(s) 2.4650 | Accuracy: 65.680198 %\n",
            "Epoch 00075 | Loss 0.5095 | Time(s) 2.4644 | Accuracy: 65.579486 %\n",
            "Epoch 00076 | Loss 0.4506 | Time(s) 2.4642 | Accuracy: 65.579486 %\n",
            "Epoch 00077 | Loss 0.5642 | Time(s) 2.4650 | Accuracy: 65.656957 %\n",
            "Epoch 00078 | Loss 0.5464 | Time(s) 2.4646 | Accuracy: 65.734428 %\n",
            "Epoch 00079 | Loss 0.5330 | Time(s) 2.4641 | Accuracy: 65.811900 %\n",
            "Epoch 00080 | Loss 0.4344 | Time(s) 2.4634 | Accuracy: 65.587233 %\n",
            "Epoch 00081 | Loss 0.5124 | Time(s) 2.4636 | Accuracy: 65.664704 %\n",
            "Epoch 00082 | Loss 0.5095 | Time(s) 2.4638 | Accuracy: 65.757670 %\n",
            "Epoch 00083 | Loss 0.3700 | Time(s) 2.4632 | Accuracy: 65.703440 %\n",
            "Epoch 00084 | Loss 0.3669 | Time(s) 2.4627 | Accuracy: 65.192129 %\n",
            "Epoch 00085 | Loss 0.4606 | Time(s) 2.4635 | Accuracy: 65.370313 %\n",
            "Epoch 00086 | Loss 0.4310 | Time(s) 2.4643 | Accuracy: 65.850635 %\n",
            "Epoch 00087 | Loss 0.4405 | Time(s) 2.4643 | Accuracy: 66.090796 %\n",
            "Epoch 00088 | Loss 0.4130 | Time(s) 2.4640 | Accuracy: 65.602727 %\n",
            "Epoch 00089 | Loss 0.4225 | Time(s) 2.4642 | Accuracy: 65.811900 %\n",
            "Epoch 00090 | Loss 0.5007 | Time(s) 2.4644 | Accuracy: 65.858382 %\n",
            "Epoch 00091 | Loss 0.4120 | Time(s) 2.4645 | Accuracy: 65.548497 %\n",
            "Epoch 00092 | Loss 0.4443 | Time(s) 2.4640 | Accuracy: 65.633716 %\n",
            "Epoch 00093 | Loss 0.5445 | Time(s) 2.4639 | Accuracy: 65.749923 %\n",
            "Epoch 00094 | Loss 0.4015 | Time(s) 2.4639 | Accuracy: 65.540750 %\n",
            "Epoch 00095 | Loss 0.3549 | Time(s) 2.4636 | Accuracy: 65.409049 %\n",
            "Epoch 00096 | Loss 0.3479 | Time(s) 2.4639 | Accuracy: 65.749923 %\n",
            "Epoch 00097 | Loss 0.5165 | Time(s) 2.4642 | Accuracy: 65.928107 %\n",
            "Epoch 00098 | Loss 0.4116 | Time(s) 2.4643 | Accuracy: 65.842888 %\n",
            "Epoch 00099 | Loss 0.3448 | Time(s) 2.4642 | Accuracy: 65.625968 %\n",
            "Epoch 00100 | Loss 0.3727 | Time(s) 2.4638 | Accuracy: 65.594980 %\n",
            "Epoch 00101 | Loss 0.4951 | Time(s) 2.4637 | Accuracy: 65.641463 %\n",
            "Epoch 00102 | Loss 0.4688 | Time(s) 2.4636 | Accuracy: 65.703440 %\n",
            "Epoch 00103 | Loss 0.4902 | Time(s) 2.4636 | Accuracy: 65.796405 %\n",
            "Epoch 00104 | Loss 0.3467 | Time(s) 2.4632 | Accuracy: 65.447784 %\n",
            "Epoch 00105 | Loss 0.3951 | Time(s) 2.4631 | Accuracy: 65.347072 %\n",
            "Epoch 00106 | Loss 0.4333 | Time(s) 2.4627 | Accuracy: 65.811900 %\n",
            "Epoch 00107 | Loss 0.3924 | Time(s) 2.4625 | Accuracy: 65.920359 %\n",
            "Epoch 00108 | Loss 0.3969 | Time(s) 2.4621 | Accuracy: 65.703440 %\n",
            "Epoch 00109 | Loss 0.3683 | Time(s) 2.4622 | Accuracy: 65.463279 %\n",
            "Epoch 00110 | Loss 0.4045 | Time(s) 2.4621 | Accuracy: 65.207623 %\n",
            "Epoch 00111 | Loss 0.4785 | Time(s) 2.4619 | Accuracy: 65.486520 %\n",
            "Epoch 00112 | Loss 0.3879 | Time(s) 2.4622 | Accuracy: 65.393554 %\n",
            "Epoch 00113 | Loss 0.3406 | Time(s) 2.4618 | Accuracy: 65.339324 %\n",
            "Epoch 00114 | Loss 0.3783 | Time(s) 2.4617 | Accuracy: 65.680198 %\n",
            "Epoch 00115 | Loss 0.4549 | Time(s) 2.4614 | Accuracy: 65.533003 %\n",
            "Epoch 00116 | Loss 0.4532 | Time(s) 2.4614 | Accuracy: 65.618221 %\n",
            "Epoch 00117 | Loss 0.3349 | Time(s) 2.4609 | Accuracy: 65.695693 %\n",
            "Epoch 00118 | Loss 0.4453 | Time(s) 2.4607 | Accuracy: 65.664704 %\n",
            "Epoch 00119 | Loss 0.3420 | Time(s) 2.4603 | Accuracy: 65.509761 %\n",
            "Epoch 00120 | Loss 0.3379 | Time(s) 2.4602 | Accuracy: 65.587233 %\n",
            "Epoch 00121 | Loss 0.3618 | Time(s) 2.4601 | Accuracy: 65.680198 %\n",
            "Epoch 00122 | Loss 0.4380 | Time(s) 2.4604 | Accuracy: 65.610474 %\n",
            "Epoch 00123 | Loss 0.3924 | Time(s) 2.4601 | Accuracy: 65.556244 %\n",
            "Epoch 00124 | Loss 0.4564 | Time(s) 2.4595 | Accuracy: 65.563991 %\n",
            "Epoch 00125 | Loss 0.3646 | Time(s) 2.4601 | Accuracy: 65.533003 %\n",
            "Epoch 00126 | Loss 0.3575 | Time(s) 2.4605 | Accuracy: 65.509761 %\n",
            "Epoch 00127 | Loss 0.3541 | Time(s) 2.4605 | Accuracy: 65.354819 %\n",
            "Epoch 00128 | Loss 0.3861 | Time(s) 2.4601 | Accuracy: 65.385807 %\n",
            "Epoch 00129 | Loss 0.3634 | Time(s) 2.4604 | Accuracy: 65.347072 %\n",
            "Epoch 00130 | Loss 0.3185 | Time(s) 2.4600 | Accuracy: 65.347072 %\n",
            "Epoch 00131 | Loss 0.4268 | Time(s) 2.4597 | Accuracy: 65.633716 %\n",
            "Epoch 00132 | Loss 0.4652 | Time(s) 2.4595 | Accuracy: 65.726681 %\n",
            "Epoch 00133 | Loss 0.3384 | Time(s) 2.4592 | Accuracy: 65.323830 %\n",
            "Epoch 00134 | Loss 0.3141 | Time(s) 2.4592 | Accuracy: 65.044933 %\n",
            "Epoch 00135 | Loss 0.3654 | Time(s) 2.4594 | Accuracy: 65.362566 %\n",
            "Epoch 00136 | Loss 0.3055 | Time(s) 2.4595 | Accuracy: 65.602727 %\n",
            "Epoch 00137 | Loss 0.3498 | Time(s) 2.4594 | Accuracy: 65.749923 %\n",
            "Epoch 00138 | Loss 0.3195 | Time(s) 2.4591 | Accuracy: 65.703440 %\n",
            "Epoch 00139 | Loss 0.3521 | Time(s) 2.4590 | Accuracy: 65.269600 %\n",
            "Epoch 00140 | Loss 0.3053 | Time(s) 2.4588 | Accuracy: 65.223117 %\n",
            "Epoch 00141 | Loss 0.3049 | Time(s) 2.4584 | Accuracy: 65.215370 %\n",
            "Epoch 00142 | Loss 0.3403 | Time(s) 2.4585 | Accuracy: 65.409049 %\n",
            "Epoch 00143 | Loss 0.3671 | Time(s) 2.4584 | Accuracy: 65.362566 %\n",
            "Epoch 00144 | Loss 0.3612 | Time(s) 2.4586 | Accuracy: 65.401302 %\n",
            "Epoch 00145 | Loss 0.3284 | Time(s) 2.4588 | Accuracy: 65.362566 %\n",
            "Epoch 00146 | Loss 0.3249 | Time(s) 2.4585 | Accuracy: 65.416796 %\n",
            "Epoch 00147 | Loss 0.4052 | Time(s) 2.4585 | Accuracy: 65.409049 %\n",
            "Epoch 00148 | Loss 0.3670 | Time(s) 2.4581 | Accuracy: 65.354819 %\n",
            "Epoch 00149 | Loss 0.3550 | Time(s) 2.4577 | Accuracy: 65.323830 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7463 | Time(s) 2.4324 | Accuracy: 22.025101 %\n",
            "Epoch 00001 | Loss 1.6478 | Time(s) 2.4481 | Accuracy: 43.267741 %\n",
            "Epoch 00002 | Loss 1.6393 | Time(s) 2.4493 | Accuracy: 54.105981 %\n",
            "Epoch 00003 | Loss 1.5740 | Time(s) 2.4443 | Accuracy: 57.894329 %\n",
            "Epoch 00004 | Loss 1.4789 | Time(s) 2.4462 | Accuracy: 61.899597 %\n",
            "Epoch 00005 | Loss 1.3257 | Time(s) 2.4489 | Accuracy: 63.572978 %\n",
            "Epoch 00006 | Loss 1.3367 | Time(s) 2.4418 | Accuracy: 64.192749 %\n",
            "Epoch 00007 | Loss 1.3426 | Time(s) 2.4444 | Accuracy: 66.462659 %\n",
            "Epoch 00008 | Loss 1.3328 | Time(s) 2.4461 | Accuracy: 68.763557 %\n",
            "Epoch 00009 | Loss 1.1412 | Time(s) 2.4517 | Accuracy: 69.592501 %\n",
            "Epoch 00010 | Loss 1.1482 | Time(s) 2.4497 | Accuracy: 70.413697 %\n",
            "Epoch 00011 | Loss 1.2243 | Time(s) 2.4507 | Accuracy: 71.072203 %\n",
            "Epoch 00012 | Loss 0.9982 | Time(s) 2.4479 | Accuracy: 70.700341 %\n",
            "Epoch 00013 | Loss 0.9151 | Time(s) 2.4504 | Accuracy: 71.622250 %\n",
            "Epoch 00014 | Loss 0.9074 | Time(s) 2.4473 | Accuracy: 73.156182 %\n",
            "Epoch 00015 | Loss 1.0780 | Time(s) 2.4468 | Accuracy: 73.799194 %\n",
            "Epoch 00016 | Loss 1.0954 | Time(s) 2.4476 | Accuracy: 73.892160 %\n",
            "Epoch 00017 | Loss 0.8241 | Time(s) 2.4457 | Accuracy: 72.916021 %\n",
            "Epoch 00018 | Loss 0.9162 | Time(s) 2.4463 | Accuracy: 72.296250 %\n",
            "Epoch 00019 | Loss 0.9744 | Time(s) 2.4446 | Accuracy: 73.024481 %\n",
            "Epoch 00020 | Loss 0.8097 | Time(s) 2.4458 | Accuracy: 74.248528 %\n",
            "Epoch 00021 | Loss 0.9001 | Time(s) 2.4460 | Accuracy: 74.775333 %\n",
            "Epoch 00022 | Loss 0.7929 | Time(s) 2.4464 | Accuracy: 74.783080 %\n",
            "Epoch 00023 | Loss 0.7969 | Time(s) 2.4499 | Accuracy: 74.047103 %\n",
            "Epoch 00024 | Loss 0.7242 | Time(s) 2.4521 | Accuracy: 73.404090 %\n",
            "Epoch 00025 | Loss 0.6573 | Time(s) 2.4547 | Accuracy: 74.171057 %\n",
            "Epoch 00026 | Loss 0.5778 | Time(s) 2.4574 | Accuracy: 74.883793 %\n",
            "Epoch 00027 | Loss 0.5349 | Time(s) 2.4593 | Accuracy: 75.116207 %\n",
            "Epoch 00028 | Loss 0.5248 | Time(s) 2.4613 | Accuracy: 74.790827 %\n",
            "Epoch 00029 | Loss 0.6073 | Time(s) 2.4613 | Accuracy: 73.884413 %\n",
            "Epoch 00030 | Loss 0.5501 | Time(s) 2.4622 | Accuracy: 74.085838 %\n",
            "Epoch 00031 | Loss 0.7721 | Time(s) 2.4650 | Accuracy: 74.480942 %\n",
            "Epoch 00032 | Loss 0.6321 | Time(s) 2.4681 | Accuracy: 74.666873 %\n",
            "Epoch 00033 | Loss 0.6723 | Time(s) 2.4690 | Accuracy: 74.845057 %\n",
            "Epoch 00034 | Loss 0.6719 | Time(s) 2.4698 | Accuracy: 75.201425 %\n",
            "Epoch 00035 | Loss 0.5112 | Time(s) 2.4704 | Accuracy: 75.348621 %\n",
            "Epoch 00036 | Loss 0.5908 | Time(s) 2.4712 | Accuracy: 75.418345 %\n",
            "Epoch 00037 | Loss 0.4721 | Time(s) 2.4730 | Accuracy: 74.930276 %\n",
            "Epoch 00038 | Loss 0.5400 | Time(s) 2.4749 | Accuracy: 74.752092 %\n",
            "Epoch 00039 | Loss 0.5940 | Time(s) 2.4774 | Accuracy: 75.309885 %\n",
            "Epoch 00040 | Loss 0.4419 | Time(s) 2.4792 | Accuracy: 75.983886 %\n",
            "Epoch 00041 | Loss 0.3585 | Time(s) 2.4800 | Accuracy: 75.650759 %\n",
            "Epoch 00042 | Loss 0.5332 | Time(s) 2.4813 | Accuracy: 74.984506 %\n",
            "Epoch 00043 | Loss 0.3818 | Time(s) 2.4820 | Accuracy: 74.535172 %\n",
            "Epoch 00044 | Loss 0.4965 | Time(s) 2.4833 | Accuracy: 75.302138 %\n",
            "Epoch 00045 | Loss 0.4728 | Time(s) 2.4845 | Accuracy: 76.363496 %\n",
            "Epoch 00046 | Loss 0.3329 | Time(s) 2.4847 | Accuracy: 76.464208 %\n",
            "Epoch 00047 | Loss 0.3359 | Time(s) 2.4855 | Accuracy: 76.417725 %\n",
            "Epoch 00048 | Loss 0.4090 | Time(s) 2.4854 | Accuracy: 75.751472 %\n",
            "Epoch 00049 | Loss 0.3663 | Time(s) 2.4860 | Accuracy: 75.426092 %\n",
            "Epoch 00050 | Loss 0.4322 | Time(s) 2.4864 | Accuracy: 75.968392 %\n",
            "Epoch 00051 | Loss 0.3318 | Time(s) 2.4871 | Accuracy: 76.177564 %\n",
            "Epoch 00052 | Loss 0.2776 | Time(s) 2.4873 | Accuracy: 75.867679 %\n",
            "Epoch 00053 | Loss 0.3586 | Time(s) 2.4898 | Accuracy: 75.836690 %\n",
            "Epoch 00054 | Loss 0.2653 | Time(s) 2.4905 | Accuracy: 76.053610 %\n",
            "Epoch 00055 | Loss 0.3726 | Time(s) 2.4910 | Accuracy: 76.417725 %\n",
            "Epoch 00056 | Loss 0.2929 | Time(s) 2.4918 | Accuracy: 76.216300 %\n",
            "Epoch 00057 | Loss 0.2143 | Time(s) 2.4926 | Accuracy: 76.185311 %\n",
            "Epoch 00058 | Loss 0.2649 | Time(s) 2.4925 | Accuracy: 75.968392 %\n",
            "Epoch 00059 | Loss 0.2903 | Time(s) 2.4928 | Accuracy: 76.355748 %\n",
            "Epoch 00060 | Loss 0.2846 | Time(s) 2.4933 | Accuracy: 76.681128 %\n",
            "Epoch 00061 | Loss 0.2470 | Time(s) 2.4950 | Accuracy: 76.665634 %\n",
            "Epoch 00062 | Loss 0.3128 | Time(s) 2.4959 | Accuracy: 76.371243 %\n",
            "Epoch 00063 | Loss 0.2328 | Time(s) 2.4959 | Accuracy: 76.030369 %\n",
            "Epoch 00064 | Loss 0.2385 | Time(s) 2.4960 | Accuracy: 75.712736 %\n",
            "Epoch 00065 | Loss 0.2370 | Time(s) 2.4961 | Accuracy: 76.200806 %\n",
            "Epoch 00066 | Loss 0.2316 | Time(s) 2.4961 | Accuracy: 76.611404 %\n",
            "Epoch 00067 | Loss 0.2413 | Time(s) 2.4964 | Accuracy: 76.533932 %\n",
            "Epoch 00068 | Loss 0.3243 | Time(s) 2.4967 | Accuracy: 76.123334 %\n",
            "Epoch 00069 | Loss 0.2031 | Time(s) 2.4967 | Accuracy: 76.278277 %\n",
            "Epoch 00070 | Loss 0.2440 | Time(s) 2.4976 | Accuracy: 76.510691 %\n",
            "Epoch 00071 | Loss 0.1674 | Time(s) 2.4976 | Accuracy: 76.371243 %\n",
            "Epoch 00072 | Loss 0.1567 | Time(s) 2.4985 | Accuracy: 76.464208 %\n",
            "Epoch 00073 | Loss 0.1471 | Time(s) 2.4986 | Accuracy: 76.433220 %\n",
            "Epoch 00074 | Loss 0.2161 | Time(s) 2.4988 | Accuracy: 76.402231 %\n",
            "Epoch 00075 | Loss 0.1702 | Time(s) 2.4995 | Accuracy: 76.611404 %\n",
            "Epoch 00076 | Loss 0.1248 | Time(s) 2.5000 | Accuracy: 76.541680 %\n",
            "Epoch 00077 | Loss 0.2404 | Time(s) 2.5003 | Accuracy: 76.518438 %\n",
            "Epoch 00078 | Loss 0.1939 | Time(s) 2.5007 | Accuracy: 76.564921 %\n",
            "Epoch 00079 | Loss 0.1830 | Time(s) 2.5005 | Accuracy: 76.797335 %\n",
            "Epoch 00080 | Loss 0.1667 | Time(s) 2.5015 | Accuracy: 76.874806 %\n",
            "Epoch 00081 | Loss 0.1200 | Time(s) 2.5017 | Accuracy: 76.595910 %\n",
            "Epoch 00082 | Loss 0.1684 | Time(s) 2.5023 | Accuracy: 76.588162 %\n",
            "Epoch 00083 | Loss 0.1815 | Time(s) 2.5037 | Accuracy: 76.960025 %\n",
            "Epoch 00084 | Loss 0.1684 | Time(s) 2.5051 | Accuracy: 76.805082 %\n",
            "Epoch 00085 | Loss 0.1773 | Time(s) 2.5053 | Accuracy: 76.619151 %\n",
            "Epoch 00086 | Loss 0.1643 | Time(s) 2.5053 | Accuracy: 76.440967 %\n",
            "Epoch 00087 | Loss 0.1832 | Time(s) 2.5053 | Accuracy: 76.619151 %\n",
            "Epoch 00088 | Loss 0.1776 | Time(s) 2.5059 | Accuracy: 76.766346 %\n",
            "Epoch 00089 | Loss 0.1530 | Time(s) 2.5057 | Accuracy: 76.704369 %\n",
            "Epoch 00090 | Loss 0.1630 | Time(s) 2.5058 | Accuracy: 76.487450 %\n",
            "Epoch 00091 | Loss 0.2099 | Time(s) 2.5057 | Accuracy: 76.502944 %\n",
            "Epoch 00092 | Loss 0.2058 | Time(s) 2.5067 | Accuracy: 76.820576 %\n",
            "Epoch 00093 | Loss 0.1236 | Time(s) 2.5072 | Accuracy: 76.805082 %\n",
            "Epoch 00094 | Loss 0.1436 | Time(s) 2.5068 | Accuracy: 76.650139 %\n",
            "Epoch 00095 | Loss 0.1385 | Time(s) 2.5071 | Accuracy: 76.595910 %\n",
            "Epoch 00096 | Loss 0.1338 | Time(s) 2.5070 | Accuracy: 76.603657 %\n",
            "Epoch 00097 | Loss 0.1571 | Time(s) 2.5076 | Accuracy: 76.642392 %\n",
            "Epoch 00098 | Loss 0.1386 | Time(s) 2.5075 | Accuracy: 76.479703 %\n",
            "Epoch 00099 | Loss 0.1436 | Time(s) 2.5074 | Accuracy: 76.657887 %\n",
            "Epoch 00100 | Loss 0.1365 | Time(s) 2.5079 | Accuracy: 76.526185 %\n",
            "Epoch 00101 | Loss 0.1363 | Time(s) 2.5085 | Accuracy: 76.464208 %\n",
            "Epoch 00102 | Loss 0.1213 | Time(s) 2.5087 | Accuracy: 76.572668 %\n",
            "Epoch 00103 | Loss 0.1130 | Time(s) 2.5088 | Accuracy: 76.549427 %\n",
            "Epoch 00104 | Loss 0.1146 | Time(s) 2.5087 | Accuracy: 76.789588 %\n",
            "Epoch 00105 | Loss 0.1440 | Time(s) 2.5091 | Accuracy: 76.828324 %\n",
            "Epoch 00106 | Loss 0.1147 | Time(s) 2.5097 | Accuracy: 76.820576 %\n",
            "Epoch 00107 | Loss 0.1409 | Time(s) 2.5100 | Accuracy: 76.851565 %\n",
            "Epoch 00108 | Loss 0.1567 | Time(s) 2.5103 | Accuracy: 76.688875 %\n",
            "Epoch 00109 | Loss 0.0999 | Time(s) 2.5101 | Accuracy: 76.495197 %\n",
            "Epoch 00110 | Loss 0.1298 | Time(s) 2.5100 | Accuracy: 76.456461 %\n",
            "Epoch 00111 | Loss 0.1019 | Time(s) 2.5096 | Accuracy: 76.433220 %\n",
            "Epoch 00112 | Loss 0.1134 | Time(s) 2.5094 | Accuracy: 76.936783 %\n",
            "Epoch 00113 | Loss 0.1387 | Time(s) 2.5095 | Accuracy: 77.022002 %\n",
            "Epoch 00114 | Loss 0.1176 | Time(s) 2.5096 | Accuracy: 76.626898 %\n",
            "Epoch 00115 | Loss 0.1132 | Time(s) 2.5094 | Accuracy: 76.495197 %\n",
            "Epoch 00116 | Loss 0.1046 | Time(s) 2.5098 | Accuracy: 76.588162 %\n",
            "Epoch 00117 | Loss 0.1010 | Time(s) 2.5098 | Accuracy: 76.719864 %\n",
            "Epoch 00118 | Loss 0.1153 | Time(s) 2.5097 | Accuracy: 76.727611 %\n",
            "Epoch 00119 | Loss 0.0949 | Time(s) 2.5097 | Accuracy: 76.626898 %\n",
            "Epoch 00120 | Loss 0.0918 | Time(s) 2.5097 | Accuracy: 76.603657 %\n",
            "Epoch 00121 | Loss 0.1287 | Time(s) 2.5095 | Accuracy: 76.812829 %\n",
            "Epoch 00122 | Loss 0.1158 | Time(s) 2.5094 | Accuracy: 76.913542 %\n",
            "Epoch 00123 | Loss 0.0958 | Time(s) 2.5090 | Accuracy: 77.006508 %\n",
            "Epoch 00124 | Loss 0.1028 | Time(s) 2.5093 | Accuracy: 76.936783 %\n",
            "Epoch 00125 | Loss 0.1004 | Time(s) 2.5091 | Accuracy: 76.797335 %\n",
            "Epoch 00126 | Loss 0.0823 | Time(s) 2.5091 | Accuracy: 76.805082 %\n",
            "Epoch 00127 | Loss 0.1195 | Time(s) 2.5094 | Accuracy: 76.758599 %\n",
            "Epoch 00128 | Loss 0.1158 | Time(s) 2.5099 | Accuracy: 76.611404 %\n",
            "Epoch 00129 | Loss 0.0808 | Time(s) 2.5101 | Accuracy: 76.541680 %\n",
            "Epoch 00130 | Loss 0.0747 | Time(s) 2.5109 | Accuracy: 76.781841 %\n",
            "Epoch 00131 | Loss 0.0725 | Time(s) 2.5107 | Accuracy: 76.952278 %\n",
            "Epoch 00132 | Loss 0.0751 | Time(s) 2.5111 | Accuracy: 77.122715 %\n",
            "Epoch 00133 | Loss 0.1227 | Time(s) 2.5113 | Accuracy: 76.967772 %\n",
            "Epoch 00134 | Loss 0.1549 | Time(s) 2.5112 | Accuracy: 76.402231 %\n",
            "Epoch 00135 | Loss 0.1168 | Time(s) 2.5111 | Accuracy: 76.425473 %\n",
            "Epoch 00136 | Loss 0.1041 | Time(s) 2.5112 | Accuracy: 76.440967 %\n",
            "Epoch 00137 | Loss 0.1162 | Time(s) 2.5109 | Accuracy: 76.758599 %\n",
            "Epoch 00138 | Loss 0.0744 | Time(s) 2.5108 | Accuracy: 76.936783 %\n",
            "Epoch 00139 | Loss 0.1015 | Time(s) 2.5111 | Accuracy: 76.913542 %\n",
            "Epoch 00140 | Loss 0.1049 | Time(s) 2.5110 | Accuracy: 76.952278 %\n",
            "Epoch 00141 | Loss 0.1252 | Time(s) 2.5108 | Accuracy: 76.890301 %\n",
            "Epoch 00142 | Loss 0.1057 | Time(s) 2.5107 | Accuracy: 76.688875 %\n",
            "Epoch 00143 | Loss 0.0711 | Time(s) 2.5108 | Accuracy: 76.471955 %\n",
            "Epoch 00144 | Loss 0.0518 | Time(s) 2.5113 | Accuracy: 76.929036 %\n",
            "Epoch 00145 | Loss 0.1881 | Time(s) 2.5112 | Accuracy: 77.076232 %\n",
            "Epoch 00146 | Loss 0.0594 | Time(s) 2.5112 | Accuracy: 76.743105 %\n",
            "Epoch 00147 | Loss 0.0656 | Time(s) 2.5116 | Accuracy: 76.518438 %\n",
            "Epoch 00148 | Loss 0.0465 | Time(s) 2.5115 | Accuracy: 76.425473 %\n",
            "Epoch 00149 | Loss 0.0793 | Time(s) 2.5116 | Accuracy: 76.526185 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7659 | Time(s) 2.5049 | Accuracy: 18.988224 %\n",
            "Epoch 00001 | Loss 1.7085 | Time(s) 2.5179 | Accuracy: 25.929656 %\n",
            "Epoch 00002 | Loss 1.6309 | Time(s) 2.5328 | Accuracy: 32.228076 %\n",
            "Epoch 00003 | Loss 1.6519 | Time(s) 2.5369 | Accuracy: 36.171367 %\n",
            "Epoch 00004 | Loss 1.5606 | Time(s) 2.5324 | Accuracy: 38.836381 %\n",
            "Epoch 00005 | Loss 1.4356 | Time(s) 2.5342 | Accuracy: 43.198017 %\n",
            "Epoch 00006 | Loss 1.4400 | Time(s) 2.5379 | Accuracy: 50.743725 %\n",
            "Epoch 00007 | Loss 1.3458 | Time(s) 2.5356 | Accuracy: 58.940192 %\n",
            "Epoch 00008 | Loss 1.3358 | Time(s) 2.5329 | Accuracy: 62.472885 %\n",
            "Epoch 00009 | Loss 1.3547 | Time(s) 2.5343 | Accuracy: 63.758909 %\n",
            "Epoch 00010 | Loss 1.3009 | Time(s) 2.5286 | Accuracy: 65.703440 %\n",
            "Epoch 00011 | Loss 1.1340 | Time(s) 2.5287 | Accuracy: 67.477533 %\n",
            "Epoch 00012 | Loss 1.0974 | Time(s) 2.5294 | Accuracy: 69.840409 %\n",
            "Epoch 00013 | Loss 1.0587 | Time(s) 2.5261 | Accuracy: 71.118686 %\n",
            "Epoch 00014 | Loss 1.1123 | Time(s) 2.5242 | Accuracy: 71.506043 %\n",
            "Epoch 00015 | Loss 1.2048 | Time(s) 2.5280 | Accuracy: 72.342733 %\n",
            "Epoch 00016 | Loss 1.1643 | Time(s) 2.5265 | Accuracy: 72.621630 %\n",
            "Epoch 00017 | Loss 0.9942 | Time(s) 2.5315 | Accuracy: 73.218159 %\n",
            "Epoch 00018 | Loss 0.9762 | Time(s) 2.5287 | Accuracy: 73.961884 %\n",
            "Epoch 00019 | Loss 0.9656 | Time(s) 2.5278 | Accuracy: 73.721723 %\n",
            "Epoch 00020 | Loss 1.0357 | Time(s) 2.5262 | Accuracy: 74.085838 %\n",
            "Epoch 00021 | Loss 0.8392 | Time(s) 2.5272 | Accuracy: 74.713356 %\n",
            "Epoch 00022 | Loss 0.7475 | Time(s) 2.5271 | Accuracy: 74.752092 %\n",
            "Epoch 00023 | Loss 0.8312 | Time(s) 2.5248 | Accuracy: 74.930276 %\n",
            "Epoch 00024 | Loss 0.7883 | Time(s) 2.5243 | Accuracy: 74.922529 %\n",
            "Epoch 00025 | Loss 0.7521 | Time(s) 2.5273 | Accuracy: 74.403471 %\n",
            "Epoch 00026 | Loss 0.8362 | Time(s) 2.5292 | Accuracy: 75.131701 %\n",
            "Epoch 00027 | Loss 1.0040 | Time(s) 2.5304 | Accuracy: 75.054230 %\n",
            "Epoch 00028 | Loss 0.6514 | Time(s) 2.5304 | Accuracy: 75.263403 %\n",
            "Epoch 00029 | Loss 0.5881 | Time(s) 2.5300 | Accuracy: 75.495817 %\n",
            "Epoch 00030 | Loss 0.5362 | Time(s) 2.5302 | Accuracy: 75.689495 %\n",
            "Epoch 00031 | Loss 0.9064 | Time(s) 2.5290 | Accuracy: 75.728231 %\n",
            "Epoch 00032 | Loss 0.5843 | Time(s) 2.5286 | Accuracy: 75.054230 %\n",
            "Epoch 00033 | Loss 0.5559 | Time(s) 2.5265 | Accuracy: 75.340874 %\n",
            "Epoch 00034 | Loss 0.4892 | Time(s) 2.5264 | Accuracy: 75.836690 %\n",
            "Epoch 00035 | Loss 0.5497 | Time(s) 2.5266 | Accuracy: 75.883173 %\n",
            "Epoch 00036 | Loss 0.5822 | Time(s) 2.5255 | Accuracy: 75.619771 %\n",
            "Epoch 00037 | Loss 0.5100 | Time(s) 2.5261 | Accuracy: 74.705609 %\n",
            "Epoch 00038 | Loss 0.6858 | Time(s) 2.5254 | Accuracy: 75.573288 %\n",
            "Epoch 00039 | Loss 0.4477 | Time(s) 2.5252 | Accuracy: 75.976139 %\n",
            "Epoch 00040 | Loss 0.4050 | Time(s) 2.5246 | Accuracy: 76.069104 %\n",
            "Epoch 00041 | Loss 0.4298 | Time(s) 2.5266 | Accuracy: 75.898667 %\n",
            "Epoch 00042 | Loss 0.4357 | Time(s) 2.5264 | Accuracy: 75.898667 %\n",
            "Epoch 00043 | Loss 0.6489 | Time(s) 2.5268 | Accuracy: 76.154323 %\n",
            "Epoch 00044 | Loss 0.3785 | Time(s) 2.5266 | Accuracy: 75.828943 %\n",
            "Epoch 00045 | Loss 0.3636 | Time(s) 2.5263 | Accuracy: 76.022622 %\n",
            "Epoch 00046 | Loss 0.3519 | Time(s) 2.5256 | Accuracy: 76.216300 %\n",
            "Epoch 00047 | Loss 0.3283 | Time(s) 2.5257 | Accuracy: 76.231794 %\n",
            "Epoch 00048 | Loss 0.3176 | Time(s) 2.5257 | Accuracy: 75.952897 %\n",
            "Epoch 00049 | Loss 0.2971 | Time(s) 2.5275 | Accuracy: 75.852185 %\n",
            "Epoch 00050 | Loss 0.2799 | Time(s) 2.5283 | Accuracy: 76.076852 %\n",
            "Epoch 00051 | Loss 0.4593 | Time(s) 2.5279 | Accuracy: 76.076852 %\n",
            "Epoch 00052 | Loss 0.3150 | Time(s) 2.5273 | Accuracy: 75.929656 %\n",
            "Epoch 00053 | Loss 0.2818 | Time(s) 2.5270 | Accuracy: 76.061357 %\n",
            "Epoch 00054 | Loss 0.2434 | Time(s) 2.5279 | Accuracy: 76.084599 %\n",
            "Epoch 00055 | Loss 0.2351 | Time(s) 2.5272 | Accuracy: 76.022622 %\n",
            "Epoch 00056 | Loss 0.2898 | Time(s) 2.5263 | Accuracy: 75.890920 %\n",
            "Epoch 00057 | Loss 0.2752 | Time(s) 2.5258 | Accuracy: 76.076852 %\n",
            "Epoch 00058 | Loss 0.2677 | Time(s) 2.5258 | Accuracy: 76.169817 %\n",
            "Epoch 00059 | Loss 0.2113 | Time(s) 2.5268 | Accuracy: 76.332507 %\n",
            "Epoch 00060 | Loss 0.5538 | Time(s) 2.5263 | Accuracy: 76.774094 %\n",
            "Epoch 00061 | Loss 0.2436 | Time(s) 2.5255 | Accuracy: 76.595910 %\n",
            "Epoch 00062 | Loss 0.2265 | Time(s) 2.5257 | Accuracy: 76.324760 %\n",
            "Epoch 00063 | Loss 0.3197 | Time(s) 2.5251 | Accuracy: 76.084599 %\n",
            "Epoch 00064 | Loss 0.2105 | Time(s) 2.5242 | Accuracy: 76.766346 %\n",
            "Epoch 00065 | Loss 0.4257 | Time(s) 2.5245 | Accuracy: 76.998760 %\n",
            "Epoch 00066 | Loss 0.2063 | Time(s) 2.5246 | Accuracy: 76.270530 %\n",
            "Epoch 00067 | Loss 0.3980 | Time(s) 2.5245 | Accuracy: 76.634645 %\n",
            "Epoch 00068 | Loss 0.2156 | Time(s) 2.5246 | Accuracy: 76.874806 %\n",
            "Epoch 00069 | Loss 0.2071 | Time(s) 2.5242 | Accuracy: 76.820576 %\n",
            "Epoch 00070 | Loss 0.2501 | Time(s) 2.5240 | Accuracy: 76.502944 %\n",
            "Epoch 00071 | Loss 0.2371 | Time(s) 2.5246 | Accuracy: 76.417725 %\n",
            "Epoch 00072 | Loss 0.2948 | Time(s) 2.5247 | Accuracy: 76.510691 %\n",
            "Epoch 00073 | Loss 0.2360 | Time(s) 2.5263 | Accuracy: 76.564921 %\n",
            "Epoch 00074 | Loss 0.2816 | Time(s) 2.5266 | Accuracy: 77.006508 %\n",
            "Epoch 00075 | Loss 0.3599 | Time(s) 2.5279 | Accuracy: 76.890301 %\n",
            "Epoch 00076 | Loss 0.1776 | Time(s) 2.5281 | Accuracy: 76.774094 %\n",
            "Epoch 00077 | Loss 0.1702 | Time(s) 2.5286 | Accuracy: 76.487450 %\n",
            "Epoch 00078 | Loss 0.1745 | Time(s) 2.5283 | Accuracy: 76.642392 %\n",
            "Epoch 00079 | Loss 0.1827 | Time(s) 2.5280 | Accuracy: 77.006508 %\n",
            "Epoch 00080 | Loss 0.2630 | Time(s) 2.5279 | Accuracy: 77.099473 %\n",
            "Epoch 00081 | Loss 0.1798 | Time(s) 2.5276 | Accuracy: 77.052990 %\n",
            "Epoch 00082 | Loss 0.1515 | Time(s) 2.5271 | Accuracy: 76.843818 %\n",
            "Epoch 00083 | Loss 0.1599 | Time(s) 2.5267 | Accuracy: 77.161450 %\n",
            "Epoch 00084 | Loss 0.1518 | Time(s) 2.5266 | Accuracy: 77.169197 %\n",
            "Epoch 00085 | Loss 0.2319 | Time(s) 2.5269 | Accuracy: 77.114967 %\n",
            "Epoch 00086 | Loss 0.3335 | Time(s) 2.5273 | Accuracy: 76.626898 %\n",
            "Epoch 00087 | Loss 0.1431 | Time(s) 2.5266 | Accuracy: 76.921289 %\n",
            "Epoch 00088 | Loss 0.1478 | Time(s) 2.5272 | Accuracy: 77.068485 %\n",
            "Epoch 00089 | Loss 0.1428 | Time(s) 2.5269 | Accuracy: 77.037496 %\n",
            "Epoch 00090 | Loss 0.1882 | Time(s) 2.5263 | Accuracy: 76.797335 %\n",
            "Epoch 00091 | Loss 0.1106 | Time(s) 2.5260 | Accuracy: 77.037496 %\n",
            "Epoch 00092 | Loss 0.1941 | Time(s) 2.5257 | Accuracy: 77.169197 %\n",
            "Epoch 00093 | Loss 0.1382 | Time(s) 2.5250 | Accuracy: 76.820576 %\n",
            "Epoch 00094 | Loss 0.1382 | Time(s) 2.5247 | Accuracy: 76.960025 %\n",
            "Epoch 00095 | Loss 0.1360 | Time(s) 2.5241 | Accuracy: 77.052990 %\n",
            "Epoch 00096 | Loss 0.2092 | Time(s) 2.5240 | Accuracy: 77.200186 %\n",
            "Epoch 00097 | Loss 0.1066 | Time(s) 2.5241 | Accuracy: 76.991013 %\n",
            "Epoch 00098 | Loss 0.2629 | Time(s) 2.5234 | Accuracy: 76.836071 %\n",
            "Epoch 00099 | Loss 0.1001 | Time(s) 2.5232 | Accuracy: 77.138209 %\n",
            "Epoch 00100 | Loss 0.0863 | Time(s) 2.5239 | Accuracy: 77.564301 %\n",
            "Epoch 00101 | Loss 0.1693 | Time(s) 2.5235 | Accuracy: 77.448094 %\n",
            "Epoch 00102 | Loss 0.1251 | Time(s) 2.5236 | Accuracy: 77.060738 %\n",
            "Epoch 00103 | Loss 0.1251 | Time(s) 2.5232 | Accuracy: 76.960025 %\n",
            "Epoch 00104 | Loss 0.0839 | Time(s) 2.5230 | Accuracy: 77.269910 %\n",
            "Epoch 00105 | Loss 0.1740 | Time(s) 2.5229 | Accuracy: 77.502324 %\n",
            "Epoch 00106 | Loss 0.1104 | Time(s) 2.5223 | Accuracy: 77.548807 %\n",
            "Epoch 00107 | Loss 0.2617 | Time(s) 2.5223 | Accuracy: 77.145956 %\n",
            "Epoch 00108 | Loss 0.1259 | Time(s) 2.5218 | Accuracy: 77.254416 %\n",
            "Epoch 00109 | Loss 0.1076 | Time(s) 2.5225 | Accuracy: 77.533313 %\n",
            "Epoch 00110 | Loss 0.1249 | Time(s) 2.5233 | Accuracy: 77.603037 %\n",
            "Epoch 00111 | Loss 0.2245 | Time(s) 2.5231 | Accuracy: 77.262163 %\n",
            "Epoch 00112 | Loss 0.0670 | Time(s) 2.5231 | Accuracy: 77.006508 %\n",
            "Epoch 00113 | Loss 0.1000 | Time(s) 2.5237 | Accuracy: 77.308646 %\n",
            "Epoch 00114 | Loss 0.0768 | Time(s) 2.5241 | Accuracy: 77.231174 %\n",
            "Epoch 00115 | Loss 0.1161 | Time(s) 2.5240 | Accuracy: 77.238922 %\n",
            "Epoch 00116 | Loss 0.1063 | Time(s) 2.5237 | Accuracy: 77.145956 %\n",
            "Epoch 00117 | Loss 0.1128 | Time(s) 2.5238 | Accuracy: 76.898048 %\n",
            "Epoch 00118 | Loss 0.1150 | Time(s) 2.5234 | Accuracy: 77.238922 %\n",
            "Epoch 00119 | Loss 0.1018 | Time(s) 2.5229 | Accuracy: 77.153703 %\n",
            "Epoch 00120 | Loss 0.1029 | Time(s) 2.5228 | Accuracy: 77.200186 %\n",
            "Epoch 00121 | Loss 0.1023 | Time(s) 2.5230 | Accuracy: 77.223427 %\n",
            "Epoch 00122 | Loss 0.1833 | Time(s) 2.5231 | Accuracy: 77.192439 %\n",
            "Epoch 00123 | Loss 0.1502 | Time(s) 2.5232 | Accuracy: 77.052990 %\n",
            "Epoch 00124 | Loss 0.0970 | Time(s) 2.5237 | Accuracy: 76.394484 %\n",
            "Epoch 00125 | Loss 0.0926 | Time(s) 2.5240 | Accuracy: 76.743105 %\n",
            "Epoch 00126 | Loss 0.0940 | Time(s) 2.5238 | Accuracy: 77.215680 %\n",
            "Epoch 00127 | Loss 0.0695 | Time(s) 2.5235 | Accuracy: 77.192439 %\n",
            "Epoch 00128 | Loss 0.1188 | Time(s) 2.5232 | Accuracy: 77.130462 %\n",
            "Epoch 00129 | Loss 0.0827 | Time(s) 2.5227 | Accuracy: 77.138209 %\n",
            "Epoch 00130 | Loss 0.1070 | Time(s) 2.5225 | Accuracy: 76.967772 %\n",
            "Epoch 00131 | Loss 0.0973 | Time(s) 2.5224 | Accuracy: 76.828324 %\n",
            "Epoch 00132 | Loss 0.0860 | Time(s) 2.5219 | Accuracy: 76.874806 %\n",
            "Epoch 00133 | Loss 0.0998 | Time(s) 2.5216 | Accuracy: 76.991013 %\n",
            "Epoch 00134 | Loss 0.1108 | Time(s) 2.5214 | Accuracy: 77.083979 %\n",
            "Epoch 00135 | Loss 0.1226 | Time(s) 2.5209 | Accuracy: 76.983266 %\n",
            "Epoch 00136 | Loss 0.1041 | Time(s) 2.5213 | Accuracy: 76.867059 %\n",
            "Epoch 00137 | Loss 0.0685 | Time(s) 2.5211 | Accuracy: 76.766346 %\n",
            "Epoch 00138 | Loss 0.1020 | Time(s) 2.5208 | Accuracy: 76.774094 %\n",
            "Epoch 00139 | Loss 0.0748 | Time(s) 2.5213 | Accuracy: 76.510691 %\n",
            "Epoch 00140 | Loss 0.0611 | Time(s) 2.5208 | Accuracy: 76.851565 %\n",
            "Epoch 00141 | Loss 0.1102 | Time(s) 2.5203 | Accuracy: 77.083979 %\n",
            "Epoch 00142 | Loss 0.1337 | Time(s) 2.5203 | Accuracy: 77.045243 %\n",
            "Epoch 00143 | Loss 0.1176 | Time(s) 2.5200 | Accuracy: 77.068485 %\n",
            "Epoch 00144 | Loss 0.0953 | Time(s) 2.5201 | Accuracy: 76.890301 %\n",
            "Epoch 00145 | Loss 0.0798 | Time(s) 2.5199 | Accuracy: 77.029749 %\n",
            "Epoch 00146 | Loss 0.1203 | Time(s) 2.5199 | Accuracy: 77.068485 %\n",
            "Epoch 00147 | Loss 0.0563 | Time(s) 2.5200 | Accuracy: 77.076232 %\n",
            "Epoch 00148 | Loss 0.0777 | Time(s) 2.5201 | Accuracy: 76.991013 %\n",
            "Epoch 00149 | Loss 0.0500 | Time(s) 2.5198 | Accuracy: 76.998760 %\n",
            "Results stored.\n",
            "Starting new training\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Epoch 00000 | Loss 1.7834 | Time(s) 2.4988 | Accuracy: 17.748683 %\n",
            "Epoch 00001 | Loss 1.7737 | Time(s) 2.4865 | Accuracy: 18.414936 %\n",
            "Epoch 00002 | Loss 1.7763 | Time(s) 2.4740 | Accuracy: 19.112178 %\n",
            "Epoch 00003 | Loss 1.7265 | Time(s) 2.4764 | Accuracy: 19.941122 %\n",
            "Epoch 00004 | Loss 1.7110 | Time(s) 2.4769 | Accuracy: 23.063217 %\n",
            "Epoch 00005 | Loss 1.6859 | Time(s) 2.4742 | Accuracy: 25.371862 %\n",
            "Epoch 00006 | Loss 1.6967 | Time(s) 2.4754 | Accuracy: 26.378990 %\n",
            "Epoch 00007 | Loss 1.6365 | Time(s) 2.4750 | Accuracy: 27.843198 %\n",
            "Epoch 00008 | Loss 1.6573 | Time(s) 2.4717 | Accuracy: 29.996901 %\n",
            "Epoch 00009 | Loss 1.5413 | Time(s) 2.4749 | Accuracy: 30.577936 %\n",
            "Epoch 00010 | Loss 1.5518 | Time(s) 2.4852 | Accuracy: 30.268051 %\n",
            "Epoch 00011 | Loss 1.5098 | Time(s) 2.4815 | Accuracy: 30.244809 %\n",
            "Epoch 00012 | Loss 1.5326 | Time(s) 2.4812 | Accuracy: 30.608925 %\n",
            "Epoch 00013 | Loss 1.5775 | Time(s) 2.4832 | Accuracy: 31.073753 %\n",
            "Epoch 00014 | Loss 1.4738 | Time(s) 2.4812 | Accuracy: 31.306167 %\n",
            "Epoch 00015 | Loss 1.4154 | Time(s) 2.4818 | Accuracy: 31.189960 %\n",
            "Epoch 00016 | Loss 1.5686 | Time(s) 2.4832 | Accuracy: 31.468857 %\n",
            "Epoch 00017 | Loss 1.4370 | Time(s) 2.4848 | Accuracy: 31.251937 %\n",
            "Epoch 00018 | Loss 1.5205 | Time(s) 2.4861 | Accuracy: 31.244190 %\n",
            "Epoch 00019 | Loss 1.3557 | Time(s) 2.4858 | Accuracy: 31.282925 %\n",
            "Epoch 00020 | Loss 1.4743 | Time(s) 2.4845 | Accuracy: 31.476604 %\n",
            "Epoch 00021 | Loss 1.5097 | Time(s) 2.4846 | Accuracy: 31.585064 %\n",
            "Epoch 00022 | Loss 1.5016 | Time(s) 2.4836 | Accuracy: 31.437868 %\n",
            "Epoch 00023 | Loss 1.3427 | Time(s) 2.4847 | Accuracy: 31.577316 %\n",
            "Epoch 00024 | Loss 1.4621 | Time(s) 2.4850 | Accuracy: 31.647041 %\n",
            "Epoch 00025 | Loss 1.4613 | Time(s) 2.4826 | Accuracy: 31.422374 %\n",
            "Epoch 00026 | Loss 1.3055 | Time(s) 2.4844 | Accuracy: 31.399132 %\n",
            "Epoch 00027 | Loss 1.4456 | Time(s) 2.4839 | Accuracy: 31.213201 %\n",
            "Epoch 00028 | Loss 1.4345 | Time(s) 2.4826 | Accuracy: 31.259684 %\n",
            "Epoch 00029 | Loss 1.2943 | Time(s) 2.4839 | Accuracy: 31.631546 %\n",
            "Epoch 00030 | Loss 1.2874 | Time(s) 2.4857 | Accuracy: 31.685776 %\n",
            "Epoch 00031 | Loss 1.2646 | Time(s) 2.4847 | Accuracy: 31.647041 %\n",
            "Epoch 00032 | Loss 1.2552 | Time(s) 2.4843 | Accuracy: 31.616052 %\n",
            "Epoch 00033 | Loss 1.4456 | Time(s) 2.4847 | Accuracy: 31.670282 %\n",
            "Epoch 00034 | Loss 1.2586 | Time(s) 2.4839 | Accuracy: 31.538581 %\n",
            "Epoch 00035 | Loss 1.2287 | Time(s) 2.4828 | Accuracy: 31.577316 %\n",
            "Epoch 00036 | Loss 1.2485 | Time(s) 2.4833 | Accuracy: 31.592811 %\n",
            "Epoch 00037 | Loss 1.3849 | Time(s) 2.4837 | Accuracy: 31.585064 %\n",
            "Epoch 00038 | Loss 1.2389 | Time(s) 2.4853 | Accuracy: 31.647041 %\n",
            "Epoch 00039 | Loss 1.3975 | Time(s) 2.4853 | Accuracy: 31.623799 %\n",
            "Epoch 00040 | Loss 1.3724 | Time(s) 2.4848 | Accuracy: 31.778742 %\n",
            "Epoch 00041 | Loss 1.2118 | Time(s) 2.4833 | Accuracy: 31.701271 %\n",
            "Epoch 00042 | Loss 1.3646 | Time(s) 2.4841 | Accuracy: 31.848466 %\n",
            "Epoch 00043 | Loss 1.3438 | Time(s) 2.4846 | Accuracy: 31.732259 %\n",
            "Epoch 00044 | Loss 1.1988 | Time(s) 2.4856 | Accuracy: 31.693523 %\n",
            "Epoch 00045 | Loss 1.1650 | Time(s) 2.4858 | Accuracy: 31.546328 %\n",
            "Epoch 00046 | Loss 1.1717 | Time(s) 2.4865 | Accuracy: 31.631546 %\n",
            "Epoch 00047 | Loss 1.2231 | Time(s) 2.4875 | Accuracy: 31.817478 %\n",
            "Epoch 00048 | Loss 1.1833 | Time(s) 2.4880 | Accuracy: 31.941432 %\n",
            "Epoch 00049 | Loss 1.1390 | Time(s) 2.4881 | Accuracy: 32.018903 %\n",
            "Epoch 00050 | Loss 1.2088 | Time(s) 2.4884 | Accuracy: 31.918190 %\n",
            "Epoch 00051 | Loss 1.3506 | Time(s) 2.4878 | Accuracy: 32.111869 %\n",
            "Epoch 00052 | Loss 1.3231 | Time(s) 2.4870 | Accuracy: 32.042144 %\n",
            "Epoch 00053 | Loss 1.3165 | Time(s) 2.4868 | Accuracy: 31.825225 %\n",
            "Epoch 00054 | Loss 1.1864 | Time(s) 2.4870 | Accuracy: 32.127363 %\n",
            "Epoch 00055 | Loss 1.1125 | Time(s) 2.4864 | Accuracy: 31.925937 %\n",
            "Epoch 00056 | Loss 1.1428 | Time(s) 2.4863 | Accuracy: 32.042144 %\n",
            "Epoch 00057 | Loss 1.3729 | Time(s) 2.4862 | Accuracy: 32.057639 %\n",
            "Epoch 00058 | Loss 1.2844 | Time(s) 2.4885 | Accuracy: 32.119616 %\n",
            "Epoch 00059 | Loss 1.2955 | Time(s) 2.4878 | Accuracy: 32.057639 %\n",
            "Epoch 00060 | Loss 1.1365 | Time(s) 2.4880 | Accuracy: 31.716765 %\n",
            "Epoch 00061 | Loss 1.2941 | Time(s) 2.4883 | Accuracy: 31.949179 %\n",
            "Epoch 00062 | Loss 1.2609 | Time(s) 2.4880 | Accuracy: 31.933685 %\n",
            "Epoch 00063 | Loss 1.3599 | Time(s) 2.4875 | Accuracy: 32.073133 %\n",
            "Epoch 00064 | Loss 1.1757 | Time(s) 2.4877 | Accuracy: 32.011156 %\n",
            "Epoch 00065 | Loss 1.2528 | Time(s) 2.4869 | Accuracy: 31.902696 %\n",
            "Epoch 00066 | Loss 1.2850 | Time(s) 2.4877 | Accuracy: 31.949179 %\n",
            "Epoch 00067 | Loss 1.2473 | Time(s) 2.4872 | Accuracy: 31.732259 %\n",
            "Epoch 00068 | Loss 1.3268 | Time(s) 2.4880 | Accuracy: 31.995662 %\n",
            "Epoch 00069 | Loss 1.0792 | Time(s) 2.4872 | Accuracy: 32.011156 %\n",
            "Epoch 00070 | Loss 1.3484 | Time(s) 2.4890 | Accuracy: 32.042144 %\n",
            "Epoch 00071 | Loss 1.3232 | Time(s) 2.4886 | Accuracy: 31.879455 %\n",
            "Epoch 00072 | Loss 1.2851 | Time(s) 2.4889 | Accuracy: 31.662535 %\n",
            "Epoch 00073 | Loss 1.1567 | Time(s) 2.4881 | Accuracy: 31.809730 %\n",
            "Epoch 00074 | Loss 1.2421 | Time(s) 2.4880 | Accuracy: 31.832972 %\n",
            "Epoch 00075 | Loss 1.3284 | Time(s) 2.4883 | Accuracy: 31.980167 %\n",
            "Epoch 00076 | Loss 1.2844 | Time(s) 2.4883 | Accuracy: 32.111869 %\n",
            "Epoch 00077 | Loss 1.2836 | Time(s) 2.4881 | Accuracy: 32.127363 %\n",
            "Epoch 00078 | Loss 1.3234 | Time(s) 2.4880 | Accuracy: 32.189340 %\n",
            "Epoch 00079 | Loss 1.3360 | Time(s) 2.4874 | Accuracy: 32.235823 %\n",
            "Epoch 00080 | Loss 1.3159 | Time(s) 2.4870 | Accuracy: 32.181593 %\n",
            "Epoch 00081 | Loss 1.1521 | Time(s) 2.4869 | Accuracy: 32.088627 %\n",
            "Epoch 00082 | Loss 1.1508 | Time(s) 2.4866 | Accuracy: 31.902696 %\n",
            "Epoch 00083 | Loss 1.3123 | Time(s) 2.4874 | Accuracy: 32.034397 %\n",
            "Epoch 00084 | Loss 1.2243 | Time(s) 2.4877 | Accuracy: 32.452742 %\n",
            "Epoch 00085 | Loss 1.2262 | Time(s) 2.4882 | Accuracy: 32.065386 %\n",
            "Epoch 00086 | Loss 1.0619 | Time(s) 2.4886 | Accuracy: 32.080880 %\n",
            "Epoch 00087 | Loss 1.2235 | Time(s) 2.4881 | Accuracy: 31.902696 %\n",
            "Epoch 00088 | Loss 1.3191 | Time(s) 2.4884 | Accuracy: 32.220328 %\n",
            "Epoch 00089 | Loss 1.3142 | Time(s) 2.4886 | Accuracy: 32.274558 %\n",
            "Epoch 00090 | Loss 1.3225 | Time(s) 2.4879 | Accuracy: 32.204834 %\n",
            "Epoch 00091 | Loss 1.2543 | Time(s) 2.4877 | Accuracy: 32.166099 %\n",
            "Epoch 00092 | Loss 1.3155 | Time(s) 2.4879 | Accuracy: 31.925937 %\n",
            "Epoch 00093 | Loss 1.2279 | Time(s) 2.4877 | Accuracy: 32.119616 %\n",
            "Epoch 00094 | Loss 1.2608 | Time(s) 2.4871 | Accuracy: 32.189340 %\n",
            "Epoch 00095 | Loss 1.0511 | Time(s) 2.4871 | Accuracy: 32.065386 %\n",
            "Epoch 00096 | Loss 1.2217 | Time(s) 2.4866 | Accuracy: 32.018903 %\n",
            "Epoch 00097 | Loss 1.0510 | Time(s) 2.4872 | Accuracy: 31.763248 %\n",
            "Epoch 00098 | Loss 1.2655 | Time(s) 2.4870 | Accuracy: 31.972420 %\n",
            "Epoch 00099 | Loss 1.1046 | Time(s) 2.4863 | Accuracy: 32.158351 %\n",
            "Epoch 00100 | Loss 1.2579 | Time(s) 2.4858 | Accuracy: 32.228076 %\n",
            "Epoch 00101 | Loss 1.3106 | Time(s) 2.4853 | Accuracy: 32.290053 %\n",
            "Epoch 00102 | Loss 1.2165 | Time(s) 2.4848 | Accuracy: 32.204834 %\n",
            "Epoch 00103 | Loss 1.2497 | Time(s) 2.4850 | Accuracy: 32.390765 %\n",
            "Epoch 00104 | Loss 1.3128 | Time(s) 2.4847 | Accuracy: 32.127363 %\n",
            "Epoch 00105 | Loss 1.0472 | Time(s) 2.4846 | Accuracy: 32.228076 %\n",
            "Epoch 00106 | Loss 1.3176 | Time(s) 2.4841 | Accuracy: 32.173846 %\n",
            "Epoch 00107 | Loss 1.1428 | Time(s) 2.4843 | Accuracy: 32.011156 %\n",
            "Epoch 00108 | Loss 1.1414 | Time(s) 2.4842 | Accuracy: 32.018903 %\n",
            "Epoch 00109 | Loss 1.1413 | Time(s) 2.4844 | Accuracy: 32.212581 %\n",
            "Epoch 00110 | Loss 1.2578 | Time(s) 2.4839 | Accuracy: 32.096374 %\n",
            "Epoch 00111 | Loss 1.0440 | Time(s) 2.4843 | Accuracy: 32.228076 %\n",
            "Epoch 00112 | Loss 1.2169 | Time(s) 2.4848 | Accuracy: 32.235823 %\n",
            "Epoch 00113 | Loss 1.3174 | Time(s) 2.4844 | Accuracy: 31.964673 %\n",
            "Epoch 00114 | Loss 1.3164 | Time(s) 2.4842 | Accuracy: 32.290053 %\n",
            "Epoch 00115 | Loss 1.2107 | Time(s) 2.4849 | Accuracy: 32.274558 %\n",
            "Epoch 00116 | Loss 1.1030 | Time(s) 2.4848 | Accuracy: 32.228076 %\n",
            "Epoch 00117 | Loss 1.0410 | Time(s) 2.4853 | Accuracy: 32.282306 %\n",
            "Epoch 00118 | Loss 1.0403 | Time(s) 2.4850 | Accuracy: 32.135110 %\n",
            "Epoch 00119 | Loss 1.1349 | Time(s) 2.4855 | Accuracy: 32.228076 %\n",
            "Epoch 00120 | Loss 1.3100 | Time(s) 2.4858 | Accuracy: 32.173846 %\n",
            "Epoch 00121 | Loss 1.1340 | Time(s) 2.4856 | Accuracy: 32.073133 %\n",
            "Epoch 00122 | Loss 1.3065 | Time(s) 2.4853 | Accuracy: 31.956926 %\n",
            "Epoch 00123 | Loss 1.2651 | Time(s) 2.4858 | Accuracy: 32.135110 %\n",
            "Epoch 00124 | Loss 1.3085 | Time(s) 2.4856 | Accuracy: 32.212581 %\n",
            "Epoch 00125 | Loss 1.0417 | Time(s) 2.4854 | Accuracy: 32.173846 %\n",
            "Epoch 00126 | Loss 1.2991 | Time(s) 2.4852 | Accuracy: 32.220328 %\n",
            "Epoch 00127 | Loss 1.1297 | Time(s) 2.4856 | Accuracy: 32.158351 %\n",
            "Epoch 00128 | Loss 1.2629 | Time(s) 2.4851 | Accuracy: 32.344283 %\n",
            "Epoch 00129 | Loss 1.0948 | Time(s) 2.4851 | Accuracy: 32.150604 %\n",
            "Epoch 00130 | Loss 1.0953 | Time(s) 2.4852 | Accuracy: 32.204834 %\n",
            "Epoch 00131 | Loss 1.0938 | Time(s) 2.4849 | Accuracy: 32.251317 %\n",
            "Epoch 00132 | Loss 1.2090 | Time(s) 2.4849 | Accuracy: 32.150604 %\n",
            "Epoch 00133 | Loss 1.3061 | Time(s) 2.4847 | Accuracy: 32.251317 %\n",
            "Epoch 00134 | Loss 1.2554 | Time(s) 2.4842 | Accuracy: 32.243570 %\n",
            "Epoch 00135 | Loss 1.2089 | Time(s) 2.4843 | Accuracy: 32.228076 %\n",
            "Epoch 00136 | Loss 1.2534 | Time(s) 2.4843 | Accuracy: 32.290053 %\n",
            "Epoch 00137 | Loss 1.0910 | Time(s) 2.4838 | Accuracy: 32.220328 %\n",
            "Epoch 00138 | Loss 1.3055 | Time(s) 2.4838 | Accuracy: 32.359777 %\n",
            "Epoch 00139 | Loss 1.3051 | Time(s) 2.4840 | Accuracy: 32.297800 %\n",
            "Epoch 00140 | Loss 1.1340 | Time(s) 2.4839 | Accuracy: 32.189340 %\n",
            "Epoch 00141 | Loss 1.0910 | Time(s) 2.4843 | Accuracy: 32.297800 %\n",
            "Epoch 00142 | Loss 1.1336 | Time(s) 2.4840 | Accuracy: 32.142857 %\n",
            "Epoch 00143 | Loss 1.0891 | Time(s) 2.4838 | Accuracy: 32.111869 %\n",
            "Epoch 00144 | Loss 1.2533 | Time(s) 2.4846 | Accuracy: 32.251317 %\n",
            "Epoch 00145 | Loss 1.2937 | Time(s) 2.4842 | Accuracy: 32.406260 %\n",
            "Epoch 00146 | Loss 1.2997 | Time(s) 2.4841 | Accuracy: 32.212581 %\n",
            "Epoch 00147 | Loss 1.2921 | Time(s) 2.4838 | Accuracy: 32.197087 %\n",
            "Epoch 00148 | Loss 1.3056 | Time(s) 2.4838 | Accuracy: 32.204834 %\n",
            "Epoch 00149 | Loss 1.2981 | Time(s) 2.4840 | Accuracy: 32.228076 %\n",
            "Results stored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-ipAEZcN5LT",
        "colab_type": "text"
      },
      "source": [
        "#On graphic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUjMKV_LXIu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accPointsCiteSeer = [0]*n_of_epochs\n",
        "lossPointsCiteSeer = [0]*n_of_epochs\n",
        "\n",
        "for d in range(n_of_training_cycles):\n",
        "  for i in range(n_of_epochs):\n",
        "    accPointsCiteSeer[i] = accPointsCiteSeer[i] + averageAccCiteSeer[d][i]\n",
        "    lossPointsCiteSeer[i] = lossPointsCiteSeer[i] + averageLossCiteSeer[d][i]\n",
        "\n",
        "for i in range(n_of_epochs):\n",
        "  accPointsCiteSeer[i] = accPointsCiteSeer[i]/n_of_training_cycles\n",
        "  lossPointsCiteSeer[i] = lossPointsCiteSeer[i]/n_of_training_cycles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Erkh6MqGjl",
        "colab_type": "code",
        "outputId": "87afe4e7-f864-481f-ea6c-dc87cc8dfd24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "maxAccCiteSeer = np.argmax(accPointsCiteSeer)\n",
        "maxAccCiteSeer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1TBb1GlN7rC",
        "colab_type": "code",
        "outputId": "1a5811b3-6c4f-429f-e596-0a962ffc3574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "axisX = range(n_of_epochs)\n",
        "\n",
        "plt.plot(axisX, accPointsCiteSeer, color='orange', label='CiteSeer')\n",
        "#plt.plot(axisX, pointsPubMed, color='blue', label='PubMed')\n",
        "plt.plot([maxAccCiteSeer], accPointsCiteSeer[maxAccCiteSeer], marker='o', color='red')\n",
        "#plt.plot([maxAccPubMed], pointsPubMed[maxAccPubMed], marker='o', color='blue')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAfaUlEQVR4nO3de3Qc5Znn8e+jlizJ8kW2LNvCsiNz\nMwYmtkF2YENCYkJCCCeBk2yAk008CbOezCa7ZieTCyHZkzk72RmymUDYyc0hJOzEGWAIHggTkgFi\nT4bZQJDBNr7jYBtL+CLfJdm6P/vHW7IlW7JallrV1f37nFOnu6qr1U+X1L9+9dZbVebuiIhI8hTE\nXYCIiJwbBbiISEIpwEVEEkoBLiKSUApwEZGEKhzNF5syZYrX1NSM5kuKiCTemjVrDrh75enLRzXA\na2pqqKurG82XFBFJPDPb1d9ydaGIiCSUAlxEJKEU4CIiCaUAFxFJKAW4iEhCKcBFZHhWrICaGigo\nCLcrVsRdUd4Y1WGEIpJjVqyApUvh+PEwv2tXmAf42MfiqytP2GieTra2ttY1DlwSq/MENG2D5h1Q\nUglls6F0Olj0j2zncUiVnJofSHcntB+G9iNQNA5KpoMZuENnE7QdhLYD0LovLBt/AYw7P/xsgBN7\n4MSbMOFSKCyF7o6wrKstPF4289S6Z7yHfmps2g77VgEGxZNh/ByYMAcK0mjfzZoJu+vPXD5zBrwR\nLXcP7+V4PXQdB++GMZMhVRzeR9tBsMKwDdqPQFcrlM2Cspqo1sJQizu07oHjbwIeHqt4G4yZOHid\n/elqg+42SJVBQerMxzqbobURWnaFusfOhPEXwpjysE53FzS/Hn5nnc3Q2RJqLxwHxRUwYW74/YwA\nM1vj7rWnL1cLXLJPxzGofxIKisKHoOwtUDQhfMB7uIcPVU8Qth8+NbUdhLb9IXALy05NqeIQdpYK\noVkwBo5uDB9QPLxe8VQomQJWBN4Bx16DY1vC1LIzrNdbqgRKq6H9UJgKisJ80bjwOqdPrfvCF4B3\nnvoZheNCfe2HQn39MhhbHcKsZUe0qBBKq0IIelff1Uumh6ApmgCF40NdRzfB8TfC/ZLp4barNTz/\ndKkSKH8rTFoQXiNVemrqbAphvP/f+g9vgN0N8PMpYRt3NIfnZEJBMUy/PmzPptfC9ksVh9ctGBMe\nT/W6753QdSLU37IzfJn0/JzCsnC/s+nsv4eKReHLZd+z4W9tIJaCCZeE0C+bDRf+Z5h46Qi+ebXA\nZaS1HwmtlvaD4Y/7RAMceAGObAityPLLobsd2o+GACkcBxPnQvkfwZFXoeEp2P14COfeCopDa7dk\nWmhFtuwMrZ6BFIwJIdTZcma4na64InzYutqh40jfx1KloTU64ZJT07jzQwu5eUcI05Y3QouybCZ0\nNIX5rhPhdb0rhEbP/eIpMO7CEIpjysOX1bGtIUiLK8I0piKsVzIt1ND8h9BKbt4e3vuUq0IL9fDa\n8OVTNjt8yaVKw2u07AzLO46FMOpoCj9/whyYeFlYdmJPWNdSMHkhVF0PqbHQ1hiC/vArcOjl8Bqn\nbxOIAn4efHIL7Dl65uNVk+Cfbg2vkSqB8ReHmgvLAAtfVl2tUHpe+G+mZ/sUlYcAbtkVpu72sLy7\nE+iGkioYOyP8B9F+FBqehIZfQNHE8BqpktCq7m4Pv8/u9l7zbeH9FpaGL7AJl4QvuM6WUxMORePD\nl17R+Oj3WgOFY8Pv9fBa2PNrOL4Lpl0H094dfmeF48JUMCb8nNZ9Yd0j60IrvXkHvOufYdq7zv63\nOICBWuAKcOmruwMa/x2ON4TALBzX9w+8q6XvfM/Uth8O1oXAPl1xRWjNNb8etXYtfHC6O84M6jGT\nYOZH4PxPhg/7sc2htdS6F07sC7eFY8OHqrQqrN97KioPr1c08VS3RHd7qLG7PXxpdHeGf8U7T4Qv\nj55/iSF8yNsPRaFf0LeLJF91d0F3a9heXSfCfxdF5WH7nt4HDjB2LCxfrj7w3twBP+e/JXWh5DN3\nOPgS7Pi/odU6tjqEXGps6PMsqQqttoanYM+voKOfFlW/7FT3xJjJMPVamLwgtBzHRK3JkqkhbHu6\nPzqPh9Z0T59jV3voxjiyPrQQJy/s2x856a3De+9moUWXKu67vHRa/+unisMXg5xSkIKCslNdDL31\nhPTdd8Mbb8CsWfD1ryu8T2cG2KCrDfnHqgWeI1p2weZvhT+UcReGHV9jZ8Le5+D1H4XuiVRp+Ne8\nvz5TCMF73gdgxk3h38vW/aHl2rsf+WR/8thoB9PI/1GKSF9qgSdVdxccqiO0dktDC7arNewYKT0v\ntF53/gy23hta2gWFUV9eL5MXwqIfwFtui7ouuqI95y1RP/We0BKffGXff/Emzh3VtyoiQ6MAz1ad\nJ2D7D2Drt6PRD/1IlYY+SYBZt8KCb4RWd+u+sOOreWfYaThpXt/nFaRCv++Y8rBDaLjdFCISCwV4\nHDpbYNcjYWdhqjh0Xcy6FSZeEvqEG56EV/4idItUXgNv/asQtl0nQtdFQVEYudC0NewcPO/GEMQ9\nSqeHqfLt8b1HEck4Bfho6mqFjX8NW+4NXRjFlYCHUQ+vfi0MTzu+O4zOKP8juG7VwMOOqq4fxcJF\nJBspwEdD884wdnTzN8NY3ln/EeYsgyn/IewEPLEXdv4UGv9feGxyLVTfnN6RcCKSt9JKCDMrBx4A\nLiccivYpYCvwCFAD7AQ+6u6HM1JlknR3hgMg9j0bAvnw2lNjoydcAoufgenv6fuc0ukw9y9A+wxF\nZAjSbeJ9G/iVu3/EzMYAY4EvA8+5+9+Y2ZeALwFfzFCd2cu7Q1C/8Sg0Ph+OYuuOzkkx8TKYthgq\namH6e8M4Zw27E5ERMmiAm9lE4J3AHwO4ezvQbmYfAt4VrfYQsJp8C/A3fw2v/HkI7VQJVL4DLv5s\n6AKZfl04RFhEJEPSaYHPBhqBH5vZPGANsAyY5u57onX2Av0e2mZmS4GlALNmzRp2wVnheAPUfQbq\nn4BxF8BVD8HMW8K5E0RERkk6B+YXAlcA33P3BUALobvkJPeeA/3P5O7L3b3W3WsrKxPeInWHPzwI\n/3xZ2Ck576/hAxvh/E8ovEVk1KXTAq8H6t39xWj+MUKA7zOzKnffY2ZVwP5MFZkVmnfC75fC3mfC\nOT/e9kA4GlJEJCaDtsDdfS+w28zmRIuuAzYBTwJLomVLgCcyUmHcvBu2fQd+eTkc+B0s/C5c9xuF\nt4jELt1RKP8VWBGNQHkd+CQh/B81szuAXcBHM1NijLra4V9vCq3uqveF84mUvSXuqkREgDQD3N3X\nAmecCYvQGs9d6+8O4V37d3DRf9EQQBHJKjrUbyBvPh2OnLzoz+Diz8RdjYjIGfL8UiMD6GiC3y0J\nJ4q64ltxVyMi0i+1wPvz2vfCtQGv/cXAV/cWEYmZWuCn6zwOW/42XOl6ytvirkZEZEAK8NNt/2G4\nlNjlX427EhGRs1KA99bVCpu/EQ7UmfqOuKsRETkr9YH39vpPwgV/r34o7kpERAalFniP7g7Y9DdQ\ncRVMy+3h7SKSG9QC77Hjp+EalLXf1QE7IpIIaoEDdHfBxv8Fk66A894fdzUiImlRCxyg4RfhWpXX\n/KNa3yKSGGqBA2y7H8bOChcSFhFJCAX4kVdh36pwvhNdBV5EEkQBvvV+SJXCBX8SdyUiIkOS3wHe\negB2/hRmfxyKJ8ddjYjIkOR3gG+7Pxx9OWdZ3JWIiAxZWgFuZjvN7FUzW2tmddGyr5lZQ7RsrZnd\nmNlSR1hHE2z9P1B9C0y8NO5qRESGbCh77d7t7gdOW3avu39zJAsaNa99HzqOwGV3xV2JiMg5yc8u\nlK5W2PKtcMh8xcK4qxEROSfpBrgD/2Jma8xsaa/lnzWz9Wb2oJlN6u+JZrbUzOrMrK6xsXHYBY+I\nXY9A61649ItxVyIics7M3QdfyWyGuzeY2VTgGcJV6rcCBwjh/j+BKnf/1Nl+Tm1trdfV1Q2/6uFw\nh18vDBdu+MBGHXkpIlnPzNa4+xkXlk+rBe7uDdHtfmAlsMjd97l7l7t3Az8EFo1kwRlz8EU4tAYu\n/qzCW0QSbdAAN7MyMxvfcx94L7DBzKp6rXYLsCEzJY6wbX8HRRNg9ifirkREZFjSGYUyDVhpobVa\nCPzM3X9lZn9vZvMJXSg7gT/NWJUjpXU/vPEoXPhnUDQu7mpERIZl0AB399eBef0s/3hGKsqkhl+E\nCzdccNauehGRRMivYYRv/hJKZ0D5W+OuRERk2PInwLvaYc8zcN6N2nkpIjkhfwL8wL9DZ1MIcBGR\nHJA/Af7mL6GgCKa/J+5KRERGRH4F+NRrNfpERHJGfgR4yy44ukndJyKSU/IjwPc+G26nvzfeOkRE\nRlB+BPi+VVAyVef9FpGckvsB7g77VsPUd2n4oIjklNwP8KbtcKIBpr077kpEREZU7gf4/tXhVgEu\nIjkm9wN83yoomQ7jL467EhGREZXbAe4eAnzau9X/LSI5J7cDvGlbuHSauk9EJAfldoDv/9dwO/Xa\neOsQEcmAHA/w58P47/EXxV2JiMiIS+eKPJjZTqAJ6AI63b3WzCYDjwA1hCvyfNTdD2emzHPU+DxU\nXqP+bxHJSUNpgb/b3ef3ujLyl4Dn3P0i4LloPnscb4CWHVD5jrgrERHJiOF0oXwIeCi6/xBw8/DL\nGUGNz4fbymvirUNEJEPSDXAH/sXM1pjZ0mjZNHffE93fS7j48RnMbKmZ1ZlZXWNj4zDLHYL9/waF\nZTBp/ui9pojIKEqrDxy4xt0bzGwq8IyZben9oLu7mXl/T3T35cBygNra2n7XyYjG52HK1VCQ7lsU\nEUmWtFrg7t4Q3e4HVgKLgH1mVgUQ3e7PVJFD1n4EjqxX/7eI5LRBA9zMysxsfM994L3ABuBJYEm0\n2hLgiUwVOWQHXgBc/d8iktPS6V+YBqy0MBSvEPiZu//KzF4CHjWzO4BdwEczV+YQHd0QbtX/LSI5\nbNAAd/fXgXn9LD8IXJeJoobt2JZwAE/x5LgrERHJmNw8EvPYFphwSdxViIhklAJcRCShci/AWw9A\n20GYMDfuSkREMir3AvxYNERdLXARyXE5GOCbw60CXERyXA4G+BZIlUDZrLgrERHJqNwM8PFzwHLv\nrYmI9JZ7KacRKCKSJ3IrwLtaoXmHAlxE8kJuBXjTa4DDRA0hFJHcl1sBfrRnBMqceOsQERkFuRXg\nxzYDFnZiiojkuNwK8KMbYdz5UFgadyUiIhmXYwG+CSZeFncVIiKjIncCvLsDmrbBxEvjrkREZFTk\nToA3bQ8hrha4iOSJtAPczFJm9oqZPRXN/8TMdpjZ2miK9/I3RzeFW7XARSRPDOWS7cuAzcCEXss+\n7+6PjWxJ5+joRsB0EI+I5I20WuBmVg18AHggs+UMw9FNMG42FI6NuxIRkVGRbhfKfcAXgO7Tln/d\nzNab2b1mVtzfE81sqZnVmVldY2PjcGo9u6MbYYK6T0Qkfwwa4GZ2E7Df3dec9tBdwCXAQmAy8MX+\nnu/uy9291t1rKysrh1tv/7o7oWkrlGsHpojkj3Ra4G8HPmhmO4GHgcVm9lN33+NBG/BjYFEG6zy7\n5j+EEShqgYtIHhk0wN39Lnevdvca4DbgN+7+n8ysCsDMDLgZ2JDRSs/m6MZwqxEoIpJHhjIK5XQr\nzKwSMGAt8OmRKekc6DqYIpKHhhTg7r4aWB3dX5yBes7Nsa1QOgOKxsVdiYjIqMmNIzGPbdUpZEUk\n7yQ/wN0V4CKSl5If4G0HoOMIjL847kpEREZV8gP82NZwqxa4iOSZ5Ad407Zwqxa4iOSZ5Af4sa1Q\nMAbKauKuRERkVCU/wJu2wvgLoSAVdyUiIqMq+QF+bJu6T0QkLyU7wLs7oXm7dmCKSF5KdoC37Awn\nsRqvABeR/JPsAD8WjUCZoC4UEck/yQ5wDSEUkTyW7AA/Xg+pUiieEnclIiKjLtkBfuJNKD0PzOKu\nRERk1OVGgIuI5KG0A9zMUmb2ipk9Fc3PNrMXzWy7mT1iZmMyV+YAFOAikseG0gJfBmzuNX8PcK+7\nXwgcBu4YycIG5a4AF5G8llaAm1k18AHggWjegMXAY9EqDxGuizl6OpugswXGKsBFJD+l2wK/D/gC\n0B3NVwBH3L0zmq8HZoxwbWd3/M1wqxa4iOSpQQPczG4C9rv7mnN5ATNbamZ1ZlbX2Nh4Lj+ifycU\n4CKS39Jpgb8d+KCZ7QQeJnSdfBsoN7OeiyJXAw39Pdndl7t7rbvXVlZWjkDJEQW4iOS5QQPc3e9y\n92p3rwFuA37j7h8DVgEfiVZbAjyRsSr7owAXkTw3nHHgXwT+3My2E/rEfzQyJaXpxJtQNAGKxo3q\ny4qIZIvCwVc5xd1XA6uj+68Di0a+pDRpCKGI5LnkHol5vEEBLiJ5LbkBrha4iOS5ZAa4jsIUEUlo\ngLcfgu52BbiI5LVkBnjPEEIdRi8ieSyZAa7D6EVEEhrgJw/iGd3Tr4iIZJOEB/j0eOsQEYlRMgO8\n7QAUjodUSdyViIjEJpkB3n4IiifHXYWISKySGeBth2BMRdxViIjEKpkB3n5QLXARyXsJDfBDMEYB\nLiL5LZkB3nYQitWFIiL5LXkB7t1qgYuIkMQA72gKIa4AF5E8l85FjUvM7Pdmts7MNprZX0bLf2Jm\nO8xsbTTNz3y5hB2YoC4UEcl76VyRpw1Y7O7NZlYEPG9mT0ePfd7dH8tcef1VcyjcqgUuInlu0AB3\ndweao9miaPJMFnVWbT0tcAW4iOS3tPrAzSxlZmuB/cAz7v5i9NDXzWy9md1rZsUDPHepmdWZWV1j\nY+PwK27vaYGrC0VE8ltaAe7uXe4+H6gGFpnZ5cBdwCXAQmAy4Sr1/T13ubvXunttZWXl8CvuCXC1\nwEUkzw1pFIq7HwFWATe4+x4P2oAfM1pXqO/pQhkzaVReTkQkW6UzCqXSzMqj+6XA9cAWM6uKlhlw\nM7Ahk4We1H4IiiZAQdGovJyISLZKZxRKFfCQmaUIgf+ouz9lZr8xs0rAgLXApzNY5yltBzUCRUSE\n9EahrAcW9LN8cUYqGoyOwhQRAZJ4JGbbIR3EIyJCEgO8XV0oIiKQyADX1XhERCBpAe7d0H5YB/GI\niJC0AO84GkJcLXARkYQFeJsOoxcR6ZGwANeJrEREeiQrwNt1KlkRkR7JDHCNAxcRSViAnzyRlVrg\nIiLJCvCTXSg6E6GISMIC/AgUjoOCdM7BJSKS25IV4J3NUDQ+7ipERLJC8gK8cFzcVYiIZIVkBXiH\nAlxEpEeyAlwtcBGRk9K5pFqJmf3ezNaZ2UYz+8to+Wwze9HMtpvZI2Y2JuPVKsBFRE5KpwXeBix2\n93nAfOAGM7sKuAe4190vBA4Dd2SuzEhnMxQpwEVEII0Aj6483xzNFkWTA4uBx6LlDxEubJxZaoGL\niJyUVh+4maXMbC2wH3gG+ANwxN07o1XqgRkDPHepmdWZWV1jY+PwqtVOTBGRk9IKcHfvcvf5QDWw\nCLgk3Rdw9+XuXuvutZWVledYJuCuFriISC9DGoXi7keAVcDVQLmZ9RwSWQ00jHBtfXW3g3eqD1xE\nJJLOKJRKMyuP7pcC1wObCUH+kWi1JcATmSoSgM6WcJsqy+jLiIgkRTonFakCHjKzFCHwH3X3p8xs\nE/Cwmf0V8ArwowzWGbpPQC1wEZHIoAHu7uuBBf0sf53QHz46egJcfeAiIkCSjsTsUICLiPSWnABX\nC1xEpI/kBbj6wEVEgCQGuFrgIiKAAlxEJLGSE+DaiSki0kdyAvxkC1wH8oiIQNICPFWiCxqLiESS\nFeDqPhEROSk5Aa5TyYqI9JGcAFcLXESkDwW4iEhCJSvAdRSmiMhJyQpwtcBFRE5KToBrJ6aISB/J\nCXC1wEVE+kjnkmozzWyVmW0ys41mtixa/jUzazCztdF0Y0YrVR+4iEgf6RzW2Al8zt1fNrPxwBoz\neyZ67F53/2bmyot0d0HXCbXARfJUR0cH9fX1tLa2xl1KRpWUlFBdXU1RUVFa66dzSbU9wJ7ofpOZ\nbQZmDKvKoeqKLmisABfJS/X19YwfP56amhrMLO5yMsLdOXjwIPX19cyePTut5wypD9zMagjXx3wx\nWvRZM1tvZg+a2aQBnrPUzOrMrK6xsXEoL3dKpwJcJJ+1trZSUVGRs+ENYGZUVFQM6b+MtAPczMYB\nPwfudPdjwPeAC4D5hBb63/b3PHdf7u617l5bWVmZdmF96FSyInkvl8O7x1DfY1oBbmZFhPBe4e6P\nA7j7Pnfvcvdu4Idk8gr1OpWsiMgZ0hmFYsCPgM3u/q1ey6t6rXYLsGHky4voepgiErO9e/dy2223\nccEFF3DllVdy4403sm3btlhrSmcUytuBjwOvmtnaaNmXgdvNbD7gwE7gTzNSIehyaiISK3fnlltu\nYcmSJTz88MMArFu3jn379nHxxRef9bmdnZ0UFmbmOgbpjEJ5HuivY+aXI1/OABTgItJjzZ1weO3g\n6w3FpPlw5X0DPrxq1SqKior49Kc/fXLZvHnzcHc+//nP8/TTT2NmfOUrX+HWW29l9erVfPWrX2XS\npEls2bKFbdu2cfPNN7N7925aW1tZtmwZS5cuHXbZybi8jXZiikiMNmzYwJVXXnnG8scff5y1a9ey\nbt06Dhw4wMKFC3nnO98JwMsvv8yGDRtODgl88MEHmTx5MidOnGDhwoV8+MMfpqKiYlh1JSPA1QIX\nkR5naSmPtueff57bb7+dVCrFtGnTuPbaa3nppZeYMGECixYt6jOe+/7772flypUA7N69m9dee23Y\nAZ6Mc6FoJ6aIxOiyyy5jzZo1Q3pOWdmpUXOrV6/m2Wef5Xe/+x3r1q1jwYIFI3JUaXIC3FJQUBx3\nJSKShxYvXkxbWxvLly8/uWz9+vWUl5fzyCOP0NXVRWNjI7/97W9ZtOjMEdVHjx5l0qRJjB07li1b\ntvDCCy+MSF3J6ELpOZVsHgzkF5HsY2asXLmSO++8k3vuuYeSkhJqamq47777aG5uZt68eZgZ3/jG\nN5g+fTpbtmzp8/wbbriB73//+8ydO5c5c+Zw1VVXjUxd7j4iPygdtbW1XldXN/Qnbn8ADr4Ab3tg\n5IsSkay3efNm5s6dG3cZo6K/92pma9y99vR1k9ECv/BPwiQiIiclow9cRETOoAAXkUQYze7euAz1\nPSrARSTrlZSUcPDgwZwO8Z7zgZeUlKT9nGT0gYtIXquurqa+vp5zvqZAQvRckSddCnARyXpFRUVp\nX6Umn6gLRUQkoRTgIiIJpQAXEUmoUT0S08wagV3n+PQpwIERLCcTVOPIUI3Dl+31gWocire4+xkX\nFR7VAB8OM6vr71DSbKIaR4ZqHL5srw9U40hQF4qISEIpwEVEEipJAb588FVipxpHhmocvmyvD1Tj\nsCWmD1xERPpKUgtcRER6UYCLiCRUIgLczG4ws61mtt3MvpQF9cw0s1VmtsnMNprZsmj5ZDN7xsxe\ni24nZUGtKTN7xcyeiuZnm9mL0bZ8xMzGxFxfuZk9ZmZbzGyzmV2dbdvRzP579HveYGb/YGYlcW9H\nM3vQzPab2YZey/rdbhbcH9W63syuiLHG/x39rteb2UozK+/12F1RjVvN7H1x1djrsc+ZmZvZlGg+\nlu14Nlkf4GaWAr4DvB+4FLjdzC6Ntyo6gc+5+6XAVcBnopq+BDzn7hcBz0XzcVsGbO41fw9wr7tf\nCBwG7oilqlO+DfzK3S8B5hFqzZrtaGYzgP8G1Lr75UAKuI34t+NPgBtOWzbQdns/cFE0LQW+F2ON\nzwCXu/tbgW3AXQDR5+c24LLoOd+NPvtx1IiZzQTeC7zRa3Fc23Fg7p7VE3A18Ote83cBd8Vd12k1\nPgFcD2wFqqJlVcDWmOuqJnyQFwNPAUY4qqywv20bQ30TgR1EO9N7Lc+a7QjMAHYDkwln73wKeF82\nbEegBtgw2HYDfgDc3t96o13jaY/dAqyI7vf5XAO/Bq6Oq0bgMUKDYicwJe7tONCU9S1wTn2AetRH\ny7KCmdUAC4AXgWnuvid6aC8wLaayetwHfAHojuYrgCPu3hnNx70tZwONwI+jbp4HzKyMLNqO7t4A\nfJPQEtsDHAXWkF3bscdA2y1bP0OfAp6O7mdNjWb2IaDB3ded9lDW1NgjCQGetcxsHPBz4E53P9b7\nMQ9f0bGN0TSzm4D97r4mrhrSUAhcAXzP3RcALZzWXZIF23ES8CHCl815QBn9/MudbeLeboMxs7sJ\nXZEr4q6lNzMbC3wZ+B9x15KOJAR4AzCz13x1tCxWZlZECO8V7v54tHifmVVFj1cB++OqD3g78EEz\n2wk8TOhG+TZQbmY9F/KIe1vWA/Xu/mI0/xgh0LNpO74H2OHuje7eATxO2LbZtB17DLTdsuozZGZ/\nDNwEfCz6ooHsqfECwpf1uuizUw28bGbTyZ4aT0pCgL8EXBTt9R9D2NHxZJwFmZkBPwI2u/u3ej30\nJLAkur+E0DceC3e/y92r3b2GsM1+4+4fA1YBH4lWi7vGvcBuM5sTLboO2EQWbUdC18lVZjY2+r33\n1Jg127GXgbbbk8AnolEUVwFHe3W1jCozu4HQrfdBdz/e66EngdvMrNjMZhN2FP5+tOtz91fdfaq7\n10SfnXrgiuhvNWu240lxdsAPYSfDjYQ91n8A7s6Ceq4h/Hu6HlgbTTcS+pifA14DngUmx11rVO+7\ngKei++cTPhjbgX8EimOubT5QF23LfwImZdt2BP4S2AJsAP4eKI57OwL/QOiT7yCEzB0DbTfCzuvv\nRJ+fVwkjauKqcTuhH7nnc/P9XuvfHdW4FXh/XDWe9vhOTu3EjGU7nm3SofQiIgmVhC4UERHphwJc\nRCShFOAiIgmlABcRSSgFuIhIQinARUQSSgEuIpJQ/x9moAtaIWHECQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5mBRqr82F5e",
        "colab_type": "code",
        "outputId": "a439ae71-d8b3-4e35-fb2e-49b57aa95713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Max accuracy CiteSeer at {:03d} epochs with value {:05f}\"\n",
        "  .format(maxAccCiteSeer, pointsCiteSeer[maxAccCiteSeer]))\n",
        "#print(\"Max accuracy PubMed at {:03d} epochs with value {:05f}\"\n",
        "#  .format(maxAccPubMed, pointsPubMed[maxAccPubMed]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max accuracy Cora at 114 epochs with value 32.290053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdTRUep-4FFJ",
        "colab_type": "code",
        "outputId": "dc7b2a7e-efec-4a3f-9c7a-e9e08230b06e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(axisX, lossPointsCiteSeer, color='orange', label='CiteSeer')\n",
        "#plt.plot(axisX, pointsLossPubMed, color='blue', label='PubMed')\n",
        "plt.plot([maxAccCiteSeer], lossPointsCiteSeer[maxAccCiteSeer], marker='o', color='red')\n",
        "#plt.plot([maxAccPubMed], pointsLossPubMed[maxAccPubMed].item(), marker='o',color='blue')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZE4oYIuIhInVNBFROLE/wOzwAsBSwc/agAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KUKoacJ2t6h",
        "colab_type": "code",
        "outputId": "3026514f-4488-4324-f81f-ff540c3b5673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"For CiteSeer, at epoch {:03d}, loss was {:05f}\"\n",
        "  .format(maxAccCiteSeer, lossPointsCiteSeer[maxAccCiteSeer]))\n",
        "#print(\"For PubMed, at epoch {:03d}, loss was {:05f}\"\n",
        "#  .format(maxAccPubMed, pointsLossPubMed[maxAccPubMed]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Cora, at epoch 114, loss was 0.493107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5EwZ8SD9nSW",
        "colab_type": "text"
      },
      "source": [
        "#Our algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eizH41lSch10",
        "colab_type": "text"
      },
      "source": [
        "For our algorithm we need to store somewhere some information. In particular for each training cycle we will update the historical activation in order to bring an efficent approximation. Also, we need to store the last recent h_0 and h_1, for computational purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMnnSp8_LU8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  NumNodes: 3327\n",
        "#  NumEdges: 9228\n",
        "#  NumFeats: 3703\n",
        "\n",
        "class HMatrices():\n",
        "  def __init__(self):\n",
        "    self.historical_activation_1 = th.Tensor(np.zeros((3327,3703)))\n",
        "    self.historical_activation_2 = th.Tensor(np.zeros((3327,40)))\n",
        "    self.h_0 = th.Tensor([])\n",
        "    self.h_1 = th.Tensor([])\n",
        "\n",
        "  def updateHMatrix(self,features,x):\n",
        "    self.h_0 = features\n",
        "    self.h_1 = x\n",
        "  \n",
        "  def updateActivation(self, row, level, a):\n",
        "    if level == 0:\n",
        "      self.historical_activation_1[row] = a\n",
        "    elif level == 1:\n",
        "      self.historical_activation_2[row] = a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0rSVV_I1S-03",
        "colab": {}
      },
      "source": [
        "class SimpleNodeApplyModule(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, activation):\n",
        "        super(SimpleNodeApplyModule, self).__init__()\n",
        "        self.linear = nn.Linear(in_feats, out_feats)\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, node):\n",
        "        #type of node: dgl.udf.NodeBatch\n",
        "        #type of node.data['h']: torch.Tensor\n",
        "        z = self.linear(node.data['h'])\n",
        "        h = self.activation(z)\n",
        "        return {'h' : h}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fXAYnjwgTCfR",
        "colab": {}
      },
      "source": [
        "class SimpleGCN(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, activation):\n",
        "        super(SimpleGCN, self).__init__()\n",
        "        self.apply_mod = SimpleNodeApplyModule(in_feats, out_feats, activation)\n",
        "\n",
        "    def forward(self, g, feature):\n",
        "        g.ndata['h'] = feature\n",
        "        g.update_all(gcn_msg, gcn_reduce)\n",
        "        g.apply_nodes(func=self.apply_mod)\n",
        "        return g.ndata.pop('h')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oBqQpHvLTHUD",
        "outputId": "5fea2662-fe22-4ef1-9765-7e7d1a1b4de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.gcn1 = SimpleGCN(3703, 40, F.relu)\n",
        "        self.gcn2 = SimpleGCN(40, 6, F.relu)\n",
        "\n",
        "    def forward(self, g, features, propMatrix, historicalActivation, hContainer):\n",
        "        #type of 'g': dgl.graph.DGLGraph\n",
        "        x = self.gcn1(g, features)\n",
        "        hContainer.updateHMatrix(features, x)\n",
        "        # CV = (P'_l*(H_l-H'_l)+P*H'_l)\n",
        "        x = th.mm(propMatrix,x.sub(historicalActivation)).add(th.mm(P,historicalActivation))\n",
        "        x = self.gcn2(g, x)\n",
        "        return x\n",
        "\n",
        "simpleNet = SimpleNet()\n",
        "print(simpleNet)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SimpleNet(\n",
            "  (gcn1): SimpleGCN(\n",
            "    (apply_mod): SimpleNodeApplyModule(\n",
            "      (linear): Linear(in_features=3703, out_features=40, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (gcn2): SimpleGCN(\n",
            "    (apply_mod): SimpleNodeApplyModule(\n",
            "      (linear): Linear(in_features=40, out_features=6, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "omo3JIZQT8Br",
        "outputId": "a4b20adb-49f4-435e-8c18-12be1992e8f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "import collections\n",
        "import numpy as np\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#init counters\n",
        "averageAccCiteSeer_our = []\n",
        "averageLossCiteSeer_our = []\n",
        "\n",
        "for t in range(1):\n",
        "  print(\"Starting new training cycle\")\n",
        "\n",
        "  simpleNet = SimpleNet()\n",
        "  #point to show on graph\n",
        "  pointsOurCiteSeer=dict()\n",
        "  pointsOurLossCiteSeer=dict()\n",
        "\n",
        "  with th.no_grad():\n",
        "    #get data\n",
        "    g, features, labels, mask = load_citeseer_data()\n",
        "\n",
        "    print(g)\n",
        "    n_masks_to_try = 4\n",
        "    ourOptimizer = th.optim.Adam(simpleNet.parameters(), lr=2e-3)\n",
        "    ourOptimizer.state = collections.defaultdict(dict)\n",
        "    dur = []\n",
        "\n",
        "    #running algOne for each mask\n",
        "    t0 = time.time()\n",
        "    print(\"Computing algorithm 1 for each mask...\")\n",
        "    resForMasks = dict()\n",
        "    for m in masks:\n",
        "      resForMasks[m] = algOne(m)\n",
        "    print(\"{:03f} seconds\".format(time.time()-t0))\n",
        "\n",
        "  #this is an object storing some constant data\n",
        "  hs = HMatrices()\n",
        "\n",
        "  for epoch in range(n_of_epochs):\n",
        "        \n",
        "      t0 = time.time()\n",
        "      #getting only some masks (4)\n",
        "      masksToTry = random.sample(masks,n_masks_to_try)\n",
        "      for m in masksToTry:\n",
        "          #calling 'net(...)' it asks to the GCN to compute the forward\n",
        "\n",
        "          #M=(P'_l*(H_l-H'_l)+P*H'_l)\n",
        "          #H_l = feature\n",
        "          #P': progationMatrix\n",
        "          #H': get from initialized matrix\n",
        "          #P: computed before\n",
        "          CV = th.mm(resForMasks[m][1][0],features.sub(hs.historical_activation_1.detach())).add(th.mm(P,hs.historical_activation_1.detach()))\n",
        "          logits = simpleNet(g, CV, resForMasks[m][1][1], hs.historical_activation_2.detach(), hs)\n",
        "          logp = F.log_softmax(logits, 1)\n",
        "\n",
        "          #compute loss like the negative log likelihood loss\n",
        "          ourLoss = F.nll_loss(logp[m], labels[m])\n",
        "\n",
        "          #Since the backward() function accumulates gradients, and you \n",
        "          #don’t want to mix up gradients between minibatch, you have \n",
        "          #to zero them out at the start of a new minibatch. This is \n",
        "          #exactly like how a general (additive) accumulator variable is \n",
        "          #initialized to 0 in code.\n",
        "          ourOptimizer.zero_grad()\n",
        "\n",
        "          #update network weights by loss\n",
        "          #ourLoss.backward(retain_graph=True)\n",
        "          ourLoss.backward()\n",
        "\n",
        "          #update optimizer's values after backward\n",
        "          ourOptimizer.step()\n",
        "\n",
        "          #computing accuracy\n",
        "          i = 0\n",
        "          matched = 0\n",
        "          while i < 3327:\n",
        "            if m[i] == 0:\n",
        "              #getting index of the maximum\n",
        "              j = 0\n",
        "              max = None\n",
        "              jMax = 0\n",
        "              for a in logp[i]:\n",
        "                if max==None:\n",
        "                  max = a.item()\n",
        "                  jMax = j\n",
        "                elif max < a.item():\n",
        "                  max = a.item()\n",
        "                  jMax = j\n",
        "                j = j + 1\n",
        "              if jMax == labels[i]:\n",
        "                matched = matched + 1\n",
        "            i = i + 1\n",
        "          acc = matched/(3327-size_masks)*100\n",
        "\n",
        "          if epoch not in pointsOurCiteSeer:\n",
        "            pointsOurCiteSeer[epoch] = 0\n",
        "            pointsOurLossCiteSeer[epoch] = 0\n",
        "          pointsOurCiteSeer[epoch] = pointsOurCiteSeer[epoch] + acc\n",
        "          pointsOurLossCiteSeer[epoch] = pointsOurLossCiteSeer[epoch] + ourLoss.item()\n",
        "          \n",
        "          #update historical activation\n",
        "          for i in range(2):\n",
        "            recField = resForMasks[m][0][i]\n",
        "            k = 0\n",
        "            if i == 0:\n",
        "              for n in recField:\n",
        "                if n == 1:\n",
        "                  hs.updateActivation(k,i,hs.h_0[k])\n",
        "                k = k + 1\n",
        "            elif i == 1:\n",
        "              for n in recField:\n",
        "                if n == 1:\n",
        "                  hs.updateActivation(k,i,hs.h_1[k])\n",
        "                k = k + 1\n",
        "\n",
        "      dur.append(time.time() - t0)\n",
        "      \n",
        "      pointsOurCiteSeer[epoch] = pointsOurCiteSeer[epoch]/n_masks_to_try\n",
        "      pointsOurLossCiteSeer[epoch] = pointsOurLossCiteSeer[epoch]/n_masks_to_try\n",
        "\n",
        "      print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f} | Accuracy: {:.6f}\".format(\n",
        "              epoch, ourLoss.item(), np.mean(dur), pointsOurCiteSeer[epoch]))\n",
        "  \n",
        "  averageAccCiteSeer_our.append(pointsOurCiteSeer)\n",
        "  averageLossCiteSeer_our.append(pointsOurLossCiteSeer)\n",
        "  print(\"Results stored\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting new training cycle\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "\n",
            "DGLGraph(num_nodes=3327, num_edges=12431,\n",
            "         ndata_schemes={}\n",
            "         edata_schemes={})\n",
            "Computing algorithm 1 for each mask...\n",
            "6.300874 seconds\n",
            "Epoch 00000 | Loss 1.7846 | Time(s) 13.1385 | Accuracy: 9.792377\n",
            "Epoch 00001 | Loss 1.7477 | Time(s) 13.1093 | Accuracy: 23.682987\n",
            "Epoch 00002 | Loss 1.7169 | Time(s) 13.1055 | Accuracy: 33.064766\n",
            "Epoch 00003 | Loss 1.6717 | Time(s) 13.0786 | Accuracy: 38.898358\n",
            "Epoch 00004 | Loss 1.5786 | Time(s) 13.0752 | Accuracy: 41.764797\n",
            "Epoch 00005 | Loss 1.5600 | Time(s) 13.0691 | Accuracy: 43.290982\n",
            "Epoch 00006 | Loss 1.5341 | Time(s) 13.0802 | Accuracy: 43.089557\n",
            "Epoch 00007 | Loss 1.5357 | Time(s) 13.0903 | Accuracy: 43.035327\n",
            "Epoch 00008 | Loss 1.4436 | Time(s) 13.1058 | Accuracy: 43.438178\n",
            "Epoch 00009 | Loss 1.4919 | Time(s) 13.1147 | Accuracy: 44.034707\n",
            "Epoch 00010 | Loss 1.3729 | Time(s) 13.1187 | Accuracy: 45.142547\n",
            "Epoch 00011 | Loss 1.3161 | Time(s) 13.1230 | Accuracy: 46.320112\n",
            "Epoch 00012 | Loss 1.3830 | Time(s) 13.1243 | Accuracy: 48.752711\n",
            "Epoch 00013 | Loss 1.2117 | Time(s) 13.1230 | Accuracy: 51.502944\n",
            "Epoch 00014 | Loss 1.2999 | Time(s) 13.1265 | Accuracy: 53.253796\n",
            "Epoch 00015 | Loss 1.2654 | Time(s) 13.1296 | Accuracy: 54.857453\n",
            "Epoch 00016 | Loss 1.1021 | Time(s) 13.1273 | Accuracy: 56.267431\n",
            "Epoch 00017 | Loss 1.0692 | Time(s) 13.1305 | Accuracy: 56.840719\n",
            "Epoch 00018 | Loss 1.0264 | Time(s) 13.1315 | Accuracy: 57.553455\n",
            "Epoch 00019 | Loss 1.0944 | Time(s) 13.1312 | Accuracy: 57.414007\n",
            "Epoch 00020 | Loss 1.0960 | Time(s) 13.1314 | Accuracy: 56.964673\n",
            "Epoch 00021 | Loss 1.1469 | Time(s) 13.1339 | Accuracy: 56.453362\n",
            "Epoch 00022 | Loss 1.0380 | Time(s) 13.1312 | Accuracy: 56.383638\n",
            "Epoch 00023 | Loss 1.0007 | Time(s) 13.1274 | Accuracy: 57.142857\n",
            "Epoch 00024 | Loss 1.1522 | Time(s) 13.1292 | Accuracy: 56.747753\n",
            "Epoch 00025 | Loss 1.1262 | Time(s) 13.1294 | Accuracy: 56.406879\n",
            "Epoch 00026 | Loss 0.9664 | Time(s) 13.1276 | Accuracy: 56.499845\n",
            "Epoch 00027 | Loss 0.8617 | Time(s) 13.1255 | Accuracy: 56.244190\n",
            "Epoch 00028 | Loss 0.7634 | Time(s) 13.1240 | Accuracy: 55.763867\n",
            "Epoch 00029 | Loss 0.9069 | Time(s) 13.1237 | Accuracy: 56.081500\n",
            "Epoch 00030 | Loss 0.8854 | Time(s) 13.1224 | Accuracy: 56.344902\n",
            "Epoch 00031 | Loss 0.8118 | Time(s) 13.1225 | Accuracy: 56.631546\n",
            "Epoch 00032 | Loss 0.8017 | Time(s) 13.1211 | Accuracy: 56.546328\n",
            "Epoch 00033 | Loss 0.7533 | Time(s) 13.1171 | Accuracy: 56.399132\n",
            "Epoch 00034 | Loss 0.6980 | Time(s) 13.1131 | Accuracy: 56.337155\n",
            "Epoch 00035 | Loss 0.8094 | Time(s) 13.1103 | Accuracy: 56.569569\n",
            "Epoch 00036 | Loss 1.0142 | Time(s) 13.1116 | Accuracy: 56.856213\n",
            "Epoch 00037 | Loss 0.6870 | Time(s) 13.1114 | Accuracy: 56.716765\n",
            "Epoch 00038 | Loss 0.9525 | Time(s) 13.1126 | Accuracy: 56.987914\n",
            "Epoch 00039 | Loss 0.7553 | Time(s) 13.1144 | Accuracy: 57.003409\n",
            "Epoch 00040 | Loss 0.9617 | Time(s) 13.1153 | Accuracy: 56.863960\n",
            "Epoch 00041 | Loss 0.6500 | Time(s) 13.1139 | Accuracy: 56.678029\n",
            "Epoch 00042 | Loss 0.6564 | Time(s) 13.1142 | Accuracy: 56.716765\n",
            "Epoch 00043 | Loss 1.0313 | Time(s) 13.1118 | Accuracy: 56.817478\n",
            "Epoch 00044 | Loss 0.8986 | Time(s) 13.1089 | Accuracy: 56.685776\n",
            "Epoch 00045 | Loss 0.7588 | Time(s) 13.1050 | Accuracy: 56.817478\n",
            "Epoch 00046 | Loss 0.8772 | Time(s) 13.1020 | Accuracy: 56.949179\n",
            "Epoch 00047 | Loss 0.7583 | Time(s) 13.0998 | Accuracy: 56.941432\n",
            "Epoch 00048 | Loss 0.7406 | Time(s) 13.0977 | Accuracy: 56.964673\n",
            "Epoch 00049 | Loss 0.9775 | Time(s) 13.0947 | Accuracy: 56.910443\n",
            "Epoch 00050 | Loss 0.5536 | Time(s) 13.0918 | Accuracy: 56.980167\n",
            "Epoch 00051 | Loss 0.9132 | Time(s) 13.0894 | Accuracy: 57.135110\n",
            "Epoch 00052 | Loss 0.7203 | Time(s) 13.0871 | Accuracy: 57.018903\n",
            "Epoch 00053 | Loss 0.6224 | Time(s) 13.0847 | Accuracy: 56.964673\n",
            "Epoch 00054 | Loss 0.6943 | Time(s) 13.0822 | Accuracy: 57.135110\n",
            "Epoch 00055 | Loss 0.7284 | Time(s) 13.0809 | Accuracy: 57.383018\n",
            "Epoch 00056 | Loss 0.5712 | Time(s) 13.0795 | Accuracy: 57.235823\n",
            "Epoch 00057 | Loss 0.8179 | Time(s) 13.0778 | Accuracy: 57.297800\n",
            "Epoch 00058 | Loss 0.8726 | Time(s) 13.0761 | Accuracy: 57.359777\n",
            "Epoch 00059 | Loss 0.5017 | Time(s) 13.0738 | Accuracy: 57.537961\n",
            "Epoch 00060 | Loss 0.8182 | Time(s) 13.0730 | Accuracy: 57.561202\n",
            "Epoch 00061 | Loss 0.7224 | Time(s) 13.0724 | Accuracy: 57.584444\n",
            "Epoch 00062 | Loss 0.8246 | Time(s) 13.0701 | Accuracy: 57.607685\n",
            "Epoch 00063 | Loss 0.7739 | Time(s) 13.0688 | Accuracy: 57.406260\n",
            "Epoch 00064 | Loss 0.5659 | Time(s) 13.0675 | Accuracy: 57.553455\n",
            "Epoch 00065 | Loss 0.5789 | Time(s) 13.0657 | Accuracy: 57.367524\n",
            "Epoch 00066 | Loss 0.7688 | Time(s) 13.0639 | Accuracy: 57.414007\n",
            "Epoch 00067 | Loss 0.4824 | Time(s) 13.0626 | Accuracy: 57.468237\n",
            "Epoch 00068 | Loss 0.7350 | Time(s) 13.0616 | Accuracy: 57.607685\n",
            "Epoch 00069 | Loss 0.4683 | Time(s) 13.0597 | Accuracy: 57.530214\n",
            "Epoch 00070 | Loss 0.5623 | Time(s) 13.0586 | Accuracy: 57.375271\n",
            "Epoch 00071 | Loss 0.6287 | Time(s) 13.0576 | Accuracy: 57.228076\n",
            "Epoch 00072 | Loss 0.7642 | Time(s) 13.0565 | Accuracy: 57.367524\n",
            "Epoch 00073 | Loss 0.6146 | Time(s) 13.0559 | Accuracy: 57.530214\n",
            "Epoch 00074 | Loss 0.7301 | Time(s) 13.0545 | Accuracy: 57.545708\n",
            "Epoch 00075 | Loss 0.4578 | Time(s) 13.0536 | Accuracy: 57.336535\n",
            "Epoch 00076 | Loss 0.6988 | Time(s) 13.0522 | Accuracy: 57.545708\n",
            "Epoch 00077 | Loss 0.5069 | Time(s) 13.0517 | Accuracy: 57.917570\n",
            "Epoch 00078 | Loss 0.4461 | Time(s) 13.0505 | Accuracy: 57.584444\n",
            "Epoch 00079 | Loss 0.5966 | Time(s) 13.0495 | Accuracy: 57.344283\n",
            "Epoch 00080 | Loss 0.5499 | Time(s) 13.0487 | Accuracy: 57.545708\n",
            "Epoch 00081 | Loss 0.4849 | Time(s) 13.0474 | Accuracy: 57.561202\n",
            "Epoch 00082 | Loss 0.5491 | Time(s) 13.0465 | Accuracy: 57.321041\n",
            "Epoch 00083 | Loss 0.4200 | Time(s) 13.0456 | Accuracy: 57.297800\n",
            "Epoch 00084 | Loss 0.6384 | Time(s) 13.0446 | Accuracy: 57.259064\n",
            "Epoch 00085 | Loss 0.6592 | Time(s) 13.0447 | Accuracy: 57.383018\n",
            "Epoch 00086 | Loss 0.4074 | Time(s) 13.0433 | Accuracy: 57.561202\n",
            "Epoch 00087 | Loss 0.6225 | Time(s) 13.0424 | Accuracy: 57.708398\n",
            "Epoch 00088 | Loss 0.6534 | Time(s) 13.0413 | Accuracy: 57.654168\n",
            "Epoch 00089 | Loss 0.3905 | Time(s) 13.0405 | Accuracy: 57.568949\n",
            "Epoch 00090 | Loss 0.4541 | Time(s) 13.0388 | Accuracy: 57.537961\n",
            "Epoch 00091 | Loss 0.6274 | Time(s) 13.0376 | Accuracy: 57.568949\n",
            "Epoch 00092 | Loss 0.5678 | Time(s) 13.0364 | Accuracy: 57.778122\n",
            "Epoch 00093 | Loss 0.5625 | Time(s) 13.0350 | Accuracy: 57.561202\n",
            "Epoch 00094 | Loss 0.3897 | Time(s) 13.0347 | Accuracy: 57.437248\n",
            "Epoch 00095 | Loss 0.6302 | Time(s) 13.0338 | Accuracy: 57.568949\n",
            "Epoch 00096 | Loss 0.5543 | Time(s) 13.0328 | Accuracy: 57.816858\n",
            "Epoch 00097 | Loss 0.5562 | Time(s) 13.0317 | Accuracy: 57.762628\n",
            "Epoch 00098 | Loss 0.5511 | Time(s) 13.0308 | Accuracy: 57.685156\n",
            "Epoch 00099 | Loss 0.3774 | Time(s) 13.0299 | Accuracy: 57.444995\n",
            "Epoch 00100 | Loss 0.7928 | Time(s) 13.0292 | Accuracy: 58.095755\n",
            "Epoch 00101 | Loss 0.5845 | Time(s) 13.0280 | Accuracy: 57.685156\n",
            "Epoch 00102 | Loss 0.5672 | Time(s) 13.0272 | Accuracy: 57.437248\n",
            "Epoch 00103 | Loss 0.6321 | Time(s) 13.0262 | Accuracy: 57.646421\n",
            "Epoch 00104 | Loss 0.5339 | Time(s) 13.0257 | Accuracy: 57.964053\n",
            "Epoch 00105 | Loss 0.5660 | Time(s) 13.0247 | Accuracy: 57.863341\n",
            "Epoch 00106 | Loss 0.5995 | Time(s) 13.0237 | Accuracy: 57.778122\n",
            "Epoch 00107 | Loss 0.5951 | Time(s) 13.0224 | Accuracy: 57.778122\n",
            "Epoch 00108 | Loss 0.3764 | Time(s) 13.0212 | Accuracy: 58.041525\n",
            "Epoch 00109 | Loss 0.5515 | Time(s) 13.0203 | Accuracy: 58.258444\n",
            "Epoch 00110 | Loss 0.6823 | Time(s) 13.0200 | Accuracy: 58.312674\n",
            "Epoch 00111 | Loss 0.3876 | Time(s) 13.0193 | Accuracy: 58.281686\n",
            "Epoch 00112 | Loss 0.6026 | Time(s) 13.0186 | Accuracy: 58.211962\n",
            "Epoch 00113 | Loss 0.7000 | Time(s) 13.0173 | Accuracy: 58.459870\n",
            "Epoch 00114 | Loss 0.3605 | Time(s) 13.0160 | Accuracy: 58.335916\n",
            "Epoch 00115 | Loss 0.5973 | Time(s) 13.0156 | Accuracy: 58.661295\n",
            "Epoch 00116 | Loss 0.5280 | Time(s) 13.0140 | Accuracy: 58.149985\n",
            "Epoch 00117 | Loss 0.4257 | Time(s) 13.0137 | Accuracy: 57.902076\n",
            "Epoch 00118 | Loss 0.6713 | Time(s) 13.0134 | Accuracy: 58.088007\n",
            "Epoch 00119 | Loss 0.7086 | Time(s) 13.0126 | Accuracy: 57.692904\n",
            "Epoch 00120 | Loss 0.4134 | Time(s) 13.0118 | Accuracy: 57.917570\n",
            "Epoch 00121 | Loss 0.4285 | Time(s) 13.0112 | Accuracy: 58.242950\n",
            "Epoch 00122 | Loss 0.6195 | Time(s) 13.0114 | Accuracy: 58.165479\n",
            "Epoch 00123 | Loss 0.5911 | Time(s) 13.0112 | Accuracy: 58.390146\n",
            "Epoch 00124 | Loss 0.5408 | Time(s) 13.0109 | Accuracy: 58.374651\n",
            "Epoch 00125 | Loss 0.3724 | Time(s) 13.0106 | Accuracy: 58.397893\n",
            "Epoch 00126 | Loss 0.4955 | Time(s) 13.0108 | Accuracy: 58.421134\n",
            "Epoch 00127 | Loss 0.5088 | Time(s) 13.0109 | Accuracy: 58.421134\n",
            "Epoch 00128 | Loss 0.3536 | Time(s) 13.0107 | Accuracy: 58.002789\n",
            "Epoch 00129 | Loss 0.5622 | Time(s) 13.0107 | Accuracy: 58.057019\n",
            "Epoch 00130 | Loss 0.5318 | Time(s) 13.0109 | Accuracy: 57.987295\n",
            "Epoch 00131 | Loss 0.3755 | Time(s) 13.0110 | Accuracy: 57.321041\n",
            "Epoch 00132 | Loss 0.5285 | Time(s) 13.0113 | Accuracy: 58.397893\n",
            "Epoch 00133 | Loss 0.6984 | Time(s) 13.0115 | Accuracy: 58.638054\n",
            "Epoch 00134 | Loss 0.5977 | Time(s) 13.0118 | Accuracy: 58.614813\n",
            "Epoch 00135 | Loss 0.4967 | Time(s) 13.0125 | Accuracy: 58.653548\n",
            "Epoch 00136 | Loss 0.5724 | Time(s) 13.0129 | Accuracy: 58.328169\n",
            "Epoch 00137 | Loss 0.4934 | Time(s) 13.0133 | Accuracy: 58.049272\n",
            "Epoch 00138 | Loss 0.5587 | Time(s) 13.0134 | Accuracy: 58.219709\n",
            "Epoch 00139 | Loss 0.4445 | Time(s) 13.0135 | Accuracy: 58.281686\n",
            "Epoch 00140 | Loss 0.4940 | Time(s) 13.0137 | Accuracy: 58.614813\n",
            "Epoch 00141 | Loss 0.5263 | Time(s) 13.0135 | Accuracy: 58.568330\n",
            "Epoch 00142 | Loss 0.5647 | Time(s) 13.0133 | Accuracy: 58.483111\n",
            "Epoch 00143 | Loss 0.5179 | Time(s) 13.0133 | Accuracy: 58.088007\n",
            "Epoch 00144 | Loss 0.5288 | Time(s) 13.0133 | Accuracy: 58.405640\n",
            "Epoch 00145 | Loss 0.6642 | Time(s) 13.0134 | Accuracy: 58.343663\n",
            "Epoch 00146 | Loss 0.5958 | Time(s) 13.0133 | Accuracy: 58.607065\n",
            "Epoch 00147 | Loss 0.5246 | Time(s) 13.0134 | Accuracy: 58.390146\n",
            "Epoch 00148 | Loss 0.5692 | Time(s) 13.0139 | Accuracy: 57.948559\n",
            "Epoch 00149 | Loss 0.3977 | Time(s) 13.0140 | Accuracy: 58.165479\n",
            "Results stored\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjvSIfKTdIgA",
        "colab_type": "text"
      },
      "source": [
        "#On graphic (our algorithm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HJAqZbH4Makd",
        "colab": {}
      },
      "source": [
        "accPointsCiteSeer_our = [0]*n_of_epochs\n",
        "lossPointsCiteSeer_our = [0]*n_of_epochs\n",
        "\n",
        "for d in range(n_of_training_cycles):\n",
        "  for i in range(n_of_epochs):\n",
        "    accPointsCiteSeer_our[i] = accPointsCiteSeer_our[i] + averageAccCiteSeer_our[d][i]\n",
        "    lossPointsCiteSeer_our[i] = lossPointsCiteSeer_our[i] + averageLossCiteSeer_our[d][i]\n",
        "\n",
        "for i in range(n_of_epochs):\n",
        "  accPointsCiteSeer_our[i] = accPointsCiteSeer_our[i]/n_of_training_cycles\n",
        "  lossPointsCiteSeer_our[i] = lossPointsCiteSeer_our[i]/n_of_training_cycles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wkuOEgTMrDI",
        "colab_type": "code",
        "outputId": "d0f6335f-f083-4e75-816c-5021bd2e0056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "maxAccCiteSeer_our = np.argmax(accPointsCiteSeer_our)\n",
        "maxAccCiteSeer_our"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLpUCy3YdMdo",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of our algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v9sNpqyQboC",
        "colab_type": "code",
        "outputId": "e543e919-457f-4f1d-9da6-e73837c1a63c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "axisX = range(n_of_epochs)\n",
        "\n",
        "plt.plot(axisX, accPointsCiteSeer_our, color='orange', label='CiteSeer')\n",
        "#plt.plot(axisX, pointsPubMed, color='blue', label='PubMed')\n",
        "plt.plot([maxAccCiteSeer_our], accPointsCiteSeer_our[maxAccCiteSeer_our], marker='o', color='red')\n",
        "#plt.plot([maxAccPubMed], pointsPubMed[maxAccPubMed], marker='o', color='blue')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WaxZKGbNQpGw",
        "outputId": "c589889c-339a-4b82-e769-2736b98b62dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Max accuracy CiteSeer at {:03d} epochs with value {:05f}\"\n",
        "  .format(maxAccCiteSeer_our, accPointsCiteSeer_our[maxAccCiteSeer_our]))\n",
        "#print(\"Max accuracy PubMed at {:03d} epochs with value {:05f}\"\n",
        "#  .format(maxAccPubMed, pointsPubMed[maxAccPubMed]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max accuracy Cora at 115 epochs with value 58.661295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdFEyVh0dQow",
        "colab_type": "text"
      },
      "source": [
        "Loss values of our algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wCO9VsNgQ8bC",
        "outputId": "4d4d8d05-bed8-4de8-811b-a25a06d48c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(axisX, lossPointsCiteSeer_our, color='orange', label='CiteSeer')\n",
        "#plt.plot(axisX, pointsLossPubMed, color='blue', label='PubMed')\n",
        "plt.plot([maxAccCiteSeer_our], lossPointsCiteSeer_our[maxAccCiteSeer_our], marker='o', color='red')\n",
        "#plt.plot([maxAccPubMed], pointsLossPubMed[maxAccPubMed].item(), marker='o',color='blue')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nj/j/+ozaGOhDqioAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wi2Qzd5YRGdg",
        "outputId": "8a29b848-bb15-41b8-ce09-0d3a865705a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"For CiteSeer, at epoch {:03d}, loss was {:05f}\"\n",
        "  .format(maxAccCiteSeer_our, lossPointsCiteSeer_our[maxAccCiteSeer_our]))\n",
        "#print(\"For PubMed, at epoch {:03d}, loss was {:05f}\"\n",
        "#  .format(maxAccPubMed, pointsLossPubMed[maxAccPubMed]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Cora, at epoch 115, loss was 0.565999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdOKWGe-SB94",
        "colab_type": "text"
      },
      "source": [
        "#Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jej5As7dUUs",
        "colab_type": "text"
      },
      "source": [
        "Comparison between accuracy of both algorithms. The red dots show the maximum values reached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4jkhpiISEL5",
        "colab_type": "code",
        "outputId": "a1bf2df0-72ad-4ea2-a3d2-22944643bcf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(axisX, accPointsCiteSeer, color='orange', label='CiteSeer')\n",
        "plt.plot(axisX, accPointsCiteSeer_our, color='blue', label='Our CiteSeer')\n",
        "plt.plot([maxAccCiteSeer], accPointsCiteSeer[maxAccCiteSeer], marker='o', color ='red')\n",
        "plt.plot([maxAccCiteSeer_our], accPointsCiteSeer_our[maxAccCiteSeer_our], marker='o', color='red')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX2zNuYpdfHI",
        "colab_type": "text"
      },
      "source": [
        "Comparison between the loss values of both algorithm. The red dots shows the loss values when the accuracy is at its maximum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WAxIo0lSv28",
        "colab_type": "code",
        "outputId": "ee640e9d-445e-466b-d4ae-2f1ff9ad15cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(axisX, lossPointsCiteSeer, color='orange', label='CiteSeer')\n",
        "plt.plot(axisX, lossPointsCiteSeer_our, color='blue', label='Our CiteSeer')\n",
        "plt.plot([maxAccCiteSeer], lossPointsCiteSeer[maxAccCiteSeer], marker='o', color ='red')\n",
        "plt.plot([maxAccCiteSeer_our], lossPointsCiteSeer_our[maxAccCiteSeer_our], marker='o', color='red')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nShUSmtCVUqqQ+H/aL0oPCnY0PAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}